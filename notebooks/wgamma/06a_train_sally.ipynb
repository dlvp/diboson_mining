{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f9deb73c-b62f-4cff-8d83-724074098c92"
    }
   },
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Marco Farina, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "fe57a76c-4838-44c4-b0cc-5ee166785e4a"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)-5.5s %(name)-20.20s %(levelname)-7.7s %(message)s',\n",
    "    datefmt='%H:%M',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "for key in logging.Logger.manager.loggerDict:\n",
    "    if \"madminer\" not in key:\n",
    "        logging.getLogger(key).setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f3463c40-6421-42a1-8681-527c3ec42541"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "b2c73eca-c625-4f7a-9cee-4ccb2dcbb3e9"
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma_sys/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma_sys/'\n",
    "log_dir = base_dir + 'logs/wgamma_sys/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma_sys/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(filename, use_tight_cuts=True, use_antitight_cuts=False, n_estimators=n_estimators, **kwargs):\n",
    "    cut_label = '_tight' if use_tight_cuts else '_antitight' if use_antitight_cuts else ''\n",
    "    \n",
    "    ensemble = EnsembleForge(n_estimators)\n",
    "\n",
    "    ensemble.train_all(\n",
    "        method='sally',\n",
    "        x_filename=[sample_dir + 'train_local{}/x_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        t_xz0_filename=[sample_dir + 'train_local{}/t_xz_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    ensemble.save(model_dir + 'sally_ensemble_' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45e7f73-8f4c-4261-a381-4b7ad6af120f"
    }
   },
   "source": [
    "## All observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:14 madminer.ml          INFO    Training 10 estimators in ensemble\n",
      "14:14 madminer.ml          INFO    Training estimator 1 / 10 in ensemble\n",
      "14:14 madminer.ml          INFO    Starting training\n",
      "14:14 madminer.ml          INFO      Method:                 sally\n",
      "14:14 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_0.npy\n",
      "14:14 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_0.npy\n",
      "14:14 madminer.ml          INFO      Features:               all\n",
      "14:14 madminer.ml          INFO      Method:                 sally\n",
      "14:14 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "14:14 madminer.ml          INFO      Activation function:    tanh\n",
      "14:14 madminer.ml          INFO      Batch size:             128\n",
      "14:14 madminer.ml          INFO      Trainer:                amsgrad\n",
      "14:14 madminer.ml          INFO      Epochs:                 50\n",
      "14:14 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "14:14 madminer.ml          INFO      Validation split:       0.5\n",
      "14:14 madminer.ml          INFO      Early stopping:         True\n",
      "14:14 madminer.ml          INFO      Scale inputs:           True\n",
      "14:14 madminer.ml          INFO      Shuffle labels          False\n",
      "14:14 madminer.ml          INFO      Regularization:         None\n",
      "14:14 madminer.ml          INFO      Samples:                all\n",
      "14:14 madminer.ml          INFO    Loading training data\n",
      "14:14 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "14:14 madminer.ml          INFO    Rescaling inputs\n",
      "14:14 madminer.ml          INFO    Creating model for method sally\n",
      "14:14 madminer.ml          INFO    Training model\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all',\n",
    "    use_tight_cuts=False,\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'all_tight',\n",
    "    use_tight_cuts=True,\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:58 madminer.ml          INFO    Training 10 estimators in ensemble\n",
      "17:58 madminer.ml          INFO    Training estimator 1 / 10 in ensemble\n",
      "17:58 madminer.ml          INFO    Starting training\n",
      "17:58 madminer.ml          INFO      Method:                 sally\n",
      "17:58 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_0.npy\n",
      "17:58 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_0.npy\n",
      "17:58 madminer.ml          INFO      Features:               all\n",
      "17:58 madminer.ml          INFO      Method:                 sally\n",
      "17:58 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "17:58 madminer.ml          INFO      Activation function:    tanh\n",
      "17:58 madminer.ml          INFO      Batch size:             128\n",
      "17:58 madminer.ml          INFO      Trainer:                amsgrad\n",
      "17:58 madminer.ml          INFO      Epochs:                 50\n",
      "17:58 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:58 madminer.ml          INFO      Validation split:       0.5\n",
      "17:58 madminer.ml          INFO      Early stopping:         True\n",
      "17:58 madminer.ml          INFO      Scale inputs:           True\n",
      "17:58 madminer.ml          INFO      Shuffle labels          False\n",
      "17:58 madminer.ml          INFO      Regularization:         None\n",
      "17:58 madminer.ml          INFO      Samples:                all\n",
      "17:58 madminer.ml          INFO    Loading training data\n",
      "17:58 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "17:58 madminer.ml          INFO    Rescaling inputs\n",
      "17:58 madminer.ml          INFO    Creating model for method sally\n",
      "17:58 madminer.ml          INFO    Training model\n",
      "17:58 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0991 (mse_score: 0.0991)\n",
      "17:58 madminer.utils.ml.sc INFO                val. loss  0.0864 (mse_score: 0.0864) (*)\n",
      "17:59 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0769 (mse_score: 0.0769)\n",
      "17:59 madminer.utils.ml.sc INFO                val. loss  0.0554 (mse_score: 0.0554) (*)\n",
      "17:59 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0658 (mse_score: 0.0658)\n",
      "17:59 madminer.utils.ml.sc INFO                val. loss  0.0467 (mse_score: 0.0467) (*)\n",
      "17:59 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0601 (mse_score: 0.0601)\n",
      "17:59 madminer.utils.ml.sc INFO                val. loss  0.0441 (mse_score: 0.0441) (*)\n",
      "18:00 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0563 (mse_score: 0.0563)\n",
      "18:00 madminer.utils.ml.sc INFO                val. loss  0.0420 (mse_score: 0.0420) (*)\n",
      "18:00 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0535 (mse_score: 0.0535)\n",
      "18:00 madminer.utils.ml.sc INFO                val. loss  0.0403 (mse_score: 0.0403) (*)\n",
      "18:01 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0517 (mse_score: 0.0517)\n",
      "18:01 madminer.utils.ml.sc INFO                val. loss  0.0394 (mse_score: 0.0394) (*)\n",
      "18:01 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0507 (mse_score: 0.0507)\n",
      "18:01 madminer.utils.ml.sc INFO                val. loss  0.0385 (mse_score: 0.0385) (*)\n",
      "18:01 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0488 (mse_score: 0.0488)\n",
      "18:01 madminer.utils.ml.sc INFO                val. loss  0.0375 (mse_score: 0.0375) (*)\n",
      "18:02 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0476 (mse_score: 0.0476)\n",
      "18:02 madminer.utils.ml.sc INFO                val. loss  0.0379 (mse_score: 0.0379)\n",
      "18:02 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0468 (mse_score: 0.0468)\n",
      "18:02 madminer.utils.ml.sc INFO                val. loss  0.0366 (mse_score: 0.0366) (*)\n",
      "18:02 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0457 (mse_score: 0.0457)\n",
      "18:02 madminer.utils.ml.sc INFO                val. loss  0.0369 (mse_score: 0.0369)\n",
      "18:03 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0451 (mse_score: 0.0451)\n",
      "18:03 madminer.utils.ml.sc INFO                val. loss  0.0363 (mse_score: 0.0363) (*)\n",
      "18:03 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0446 (mse_score: 0.0446)\n",
      "18:03 madminer.utils.ml.sc INFO                val. loss  0.0356 (mse_score: 0.0356) (*)\n",
      "18:03 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0439 (mse_score: 0.0439)\n",
      "18:03 madminer.utils.ml.sc INFO                val. loss  0.0349 (mse_score: 0.0349) (*)\n",
      "18:04 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0435 (mse_score: 0.0435)\n",
      "18:04 madminer.utils.ml.sc INFO                val. loss  0.0347 (mse_score: 0.0347) (*)\n",
      "18:04 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0429 (mse_score: 0.0429)\n",
      "18:04 madminer.utils.ml.sc INFO                val. loss  0.0360 (mse_score: 0.0360)\n",
      "18:05 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0423 (mse_score: 0.0423)\n",
      "18:05 madminer.utils.ml.sc INFO                val. loss  0.0341 (mse_score: 0.0341) (*)\n",
      "18:05 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0419 (mse_score: 0.0419)\n",
      "18:05 madminer.utils.ml.sc INFO                val. loss  0.0342 (mse_score: 0.0342)\n",
      "18:05 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0415 (mse_score: 0.0415)\n",
      "18:05 madminer.utils.ml.sc INFO                val. loss  0.0339 (mse_score: 0.0339) (*)\n",
      "18:06 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0411 (mse_score: 0.0411)\n",
      "18:06 madminer.utils.ml.sc INFO                val. loss  0.0339 (mse_score: 0.0339) (*)\n",
      "18:06 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0406 (mse_score: 0.0406)\n",
      "18:06 madminer.utils.ml.sc INFO                val. loss  0.0337 (mse_score: 0.0337) (*)\n",
      "18:06 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0404 (mse_score: 0.0404)\n",
      "18:06 madminer.utils.ml.sc INFO                val. loss  0.0334 (mse_score: 0.0334) (*)\n",
      "18:07 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0401 (mse_score: 0.0401)\n",
      "18:07 madminer.utils.ml.sc INFO                val. loss  0.0334 (mse_score: 0.0334) (*)\n",
      "18:07 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0398 (mse_score: 0.0398)\n",
      "18:07 madminer.utils.ml.sc INFO                val. loss  0.0338 (mse_score: 0.0338)\n",
      "18:07 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0395 (mse_score: 0.0395)\n",
      "18:07 madminer.utils.ml.sc INFO                val. loss  0.0331 (mse_score: 0.0331) (*)\n",
      "18:08 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0392 (mse_score: 0.0392)\n",
      "18:08 madminer.utils.ml.sc INFO                val. loss  0.0332 (mse_score: 0.0332)\n",
      "18:08 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0389 (mse_score: 0.0389)\n",
      "18:08 madminer.utils.ml.sc INFO                val. loss  0.0333 (mse_score: 0.0333)\n",
      "18:09 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0387 (mse_score: 0.0387)\n",
      "18:09 madminer.utils.ml.sc INFO                val. loss  0.0330 (mse_score: 0.0330) (*)\n",
      "18:09 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0385 (mse_score: 0.0385)\n",
      "18:09 madminer.utils.ml.sc INFO                val. loss  0.0330 (mse_score: 0.0330)\n",
      "18:09 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0383 (mse_score: 0.0383)\n",
      "18:09 madminer.utils.ml.sc INFO                val. loss  0.0330 (mse_score: 0.0330)\n",
      "18:10 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0381 (mse_score: 0.0381)\n",
      "18:10 madminer.utils.ml.sc INFO                val. loss  0.0330 (mse_score: 0.0330)\n",
      "18:10 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0379 (mse_score: 0.0379)\n",
      "18:10 madminer.utils.ml.sc INFO                val. loss  0.0325 (mse_score: 0.0325) (*)\n",
      "18:10 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0377 (mse_score: 0.0377)\n",
      "18:10 madminer.utils.ml.sc INFO                val. loss  0.0360 (mse_score: 0.0360)\n",
      "18:11 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0376 (mse_score: 0.0376)\n",
      "18:11 madminer.utils.ml.sc INFO                val. loss  0.0325 (mse_score: 0.0325) (*)\n",
      "18:11 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0374 (mse_score: 0.0374)\n",
      "18:11 madminer.utils.ml.sc INFO                val. loss  0.0329 (mse_score: 0.0329)\n",
      "18:12 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0373 (mse_score: 0.0373)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:12 madminer.utils.ml.sc INFO                val. loss  0.0327 (mse_score: 0.0327)\n",
      "18:12 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0371 (mse_score: 0.0371)\n",
      "18:12 madminer.utils.ml.sc INFO                val. loss  0.0324 (mse_score: 0.0324) (*)\n",
      "18:12 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0370 (mse_score: 0.0370)\n",
      "18:12 madminer.utils.ml.sc INFO                val. loss  0.0324 (mse_score: 0.0324)\n",
      "18:13 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0368 (mse_score: 0.0368)\n",
      "18:13 madminer.utils.ml.sc INFO                val. loss  0.0325 (mse_score: 0.0325)\n",
      "18:13 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0367 (mse_score: 0.0367)\n",
      "18:13 madminer.utils.ml.sc INFO                val. loss  0.0322 (mse_score: 0.0322) (*)\n",
      "18:14 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0366 (mse_score: 0.0366)\n",
      "18:14 madminer.utils.ml.sc INFO                val. loss  0.0324 (mse_score: 0.0324)\n",
      "18:14 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0365 (mse_score: 0.0365)\n",
      "18:14 madminer.utils.ml.sc INFO                val. loss  0.0325 (mse_score: 0.0325)\n",
      "18:14 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0364 (mse_score: 0.0364)\n",
      "18:14 madminer.utils.ml.sc INFO                val. loss  0.0324 (mse_score: 0.0324)\n",
      "18:15 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0362 (mse_score: 0.0362)\n",
      "18:15 madminer.utils.ml.sc INFO                val. loss  0.0321 (mse_score: 0.0321) (*)\n",
      "18:15 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0361 (mse_score: 0.0361)\n",
      "18:15 madminer.utils.ml.sc INFO                val. loss  0.0324 (mse_score: 0.0324)\n",
      "18:15 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0361 (mse_score: 0.0361)\n",
      "18:15 madminer.utils.ml.sc INFO                val. loss  0.0321 (mse_score: 0.0321) (*)\n",
      "18:16 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0360 (mse_score: 0.0360)\n",
      "18:16 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "18:16 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0359 (mse_score: 0.0359)\n",
      "18:16 madminer.utils.ml.sc INFO                val. loss  0.0321 (mse_score: 0.0321)\n",
      "18:16 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0358 (mse_score: 0.0358)\n",
      "18:16 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "18:16 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "18:16 madminer.utils.ml.sc INFO    Finished training\n",
      "18:16 madminer.ml          INFO    Training estimator 2 / 10 in ensemble\n",
      "18:16 madminer.ml          INFO    Starting training\n",
      "18:16 madminer.ml          INFO      Method:                 sally\n",
      "18:16 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_1.npy\n",
      "18:16 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_1.npy\n",
      "18:16 madminer.ml          INFO      Features:               all\n",
      "18:16 madminer.ml          INFO      Method:                 sally\n",
      "18:16 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "18:16 madminer.ml          INFO      Activation function:    tanh\n",
      "18:16 madminer.ml          INFO      Batch size:             128\n",
      "18:16 madminer.ml          INFO      Trainer:                amsgrad\n",
      "18:16 madminer.ml          INFO      Epochs:                 50\n",
      "18:16 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "18:16 madminer.ml          INFO      Validation split:       0.5\n",
      "18:16 madminer.ml          INFO      Early stopping:         True\n",
      "18:16 madminer.ml          INFO      Scale inputs:           True\n",
      "18:16 madminer.ml          INFO      Shuffle labels          False\n",
      "18:16 madminer.ml          INFO      Regularization:         None\n",
      "18:16 madminer.ml          INFO      Samples:                all\n",
      "18:16 madminer.ml          INFO    Loading training data\n",
      "18:16 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "18:16 madminer.ml          INFO    Rescaling inputs\n",
      "18:17 madminer.ml          INFO    Creating model for method sally\n",
      "18:17 madminer.ml          INFO    Training model\n",
      "18:17 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0804 (mse_score: 0.0804)\n",
      "18:17 madminer.utils.ml.sc INFO                val. loss  0.0572 (mse_score: 0.0572) (*)\n",
      "18:17 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0589 (mse_score: 0.0589)\n",
      "18:17 madminer.utils.ml.sc INFO                val. loss  0.0499 (mse_score: 0.0499) (*)\n",
      "18:18 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0472 (mse_score: 0.0472)\n",
      "18:18 madminer.utils.ml.sc INFO                val. loss  0.0411 (mse_score: 0.0411) (*)\n",
      "18:18 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0417 (mse_score: 0.0417)\n",
      "18:18 madminer.utils.ml.sc INFO                val. loss  0.0334 (mse_score: 0.0334) (*)\n",
      "18:18 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0385 (mse_score: 0.0385)\n",
      "18:18 madminer.utils.ml.sc INFO                val. loss  0.0311 (mse_score: 0.0311) (*)\n",
      "18:19 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0358 (mse_score: 0.0358)\n",
      "18:19 madminer.utils.ml.sc INFO                val. loss  0.0300 (mse_score: 0.0300) (*)\n",
      "18:19 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0342 (mse_score: 0.0342)\n",
      "18:19 madminer.utils.ml.sc INFO                val. loss  0.0294 (mse_score: 0.0294) (*)\n",
      "18:20 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0326 (mse_score: 0.0326)\n",
      "18:20 madminer.utils.ml.sc INFO                val. loss  0.0293 (mse_score: 0.0293) (*)\n",
      "18:20 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0313 (mse_score: 0.0313)\n",
      "18:20 madminer.utils.ml.sc INFO                val. loss  0.0330 (mse_score: 0.0330)\n",
      "18:20 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0306 (mse_score: 0.0306)\n",
      "18:20 madminer.utils.ml.sc INFO                val. loss  0.0276 (mse_score: 0.0276) (*)\n",
      "18:21 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0295 (mse_score: 0.0295)\n",
      "18:21 madminer.utils.ml.sc INFO                val. loss  0.0271 (mse_score: 0.0271) (*)\n",
      "18:21 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0289 (mse_score: 0.0289)\n",
      "18:21 madminer.utils.ml.sc INFO                val. loss  0.0280 (mse_score: 0.0280)\n",
      "18:22 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0282 (mse_score: 0.0282)\n",
      "18:22 madminer.utils.ml.sc INFO                val. loss  0.0254 (mse_score: 0.0254) (*)\n",
      "18:22 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0275 (mse_score: 0.0275)\n",
      "18:22 madminer.utils.ml.sc INFO                val. loss  0.0251 (mse_score: 0.0251) (*)\n",
      "18:22 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0270 (mse_score: 0.0270)\n",
      "18:22 madminer.utils.ml.sc INFO                val. loss  0.0257 (mse_score: 0.0257)\n",
      "18:23 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0266 (mse_score: 0.0266)\n",
      "18:23 madminer.utils.ml.sc INFO                val. loss  0.0260 (mse_score: 0.0260)\n",
      "18:23 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0260 (mse_score: 0.0260)\n",
      "18:23 madminer.utils.ml.sc INFO                val. loss  0.0243 (mse_score: 0.0243) (*)\n",
      "18:24 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0256 (mse_score: 0.0256)\n",
      "18:24 madminer.utils.ml.sc INFO                val. loss  0.0243 (mse_score: 0.0243) (*)\n",
      "18:24 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0252 (mse_score: 0.0252)\n",
      "18:24 madminer.utils.ml.sc INFO                val. loss  0.0239 (mse_score: 0.0239) (*)\n",
      "18:24 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0249 (mse_score: 0.0249)\n",
      "18:24 madminer.utils.ml.sc INFO                val. loss  0.0247 (mse_score: 0.0247)\n",
      "18:25 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0246 (mse_score: 0.0246)\n",
      "18:25 madminer.utils.ml.sc INFO                val. loss  0.0247 (mse_score: 0.0247)\n",
      "18:25 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0242 (mse_score: 0.0242)\n",
      "18:25 madminer.utils.ml.sc INFO                val. loss  0.0239 (mse_score: 0.0239) (*)\n",
      "18:26 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0239 (mse_score: 0.0239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:26 madminer.utils.ml.sc INFO                val. loss  0.0248 (mse_score: 0.0248)\n",
      "18:26 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0236 (mse_score: 0.0236)\n",
      "18:26 madminer.utils.ml.sc INFO                val. loss  0.0236 (mse_score: 0.0236) (*)\n",
      "18:26 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0233 (mse_score: 0.0233)\n",
      "18:26 madminer.utils.ml.sc INFO                val. loss  0.0231 (mse_score: 0.0231) (*)\n",
      "18:27 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0231 (mse_score: 0.0231)\n",
      "18:27 madminer.utils.ml.sc INFO                val. loss  0.0238 (mse_score: 0.0238)\n",
      "18:27 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0229 (mse_score: 0.0229)\n",
      "18:27 madminer.utils.ml.sc INFO                val. loss  0.0230 (mse_score: 0.0230) (*)\n",
      "18:28 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0227 (mse_score: 0.0227)\n",
      "18:28 madminer.utils.ml.sc INFO                val. loss  0.0230 (mse_score: 0.0230) (*)\n",
      "18:28 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0224 (mse_score: 0.0224)\n",
      "18:28 madminer.utils.ml.sc INFO                val. loss  0.0239 (mse_score: 0.0239)\n",
      "18:29 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0223 (mse_score: 0.0223)\n",
      "18:29 madminer.utils.ml.sc INFO                val. loss  0.0229 (mse_score: 0.0229) (*)\n",
      "18:29 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0222 (mse_score: 0.0222)\n",
      "18:29 madminer.utils.ml.sc INFO                val. loss  0.0228 (mse_score: 0.0228) (*)\n",
      "18:29 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0220 (mse_score: 0.0220)\n",
      "18:29 madminer.utils.ml.sc INFO                val. loss  0.0228 (mse_score: 0.0228)\n",
      "18:30 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0218 (mse_score: 0.0218)\n",
      "18:30 madminer.utils.ml.sc INFO                val. loss  0.0226 (mse_score: 0.0226) (*)\n",
      "18:30 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0217 (mse_score: 0.0217)\n",
      "18:30 madminer.utils.ml.sc INFO                val. loss  0.0227 (mse_score: 0.0227)\n",
      "18:31 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0216 (mse_score: 0.0216)\n",
      "18:31 madminer.utils.ml.sc INFO                val. loss  0.0225 (mse_score: 0.0225) (*)\n",
      "18:31 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0214 (mse_score: 0.0214)\n",
      "18:31 madminer.utils.ml.sc INFO                val. loss  0.0226 (mse_score: 0.0226)\n",
      "18:32 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0213 (mse_score: 0.0213)\n",
      "18:32 madminer.utils.ml.sc INFO                val. loss  0.0226 (mse_score: 0.0226)\n",
      "18:32 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0212 (mse_score: 0.0212)\n",
      "18:32 madminer.utils.ml.sc INFO                val. loss  0.0227 (mse_score: 0.0227)\n",
      "18:33 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0211 (mse_score: 0.0211)\n",
      "18:33 madminer.utils.ml.sc INFO                val. loss  0.0226 (mse_score: 0.0226)\n",
      "18:33 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0210 (mse_score: 0.0210)\n",
      "18:33 madminer.utils.ml.sc INFO                val. loss  0.0237 (mse_score: 0.0237)\n",
      "18:34 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0209 (mse_score: 0.0209)\n",
      "18:34 madminer.utils.ml.sc INFO                val. loss  0.0224 (mse_score: 0.0224) (*)\n",
      "18:34 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0208 (mse_score: 0.0208)\n",
      "18:34 madminer.utils.ml.sc INFO                val. loss  0.0227 (mse_score: 0.0227)\n",
      "18:35 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0207 (mse_score: 0.0207)\n",
      "18:35 madminer.utils.ml.sc INFO                val. loss  0.0223 (mse_score: 0.0223) (*)\n",
      "18:35 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0207 (mse_score: 0.0207)\n",
      "18:35 madminer.utils.ml.sc INFO                val. loss  0.0224 (mse_score: 0.0224)\n",
      "18:35 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0206 (mse_score: 0.0206)\n",
      "18:35 madminer.utils.ml.sc INFO                val. loss  0.0223 (mse_score: 0.0223) (*)\n",
      "18:36 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0205 (mse_score: 0.0205)\n",
      "18:36 madminer.utils.ml.sc INFO                val. loss  0.0222 (mse_score: 0.0222) (*)\n",
      "18:36 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0204 (mse_score: 0.0204)\n",
      "18:36 madminer.utils.ml.sc INFO                val. loss  0.0223 (mse_score: 0.0223)\n",
      "18:37 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0204 (mse_score: 0.0204)\n",
      "18:37 madminer.utils.ml.sc INFO                val. loss  0.0221 (mse_score: 0.0221) (*)\n",
      "18:37 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0203 (mse_score: 0.0203)\n",
      "18:37 madminer.utils.ml.sc INFO                val. loss  0.0222 (mse_score: 0.0222)\n",
      "18:38 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0202 (mse_score: 0.0202)\n",
      "18:38 madminer.utils.ml.sc INFO                val. loss  0.0221 (mse_score: 0.0221)\n",
      "18:38 madminer.utils.ml.sc INFO    Early stopping after epoch 48, with loss 0.02 compared to final loss 0.02\n",
      "18:38 madminer.utils.ml.sc INFO    Finished training\n",
      "18:38 madminer.ml          INFO    Training estimator 3 / 10 in ensemble\n",
      "18:38 madminer.ml          INFO    Starting training\n",
      "18:38 madminer.ml          INFO      Method:                 sally\n",
      "18:38 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_2.npy\n",
      "18:38 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_2.npy\n",
      "18:38 madminer.ml          INFO      Features:               all\n",
      "18:38 madminer.ml          INFO      Method:                 sally\n",
      "18:38 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "18:38 madminer.ml          INFO      Activation function:    tanh\n",
      "18:38 madminer.ml          INFO      Batch size:             128\n",
      "18:38 madminer.ml          INFO      Trainer:                amsgrad\n",
      "18:38 madminer.ml          INFO      Epochs:                 50\n",
      "18:38 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "18:38 madminer.ml          INFO      Validation split:       0.5\n",
      "18:38 madminer.ml          INFO      Early stopping:         True\n",
      "18:38 madminer.ml          INFO      Scale inputs:           True\n",
      "18:38 madminer.ml          INFO      Shuffle labels          False\n",
      "18:38 madminer.ml          INFO      Regularization:         None\n",
      "18:38 madminer.ml          INFO      Samples:                all\n",
      "18:38 madminer.ml          INFO    Loading training data\n",
      "18:38 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "18:38 madminer.ml          INFO    Rescaling inputs\n",
      "18:38 madminer.ml          INFO    Creating model for method sally\n",
      "18:38 madminer.ml          INFO    Training model\n",
      "18:38 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0888 (mse_score: 0.0888)\n",
      "18:38 madminer.utils.ml.sc INFO                val. loss  0.0910 (mse_score: 0.0910) (*)\n",
      "18:39 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0690 (mse_score: 0.0690)\n",
      "18:39 madminer.utils.ml.sc INFO                val. loss  0.0760 (mse_score: 0.0760) (*)\n",
      "18:39 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0586 (mse_score: 0.0586)\n",
      "18:39 madminer.utils.ml.sc INFO                val. loss  0.0739 (mse_score: 0.0739) (*)\n",
      "18:40 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0520 (mse_score: 0.0520)\n",
      "18:40 madminer.utils.ml.sc INFO                val. loss  0.0655 (mse_score: 0.0655) (*)\n",
      "18:40 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0489 (mse_score: 0.0489)\n",
      "18:40 madminer.utils.ml.sc INFO                val. loss  0.0666 (mse_score: 0.0666)\n",
      "18:40 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0463 (mse_score: 0.0463)\n",
      "18:40 madminer.utils.ml.sc INFO                val. loss  0.0621 (mse_score: 0.0621) (*)\n",
      "18:41 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0437 (mse_score: 0.0437)\n",
      "18:41 madminer.utils.ml.sc INFO                val. loss  0.0611 (mse_score: 0.0611) (*)\n",
      "18:41 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0419 (mse_score: 0.0419)\n",
      "18:41 madminer.utils.ml.sc INFO                val. loss  0.0604 (mse_score: 0.0604) (*)\n",
      "18:42 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0405 (mse_score: 0.0405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:42 madminer.utils.ml.sc INFO                val. loss  0.0592 (mse_score: 0.0592) (*)\n",
      "18:42 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0394 (mse_score: 0.0394)\n",
      "18:42 madminer.utils.ml.sc INFO                val. loss  0.0598 (mse_score: 0.0598)\n",
      "18:43 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0384 (mse_score: 0.0384)\n",
      "18:43 madminer.utils.ml.sc INFO                val. loss  0.0584 (mse_score: 0.0584) (*)\n",
      "18:43 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0374 (mse_score: 0.0374)\n",
      "18:43 madminer.utils.ml.sc INFO                val. loss  0.0585 (mse_score: 0.0585)\n",
      "18:44 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0370 (mse_score: 0.0370)\n",
      "18:44 madminer.utils.ml.sc INFO                val. loss  0.0575 (mse_score: 0.0575) (*)\n",
      "18:44 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0362 (mse_score: 0.0362)\n",
      "18:44 madminer.utils.ml.sc INFO                val. loss  0.0572 (mse_score: 0.0572) (*)\n",
      "18:45 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0355 (mse_score: 0.0355)\n",
      "18:45 madminer.utils.ml.sc INFO                val. loss  0.0566 (mse_score: 0.0566) (*)\n",
      "18:45 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0350 (mse_score: 0.0350)\n",
      "18:45 madminer.utils.ml.sc INFO                val. loss  0.0568 (mse_score: 0.0568)\n",
      "18:45 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0345 (mse_score: 0.0345)\n",
      "18:45 madminer.utils.ml.sc INFO                val. loss  0.0565 (mse_score: 0.0565) (*)\n",
      "18:46 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0340 (mse_score: 0.0340)\n",
      "18:46 madminer.utils.ml.sc INFO                val. loss  0.0560 (mse_score: 0.0560) (*)\n",
      "18:46 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0336 (mse_score: 0.0336)\n",
      "18:46 madminer.utils.ml.sc INFO                val. loss  0.0557 (mse_score: 0.0557) (*)\n",
      "18:47 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0332 (mse_score: 0.0332)\n",
      "18:47 madminer.utils.ml.sc INFO                val. loss  0.0565 (mse_score: 0.0565)\n",
      "18:48 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0328 (mse_score: 0.0328)\n",
      "18:48 madminer.utils.ml.sc INFO                val. loss  0.0563 (mse_score: 0.0563)\n",
      "18:48 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0325 (mse_score: 0.0325)\n",
      "18:48 madminer.utils.ml.sc INFO                val. loss  0.0552 (mse_score: 0.0552) (*)\n",
      "18:49 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0322 (mse_score: 0.0322)\n",
      "18:49 madminer.utils.ml.sc INFO                val. loss  0.0553 (mse_score: 0.0553)\n",
      "18:49 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0319 (mse_score: 0.0319)\n",
      "18:49 madminer.utils.ml.sc INFO                val. loss  0.0554 (mse_score: 0.0554)\n",
      "18:50 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0317 (mse_score: 0.0317)\n",
      "18:50 madminer.utils.ml.sc INFO                val. loss  0.0553 (mse_score: 0.0553)\n",
      "18:50 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0314 (mse_score: 0.0314)\n",
      "18:50 madminer.utils.ml.sc INFO                val. loss  0.0547 (mse_score: 0.0547) (*)\n",
      "18:51 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0312 (mse_score: 0.0312)\n",
      "18:51 madminer.utils.ml.sc INFO                val. loss  0.0551 (mse_score: 0.0551)\n",
      "18:51 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0310 (mse_score: 0.0310)\n",
      "18:51 madminer.utils.ml.sc INFO                val. loss  0.0549 (mse_score: 0.0549)\n",
      "18:52 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0307 (mse_score: 0.0307)\n",
      "18:52 madminer.utils.ml.sc INFO                val. loss  0.0547 (mse_score: 0.0547) (*)\n",
      "18:52 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0305 (mse_score: 0.0305)\n",
      "18:52 madminer.utils.ml.sc INFO                val. loss  0.0546 (mse_score: 0.0546) (*)\n",
      "18:53 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0304 (mse_score: 0.0304)\n",
      "18:53 madminer.utils.ml.sc INFO                val. loss  0.0546 (mse_score: 0.0546)\n",
      "18:53 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0302 (mse_score: 0.0302)\n",
      "18:53 madminer.utils.ml.sc INFO                val. loss  0.0546 (mse_score: 0.0546) (*)\n",
      "18:54 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0300 (mse_score: 0.0300)\n",
      "18:54 madminer.utils.ml.sc INFO                val. loss  0.0545 (mse_score: 0.0545) (*)\n",
      "18:54 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0299 (mse_score: 0.0299)\n",
      "18:54 madminer.utils.ml.sc INFO                val. loss  0.0543 (mse_score: 0.0543) (*)\n",
      "18:55 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0297 (mse_score: 0.0297)\n",
      "18:55 madminer.utils.ml.sc INFO                val. loss  0.0542 (mse_score: 0.0542) (*)\n",
      "18:55 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0296 (mse_score: 0.0296)\n",
      "18:55 madminer.utils.ml.sc INFO                val. loss  0.0543 (mse_score: 0.0543)\n",
      "18:56 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0295 (mse_score: 0.0295)\n",
      "18:56 madminer.utils.ml.sc INFO                val. loss  0.0542 (mse_score: 0.0542)\n",
      "18:56 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0294 (mse_score: 0.0294)\n",
      "18:56 madminer.utils.ml.sc INFO                val. loss  0.0541 (mse_score: 0.0541) (*)\n",
      "18:56 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0292 (mse_score: 0.0292)\n",
      "18:56 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540) (*)\n",
      "18:57 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0291 (mse_score: 0.0291)\n",
      "18:57 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540) (*)\n",
      "18:57 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0290 (mse_score: 0.0290)\n",
      "18:57 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540)\n",
      "18:58 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0289 (mse_score: 0.0289)\n",
      "18:58 madminer.utils.ml.sc INFO                val. loss  0.0539 (mse_score: 0.0539) (*)\n",
      "18:58 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0288 (mse_score: 0.0288)\n",
      "18:58 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540)\n",
      "18:59 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0287 (mse_score: 0.0287)\n",
      "18:59 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540)\n",
      "18:59 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0286 (mse_score: 0.0286)\n",
      "18:59 madminer.utils.ml.sc INFO                val. loss  0.0539 (mse_score: 0.0539)\n",
      "18:59 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0285 (mse_score: 0.0285)\n",
      "18:59 madminer.utils.ml.sc INFO                val. loss  0.0539 (mse_score: 0.0539)\n",
      "19:00 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0284 (mse_score: 0.0284)\n",
      "19:00 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538) (*)\n",
      "19:00 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0284 (mse_score: 0.0284)\n",
      "19:00 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538) (*)\n",
      "19:01 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0283 (mse_score: 0.0283)\n",
      "19:01 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538)\n",
      "19:01 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0282 (mse_score: 0.0282)\n",
      "19:01 madminer.utils.ml.sc INFO                val. loss  0.0537 (mse_score: 0.0537) (*)\n",
      "19:01 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "19:01 madminer.utils.ml.sc INFO    Finished training\n",
      "19:01 madminer.ml          INFO    Training estimator 4 / 10 in ensemble\n",
      "19:01 madminer.ml          INFO    Starting training\n",
      "19:01 madminer.ml          INFO      Method:                 sally\n",
      "19:01 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_3.npy\n",
      "19:01 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_3.npy\n",
      "19:01 madminer.ml          INFO      Features:               all\n",
      "19:01 madminer.ml          INFO      Method:                 sally\n",
      "19:01 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "19:01 madminer.ml          INFO      Activation function:    tanh\n",
      "19:01 madminer.ml          INFO      Batch size:             128\n",
      "19:01 madminer.ml          INFO      Trainer:                amsgrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01 madminer.ml          INFO      Epochs:                 50\n",
      "19:01 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "19:01 madminer.ml          INFO      Validation split:       0.5\n",
      "19:01 madminer.ml          INFO      Early stopping:         True\n",
      "19:01 madminer.ml          INFO      Scale inputs:           True\n",
      "19:01 madminer.ml          INFO      Shuffle labels          False\n",
      "19:01 madminer.ml          INFO      Regularization:         None\n",
      "19:01 madminer.ml          INFO      Samples:                all\n",
      "19:01 madminer.ml          INFO    Loading training data\n",
      "19:01 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "19:01 madminer.ml          INFO    Rescaling inputs\n",
      "19:01 madminer.ml          INFO    Creating model for method sally\n",
      "19:01 madminer.ml          INFO    Training model\n",
      "19:02 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0977 (mse_score: 0.0977)\n",
      "19:02 madminer.utils.ml.sc INFO                val. loss  0.0926 (mse_score: 0.0926) (*)\n",
      "19:02 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0794 (mse_score: 0.0794)\n",
      "19:02 madminer.utils.ml.sc INFO                val. loss  0.0756 (mse_score: 0.0756) (*)\n",
      "19:03 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0688 (mse_score: 0.0688)\n",
      "19:03 madminer.utils.ml.sc INFO                val. loss  0.0688 (mse_score: 0.0688) (*)\n",
      "19:03 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0635 (mse_score: 0.0635)\n",
      "19:03 madminer.utils.ml.sc INFO                val. loss  0.0651 (mse_score: 0.0651) (*)\n",
      "19:03 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0593 (mse_score: 0.0593)\n",
      "19:03 madminer.utils.ml.sc INFO                val. loss  0.0643 (mse_score: 0.0643) (*)\n",
      "19:04 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0563 (mse_score: 0.0563)\n",
      "19:04 madminer.utils.ml.sc INFO                val. loss  0.0634 (mse_score: 0.0634) (*)\n",
      "19:04 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0541 (mse_score: 0.0541)\n",
      "19:04 madminer.utils.ml.sc INFO                val. loss  0.0611 (mse_score: 0.0611) (*)\n",
      "19:05 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0524 (mse_score: 0.0524)\n",
      "19:05 madminer.utils.ml.sc INFO                val. loss  0.0587 (mse_score: 0.0587) (*)\n",
      "19:05 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0513 (mse_score: 0.0513)\n",
      "19:05 madminer.utils.ml.sc INFO                val. loss  0.0579 (mse_score: 0.0579) (*)\n",
      "19:06 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0498 (mse_score: 0.0498)\n",
      "19:06 madminer.utils.ml.sc INFO                val. loss  0.0595 (mse_score: 0.0595)\n",
      "19:06 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0490 (mse_score: 0.0490)\n",
      "19:06 madminer.utils.ml.sc INFO                val. loss  0.0567 (mse_score: 0.0567) (*)\n",
      "19:06 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0477 (mse_score: 0.0477)\n",
      "19:06 madminer.utils.ml.sc INFO                val. loss  0.0569 (mse_score: 0.0569)\n",
      "19:07 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0473 (mse_score: 0.0473)\n",
      "19:07 madminer.utils.ml.sc INFO                val. loss  0.0571 (mse_score: 0.0571)\n",
      "19:07 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0463 (mse_score: 0.0463)\n",
      "19:07 madminer.utils.ml.sc INFO                val. loss  0.0575 (mse_score: 0.0575)\n",
      "19:08 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0457 (mse_score: 0.0457)\n",
      "19:08 madminer.utils.ml.sc INFO                val. loss  0.0553 (mse_score: 0.0553) (*)\n",
      "19:08 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0449 (mse_score: 0.0449)\n",
      "19:08 madminer.utils.ml.sc INFO                val. loss  0.0552 (mse_score: 0.0552) (*)\n",
      "19:09 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0444 (mse_score: 0.0444)\n",
      "19:09 madminer.utils.ml.sc INFO                val. loss  0.0541 (mse_score: 0.0541) (*)\n",
      "19:09 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0439 (mse_score: 0.0439)\n",
      "19:09 madminer.utils.ml.sc INFO                val. loss  0.0542 (mse_score: 0.0542)\n",
      "19:10 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0433 (mse_score: 0.0433)\n",
      "19:10 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538) (*)\n",
      "19:10 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0429 (mse_score: 0.0429)\n",
      "19:10 madminer.utils.ml.sc INFO                val. loss  0.0535 (mse_score: 0.0535) (*)\n",
      "19:10 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0424 (mse_score: 0.0424)\n",
      "19:10 madminer.utils.ml.sc INFO                val. loss  0.0537 (mse_score: 0.0537)\n",
      "19:11 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0421 (mse_score: 0.0421)\n",
      "19:11 madminer.utils.ml.sc INFO                val. loss  0.0536 (mse_score: 0.0536)\n",
      "19:11 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0417 (mse_score: 0.0417)\n",
      "19:11 madminer.utils.ml.sc INFO                val. loss  0.0533 (mse_score: 0.0533) (*)\n",
      "19:12 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0414 (mse_score: 0.0414)\n",
      "19:12 madminer.utils.ml.sc INFO                val. loss  0.0533 (mse_score: 0.0533) (*)\n",
      "19:12 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0411 (mse_score: 0.0411)\n",
      "19:12 madminer.utils.ml.sc INFO                val. loss  0.0532 (mse_score: 0.0532) (*)\n",
      "19:13 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0408 (mse_score: 0.0408)\n",
      "19:13 madminer.utils.ml.sc INFO                val. loss  0.0529 (mse_score: 0.0529) (*)\n",
      "19:13 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0405 (mse_score: 0.0405)\n",
      "19:13 madminer.utils.ml.sc INFO                val. loss  0.0527 (mse_score: 0.0527) (*)\n",
      "19:14 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0402 (mse_score: 0.0402)\n",
      "19:14 madminer.utils.ml.sc INFO                val. loss  0.0525 (mse_score: 0.0525) (*)\n",
      "19:14 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0400 (mse_score: 0.0400)\n",
      "19:14 madminer.utils.ml.sc INFO                val. loss  0.0528 (mse_score: 0.0528)\n",
      "19:14 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0398 (mse_score: 0.0398)\n",
      "19:14 madminer.utils.ml.sc INFO                val. loss  0.0526 (mse_score: 0.0526)\n",
      "19:15 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0396 (mse_score: 0.0396)\n",
      "19:15 madminer.utils.ml.sc INFO                val. loss  0.0524 (mse_score: 0.0524) (*)\n",
      "19:15 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0393 (mse_score: 0.0393)\n",
      "19:15 madminer.utils.ml.sc INFO                val. loss  0.0525 (mse_score: 0.0525)\n",
      "19:16 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0392 (mse_score: 0.0392)\n",
      "19:16 madminer.utils.ml.sc INFO                val. loss  0.0521 (mse_score: 0.0521) (*)\n",
      "19:16 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0390 (mse_score: 0.0390)\n",
      "19:16 madminer.utils.ml.sc INFO                val. loss  0.0520 (mse_score: 0.0520) (*)\n",
      "19:17 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0388 (mse_score: 0.0388)\n",
      "19:17 madminer.utils.ml.sc INFO                val. loss  0.0519 (mse_score: 0.0519) (*)\n",
      "19:17 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0386 (mse_score: 0.0386)\n",
      "19:17 madminer.utils.ml.sc INFO                val. loss  0.0521 (mse_score: 0.0521)\n",
      "19:17 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0385 (mse_score: 0.0385)\n",
      "19:17 madminer.utils.ml.sc INFO                val. loss  0.0521 (mse_score: 0.0521)\n",
      "19:18 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0383 (mse_score: 0.0383)\n",
      "19:18 madminer.utils.ml.sc INFO                val. loss  0.0520 (mse_score: 0.0520)\n",
      "19:18 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0382 (mse_score: 0.0382)\n",
      "19:18 madminer.utils.ml.sc INFO                val. loss  0.0518 (mse_score: 0.0518) (*)\n",
      "19:19 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0381 (mse_score: 0.0381)\n",
      "19:19 madminer.utils.ml.sc INFO                val. loss  0.0519 (mse_score: 0.0519)\n",
      "19:19 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0379 (mse_score: 0.0379)\n",
      "19:19 madminer.utils.ml.sc INFO                val. loss  0.0518 (mse_score: 0.0518) (*)\n",
      "19:20 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0378 (mse_score: 0.0378)\n",
      "19:20 madminer.utils.ml.sc INFO                val. loss  0.0517 (mse_score: 0.0517) (*)\n",
      "19:20 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0377 (mse_score: 0.0377)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:20 madminer.utils.ml.sc INFO                val. loss  0.0519 (mse_score: 0.0519)\n",
      "19:20 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0376 (mse_score: 0.0376)\n",
      "19:20 madminer.utils.ml.sc INFO                val. loss  0.0517 (mse_score: 0.0517) (*)\n",
      "19:21 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0375 (mse_score: 0.0375)\n",
      "19:21 madminer.utils.ml.sc INFO                val. loss  0.0517 (mse_score: 0.0517)\n",
      "19:21 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0374 (mse_score: 0.0374)\n",
      "19:21 madminer.utils.ml.sc INFO                val. loss  0.0518 (mse_score: 0.0518)\n",
      "19:22 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0373 (mse_score: 0.0373)\n",
      "19:22 madminer.utils.ml.sc INFO                val. loss  0.0515 (mse_score: 0.0515) (*)\n",
      "19:22 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0373 (mse_score: 0.0373)\n",
      "19:22 madminer.utils.ml.sc INFO                val. loss  0.0515 (mse_score: 0.0515)\n",
      "19:23 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0371 (mse_score: 0.0371)\n",
      "19:23 madminer.utils.ml.sc INFO                val. loss  0.0515 (mse_score: 0.0515)\n",
      "19:23 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0371 (mse_score: 0.0371)\n",
      "19:23 madminer.utils.ml.sc INFO                val. loss  0.0515 (mse_score: 0.0515)\n",
      "19:23 madminer.utils.ml.sc INFO    Early stopping after epoch 47, with loss 0.05 compared to final loss 0.05\n",
      "19:23 madminer.utils.ml.sc INFO    Finished training\n",
      "19:23 madminer.ml          INFO    Training estimator 5 / 10 in ensemble\n",
      "19:23 madminer.ml          INFO    Starting training\n",
      "19:23 madminer.ml          INFO      Method:                 sally\n",
      "19:23 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_4.npy\n",
      "19:23 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_4.npy\n",
      "19:23 madminer.ml          INFO      Features:               all\n",
      "19:23 madminer.ml          INFO      Method:                 sally\n",
      "19:23 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "19:23 madminer.ml          INFO      Activation function:    tanh\n",
      "19:23 madminer.ml          INFO      Batch size:             128\n",
      "19:23 madminer.ml          INFO      Trainer:                amsgrad\n",
      "19:23 madminer.ml          INFO      Epochs:                 50\n",
      "19:23 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "19:23 madminer.ml          INFO      Validation split:       0.5\n",
      "19:23 madminer.ml          INFO      Early stopping:         True\n",
      "19:23 madminer.ml          INFO      Scale inputs:           True\n",
      "19:23 madminer.ml          INFO      Shuffle labels          False\n",
      "19:23 madminer.ml          INFO      Regularization:         None\n",
      "19:23 madminer.ml          INFO      Samples:                all\n",
      "19:23 madminer.ml          INFO    Loading training data\n",
      "19:23 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "19:23 madminer.ml          INFO    Rescaling inputs\n",
      "19:23 madminer.ml          INFO    Creating model for method sally\n",
      "19:23 madminer.ml          INFO    Training model\n",
      "19:23 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0721 (mse_score: 0.0721)\n",
      "19:23 madminer.utils.ml.sc INFO                val. loss  0.0887 (mse_score: 0.0887) (*)\n",
      "19:24 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0510 (mse_score: 0.0510)\n",
      "19:24 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747) (*)\n",
      "19:24 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0415 (mse_score: 0.0415)\n",
      "19:24 madminer.utils.ml.sc INFO                val. loss  0.0690 (mse_score: 0.0690) (*)\n",
      "19:24 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0366 (mse_score: 0.0366)\n",
      "19:24 madminer.utils.ml.sc INFO                val. loss  0.0666 (mse_score: 0.0666) (*)\n",
      "19:25 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0335 (mse_score: 0.0335)\n",
      "19:25 madminer.utils.ml.sc INFO                val. loss  0.0639 (mse_score: 0.0639) (*)\n",
      "19:25 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0313 (mse_score: 0.0313)\n",
      "19:25 madminer.utils.ml.sc INFO                val. loss  0.0616 (mse_score: 0.0616) (*)\n",
      "19:26 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0294 (mse_score: 0.0294)\n",
      "19:26 madminer.utils.ml.sc INFO                val. loss  0.0623 (mse_score: 0.0623)\n",
      "19:26 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0280 (mse_score: 0.0280)\n",
      "19:26 madminer.utils.ml.sc INFO                val. loss  0.0617 (mse_score: 0.0617)\n",
      "19:26 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0268 (mse_score: 0.0268)\n",
      "19:26 madminer.utils.ml.sc INFO                val. loss  0.0593 (mse_score: 0.0593) (*)\n",
      "19:27 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0259 (mse_score: 0.0259)\n",
      "19:27 madminer.utils.ml.sc INFO                val. loss  0.0585 (mse_score: 0.0585) (*)\n",
      "19:27 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0248 (mse_score: 0.0248)\n",
      "19:27 madminer.utils.ml.sc INFO                val. loss  0.0582 (mse_score: 0.0582) (*)\n",
      "19:27 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0241 (mse_score: 0.0241)\n",
      "19:27 madminer.utils.ml.sc INFO                val. loss  0.0573 (mse_score: 0.0573) (*)\n",
      "19:28 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0235 (mse_score: 0.0235)\n",
      "19:28 madminer.utils.ml.sc INFO                val. loss  0.0578 (mse_score: 0.0578)\n",
      "19:28 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0229 (mse_score: 0.0229)\n",
      "19:28 madminer.utils.ml.sc INFO                val. loss  0.0569 (mse_score: 0.0569) (*)\n",
      "19:29 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0224 (mse_score: 0.0224)\n",
      "19:29 madminer.utils.ml.sc INFO                val. loss  0.0566 (mse_score: 0.0566) (*)\n",
      "19:29 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0217 (mse_score: 0.0217)\n",
      "19:29 madminer.utils.ml.sc INFO                val. loss  0.0567 (mse_score: 0.0567)\n",
      "19:29 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0213 (mse_score: 0.0213)\n",
      "19:29 madminer.utils.ml.sc INFO                val. loss  0.0562 (mse_score: 0.0562) (*)\n",
      "19:30 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0210 (mse_score: 0.0210)\n",
      "19:30 madminer.utils.ml.sc INFO                val. loss  0.0561 (mse_score: 0.0561) (*)\n",
      "19:30 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0206 (mse_score: 0.0206)\n",
      "19:30 madminer.utils.ml.sc INFO                val. loss  0.0558 (mse_score: 0.0558) (*)\n",
      "19:31 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0202 (mse_score: 0.0202)\n",
      "19:31 madminer.utils.ml.sc INFO                val. loss  0.0557 (mse_score: 0.0557) (*)\n",
      "19:31 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0199 (mse_score: 0.0199)\n",
      "19:31 madminer.utils.ml.sc INFO                val. loss  0.0554 (mse_score: 0.0554) (*)\n",
      "19:32 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0196 (mse_score: 0.0196)\n",
      "19:32 madminer.utils.ml.sc INFO                val. loss  0.0564 (mse_score: 0.0564)\n",
      "19:32 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0194 (mse_score: 0.0194)\n",
      "19:32 madminer.utils.ml.sc INFO                val. loss  0.0552 (mse_score: 0.0552) (*)\n",
      "19:32 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0192 (mse_score: 0.0192)\n",
      "19:32 madminer.utils.ml.sc INFO                val. loss  0.0551 (mse_score: 0.0551) (*)\n",
      "19:33 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0190 (mse_score: 0.0190)\n",
      "19:33 madminer.utils.ml.sc INFO                val. loss  0.0554 (mse_score: 0.0554)\n",
      "19:33 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0187 (mse_score: 0.0187)\n",
      "19:33 madminer.utils.ml.sc INFO                val. loss  0.0548 (mse_score: 0.0548) (*)\n",
      "19:34 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0185 (mse_score: 0.0185)\n",
      "19:34 madminer.utils.ml.sc INFO                val. loss  0.0545 (mse_score: 0.0545) (*)\n",
      "19:34 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0184 (mse_score: 0.0184)\n",
      "19:34 madminer.utils.ml.sc INFO                val. loss  0.0546 (mse_score: 0.0546)\n",
      "19:34 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0182 (mse_score: 0.0182)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:34 madminer.utils.ml.sc INFO                val. loss  0.0545 (mse_score: 0.0545) (*)\n",
      "19:35 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0181 (mse_score: 0.0181)\n",
      "19:35 madminer.utils.ml.sc INFO                val. loss  0.0547 (mse_score: 0.0547)\n",
      "19:35 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0179 (mse_score: 0.0179)\n",
      "19:35 madminer.utils.ml.sc INFO                val. loss  0.0546 (mse_score: 0.0546)\n",
      "19:36 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0178 (mse_score: 0.0178)\n",
      "19:36 madminer.utils.ml.sc INFO                val. loss  0.0545 (mse_score: 0.0545) (*)\n",
      "19:36 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0177 (mse_score: 0.0177)\n",
      "19:36 madminer.utils.ml.sc INFO                val. loss  0.0542 (mse_score: 0.0542) (*)\n",
      "19:37 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0176 (mse_score: 0.0176)\n",
      "19:37 madminer.utils.ml.sc INFO                val. loss  0.0543 (mse_score: 0.0543)\n",
      "19:37 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0174 (mse_score: 0.0174)\n",
      "19:37 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540) (*)\n",
      "19:37 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0173 (mse_score: 0.0173)\n",
      "19:37 madminer.utils.ml.sc INFO                val. loss  0.0542 (mse_score: 0.0542)\n",
      "19:38 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0172 (mse_score: 0.0172)\n",
      "19:38 madminer.utils.ml.sc INFO                val. loss  0.0541 (mse_score: 0.0541)\n",
      "19:38 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0171 (mse_score: 0.0171)\n",
      "19:38 madminer.utils.ml.sc INFO                val. loss  0.0541 (mse_score: 0.0541)\n",
      "19:39 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0170 (mse_score: 0.0170)\n",
      "19:39 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540)\n",
      "19:39 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0169 (mse_score: 0.0169)\n",
      "19:39 madminer.utils.ml.sc INFO                val. loss  0.0539 (mse_score: 0.0539) (*)\n",
      "19:39 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0169 (mse_score: 0.0169)\n",
      "19:39 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540)\n",
      "19:40 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0168 (mse_score: 0.0168)\n",
      "19:40 madminer.utils.ml.sc INFO                val. loss  0.0540 (mse_score: 0.0540)\n",
      "19:40 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0167 (mse_score: 0.0167)\n",
      "19:40 madminer.utils.ml.sc INFO                val. loss  0.0539 (mse_score: 0.0539) (*)\n",
      "19:41 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0166 (mse_score: 0.0166)\n",
      "19:41 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538) (*)\n",
      "19:41 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0166 (mse_score: 0.0166)\n",
      "19:41 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538) (*)\n",
      "19:42 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0165 (mse_score: 0.0165)\n",
      "19:42 madminer.utils.ml.sc INFO                val. loss  0.0539 (mse_score: 0.0539)\n",
      "19:42 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0165 (mse_score: 0.0165)\n",
      "19:42 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538) (*)\n",
      "19:42 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0164 (mse_score: 0.0164)\n",
      "19:42 madminer.utils.ml.sc INFO                val. loss  0.0538 (mse_score: 0.0538)\n",
      "19:43 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0163 (mse_score: 0.0163)\n",
      "19:43 madminer.utils.ml.sc INFO                val. loss  0.0537 (mse_score: 0.0537) (*)\n",
      "19:43 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0163 (mse_score: 0.0163)\n",
      "19:43 madminer.utils.ml.sc INFO                val. loss  0.0537 (mse_score: 0.0537)\n",
      "19:43 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 0.05 compared to final loss 0.05\n",
      "19:43 madminer.utils.ml.sc INFO    Finished training\n",
      "19:43 madminer.ml          INFO    Training estimator 6 / 10 in ensemble\n",
      "19:43 madminer.ml          INFO    Starting training\n",
      "19:43 madminer.ml          INFO      Method:                 sally\n",
      "19:43 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_5.npy\n",
      "19:43 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_5.npy\n",
      "19:43 madminer.ml          INFO      Features:               all\n",
      "19:43 madminer.ml          INFO      Method:                 sally\n",
      "19:43 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "19:43 madminer.ml          INFO      Activation function:    tanh\n",
      "19:43 madminer.ml          INFO      Batch size:             128\n",
      "19:43 madminer.ml          INFO      Trainer:                amsgrad\n",
      "19:43 madminer.ml          INFO      Epochs:                 50\n",
      "19:43 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "19:43 madminer.ml          INFO      Validation split:       0.5\n",
      "19:43 madminer.ml          INFO      Early stopping:         True\n",
      "19:43 madminer.ml          INFO      Scale inputs:           True\n",
      "19:43 madminer.ml          INFO      Shuffle labels          False\n",
      "19:43 madminer.ml          INFO      Regularization:         None\n",
      "19:43 madminer.ml          INFO      Samples:                all\n",
      "19:43 madminer.ml          INFO    Loading training data\n",
      "19:43 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "19:43 madminer.ml          INFO    Rescaling inputs\n",
      "19:43 madminer.ml          INFO    Creating model for method sally\n",
      "19:43 madminer.ml          INFO    Training model\n",
      "19:44 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.2040 (mse_score: 0.2040)\n",
      "19:44 madminer.utils.ml.sc INFO                val. loss  0.0653 (mse_score: 0.0653) (*)\n",
      "19:44 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1887 (mse_score: 0.1887)\n",
      "19:44 madminer.utils.ml.sc INFO                val. loss  0.0537 (mse_score: 0.0537) (*)\n",
      "19:44 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1800 (mse_score: 0.1800)\n",
      "19:44 madminer.utils.ml.sc INFO                val. loss  0.0474 (mse_score: 0.0474) (*)\n",
      "19:45 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1743 (mse_score: 0.1743)\n",
      "19:45 madminer.utils.ml.sc INFO                val. loss  0.0433 (mse_score: 0.0433) (*)\n",
      "19:45 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1684 (mse_score: 0.1684)\n",
      "19:45 madminer.utils.ml.sc INFO                val. loss  0.0388 (mse_score: 0.0388) (*)\n",
      "19:45 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1638 (mse_score: 0.1638)\n",
      "19:45 madminer.utils.ml.sc INFO                val. loss  0.0372 (mse_score: 0.0372) (*)\n",
      "19:46 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1606 (mse_score: 0.1606)\n",
      "19:46 madminer.utils.ml.sc INFO                val. loss  0.0363 (mse_score: 0.0363) (*)\n",
      "19:46 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1583 (mse_score: 0.1583)\n",
      "19:46 madminer.utils.ml.sc INFO                val. loss  0.0360 (mse_score: 0.0360) (*)\n",
      "19:47 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1563 (mse_score: 0.1563)\n",
      "19:47 madminer.utils.ml.sc INFO                val. loss  0.0330 (mse_score: 0.0330) (*)\n",
      "19:47 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.1543 (mse_score: 0.1543)\n",
      "19:47 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "19:47 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.1527 (mse_score: 0.1527)\n",
      "19:47 madminer.utils.ml.sc INFO                val. loss  0.0311 (mse_score: 0.0311) (*)\n",
      "19:48 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.1513 (mse_score: 0.1513)\n",
      "19:48 madminer.utils.ml.sc INFO                val. loss  0.0309 (mse_score: 0.0309) (*)\n",
      "19:48 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.1500 (mse_score: 0.1500)\n",
      "19:48 madminer.utils.ml.sc INFO                val. loss  0.0299 (mse_score: 0.0299) (*)\n",
      "19:48 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.1490 (mse_score: 0.1490)\n",
      "19:48 madminer.utils.ml.sc INFO                val. loss  0.0310 (mse_score: 0.0310)\n",
      "19:49 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.1479 (mse_score: 0.1479)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:49 madminer.utils.ml.sc INFO                val. loss  0.0293 (mse_score: 0.0293) (*)\n",
      "19:49 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.1471 (mse_score: 0.1471)\n",
      "19:49 madminer.utils.ml.sc INFO                val. loss  0.0285 (mse_score: 0.0285) (*)\n",
      "19:50 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.1461 (mse_score: 0.1461)\n",
      "19:50 madminer.utils.ml.sc INFO                val. loss  0.0287 (mse_score: 0.0287)\n",
      "19:50 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.1454 (mse_score: 0.1454)\n",
      "19:50 madminer.utils.ml.sc INFO                val. loss  0.0278 (mse_score: 0.0278) (*)\n",
      "19:50 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.1447 (mse_score: 0.1447)\n",
      "19:50 madminer.utils.ml.sc INFO                val. loss  0.0276 (mse_score: 0.0276) (*)\n",
      "19:51 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.1440 (mse_score: 0.1440)\n",
      "19:51 madminer.utils.ml.sc INFO                val. loss  0.0276 (mse_score: 0.0276) (*)\n",
      "19:51 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.1434 (mse_score: 0.1434)\n",
      "19:51 madminer.utils.ml.sc INFO                val. loss  0.0273 (mse_score: 0.0273) (*)\n",
      "19:52 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.1426 (mse_score: 0.1426)\n",
      "19:52 madminer.utils.ml.sc INFO                val. loss  0.0270 (mse_score: 0.0270) (*)\n",
      "19:52 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.1422 (mse_score: 0.1422)\n",
      "19:52 madminer.utils.ml.sc INFO                val. loss  0.0269 (mse_score: 0.0269) (*)\n",
      "19:52 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.1416 (mse_score: 0.1416)\n",
      "19:52 madminer.utils.ml.sc INFO                val. loss  0.0275 (mse_score: 0.0275)\n",
      "19:53 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.1412 (mse_score: 0.1412)\n",
      "19:53 madminer.utils.ml.sc INFO                val. loss  0.0268 (mse_score: 0.0268) (*)\n",
      "19:53 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.1408 (mse_score: 0.1408)\n",
      "19:53 madminer.utils.ml.sc INFO                val. loss  0.0268 (mse_score: 0.0268) (*)\n",
      "19:54 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.1403 (mse_score: 0.1403)\n",
      "19:54 madminer.utils.ml.sc INFO                val. loss  0.0267 (mse_score: 0.0267) (*)\n",
      "19:54 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.1399 (mse_score: 0.1399)\n",
      "19:54 madminer.utils.ml.sc INFO                val. loss  0.0262 (mse_score: 0.0262) (*)\n",
      "19:54 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.1395 (mse_score: 0.1395)\n",
      "19:54 madminer.utils.ml.sc INFO                val. loss  0.0261 (mse_score: 0.0261) (*)\n",
      "19:55 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.1392 (mse_score: 0.1392)\n",
      "19:55 madminer.utils.ml.sc INFO                val. loss  0.0267 (mse_score: 0.0267)\n",
      "19:55 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.1388 (mse_score: 0.1388)\n",
      "19:55 madminer.utils.ml.sc INFO                val. loss  0.0260 (mse_score: 0.0260) (*)\n",
      "19:56 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.1385 (mse_score: 0.1385)\n",
      "19:56 madminer.utils.ml.sc INFO                val. loss  0.0259 (mse_score: 0.0259) (*)\n",
      "19:56 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.1382 (mse_score: 0.1382)\n",
      "19:56 madminer.utils.ml.sc INFO                val. loss  0.0259 (mse_score: 0.0259)\n",
      "19:57 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.1380 (mse_score: 0.1380)\n",
      "19:57 madminer.utils.ml.sc INFO                val. loss  0.0258 (mse_score: 0.0258) (*)\n",
      "19:57 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.1377 (mse_score: 0.1377)\n",
      "19:57 madminer.utils.ml.sc INFO                val. loss  0.0259 (mse_score: 0.0259)\n",
      "19:57 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.1374 (mse_score: 0.1374)\n",
      "19:57 madminer.utils.ml.sc INFO                val. loss  0.0257 (mse_score: 0.0257) (*)\n",
      "19:58 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.1372 (mse_score: 0.1372)\n",
      "19:58 madminer.utils.ml.sc INFO                val. loss  0.0256 (mse_score: 0.0256) (*)\n",
      "19:58 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.1369 (mse_score: 0.1369)\n",
      "19:58 madminer.utils.ml.sc INFO                val. loss  0.0255 (mse_score: 0.0255) (*)\n",
      "19:59 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.1367 (mse_score: 0.1367)\n",
      "19:59 madminer.utils.ml.sc INFO                val. loss  0.0255 (mse_score: 0.0255) (*)\n",
      "19:59 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.1365 (mse_score: 0.1365)\n",
      "19:59 madminer.utils.ml.sc INFO                val. loss  0.0254 (mse_score: 0.0254) (*)\n",
      "20:00 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.1363 (mse_score: 0.1363)\n",
      "20:00 madminer.utils.ml.sc INFO                val. loss  0.0259 (mse_score: 0.0259)\n",
      "20:00 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.1362 (mse_score: 0.1362)\n",
      "20:00 madminer.utils.ml.sc INFO                val. loss  0.0256 (mse_score: 0.0256)\n",
      "20:00 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.1360 (mse_score: 0.1360)\n",
      "20:00 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253) (*)\n",
      "20:01 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.1358 (mse_score: 0.1358)\n",
      "20:01 madminer.utils.ml.sc INFO                val. loss  0.0255 (mse_score: 0.0255)\n",
      "20:01 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.1357 (mse_score: 0.1357)\n",
      "20:01 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253) (*)\n",
      "20:02 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.1355 (mse_score: 0.1355)\n",
      "20:02 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253) (*)\n",
      "20:02 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.1354 (mse_score: 0.1354)\n",
      "20:02 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253) (*)\n",
      "20:02 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.1352 (mse_score: 0.1352)\n",
      "20:02 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253)\n",
      "20:03 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.1351 (mse_score: 0.1351)\n",
      "20:03 madminer.utils.ml.sc INFO                val. loss  0.0251 (mse_score: 0.0251) (*)\n",
      "20:03 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.1350 (mse_score: 0.1350)\n",
      "20:03 madminer.utils.ml.sc INFO                val. loss  0.0252 (mse_score: 0.0252)\n",
      "20:03 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 0.03 compared to final loss 0.03\n",
      "20:03 madminer.utils.ml.sc INFO    Finished training\n",
      "20:03 madminer.ml          INFO    Training estimator 7 / 10 in ensemble\n",
      "20:03 madminer.ml          INFO    Starting training\n",
      "20:03 madminer.ml          INFO      Method:                 sally\n",
      "20:03 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_6.npy\n",
      "20:03 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_6.npy\n",
      "20:03 madminer.ml          INFO      Features:               all\n",
      "20:03 madminer.ml          INFO      Method:                 sally\n",
      "20:03 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "20:03 madminer.ml          INFO      Activation function:    tanh\n",
      "20:03 madminer.ml          INFO      Batch size:             128\n",
      "20:03 madminer.ml          INFO      Trainer:                amsgrad\n",
      "20:03 madminer.ml          INFO      Epochs:                 50\n",
      "20:03 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "20:03 madminer.ml          INFO      Validation split:       0.5\n",
      "20:03 madminer.ml          INFO      Early stopping:         True\n",
      "20:03 madminer.ml          INFO      Scale inputs:           True\n",
      "20:03 madminer.ml          INFO      Shuffle labels          False\n",
      "20:03 madminer.ml          INFO      Regularization:         None\n",
      "20:03 madminer.ml          INFO      Samples:                all\n",
      "20:03 madminer.ml          INFO    Loading training data\n",
      "20:03 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "20:03 madminer.ml          INFO    Rescaling inputs\n",
      "20:03 madminer.ml          INFO    Creating model for method sally\n",
      "20:03 madminer.ml          INFO    Training model\n",
      "20:04 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0779 (mse_score: 0.0779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:04 madminer.utils.ml.sc INFO                val. loss  0.0603 (mse_score: 0.0603) (*)\n",
      "20:04 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0561 (mse_score: 0.0561)\n",
      "20:04 madminer.utils.ml.sc INFO                val. loss  0.0477 (mse_score: 0.0477) (*)\n",
      "20:05 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0448 (mse_score: 0.0448)\n",
      "20:05 madminer.utils.ml.sc INFO                val. loss  0.0405 (mse_score: 0.0405) (*)\n",
      "20:05 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0393 (mse_score: 0.0393)\n",
      "20:05 madminer.utils.ml.sc INFO                val. loss  0.0364 (mse_score: 0.0364) (*)\n",
      "20:05 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0355 (mse_score: 0.0355)\n",
      "20:05 madminer.utils.ml.sc INFO                val. loss  0.0344 (mse_score: 0.0344) (*)\n",
      "20:06 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0330 (mse_score: 0.0330)\n",
      "20:06 madminer.utils.ml.sc INFO                val. loss  0.0357 (mse_score: 0.0357)\n",
      "20:06 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0310 (mse_score: 0.0310)\n",
      "20:06 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "20:07 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0294 (mse_score: 0.0294)\n",
      "20:07 madminer.utils.ml.sc INFO                val. loss  0.0311 (mse_score: 0.0311) (*)\n",
      "20:07 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0282 (mse_score: 0.0282)\n",
      "20:07 madminer.utils.ml.sc INFO                val. loss  0.0305 (mse_score: 0.0305) (*)\n",
      "20:07 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0271 (mse_score: 0.0271)\n",
      "20:07 madminer.utils.ml.sc INFO                val. loss  0.0294 (mse_score: 0.0294) (*)\n",
      "20:08 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0259 (mse_score: 0.0259)\n",
      "20:08 madminer.utils.ml.sc INFO                val. loss  0.0291 (mse_score: 0.0291) (*)\n",
      "20:08 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0253 (mse_score: 0.0253)\n",
      "20:08 madminer.utils.ml.sc INFO                val. loss  0.0305 (mse_score: 0.0305)\n",
      "20:09 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0244 (mse_score: 0.0244)\n",
      "20:09 madminer.utils.ml.sc INFO                val. loss  0.0290 (mse_score: 0.0290) (*)\n",
      "20:09 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0238 (mse_score: 0.0238)\n",
      "20:09 madminer.utils.ml.sc INFO                val. loss  0.0278 (mse_score: 0.0278) (*)\n",
      "20:10 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0232 (mse_score: 0.0232)\n",
      "20:10 madminer.utils.ml.sc INFO                val. loss  0.0283 (mse_score: 0.0283)\n",
      "20:10 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0225 (mse_score: 0.0225)\n",
      "20:10 madminer.utils.ml.sc INFO                val. loss  0.0273 (mse_score: 0.0273) (*)\n",
      "20:10 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0221 (mse_score: 0.0221)\n",
      "20:10 madminer.utils.ml.sc INFO                val. loss  0.0284 (mse_score: 0.0284)\n",
      "20:11 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0216 (mse_score: 0.0216)\n",
      "20:11 madminer.utils.ml.sc INFO                val. loss  0.0268 (mse_score: 0.0268) (*)\n",
      "20:11 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0212 (mse_score: 0.0212)\n",
      "20:11 madminer.utils.ml.sc INFO                val. loss  0.0267 (mse_score: 0.0267) (*)\n",
      "20:12 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0208 (mse_score: 0.0208)\n",
      "20:12 madminer.utils.ml.sc INFO                val. loss  0.0270 (mse_score: 0.0270)\n",
      "20:12 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0204 (mse_score: 0.0204)\n",
      "20:12 madminer.utils.ml.sc INFO                val. loss  0.0269 (mse_score: 0.0269)\n",
      "20:12 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0202 (mse_score: 0.0202)\n",
      "20:12 madminer.utils.ml.sc INFO                val. loss  0.0264 (mse_score: 0.0264) (*)\n",
      "20:13 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0198 (mse_score: 0.0198)\n",
      "20:13 madminer.utils.ml.sc INFO                val. loss  0.0264 (mse_score: 0.0264) (*)\n",
      "20:13 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0195 (mse_score: 0.0195)\n",
      "20:13 madminer.utils.ml.sc INFO                val. loss  0.0262 (mse_score: 0.0262) (*)\n",
      "20:14 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0192 (mse_score: 0.0192)\n",
      "20:14 madminer.utils.ml.sc INFO                val. loss  0.0258 (mse_score: 0.0258) (*)\n",
      "20:14 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0190 (mse_score: 0.0190)\n",
      "20:14 madminer.utils.ml.sc INFO                val. loss  0.0258 (mse_score: 0.0258) (*)\n",
      "20:15 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0188 (mse_score: 0.0188)\n",
      "20:15 madminer.utils.ml.sc INFO                val. loss  0.0256 (mse_score: 0.0256) (*)\n",
      "20:15 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0185 (mse_score: 0.0185)\n",
      "20:15 madminer.utils.ml.sc INFO                val. loss  0.0254 (mse_score: 0.0254) (*)\n",
      "20:15 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0184 (mse_score: 0.0184)\n",
      "20:15 madminer.utils.ml.sc INFO                val. loss  0.0256 (mse_score: 0.0256)\n",
      "20:16 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0182 (mse_score: 0.0182)\n",
      "20:16 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253) (*)\n",
      "20:16 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0180 (mse_score: 0.0180)\n",
      "20:16 madminer.utils.ml.sc INFO                val. loss  0.0254 (mse_score: 0.0254)\n",
      "20:17 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0178 (mse_score: 0.0178)\n",
      "20:17 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253) (*)\n",
      "20:17 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0176 (mse_score: 0.0176)\n",
      "20:17 madminer.utils.ml.sc INFO                val. loss  0.0253 (mse_score: 0.0253)\n",
      "20:17 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0176 (mse_score: 0.0176)\n",
      "20:17 madminer.utils.ml.sc INFO                val. loss  0.0250 (mse_score: 0.0250) (*)\n",
      "20:18 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0174 (mse_score: 0.0174)\n",
      "20:18 madminer.utils.ml.sc INFO                val. loss  0.0250 (mse_score: 0.0250) (*)\n",
      "20:18 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0173 (mse_score: 0.0173)\n",
      "20:18 madminer.utils.ml.sc INFO                val. loss  0.0249 (mse_score: 0.0249) (*)\n",
      "20:19 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0172 (mse_score: 0.0172)\n",
      "20:19 madminer.utils.ml.sc INFO                val. loss  0.0250 (mse_score: 0.0250)\n",
      "20:19 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0170 (mse_score: 0.0170)\n",
      "20:19 madminer.utils.ml.sc INFO                val. loss  0.0251 (mse_score: 0.0251)\n",
      "20:20 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0169 (mse_score: 0.0169)\n",
      "20:20 madminer.utils.ml.sc INFO                val. loss  0.0248 (mse_score: 0.0248) (*)\n",
      "20:20 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0168 (mse_score: 0.0168)\n",
      "20:20 madminer.utils.ml.sc INFO                val. loss  0.0249 (mse_score: 0.0249)\n",
      "20:20 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0167 (mse_score: 0.0167)\n",
      "20:20 madminer.utils.ml.sc INFO                val. loss  0.0248 (mse_score: 0.0248) (*)\n",
      "20:21 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0166 (mse_score: 0.0166)\n",
      "20:21 madminer.utils.ml.sc INFO                val. loss  0.0249 (mse_score: 0.0249)\n",
      "20:21 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0165 (mse_score: 0.0165)\n",
      "20:21 madminer.utils.ml.sc INFO                val. loss  0.0248 (mse_score: 0.0248)\n",
      "20:22 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0164 (mse_score: 0.0164)\n",
      "20:22 madminer.utils.ml.sc INFO                val. loss  0.0246 (mse_score: 0.0246) (*)\n",
      "20:22 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0163 (mse_score: 0.0163)\n",
      "20:22 madminer.utils.ml.sc INFO                val. loss  0.0248 (mse_score: 0.0248)\n",
      "20:22 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0163 (mse_score: 0.0163)\n",
      "20:22 madminer.utils.ml.sc INFO                val. loss  0.0246 (mse_score: 0.0246) (*)\n",
      "20:23 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0162 (mse_score: 0.0162)\n",
      "20:23 madminer.utils.ml.sc INFO                val. loss  0.0247 (mse_score: 0.0247)\n",
      "20:23 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0161 (mse_score: 0.0161)\n",
      "20:23 madminer.utils.ml.sc INFO                val. loss  0.0248 (mse_score: 0.0248)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0160 (mse_score: 0.0160)\n",
      "20:24 madminer.utils.ml.sc INFO                val. loss  0.0245 (mse_score: 0.0245) (*)\n",
      "20:24 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0160 (mse_score: 0.0160)\n",
      "20:24 madminer.utils.ml.sc INFO                val. loss  0.0246 (mse_score: 0.0246)\n",
      "20:24 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 0.02 compared to final loss 0.02\n",
      "20:24 madminer.utils.ml.sc INFO    Finished training\n",
      "20:24 madminer.ml          INFO    Training estimator 8 / 10 in ensemble\n",
      "20:24 madminer.ml          INFO    Starting training\n",
      "20:24 madminer.ml          INFO      Method:                 sally\n",
      "20:24 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_7.npy\n",
      "20:24 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_7.npy\n",
      "20:24 madminer.ml          INFO      Features:               all\n",
      "20:24 madminer.ml          INFO      Method:                 sally\n",
      "20:24 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "20:24 madminer.ml          INFO      Activation function:    tanh\n",
      "20:24 madminer.ml          INFO      Batch size:             128\n",
      "20:24 madminer.ml          INFO      Trainer:                amsgrad\n",
      "20:24 madminer.ml          INFO      Epochs:                 50\n",
      "20:24 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "20:24 madminer.ml          INFO      Validation split:       0.5\n",
      "20:24 madminer.ml          INFO      Early stopping:         True\n",
      "20:24 madminer.ml          INFO      Scale inputs:           True\n",
      "20:24 madminer.ml          INFO      Shuffle labels          False\n",
      "20:24 madminer.ml          INFO      Regularization:         None\n",
      "20:24 madminer.ml          INFO      Samples:                all\n",
      "20:24 madminer.ml          INFO    Loading training data\n",
      "20:24 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "20:24 madminer.ml          INFO    Rescaling inputs\n",
      "20:24 madminer.ml          INFO    Creating model for method sally\n",
      "20:24 madminer.ml          INFO    Training model\n",
      "20:25 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0941 (mse_score: 0.0941)\n",
      "20:25 madminer.utils.ml.sc INFO                val. loss  0.0588 (mse_score: 0.0588) (*)\n",
      "20:25 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0731 (mse_score: 0.0731)\n",
      "20:25 madminer.utils.ml.sc INFO                val. loss  0.0452 (mse_score: 0.0452) (*)\n",
      "20:25 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0619 (mse_score: 0.0619)\n",
      "20:25 madminer.utils.ml.sc INFO                val. loss  0.0374 (mse_score: 0.0374) (*)\n",
      "20:26 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0558 (mse_score: 0.0558)\n",
      "20:26 madminer.utils.ml.sc INFO                val. loss  0.0336 (mse_score: 0.0336) (*)\n",
      "20:26 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0520 (mse_score: 0.0520)\n",
      "20:26 madminer.utils.ml.sc INFO                val. loss  0.0310 (mse_score: 0.0310) (*)\n",
      "20:26 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0487 (mse_score: 0.0487)\n",
      "20:26 madminer.utils.ml.sc INFO                val. loss  0.0306 (mse_score: 0.0306) (*)\n",
      "20:27 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0468 (mse_score: 0.0468)\n",
      "20:27 madminer.utils.ml.sc INFO                val. loss  0.0506 (mse_score: 0.0506)\n",
      "20:27 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0446 (mse_score: 0.0446)\n",
      "20:27 madminer.utils.ml.sc INFO                val. loss  0.0282 (mse_score: 0.0282) (*)\n",
      "20:28 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0435 (mse_score: 0.0435)\n",
      "20:28 madminer.utils.ml.sc INFO                val. loss  0.0269 (mse_score: 0.0269) (*)\n",
      "20:28 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0418 (mse_score: 0.0418)\n",
      "20:28 madminer.utils.ml.sc INFO                val. loss  0.0275 (mse_score: 0.0275)\n",
      "20:47 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0408 (mse_score: 0.0408)\n",
      "20:47 madminer.utils.ml.sc INFO                val. loss  0.0267 (mse_score: 0.0267) (*)\n",
      "20:47 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0398 (mse_score: 0.0398)\n",
      "20:47 madminer.utils.ml.sc INFO                val. loss  0.0260 (mse_score: 0.0260) (*)\n",
      "21:27 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0389 (mse_score: 0.0389)\n",
      "21:27 madminer.utils.ml.sc INFO                val. loss  0.0252 (mse_score: 0.0252) (*)\n",
      "21:28 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0381 (mse_score: 0.0381)\n",
      "21:28 madminer.utils.ml.sc INFO                val. loss  0.0271 (mse_score: 0.0271)\n",
      "22:05 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0371 (mse_score: 0.0371)\n",
      "22:05 madminer.utils.ml.sc INFO                val. loss  0.0251 (mse_score: 0.0251) (*)\n",
      "22:05 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0364 (mse_score: 0.0364)\n",
      "22:05 madminer.utils.ml.sc INFO                val. loss  0.0249 (mse_score: 0.0249) (*)\n",
      "22:06 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0357 (mse_score: 0.0357)\n",
      "22:06 madminer.utils.ml.sc INFO                val. loss  0.0242 (mse_score: 0.0242) (*)\n",
      "22:37 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0350 (mse_score: 0.0350)\n",
      "22:37 madminer.utils.ml.sc INFO                val. loss  0.0242 (mse_score: 0.0242) (*)\n",
      "22:37 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0343 (mse_score: 0.0343)\n",
      "22:37 madminer.utils.ml.sc INFO                val. loss  0.0245 (mse_score: 0.0245)\n",
      "23:15 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0341 (mse_score: 0.0341)\n",
      "23:15 madminer.utils.ml.sc INFO                val. loss  0.0238 (mse_score: 0.0238) (*)\n",
      "23:16 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0336 (mse_score: 0.0336)\n",
      "23:16 madminer.utils.ml.sc INFO                val. loss  0.0237 (mse_score: 0.0237) (*)\n",
      "23:16 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0331 (mse_score: 0.0331)\n",
      "23:16 madminer.utils.ml.sc INFO                val. loss  0.0241 (mse_score: 0.0241)\n",
      "23:51 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0327 (mse_score: 0.0327)\n",
      "23:51 madminer.utils.ml.sc INFO                val. loss  0.0233 (mse_score: 0.0233) (*)\n",
      "23:52 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0324 (mse_score: 0.0324)\n",
      "23:52 madminer.utils.ml.sc INFO                val. loss  0.0277 (mse_score: 0.0277)\n",
      "00:25 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0320 (mse_score: 0.0320)\n",
      "00:25 madminer.utils.ml.sc INFO                val. loss  0.0231 (mse_score: 0.0231) (*)\n",
      "00:26 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0316 (mse_score: 0.0316)\n",
      "00:26 madminer.utils.ml.sc INFO                val. loss  0.0234 (mse_score: 0.0234)\n",
      "01:03 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0313 (mse_score: 0.0313)\n",
      "01:03 madminer.utils.ml.sc INFO                val. loss  0.0232 (mse_score: 0.0232)\n",
      "01:03 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0311 (mse_score: 0.0311)\n",
      "01:03 madminer.utils.ml.sc INFO                val. loss  0.0233 (mse_score: 0.0233)\n",
      "01:04 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0308 (mse_score: 0.0308)\n",
      "01:04 madminer.utils.ml.sc INFO                val. loss  0.0227 (mse_score: 0.0227) (*)\n",
      "01:35 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0305 (mse_score: 0.0305)\n",
      "01:35 madminer.utils.ml.sc INFO                val. loss  0.0229 (mse_score: 0.0229)\n",
      "01:35 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0302 (mse_score: 0.0302)\n",
      "01:35 madminer.utils.ml.sc INFO                val. loss  0.0231 (mse_score: 0.0231)\n",
      "02:08 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0300 (mse_score: 0.0300)\n",
      "02:08 madminer.utils.ml.sc INFO                val. loss  0.0225 (mse_score: 0.0225) (*)\n",
      "02:08 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0298 (mse_score: 0.0298)\n",
      "02:08 madminer.utils.ml.sc INFO                val. loss  0.0226 (mse_score: 0.0226)\n",
      "02:09 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0296 (mse_score: 0.0296)\n",
      "02:09 madminer.utils.ml.sc INFO                val. loss  0.0227 (mse_score: 0.0227)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:09 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0294 (mse_score: 0.0294)\n",
      "02:09 madminer.utils.ml.sc INFO                val. loss  0.0223 (mse_score: 0.0223) (*)\n",
      "02:10 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0292 (mse_score: 0.0292)\n",
      "02:10 madminer.utils.ml.sc INFO                val. loss  0.0224 (mse_score: 0.0224)\n",
      "02:10 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0290 (mse_score: 0.0290)\n",
      "02:10 madminer.utils.ml.sc INFO                val. loss  0.0228 (mse_score: 0.0228)\n",
      "02:10 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0288 (mse_score: 0.0288)\n",
      "02:10 madminer.utils.ml.sc INFO                val. loss  0.0224 (mse_score: 0.0224)\n",
      "02:11 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0287 (mse_score: 0.0287)\n",
      "02:11 madminer.utils.ml.sc INFO                val. loss  0.0222 (mse_score: 0.0222) (*)\n",
      "02:11 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0285 (mse_score: 0.0285)\n",
      "02:11 madminer.utils.ml.sc INFO                val. loss  0.0223 (mse_score: 0.0223)\n",
      "02:11 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0283 (mse_score: 0.0283)\n",
      "02:11 madminer.utils.ml.sc INFO                val. loss  0.0224 (mse_score: 0.0224)\n",
      "02:12 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0282 (mse_score: 0.0282)\n",
      "02:12 madminer.utils.ml.sc INFO                val. loss  0.0223 (mse_score: 0.0223)\n",
      "02:12 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0281 (mse_score: 0.0281)\n",
      "02:12 madminer.utils.ml.sc INFO                val. loss  0.0221 (mse_score: 0.0221) (*)\n",
      "02:13 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0279 (mse_score: 0.0279)\n",
      "02:13 madminer.utils.ml.sc INFO                val. loss  0.0224 (mse_score: 0.0224)\n",
      "02:13 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0279 (mse_score: 0.0279)\n",
      "02:13 madminer.utils.ml.sc INFO                val. loss  0.0223 (mse_score: 0.0223)\n",
      "02:13 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0277 (mse_score: 0.0277)\n",
      "02:13 madminer.utils.ml.sc INFO                val. loss  0.0230 (mse_score: 0.0230)\n",
      "02:14 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0277 (mse_score: 0.0277)\n",
      "02:14 madminer.utils.ml.sc INFO                val. loss  0.0220 (mse_score: 0.0220) (*)\n",
      "02:14 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0275 (mse_score: 0.0275)\n",
      "02:14 madminer.utils.ml.sc INFO                val. loss  0.0221 (mse_score: 0.0221)\n",
      "02:14 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0274 (mse_score: 0.0274)\n",
      "02:14 madminer.utils.ml.sc INFO                val. loss  0.0221 (mse_score: 0.0221)\n",
      "02:15 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0273 (mse_score: 0.0273)\n",
      "02:15 madminer.utils.ml.sc INFO                val. loss  0.0221 (mse_score: 0.0221)\n",
      "02:15 madminer.utils.ml.sc INFO    Early stopping after epoch 47, with loss 0.02 compared to final loss 0.02\n",
      "02:15 madminer.utils.ml.sc INFO    Finished training\n",
      "02:15 madminer.ml          INFO    Training estimator 9 / 10 in ensemble\n",
      "02:15 madminer.ml          INFO    Starting training\n",
      "02:15 madminer.ml          INFO      Method:                 sally\n",
      "02:15 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_8.npy\n",
      "02:15 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_8.npy\n",
      "02:15 madminer.ml          INFO      Features:               all\n",
      "02:15 madminer.ml          INFO      Method:                 sally\n",
      "02:15 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "02:15 madminer.ml          INFO      Activation function:    tanh\n",
      "02:15 madminer.ml          INFO      Batch size:             128\n",
      "02:15 madminer.ml          INFO      Trainer:                amsgrad\n",
      "02:15 madminer.ml          INFO      Epochs:                 50\n",
      "02:15 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "02:15 madminer.ml          INFO      Validation split:       0.5\n",
      "02:15 madminer.ml          INFO      Early stopping:         True\n",
      "02:15 madminer.ml          INFO      Scale inputs:           True\n",
      "02:15 madminer.ml          INFO      Shuffle labels          False\n",
      "02:15 madminer.ml          INFO      Regularization:         None\n",
      "02:15 madminer.ml          INFO      Samples:                all\n",
      "02:15 madminer.ml          INFO    Loading training data\n",
      "02:15 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "02:15 madminer.ml          INFO    Rescaling inputs\n",
      "02:15 madminer.ml          INFO    Creating model for method sally\n",
      "02:15 madminer.ml          INFO    Training model\n",
      "02:15 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0715 (mse_score: 0.0715)\n",
      "02:15 madminer.utils.ml.sc INFO                val. loss  0.0715 (mse_score: 0.0715) (*)\n",
      "02:16 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0536 (mse_score: 0.0536)\n",
      "02:16 madminer.utils.ml.sc INFO                val. loss  0.0565 (mse_score: 0.0565) (*)\n",
      "02:16 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0413 (mse_score: 0.0413)\n",
      "02:16 madminer.utils.ml.sc INFO                val. loss  0.0485 (mse_score: 0.0485) (*)\n",
      "02:16 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0352 (mse_score: 0.0352)\n",
      "02:16 madminer.utils.ml.sc INFO                val. loss  0.0454 (mse_score: 0.0454) (*)\n",
      "02:17 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0328 (mse_score: 0.0328)\n",
      "02:17 madminer.utils.ml.sc INFO                val. loss  0.0409 (mse_score: 0.0409) (*)\n",
      "02:17 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0301 (mse_score: 0.0301)\n",
      "02:17 madminer.utils.ml.sc INFO                val. loss  0.0397 (mse_score: 0.0397) (*)\n",
      "02:17 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0286 (mse_score: 0.0286)\n",
      "02:17 madminer.utils.ml.sc INFO                val. loss  0.0387 (mse_score: 0.0387) (*)\n",
      "02:18 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0272 (mse_score: 0.0272)\n",
      "02:18 madminer.utils.ml.sc INFO                val. loss  0.0386 (mse_score: 0.0386) (*)\n",
      "02:18 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0260 (mse_score: 0.0260)\n",
      "02:18 madminer.utils.ml.sc INFO                val. loss  0.0398 (mse_score: 0.0398)\n",
      "02:18 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0251 (mse_score: 0.0251)\n",
      "02:18 madminer.utils.ml.sc INFO                val. loss  0.0367 (mse_score: 0.0367) (*)\n",
      "02:19 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0241 (mse_score: 0.0241)\n",
      "02:19 madminer.utils.ml.sc INFO                val. loss  0.0371 (mse_score: 0.0371)\n",
      "02:19 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0233 (mse_score: 0.0233)\n",
      "02:19 madminer.utils.ml.sc INFO                val. loss  0.0356 (mse_score: 0.0356) (*)\n",
      "02:19 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0227 (mse_score: 0.0227)\n",
      "02:19 madminer.utils.ml.sc INFO                val. loss  0.0350 (mse_score: 0.0350) (*)\n",
      "02:20 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0222 (mse_score: 0.0222)\n",
      "02:20 madminer.utils.ml.sc INFO                val. loss  0.0356 (mse_score: 0.0356)\n",
      "02:20 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0215 (mse_score: 0.0215)\n",
      "02:20 madminer.utils.ml.sc INFO                val. loss  0.0349 (mse_score: 0.0349) (*)\n",
      "02:21 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0211 (mse_score: 0.0211)\n",
      "02:21 madminer.utils.ml.sc INFO                val. loss  0.0344 (mse_score: 0.0344) (*)\n",
      "02:21 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0206 (mse_score: 0.0206)\n",
      "02:21 madminer.utils.ml.sc INFO                val. loss  0.0344 (mse_score: 0.0344) (*)\n",
      "02:21 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0203 (mse_score: 0.0203)\n",
      "02:21 madminer.utils.ml.sc INFO                val. loss  0.0339 (mse_score: 0.0339) (*)\n",
      "02:22 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0199 (mse_score: 0.0199)\n",
      "02:22 madminer.utils.ml.sc INFO                val. loss  0.0338 (mse_score: 0.0338) (*)\n",
      "02:22 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0196 (mse_score: 0.0196)\n",
      "02:22 madminer.utils.ml.sc INFO                val. loss  0.0334 (mse_score: 0.0334) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:22 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0193 (mse_score: 0.0193)\n",
      "02:22 madminer.utils.ml.sc INFO                val. loss  0.0333 (mse_score: 0.0333) (*)\n",
      "02:23 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0190 (mse_score: 0.0190)\n",
      "02:23 madminer.utils.ml.sc INFO                val. loss  0.0330 (mse_score: 0.0330) (*)\n",
      "02:23 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0187 (mse_score: 0.0187)\n",
      "02:23 madminer.utils.ml.sc INFO                val. loss  0.0341 (mse_score: 0.0341)\n",
      "02:23 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0185 (mse_score: 0.0185)\n",
      "02:23 madminer.utils.ml.sc INFO                val. loss  0.0331 (mse_score: 0.0331)\n",
      "02:24 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0184 (mse_score: 0.0184)\n",
      "02:24 madminer.utils.ml.sc INFO                val. loss  0.0328 (mse_score: 0.0328) (*)\n",
      "02:24 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0181 (mse_score: 0.0181)\n",
      "02:24 madminer.utils.ml.sc INFO                val. loss  0.0326 (mse_score: 0.0326) (*)\n",
      "02:24 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0179 (mse_score: 0.0179)\n",
      "02:24 madminer.utils.ml.sc INFO                val. loss  0.0341 (mse_score: 0.0341)\n",
      "02:25 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0178 (mse_score: 0.0178)\n",
      "02:25 madminer.utils.ml.sc INFO                val. loss  0.0327 (mse_score: 0.0327)\n",
      "02:25 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0176 (mse_score: 0.0176)\n",
      "02:25 madminer.utils.ml.sc INFO                val. loss  0.0324 (mse_score: 0.0324) (*)\n",
      "02:26 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0174 (mse_score: 0.0174)\n",
      "02:26 madminer.utils.ml.sc INFO                val. loss  0.0325 (mse_score: 0.0325)\n",
      "02:26 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0173 (mse_score: 0.0173)\n",
      "02:26 madminer.utils.ml.sc INFO                val. loss  0.0322 (mse_score: 0.0322) (*)\n",
      "02:26 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0171 (mse_score: 0.0171)\n",
      "02:26 madminer.utils.ml.sc INFO                val. loss  0.0324 (mse_score: 0.0324)\n",
      "02:27 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0170 (mse_score: 0.0170)\n",
      "02:27 madminer.utils.ml.sc INFO                val. loss  0.0321 (mse_score: 0.0321) (*)\n",
      "02:27 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0169 (mse_score: 0.0169)\n",
      "02:27 madminer.utils.ml.sc INFO                val. loss  0.0321 (mse_score: 0.0321) (*)\n",
      "02:28 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0168 (mse_score: 0.0168)\n",
      "02:28 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "02:28 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0167 (mse_score: 0.0167)\n",
      "02:28 madminer.utils.ml.sc INFO                val. loss  0.0321 (mse_score: 0.0321)\n",
      "02:28 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0166 (mse_score: 0.0166)\n",
      "02:28 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "02:29 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0165 (mse_score: 0.0165)\n",
      "02:29 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "02:29 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0164 (mse_score: 0.0164)\n",
      "02:29 madminer.utils.ml.sc INFO                val. loss  0.0319 (mse_score: 0.0319) (*)\n",
      "02:30 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0163 (mse_score: 0.0163)\n",
      "02:30 madminer.utils.ml.sc INFO                val. loss  0.0318 (mse_score: 0.0318) (*)\n",
      "02:30 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0162 (mse_score: 0.0162)\n",
      "02:30 madminer.utils.ml.sc INFO                val. loss  0.0318 (mse_score: 0.0318) (*)\n",
      "02:30 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0162 (mse_score: 0.0162)\n",
      "02:30 madminer.utils.ml.sc INFO                val. loss  0.0318 (mse_score: 0.0318) (*)\n",
      "02:31 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0161 (mse_score: 0.0161)\n",
      "02:31 madminer.utils.ml.sc INFO                val. loss  0.0319 (mse_score: 0.0319)\n",
      "02:31 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0160 (mse_score: 0.0160)\n",
      "02:31 madminer.utils.ml.sc INFO                val. loss  0.0318 (mse_score: 0.0318) (*)\n",
      "02:32 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0160 (mse_score: 0.0160)\n",
      "02:32 madminer.utils.ml.sc INFO                val. loss  0.0317 (mse_score: 0.0317) (*)\n",
      "02:32 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0159 (mse_score: 0.0159)\n",
      "02:32 madminer.utils.ml.sc INFO                val. loss  0.0318 (mse_score: 0.0318)\n",
      "02:32 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0158 (mse_score: 0.0158)\n",
      "02:32 madminer.utils.ml.sc INFO                val. loss  0.0317 (mse_score: 0.0317) (*)\n",
      "02:33 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0158 (mse_score: 0.0158)\n",
      "02:33 madminer.utils.ml.sc INFO                val. loss  0.0316 (mse_score: 0.0316) (*)\n",
      "02:33 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0157 (mse_score: 0.0157)\n",
      "02:33 madminer.utils.ml.sc INFO                val. loss  0.0317 (mse_score: 0.0317)\n",
      "02:34 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0157 (mse_score: 0.0157)\n",
      "02:34 madminer.utils.ml.sc INFO                val. loss  0.0316 (mse_score: 0.0316)\n",
      "02:34 madminer.utils.ml.sc INFO    Early stopping after epoch 48, with loss 0.03 compared to final loss 0.03\n",
      "02:34 madminer.utils.ml.sc INFO    Finished training\n",
      "02:34 madminer.ml          INFO    Training estimator 10 / 10 in ensemble\n",
      "02:34 madminer.ml          INFO    Starting training\n",
      "02:34 madminer.ml          INFO      Method:                 sally\n",
      "02:34 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/x_train_9.npy\n",
      "02:34 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_antitight/t_xz_train_9.npy\n",
      "02:34 madminer.ml          INFO      Features:               all\n",
      "02:34 madminer.ml          INFO      Method:                 sally\n",
      "02:34 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "02:34 madminer.ml          INFO      Activation function:    tanh\n",
      "02:34 madminer.ml          INFO      Batch size:             128\n",
      "02:34 madminer.ml          INFO      Trainer:                amsgrad\n",
      "02:34 madminer.ml          INFO      Epochs:                 50\n",
      "02:34 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "02:34 madminer.ml          INFO      Validation split:       0.5\n",
      "02:34 madminer.ml          INFO      Early stopping:         True\n",
      "02:34 madminer.ml          INFO      Scale inputs:           True\n",
      "02:34 madminer.ml          INFO      Shuffle labels          False\n",
      "02:34 madminer.ml          INFO      Regularization:         None\n",
      "02:34 madminer.ml          INFO      Samples:                all\n",
      "02:34 madminer.ml          INFO    Loading training data\n",
      "02:34 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "02:34 madminer.ml          INFO    Rescaling inputs\n",
      "02:34 madminer.ml          INFO    Creating model for method sally\n",
      "02:34 madminer.ml          INFO    Training model\n",
      "02:34 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0900 (mse_score: 0.0900)\n",
      "02:34 madminer.utils.ml.sc INFO                val. loss  0.0820 (mse_score: 0.0820) (*)\n",
      "02:34 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0718 (mse_score: 0.0718)\n",
      "02:34 madminer.utils.ml.sc INFO                val. loss  0.0536 (mse_score: 0.0536) (*)\n",
      "02:35 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0622 (mse_score: 0.0622)\n",
      "02:35 madminer.utils.ml.sc INFO                val. loss  0.0460 (mse_score: 0.0460) (*)\n",
      "02:35 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0565 (mse_score: 0.0565)\n",
      "02:35 madminer.utils.ml.sc INFO                val. loss  0.0438 (mse_score: 0.0438) (*)\n",
      "02:35 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0530 (mse_score: 0.0530)\n",
      "02:35 madminer.utils.ml.sc INFO                val. loss  0.0415 (mse_score: 0.0415) (*)\n",
      "02:36 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0507 (mse_score: 0.0507)\n",
      "02:36 madminer.utils.ml.sc INFO                val. loss  0.0387 (mse_score: 0.0387) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:36 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0483 (mse_score: 0.0483)\n",
      "02:36 madminer.utils.ml.sc INFO                val. loss  0.0370 (mse_score: 0.0370) (*)\n",
      "02:37 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0464 (mse_score: 0.0464)\n",
      "02:37 madminer.utils.ml.sc INFO                val. loss  0.0364 (mse_score: 0.0364) (*)\n",
      "02:37 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0450 (mse_score: 0.0450)\n",
      "02:37 madminer.utils.ml.sc INFO                val. loss  0.0360 (mse_score: 0.0360) (*)\n",
      "02:37 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0439 (mse_score: 0.0439)\n",
      "02:37 madminer.utils.ml.sc INFO                val. loss  0.0350 (mse_score: 0.0350) (*)\n",
      "02:38 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0428 (mse_score: 0.0428)\n",
      "02:38 madminer.utils.ml.sc INFO                val. loss  0.0343 (mse_score: 0.0343) (*)\n",
      "02:38 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0420 (mse_score: 0.0420)\n",
      "02:38 madminer.utils.ml.sc INFO                val. loss  0.0344 (mse_score: 0.0344)\n",
      "02:39 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0411 (mse_score: 0.0411)\n",
      "02:39 madminer.utils.ml.sc INFO                val. loss  0.0338 (mse_score: 0.0338) (*)\n",
      "02:39 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0404 (mse_score: 0.0404)\n",
      "02:39 madminer.utils.ml.sc INFO                val. loss  0.0348 (mse_score: 0.0348)\n",
      "02:39 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0398 (mse_score: 0.0398)\n",
      "02:39 madminer.utils.ml.sc INFO                val. loss  0.0326 (mse_score: 0.0326) (*)\n",
      "02:40 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0391 (mse_score: 0.0391)\n",
      "02:40 madminer.utils.ml.sc INFO                val. loss  0.0327 (mse_score: 0.0327)\n",
      "02:40 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0385 (mse_score: 0.0385)\n",
      "02:40 madminer.utils.ml.sc INFO                val. loss  0.0320 (mse_score: 0.0320) (*)\n",
      "02:41 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0380 (mse_score: 0.0380)\n",
      "02:41 madminer.utils.ml.sc INFO                val. loss  0.0322 (mse_score: 0.0322)\n",
      "02:41 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0376 (mse_score: 0.0376)\n",
      "02:41 madminer.utils.ml.sc INFO                val. loss  0.0317 (mse_score: 0.0317) (*)\n",
      "02:41 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0371 (mse_score: 0.0371)\n",
      "02:41 madminer.utils.ml.sc INFO                val. loss  0.0316 (mse_score: 0.0316) (*)\n",
      "02:42 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0367 (mse_score: 0.0367)\n",
      "02:42 madminer.utils.ml.sc INFO                val. loss  0.0314 (mse_score: 0.0314) (*)\n",
      "02:42 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0363 (mse_score: 0.0363)\n",
      "02:42 madminer.utils.ml.sc INFO                val. loss  0.0317 (mse_score: 0.0317)\n",
      "02:43 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0360 (mse_score: 0.0360)\n",
      "02:43 madminer.utils.ml.sc INFO                val. loss  0.0308 (mse_score: 0.0308) (*)\n",
      "02:43 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0357 (mse_score: 0.0357)\n",
      "02:43 madminer.utils.ml.sc INFO                val. loss  0.0309 (mse_score: 0.0309)\n",
      "02:43 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0354 (mse_score: 0.0354)\n",
      "02:43 madminer.utils.ml.sc INFO                val. loss  0.0310 (mse_score: 0.0310)\n",
      "02:44 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0351 (mse_score: 0.0351)\n",
      "02:44 madminer.utils.ml.sc INFO                val. loss  0.0307 (mse_score: 0.0307) (*)\n",
      "02:44 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0349 (mse_score: 0.0349)\n",
      "02:44 madminer.utils.ml.sc INFO                val. loss  0.0305 (mse_score: 0.0305) (*)\n",
      "02:45 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0346 (mse_score: 0.0346)\n",
      "02:45 madminer.utils.ml.sc INFO                val. loss  0.0305 (mse_score: 0.0305) (*)\n",
      "02:45 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0344 (mse_score: 0.0344)\n",
      "02:45 madminer.utils.ml.sc INFO                val. loss  0.0305 (mse_score: 0.0305) (*)\n",
      "02:46 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0342 (mse_score: 0.0342)\n",
      "02:46 madminer.utils.ml.sc INFO                val. loss  0.0302 (mse_score: 0.0302) (*)\n",
      "02:46 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0340 (mse_score: 0.0340)\n",
      "02:46 madminer.utils.ml.sc INFO                val. loss  0.0302 (mse_score: 0.0302) (*)\n",
      "02:46 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0340 (mse_score: 0.0340)\n",
      "02:46 madminer.utils.ml.sc INFO                val. loss  0.0305 (mse_score: 0.0305)\n",
      "02:47 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0336 (mse_score: 0.0336)\n",
      "02:47 madminer.utils.ml.sc INFO                val. loss  0.0300 (mse_score: 0.0300) (*)\n",
      "02:47 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0334 (mse_score: 0.0334)\n",
      "02:47 madminer.utils.ml.sc INFO                val. loss  0.0298 (mse_score: 0.0298) (*)\n",
      "02:48 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0333 (mse_score: 0.0333)\n",
      "02:48 madminer.utils.ml.sc INFO                val. loss  0.0299 (mse_score: 0.0299)\n",
      "02:48 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0331 (mse_score: 0.0331)\n",
      "02:48 madminer.utils.ml.sc INFO                val. loss  0.0298 (mse_score: 0.0298) (*)\n",
      "02:48 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0330 (mse_score: 0.0330)\n",
      "02:48 madminer.utils.ml.sc INFO                val. loss  0.0297 (mse_score: 0.0297) (*)\n",
      "02:49 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0328 (mse_score: 0.0328)\n",
      "02:49 madminer.utils.ml.sc INFO                val. loss  0.0297 (mse_score: 0.0297) (*)\n",
      "02:49 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0327 (mse_score: 0.0327)\n",
      "02:49 madminer.utils.ml.sc INFO                val. loss  0.0297 (mse_score: 0.0297) (*)\n",
      "02:50 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0326 (mse_score: 0.0326)\n",
      "02:50 madminer.utils.ml.sc INFO                val. loss  0.0296 (mse_score: 0.0296) (*)\n",
      "02:50 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0325 (mse_score: 0.0325)\n",
      "02:50 madminer.utils.ml.sc INFO                val. loss  0.0295 (mse_score: 0.0295) (*)\n",
      "02:50 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0324 (mse_score: 0.0324)\n",
      "02:50 madminer.utils.ml.sc INFO                val. loss  0.0296 (mse_score: 0.0296)\n",
      "02:51 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0323 (mse_score: 0.0323)\n",
      "02:51 madminer.utils.ml.sc INFO                val. loss  0.0296 (mse_score: 0.0296)\n",
      "02:51 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0322 (mse_score: 0.0322)\n",
      "02:51 madminer.utils.ml.sc INFO                val. loss  0.0296 (mse_score: 0.0296)\n",
      "02:52 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0321 (mse_score: 0.0321)\n",
      "02:52 madminer.utils.ml.sc INFO                val. loss  0.0295 (mse_score: 0.0295)\n",
      "02:52 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0320 (mse_score: 0.0320)\n",
      "02:52 madminer.utils.ml.sc INFO                val. loss  0.0295 (mse_score: 0.0295) (*)\n",
      "02:52 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0320 (mse_score: 0.0320)\n",
      "02:52 madminer.utils.ml.sc INFO                val. loss  0.0295 (mse_score: 0.0295)\n",
      "02:53 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0318 (mse_score: 0.0318)\n",
      "02:53 madminer.utils.ml.sc INFO                val. loss  0.0296 (mse_score: 0.0296)\n",
      "02:53 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0318 (mse_score: 0.0318)\n",
      "02:53 madminer.utils.ml.sc INFO                val. loss  0.0296 (mse_score: 0.0296)\n",
      "02:54 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0317 (mse_score: 0.0317)\n",
      "02:54 madminer.utils.ml.sc INFO                val. loss  0.0294 (mse_score: 0.0294) (*)\n",
      "02:54 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "02:54 madminer.utils.ml.sc INFO    Finished training\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all_antitight',\n",
    "    use_tight_cuts=False,\n",
    "    use_antitight_cuts=True,\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal observable basis (no jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_obs = [0,1] + list(range(4,12)) + list(range(16,33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'minimal',\n",
    "    use_tight_cuts=False,\n",
    "    features=[min_obs for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'minimal_tight',\n",
    "    use_tight_cuts=True,\n",
    "    features=[min_obs for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just resurrection phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'phi_tight',\n",
    "    use_tight_cuts=True,\n",
    "    features=[[32] for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'pta_phi_tight',\n",
    "    use_tight_cuts=True,\n",
    "    features=[[9, 32] for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (higgs_inference)",
   "language": "python",
   "name": "higgs_inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
