{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f9deb73c-b62f-4cff-8d83-724074098c92"
    }
   },
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Marco Farina, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "fe57a76c-4838-44c4-b0cc-5ee166785e4a"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)-5.5s %(name)-20.20s %(levelname)-7.7s %(message)s',\n",
    "    datefmt='%H:%M',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "for key in logging.Logger.manager.loggerDict:\n",
    "    if \"madminer\" not in key:\n",
    "        logging.getLogger(key).setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f3463c40-6421-42a1-8681-527c3ec42541"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "b2c73eca-c625-4f7a-9cee-4ccb2dcbb3e9"
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma_sys/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma_sys/'\n",
    "log_dir = base_dir + 'logs/wgamma_sys/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma_sys/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(filename, use_tight_cuts=True, n_estimators=n_estimators, **kwargs):\n",
    "    cut_label = '_tight' if use_tight_cuts else ''\n",
    "    \n",
    "    ensemble = EnsembleForge(n_estimators, debug=True)\n",
    "\n",
    "    ensemble.train_all(\n",
    "        method='sally',\n",
    "        x_filename=[sample_dir + 'train_local{}/x_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        t_xz0_filename=[sample_dir + 'train_local{}/t_xz_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    ensemble.save(model_dir + 'sally_ensemble_' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45e7f73-8f4c-4261-a381-4b7ad6af120f"
    }
   },
   "source": [
    "## All observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:45 madminer.ml          INFO    Training 10 estimators in ensemble\n",
      "10:45 madminer.ml          INFO    Training estimator 1 / 10 in ensemble\n",
      "10:45 madminer.ml          INFO    Starting training\n",
      "10:45 madminer.ml          INFO      Method:                 sally\n",
      "10:45 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_0.npy\n",
      "10:45 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_0.npy\n",
      "10:45 madminer.ml          INFO      Features:               all\n",
      "10:45 madminer.ml          INFO      Method:                 sally\n",
      "10:45 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "10:45 madminer.ml          INFO      Activation function:    tanh\n",
      "10:45 madminer.ml          INFO      Batch size:             128\n",
      "10:45 madminer.ml          INFO      Trainer:                amsgrad\n",
      "10:45 madminer.ml          INFO      Epochs:                 50\n",
      "10:45 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "10:45 madminer.ml          INFO      Validation split:       0.5\n",
      "10:45 madminer.ml          INFO      Early stopping:         True\n",
      "10:45 madminer.ml          INFO      Scale inputs:           True\n",
      "10:45 madminer.ml          INFO      Shuffle labels          False\n",
      "10:45 madminer.ml          INFO      Regularization:         None\n",
      "10:45 madminer.ml          INFO      Samples:                all\n",
      "10:45 madminer.ml          INFO    Loading training data\n",
      "10:45 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "10:45 madminer.ml          INFO    Rescaling inputs\n",
      "10:45 madminer.ml          INFO    Creating model for method sally\n",
      "10:45 madminer.ml          INFO    Training model\n",
      "10:46 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1072 (mse_score: 0.1072)\n",
      "10:46 madminer.utils.ml.sc INFO                val. loss  0.1114 (mse_score: 0.1114) (*)\n",
      "10:47 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1037 (mse_score: 0.1037)\n",
      "10:47 madminer.utils.ml.sc INFO                val. loss  0.1082 (mse_score: 0.1082) (*)\n",
      "10:48 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1010 (mse_score: 0.1010)\n",
      "10:48 madminer.utils.ml.sc INFO                val. loss  0.1093 (mse_score: 0.1093)\n",
      "10:49 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0998 (mse_score: 0.0998)\n",
      "10:49 madminer.utils.ml.sc INFO                val. loss  0.1039 (mse_score: 0.1039) (*)\n",
      "10:50 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0983 (mse_score: 0.0983)\n",
      "10:50 madminer.utils.ml.sc INFO                val. loss  0.1039 (mse_score: 0.1039) (*)\n",
      "10:50 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0964 (mse_score: 0.0964)\n",
      "10:50 madminer.utils.ml.sc INFO                val. loss  0.1024 (mse_score: 0.1024) (*)\n",
      "10:51 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0945 (mse_score: 0.0945)\n",
      "10:51 madminer.utils.ml.sc INFO                val. loss  0.1024 (mse_score: 0.1024) (*)\n",
      "10:51 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0937 (mse_score: 0.0937)\n",
      "10:51 madminer.utils.ml.sc INFO                val. loss  0.1022 (mse_score: 0.1022) (*)\n",
      "10:52 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0926 (mse_score: 0.0926)\n",
      "10:52 madminer.utils.ml.sc INFO                val. loss  0.1082 (mse_score: 0.1082)\n",
      "10:52 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0904 (mse_score: 0.0904)\n",
      "10:52 madminer.utils.ml.sc INFO                val. loss  0.1004 (mse_score: 0.1004) (*)\n",
      "10:53 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0887 (mse_score: 0.0887)\n",
      "10:53 madminer.utils.ml.sc INFO                val. loss  0.1028 (mse_score: 0.1028)\n",
      "10:53 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0870 (mse_score: 0.0870)\n",
      "10:53 madminer.utils.ml.sc INFO                val. loss  0.1051 (mse_score: 0.1051)\n",
      "10:53 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0863 (mse_score: 0.0863)\n",
      "10:53 madminer.utils.ml.sc INFO                val. loss  0.1004 (mse_score: 0.1004)\n",
      "10:54 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0844 (mse_score: 0.0844)\n",
      "10:54 madminer.utils.ml.sc INFO                val. loss  0.1009 (mse_score: 0.1009)\n",
      "10:54 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0833 (mse_score: 0.0833)\n",
      "10:54 madminer.utils.ml.sc INFO                val. loss  0.1014 (mse_score: 0.1014)\n",
      "10:55 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0817 (mse_score: 0.0817)\n",
      "10:55 madminer.utils.ml.sc INFO                val. loss  0.1018 (mse_score: 0.1018)\n",
      "10:55 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0808 (mse_score: 0.0808)\n",
      "10:55 madminer.utils.ml.sc INFO                val. loss  0.1009 (mse_score: 0.1009)\n",
      "10:55 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0795 (mse_score: 0.0795)\n",
      "10:55 madminer.utils.ml.sc INFO                val. loss  0.1012 (mse_score: 0.1012)\n",
      "10:56 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0785 (mse_score: 0.0785)\n",
      "10:56 madminer.utils.ml.sc INFO                val. loss  0.1025 (mse_score: 0.1025)\n",
      "10:56 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0772 (mse_score: 0.0772)\n",
      "10:56 madminer.utils.ml.sc INFO                val. loss  0.1014 (mse_score: 0.1014)\n",
      "10:57 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0765 (mse_score: 0.0765)\n",
      "10:57 madminer.utils.ml.sc INFO                val. loss  0.1009 (mse_score: 0.1009)\n",
      "10:57 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0753 (mse_score: 0.0753)\n",
      "10:57 madminer.utils.ml.sc INFO                val. loss  0.1012 (mse_score: 0.1012)\n",
      "10:58 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0742 (mse_score: 0.0742)\n",
      "10:58 madminer.utils.ml.sc INFO                val. loss  0.1014 (mse_score: 0.1014)\n",
      "10:58 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0734 (mse_score: 0.0734)\n",
      "10:58 madminer.utils.ml.sc INFO                val. loss  0.1065 (mse_score: 0.1065)\n",
      "10:58 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0726 (mse_score: 0.0726)\n",
      "10:58 madminer.utils.ml.sc INFO                val. loss  0.1012 (mse_score: 0.1012)\n",
      "10:59 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0715 (mse_score: 0.0715)\n",
      "10:59 madminer.utils.ml.sc INFO                val. loss  0.1020 (mse_score: 0.1020)\n",
      "10:59 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0707 (mse_score: 0.0707)\n",
      "10:59 madminer.utils.ml.sc INFO                val. loss  0.1021 (mse_score: 0.1021)\n",
      "11:00 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0699 (mse_score: 0.0699)\n",
      "11:00 madminer.utils.ml.sc INFO                val. loss  0.1023 (mse_score: 0.1023)\n",
      "11:00 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0692 (mse_score: 0.0692)\n",
      "11:00 madminer.utils.ml.sc INFO                val. loss  0.1025 (mse_score: 0.1025)\n",
      "11:01 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0686 (mse_score: 0.0686)\n",
      "11:01 madminer.utils.ml.sc INFO                val. loss  0.1026 (mse_score: 0.1026)\n",
      "11:01 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0679 (mse_score: 0.0679)\n",
      "11:01 madminer.utils.ml.sc INFO                val. loss  0.1030 (mse_score: 0.1030)\n",
      "11:02 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0672 (mse_score: 0.0672)\n",
      "11:02 madminer.utils.ml.sc INFO                val. loss  0.1032 (mse_score: 0.1032)\n",
      "11:03 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0666 (mse_score: 0.0666)\n",
      "11:03 madminer.utils.ml.sc INFO                val. loss  0.1029 (mse_score: 0.1029)\n",
      "11:03 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0660 (mse_score: 0.0660)\n",
      "11:03 madminer.utils.ml.sc INFO                val. loss  0.1041 (mse_score: 0.1041)\n",
      "11:04 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0654 (mse_score: 0.0654)\n",
      "11:04 madminer.utils.ml.sc INFO                val. loss  0.1028 (mse_score: 0.1028)\n",
      "11:04 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0650 (mse_score: 0.0650)\n",
      "11:04 madminer.utils.ml.sc INFO                val. loss  0.1039 (mse_score: 0.1039)\n",
      "11:05 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0644 (mse_score: 0.0644)\n",
      "11:05 madminer.utils.ml.sc INFO                val. loss  0.1035 (mse_score: 0.1035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:05 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0639 (mse_score: 0.0639)\n",
      "11:05 madminer.utils.ml.sc INFO                val. loss  0.1037 (mse_score: 0.1037)\n",
      "11:05 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0635 (mse_score: 0.0635)\n",
      "11:05 madminer.utils.ml.sc INFO                val. loss  0.1048 (mse_score: 0.1048)\n",
      "11:06 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0632 (mse_score: 0.0632)\n",
      "11:06 madminer.utils.ml.sc INFO                val. loss  0.1036 (mse_score: 0.1036)\n",
      "11:06 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0626 (mse_score: 0.0626)\n",
      "11:06 madminer.utils.ml.sc INFO                val. loss  0.1042 (mse_score: 0.1042)\n",
      "11:07 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0624 (mse_score: 0.0624)\n",
      "11:07 madminer.utils.ml.sc INFO                val. loss  0.1036 (mse_score: 0.1036)\n",
      "11:07 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0620 (mse_score: 0.0620)\n",
      "11:07 madminer.utils.ml.sc INFO                val. loss  0.1047 (mse_score: 0.1047)\n",
      "11:08 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0616 (mse_score: 0.0616)\n",
      "11:08 madminer.utils.ml.sc INFO                val. loss  0.1047 (mse_score: 0.1047)\n",
      "11:09 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0613 (mse_score: 0.0613)\n",
      "11:09 madminer.utils.ml.sc INFO                val. loss  0.1045 (mse_score: 0.1045)\n",
      "11:09 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0609 (mse_score: 0.0609)\n",
      "11:09 madminer.utils.ml.sc INFO                val. loss  0.1046 (mse_score: 0.1046)\n",
      "11:10 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0606 (mse_score: 0.0606)\n",
      "11:10 madminer.utils.ml.sc INFO                val. loss  0.1065 (mse_score: 0.1065)\n",
      "11:10 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0604 (mse_score: 0.0604)\n",
      "11:10 madminer.utils.ml.sc INFO                val. loss  0.1056 (mse_score: 0.1056)\n",
      "11:11 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0604 (mse_score: 0.0604)\n",
      "11:11 madminer.utils.ml.sc INFO                val. loss  0.1058 (mse_score: 0.1058)\n",
      "11:11 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0599 (mse_score: 0.0599)\n",
      "11:11 madminer.utils.ml.sc INFO                val. loss  0.1055 (mse_score: 0.1055)\n",
      "11:11 madminer.utils.ml.sc INFO    Early stopping after epoch 10, with loss 0.10 compared to final loss 0.11\n",
      "11:11 madminer.utils.ml.sc INFO    Finished training\n",
      "11:11 madminer.ml          INFO    Training estimator 2 / 10 in ensemble\n",
      "11:11 madminer.ml          INFO    Starting training\n",
      "11:11 madminer.ml          INFO      Method:                 sally\n",
      "11:11 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_1.npy\n",
      "11:11 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_1.npy\n",
      "11:11 madminer.ml          INFO      Features:               all\n",
      "11:11 madminer.ml          INFO      Method:                 sally\n",
      "11:11 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "11:11 madminer.ml          INFO      Activation function:    tanh\n",
      "11:11 madminer.ml          INFO      Batch size:             128\n",
      "11:11 madminer.ml          INFO      Trainer:                amsgrad\n",
      "11:11 madminer.ml          INFO      Epochs:                 50\n",
      "11:11 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "11:11 madminer.ml          INFO      Validation split:       0.5\n",
      "11:11 madminer.ml          INFO      Early stopping:         True\n",
      "11:11 madminer.ml          INFO      Scale inputs:           True\n",
      "11:11 madminer.ml          INFO      Shuffle labels          False\n",
      "11:11 madminer.ml          INFO      Regularization:         None\n",
      "11:11 madminer.ml          INFO      Samples:                all\n",
      "11:11 madminer.ml          INFO    Loading training data\n",
      "11:11 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "11:11 madminer.ml          INFO    Rescaling inputs\n",
      "11:11 madminer.ml          INFO    Creating model for method sally\n",
      "11:11 madminer.ml          INFO    Training model\n",
      "11:12 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1018 (mse_score: 0.1018)\n",
      "11:12 madminer.utils.ml.sc INFO                val. loss  0.1716 (mse_score: 0.1716) (*)\n",
      "11:13 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0984 (mse_score: 0.0984)\n",
      "11:13 madminer.utils.ml.sc INFO                val. loss  0.1695 (mse_score: 0.1695) (*)\n",
      "11:13 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0965 (mse_score: 0.0965)\n",
      "11:13 madminer.utils.ml.sc INFO                val. loss  0.1705 (mse_score: 0.1705)\n",
      "11:14 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0946 (mse_score: 0.0946)\n",
      "11:14 madminer.utils.ml.sc INFO                val. loss  0.1674 (mse_score: 0.1674) (*)\n",
      "11:15 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0933 (mse_score: 0.0933)\n",
      "11:15 madminer.utils.ml.sc INFO                val. loss  0.1652 (mse_score: 0.1652) (*)\n",
      "11:16 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0921 (mse_score: 0.0921)\n",
      "11:16 madminer.utils.ml.sc INFO                val. loss  0.1644 (mse_score: 0.1644) (*)\n",
      "11:17 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0908 (mse_score: 0.0908)\n",
      "11:17 madminer.utils.ml.sc INFO                val. loss  0.1720 (mse_score: 0.1720)\n",
      "11:17 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0897 (mse_score: 0.0897)\n",
      "11:17 madminer.utils.ml.sc INFO                val. loss  0.1631 (mse_score: 0.1631) (*)\n",
      "11:18 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0876 (mse_score: 0.0876)\n",
      "11:18 madminer.utils.ml.sc INFO                val. loss  0.1623 (mse_score: 0.1623) (*)\n",
      "11:19 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0869 (mse_score: 0.0869)\n",
      "11:19 madminer.utils.ml.sc INFO                val. loss  0.1616 (mse_score: 0.1616) (*)\n",
      "11:19 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0859 (mse_score: 0.0859)\n",
      "11:19 madminer.utils.ml.sc INFO                val. loss  0.1611 (mse_score: 0.1611) (*)\n",
      "11:20 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0850 (mse_score: 0.0850)\n",
      "11:20 madminer.utils.ml.sc INFO                val. loss  0.1610 (mse_score: 0.1610) (*)\n",
      "11:20 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0835 (mse_score: 0.0835)\n",
      "11:20 madminer.utils.ml.sc INFO                val. loss  0.1596 (mse_score: 0.1596) (*)\n",
      "11:21 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0823 (mse_score: 0.0823)\n",
      "11:21 madminer.utils.ml.sc INFO                val. loss  0.1601 (mse_score: 0.1601)\n",
      "11:22 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0819 (mse_score: 0.0819)\n",
      "11:22 madminer.utils.ml.sc INFO                val. loss  0.1610 (mse_score: 0.1610)\n",
      "11:22 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0808 (mse_score: 0.0808)\n",
      "11:22 madminer.utils.ml.sc INFO                val. loss  0.1591 (mse_score: 0.1591) (*)\n",
      "11:23 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0799 (mse_score: 0.0799)\n",
      "11:23 madminer.utils.ml.sc INFO                val. loss  0.1601 (mse_score: 0.1601)\n",
      "11:24 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0794 (mse_score: 0.0794)\n",
      "11:24 madminer.utils.ml.sc INFO                val. loss  0.1600 (mse_score: 0.1600)\n",
      "11:25 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0784 (mse_score: 0.0784)\n",
      "11:25 madminer.utils.ml.sc INFO                val. loss  0.1606 (mse_score: 0.1606)\n",
      "11:26 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0774 (mse_score: 0.0774)\n",
      "11:26 madminer.utils.ml.sc INFO                val. loss  0.1612 (mse_score: 0.1612)\n",
      "11:26 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0767 (mse_score: 0.0767)\n",
      "11:26 madminer.utils.ml.sc INFO                val. loss  0.1607 (mse_score: 0.1607)\n",
      "11:27 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0756 (mse_score: 0.0756)\n",
      "11:27 madminer.utils.ml.sc INFO                val. loss  0.1607 (mse_score: 0.1607)\n",
      "11:28 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0750 (mse_score: 0.0750)\n",
      "11:28 madminer.utils.ml.sc INFO                val. loss  0.1603 (mse_score: 0.1603)\n",
      "11:29 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0743 (mse_score: 0.0743)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:29 madminer.utils.ml.sc INFO                val. loss  0.1594 (mse_score: 0.1594)\n",
      "11:29 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0737 (mse_score: 0.0737)\n",
      "11:29 madminer.utils.ml.sc INFO                val. loss  0.1588 (mse_score: 0.1588) (*)\n",
      "11:30 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0728 (mse_score: 0.0728)\n",
      "11:30 madminer.utils.ml.sc INFO                val. loss  0.1595 (mse_score: 0.1595)\n",
      "11:31 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0722 (mse_score: 0.0722)\n",
      "11:31 madminer.utils.ml.sc INFO                val. loss  0.1600 (mse_score: 0.1600)\n",
      "11:32 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0714 (mse_score: 0.0714)\n",
      "11:32 madminer.utils.ml.sc INFO                val. loss  0.1596 (mse_score: 0.1596)\n",
      "11:32 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0709 (mse_score: 0.0709)\n",
      "11:32 madminer.utils.ml.sc INFO                val. loss  0.1617 (mse_score: 0.1617)\n",
      "11:33 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0704 (mse_score: 0.0704)\n",
      "11:33 madminer.utils.ml.sc INFO                val. loss  0.1606 (mse_score: 0.1606)\n",
      "11:34 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0696 (mse_score: 0.0696)\n",
      "11:34 madminer.utils.ml.sc INFO                val. loss  0.1591 (mse_score: 0.1591)\n",
      "11:34 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0694 (mse_score: 0.0694)\n",
      "11:34 madminer.utils.ml.sc INFO                val. loss  0.1594 (mse_score: 0.1594)\n",
      "11:35 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0688 (mse_score: 0.0688)\n",
      "11:35 madminer.utils.ml.sc INFO                val. loss  0.1611 (mse_score: 0.1611)\n",
      "11:35 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0683 (mse_score: 0.0683)\n",
      "11:35 madminer.utils.ml.sc INFO                val. loss  0.1589 (mse_score: 0.1589)\n",
      "11:35 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0678 (mse_score: 0.0678)\n",
      "11:35 madminer.utils.ml.sc INFO                val. loss  0.1611 (mse_score: 0.1611)\n",
      "11:36 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0675 (mse_score: 0.0675)\n",
      "11:36 madminer.utils.ml.sc INFO                val. loss  0.1598 (mse_score: 0.1598)\n",
      "11:36 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0669 (mse_score: 0.0669)\n",
      "11:36 madminer.utils.ml.sc INFO                val. loss  0.1594 (mse_score: 0.1594)\n",
      "11:37 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0666 (mse_score: 0.0666)\n",
      "11:37 madminer.utils.ml.sc INFO                val. loss  0.1591 (mse_score: 0.1591)\n",
      "11:37 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0663 (mse_score: 0.0663)\n",
      "11:37 madminer.utils.ml.sc INFO                val. loss  0.1596 (mse_score: 0.1596)\n",
      "11:38 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0659 (mse_score: 0.0659)\n",
      "11:38 madminer.utils.ml.sc INFO                val. loss  0.1601 (mse_score: 0.1601)\n",
      "11:39 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0656 (mse_score: 0.0656)\n",
      "11:39 madminer.utils.ml.sc INFO                val. loss  0.1591 (mse_score: 0.1591)\n",
      "11:40 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0652 (mse_score: 0.0652)\n",
      "11:40 madminer.utils.ml.sc INFO                val. loss  0.1598 (mse_score: 0.1598)\n",
      "11:40 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0650 (mse_score: 0.0650)\n",
      "11:40 madminer.utils.ml.sc INFO                val. loss  0.1595 (mse_score: 0.1595)\n",
      "11:41 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0647 (mse_score: 0.0647)\n",
      "11:41 madminer.utils.ml.sc INFO                val. loss  0.1608 (mse_score: 0.1608)\n",
      "11:42 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0645 (mse_score: 0.0645)\n",
      "11:42 madminer.utils.ml.sc INFO                val. loss  0.1592 (mse_score: 0.1592)\n",
      "11:43 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0641 (mse_score: 0.0641)\n",
      "11:43 madminer.utils.ml.sc INFO                val. loss  0.1596 (mse_score: 0.1596)\n",
      "11:43 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0639 (mse_score: 0.0639)\n",
      "11:43 madminer.utils.ml.sc INFO                val. loss  0.1591 (mse_score: 0.1591)\n",
      "11:44 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0637 (mse_score: 0.0637)\n",
      "11:44 madminer.utils.ml.sc INFO                val. loss  0.1590 (mse_score: 0.1590)\n",
      "11:45 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0635 (mse_score: 0.0635)\n",
      "11:45 madminer.utils.ml.sc INFO                val. loss  0.1602 (mse_score: 0.1602)\n",
      "11:46 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0632 (mse_score: 0.0632)\n",
      "11:46 madminer.utils.ml.sc INFO                val. loss  0.1613 (mse_score: 0.1613)\n",
      "11:46 madminer.utils.ml.sc INFO    Early stopping after epoch 25, with loss 0.16 compared to final loss 0.16\n",
      "11:46 madminer.utils.ml.sc INFO    Finished training\n",
      "11:46 madminer.ml          INFO    Training estimator 3 / 10 in ensemble\n",
      "11:46 madminer.ml          INFO    Starting training\n",
      "11:46 madminer.ml          INFO      Method:                 sally\n",
      "11:46 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_2.npy\n",
      "11:46 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_2.npy\n",
      "11:46 madminer.ml          INFO      Features:               all\n",
      "11:46 madminer.ml          INFO      Method:                 sally\n",
      "11:46 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "11:46 madminer.ml          INFO      Activation function:    tanh\n",
      "11:46 madminer.ml          INFO      Batch size:             128\n",
      "11:46 madminer.ml          INFO      Trainer:                amsgrad\n",
      "11:46 madminer.ml          INFO      Epochs:                 50\n",
      "11:46 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "11:46 madminer.ml          INFO      Validation split:       0.5\n",
      "11:46 madminer.ml          INFO      Early stopping:         True\n",
      "11:46 madminer.ml          INFO      Scale inputs:           True\n",
      "11:46 madminer.ml          INFO      Shuffle labels          False\n",
      "11:46 madminer.ml          INFO      Regularization:         None\n",
      "11:46 madminer.ml          INFO      Samples:                all\n",
      "11:46 madminer.ml          INFO    Loading training data\n",
      "11:46 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "11:46 madminer.ml          INFO    Rescaling inputs\n",
      "11:46 madminer.ml          INFO    Creating model for method sally\n",
      "11:46 madminer.ml          INFO    Training model\n",
      "11:47 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0956 (mse_score: 0.0956)\n",
      "11:47 madminer.utils.ml.sc INFO                val. loss  0.0936 (mse_score: 0.0936) (*)\n",
      "11:47 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0920 (mse_score: 0.0920)\n",
      "11:47 madminer.utils.ml.sc INFO                val. loss  0.0892 (mse_score: 0.0892) (*)\n",
      "11:48 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0896 (mse_score: 0.0896)\n",
      "11:48 madminer.utils.ml.sc INFO                val. loss  0.0884 (mse_score: 0.0884) (*)\n",
      "11:49 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0879 (mse_score: 0.0879)\n",
      "11:49 madminer.utils.ml.sc INFO                val. loss  0.0878 (mse_score: 0.0878) (*)\n",
      "11:50 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0859 (mse_score: 0.0859)\n",
      "11:50 madminer.utils.ml.sc INFO                val. loss  0.0849 (mse_score: 0.0849) (*)\n",
      "11:50 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0849 (mse_score: 0.0849)\n",
      "11:50 madminer.utils.ml.sc INFO                val. loss  0.0840 (mse_score: 0.0840) (*)\n",
      "11:51 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0825 (mse_score: 0.0825)\n",
      "11:51 madminer.utils.ml.sc INFO                val. loss  0.0859 (mse_score: 0.0859)\n",
      "11:51 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0823 (mse_score: 0.0823)\n",
      "11:51 madminer.utils.ml.sc INFO                val. loss  0.0832 (mse_score: 0.0832) (*)\n",
      "11:52 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0805 (mse_score: 0.0805)\n",
      "11:52 madminer.utils.ml.sc INFO                val. loss  0.0836 (mse_score: 0.0836)\n",
      "11:52 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0791 (mse_score: 0.0791)\n",
      "11:52 madminer.utils.ml.sc INFO                val. loss  0.0837 (mse_score: 0.0837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:53 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0772 (mse_score: 0.0772)\n",
      "11:53 madminer.utils.ml.sc INFO                val. loss  0.0825 (mse_score: 0.0825) (*)\n",
      "11:54 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0768 (mse_score: 0.0768)\n",
      "11:54 madminer.utils.ml.sc INFO                val. loss  0.0833 (mse_score: 0.0833)\n",
      "11:54 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0759 (mse_score: 0.0759)\n",
      "11:54 madminer.utils.ml.sc INFO                val. loss  0.0816 (mse_score: 0.0816) (*)\n",
      "11:55 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0741 (mse_score: 0.0741)\n",
      "11:55 madminer.utils.ml.sc INFO                val. loss  0.0833 (mse_score: 0.0833)\n",
      "11:56 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0735 (mse_score: 0.0735)\n",
      "11:56 madminer.utils.ml.sc INFO                val. loss  0.0817 (mse_score: 0.0817)\n",
      "11:56 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0723 (mse_score: 0.0723)\n",
      "11:56 madminer.utils.ml.sc INFO                val. loss  0.0817 (mse_score: 0.0817)\n",
      "11:57 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0706 (mse_score: 0.0706)\n",
      "11:57 madminer.utils.ml.sc INFO                val. loss  0.0808 (mse_score: 0.0808) (*)\n",
      "11:58 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0702 (mse_score: 0.0702)\n",
      "11:58 madminer.utils.ml.sc INFO                val. loss  0.0814 (mse_score: 0.0814)\n",
      "11:58 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0694 (mse_score: 0.0694)\n",
      "11:58 madminer.utils.ml.sc INFO                val. loss  0.0810 (mse_score: 0.0810)\n",
      "11:59 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0686 (mse_score: 0.0686)\n",
      "11:59 madminer.utils.ml.sc INFO                val. loss  0.0805 (mse_score: 0.0805) (*)\n",
      "11:59 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0675 (mse_score: 0.0675)\n",
      "11:59 madminer.utils.ml.sc INFO                val. loss  0.0825 (mse_score: 0.0825)\n",
      "12:00 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0662 (mse_score: 0.0662)\n",
      "12:00 madminer.utils.ml.sc INFO                val. loss  0.0801 (mse_score: 0.0801) (*)\n",
      "12:01 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0657 (mse_score: 0.0657)\n",
      "12:01 madminer.utils.ml.sc INFO                val. loss  0.0800 (mse_score: 0.0800) (*)\n",
      "12:01 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0648 (mse_score: 0.0648)\n",
      "12:01 madminer.utils.ml.sc INFO                val. loss  0.0808 (mse_score: 0.0808)\n",
      "12:02 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0641 (mse_score: 0.0641)\n",
      "12:02 madminer.utils.ml.sc INFO                val. loss  0.0807 (mse_score: 0.0807)\n",
      "12:02 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0633 (mse_score: 0.0633)\n",
      "12:02 madminer.utils.ml.sc INFO                val. loss  0.0810 (mse_score: 0.0810)\n",
      "12:03 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0627 (mse_score: 0.0627)\n",
      "12:03 madminer.utils.ml.sc INFO                val. loss  0.0807 (mse_score: 0.0807)\n",
      "12:04 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0618 (mse_score: 0.0618)\n",
      "12:04 madminer.utils.ml.sc INFO                val. loss  0.0808 (mse_score: 0.0808)\n",
      "12:04 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0613 (mse_score: 0.0613)\n",
      "12:04 madminer.utils.ml.sc INFO                val. loss  0.0836 (mse_score: 0.0836)\n",
      "12:05 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0609 (mse_score: 0.0609)\n",
      "12:05 madminer.utils.ml.sc INFO                val. loss  0.0805 (mse_score: 0.0805)\n",
      "12:05 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0603 (mse_score: 0.0603)\n",
      "12:05 madminer.utils.ml.sc INFO                val. loss  0.0808 (mse_score: 0.0808)\n",
      "12:06 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0595 (mse_score: 0.0595)\n",
      "12:06 madminer.utils.ml.sc INFO                val. loss  0.0803 (mse_score: 0.0803)\n",
      "12:06 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0590 (mse_score: 0.0590)\n",
      "12:06 madminer.utils.ml.sc INFO                val. loss  0.0806 (mse_score: 0.0806)\n",
      "12:07 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0585 (mse_score: 0.0585)\n",
      "12:07 madminer.utils.ml.sc INFO                val. loss  0.0810 (mse_score: 0.0810)\n",
      "12:07 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0581 (mse_score: 0.0581)\n",
      "12:07 madminer.utils.ml.sc INFO                val. loss  0.0804 (mse_score: 0.0804)\n",
      "12:08 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0577 (mse_score: 0.0577)\n",
      "12:08 madminer.utils.ml.sc INFO                val. loss  0.0813 (mse_score: 0.0813)\n",
      "12:09 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0573 (mse_score: 0.0573)\n",
      "12:09 madminer.utils.ml.sc INFO                val. loss  0.0819 (mse_score: 0.0819)\n",
      "12:09 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0569 (mse_score: 0.0569)\n",
      "12:09 madminer.utils.ml.sc INFO                val. loss  0.0811 (mse_score: 0.0811)\n",
      "12:10 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0565 (mse_score: 0.0565)\n",
      "12:10 madminer.utils.ml.sc INFO                val. loss  0.0813 (mse_score: 0.0813)\n",
      "12:10 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0560 (mse_score: 0.0560)\n",
      "12:10 madminer.utils.ml.sc INFO                val. loss  0.0809 (mse_score: 0.0809)\n",
      "12:11 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0558 (mse_score: 0.0558)\n",
      "12:11 madminer.utils.ml.sc INFO                val. loss  0.0815 (mse_score: 0.0815)\n",
      "12:11 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0554 (mse_score: 0.0554)\n",
      "12:11 madminer.utils.ml.sc INFO                val. loss  0.0811 (mse_score: 0.0811)\n",
      "12:12 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0551 (mse_score: 0.0551)\n",
      "12:12 madminer.utils.ml.sc INFO                val. loss  0.0815 (mse_score: 0.0815)\n",
      "12:12 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0548 (mse_score: 0.0548)\n",
      "12:12 madminer.utils.ml.sc INFO                val. loss  0.0815 (mse_score: 0.0815)\n",
      "12:13 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0548 (mse_score: 0.0548)\n",
      "12:13 madminer.utils.ml.sc INFO                val. loss  0.0810 (mse_score: 0.0810)\n",
      "12:14 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0543 (mse_score: 0.0543)\n",
      "12:14 madminer.utils.ml.sc INFO                val. loss  0.0811 (mse_score: 0.0811)\n",
      "12:14 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0540 (mse_score: 0.0540)\n",
      "12:14 madminer.utils.ml.sc INFO                val. loss  0.0817 (mse_score: 0.0817)\n",
      "12:15 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0537 (mse_score: 0.0537)\n",
      "12:15 madminer.utils.ml.sc INFO                val. loss  0.0808 (mse_score: 0.0808)\n",
      "12:15 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0535 (mse_score: 0.0535)\n",
      "12:15 madminer.utils.ml.sc INFO                val. loss  0.0820 (mse_score: 0.0820)\n",
      "12:16 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0533 (mse_score: 0.0533)\n",
      "12:16 madminer.utils.ml.sc INFO                val. loss  0.0812 (mse_score: 0.0812)\n",
      "12:16 madminer.utils.ml.sc INFO    Early stopping after epoch 23, with loss 0.08 compared to final loss 0.08\n",
      "12:16 madminer.utils.ml.sc INFO    Finished training\n",
      "12:16 madminer.ml          INFO    Training estimator 4 / 10 in ensemble\n",
      "12:16 madminer.ml          INFO    Starting training\n",
      "12:16 madminer.ml          INFO      Method:                 sally\n",
      "12:16 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_3.npy\n",
      "12:16 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_3.npy\n",
      "12:16 madminer.ml          INFO      Features:               all\n",
      "12:16 madminer.ml          INFO      Method:                 sally\n",
      "12:16 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "12:16 madminer.ml          INFO      Activation function:    tanh\n",
      "12:16 madminer.ml          INFO      Batch size:             128\n",
      "12:16 madminer.ml          INFO      Trainer:                amsgrad\n",
      "12:16 madminer.ml          INFO      Epochs:                 50\n",
      "12:16 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "12:16 madminer.ml          INFO      Validation split:       0.5\n",
      "12:16 madminer.ml          INFO      Early stopping:         True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:16 madminer.ml          INFO      Scale inputs:           True\n",
      "12:16 madminer.ml          INFO      Shuffle labels          False\n",
      "12:16 madminer.ml          INFO      Regularization:         None\n",
      "12:16 madminer.ml          INFO      Samples:                all\n",
      "12:16 madminer.ml          INFO    Loading training data\n",
      "12:16 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "12:16 madminer.ml          INFO    Rescaling inputs\n",
      "12:16 madminer.ml          INFO    Creating model for method sally\n",
      "12:16 madminer.ml          INFO    Training model\n",
      "12:16 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1671 (mse_score: 0.1671)\n",
      "12:16 madminer.utils.ml.sc INFO                val. loss  0.0773 (mse_score: 0.0773) (*)\n",
      "12:17 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1633 (mse_score: 0.1633)\n",
      "12:17 madminer.utils.ml.sc INFO                val. loss  0.0753 (mse_score: 0.0753) (*)\n",
      "12:17 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1614 (mse_score: 0.1614)\n",
      "12:17 madminer.utils.ml.sc INFO                val. loss  0.0728 (mse_score: 0.0728) (*)\n",
      "12:18 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1598 (mse_score: 0.1598)\n",
      "12:18 madminer.utils.ml.sc INFO                val. loss  0.0748 (mse_score: 0.0748)\n",
      "12:19 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1578 (mse_score: 0.1578)\n",
      "12:19 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708) (*)\n",
      "12:19 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1569 (mse_score: 0.1569)\n",
      "12:19 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701) (*)\n",
      "12:20 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1549 (mse_score: 0.1549)\n",
      "12:20 madminer.utils.ml.sc INFO                val. loss  0.0705 (mse_score: 0.0705)\n",
      "12:20 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1541 (mse_score: 0.1541)\n",
      "12:20 madminer.utils.ml.sc INFO                val. loss  0.0684 (mse_score: 0.0684) (*)\n",
      "12:21 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1527 (mse_score: 0.1527)\n",
      "12:21 madminer.utils.ml.sc INFO                val. loss  0.0681 (mse_score: 0.0681) (*)\n",
      "12:21 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.1508 (mse_score: 0.1508)\n",
      "12:21 madminer.utils.ml.sc INFO                val. loss  0.0682 (mse_score: 0.0682)\n",
      "12:22 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.1514 (mse_score: 0.1514)\n",
      "12:22 madminer.utils.ml.sc INFO                val. loss  0.0687 (mse_score: 0.0687)\n",
      "12:22 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.1494 (mse_score: 0.1494)\n",
      "12:22 madminer.utils.ml.sc INFO                val. loss  0.0679 (mse_score: 0.0679) (*)\n",
      "12:23 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.1478 (mse_score: 0.1478)\n",
      "12:23 madminer.utils.ml.sc INFO                val. loss  0.0672 (mse_score: 0.0672) (*)\n",
      "12:24 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.1465 (mse_score: 0.1465)\n",
      "12:24 madminer.utils.ml.sc INFO                val. loss  0.0673 (mse_score: 0.0673)\n",
      "12:24 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.1468 (mse_score: 0.1468)\n",
      "12:24 madminer.utils.ml.sc INFO                val. loss  0.0663 (mse_score: 0.0663) (*)\n",
      "12:25 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.1445 (mse_score: 0.1445)\n",
      "12:25 madminer.utils.ml.sc INFO                val. loss  0.0663 (mse_score: 0.0663)\n",
      "12:25 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.1432 (mse_score: 0.1432)\n",
      "12:25 madminer.utils.ml.sc INFO                val. loss  0.0662 (mse_score: 0.0662) (*)\n",
      "12:26 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.1422 (mse_score: 0.1422)\n",
      "12:26 madminer.utils.ml.sc INFO                val. loss  0.0664 (mse_score: 0.0664)\n",
      "12:26 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.1416 (mse_score: 0.1416)\n",
      "12:26 madminer.utils.ml.sc INFO                val. loss  0.0673 (mse_score: 0.0673)\n",
      "12:27 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.1404 (mse_score: 0.1404)\n",
      "12:27 madminer.utils.ml.sc INFO                val. loss  0.0661 (mse_score: 0.0661) (*)\n",
      "12:27 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.1395 (mse_score: 0.1395)\n",
      "12:27 madminer.utils.ml.sc INFO                val. loss  0.0666 (mse_score: 0.0666)\n",
      "12:28 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.1386 (mse_score: 0.1386)\n",
      "12:28 madminer.utils.ml.sc INFO                val. loss  0.0657 (mse_score: 0.0657) (*)\n",
      "12:29 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.1380 (mse_score: 0.1380)\n",
      "12:29 madminer.utils.ml.sc INFO                val. loss  0.0659 (mse_score: 0.0659)\n",
      "12:29 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.1372 (mse_score: 0.1372)\n",
      "12:29 madminer.utils.ml.sc INFO                val. loss  0.0665 (mse_score: 0.0665)\n",
      "12:30 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.1365 (mse_score: 0.1365)\n",
      "12:30 madminer.utils.ml.sc INFO                val. loss  0.0661 (mse_score: 0.0661)\n",
      "12:30 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.1357 (mse_score: 0.1357)\n",
      "12:30 madminer.utils.ml.sc INFO                val. loss  0.0659 (mse_score: 0.0659)\n",
      "12:31 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.1353 (mse_score: 0.1353)\n",
      "12:31 madminer.utils.ml.sc INFO                val. loss  0.0661 (mse_score: 0.0661)\n",
      "12:31 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.1345 (mse_score: 0.1345)\n",
      "12:31 madminer.utils.ml.sc INFO                val. loss  0.0660 (mse_score: 0.0660)\n",
      "12:32 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.1339 (mse_score: 0.1339)\n",
      "12:32 madminer.utils.ml.sc INFO                val. loss  0.0659 (mse_score: 0.0659)\n",
      "12:32 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.1334 (mse_score: 0.1334)\n",
      "12:32 madminer.utils.ml.sc INFO                val. loss  0.0654 (mse_score: 0.0654) (*)\n",
      "12:33 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.1327 (mse_score: 0.1327)\n",
      "12:33 madminer.utils.ml.sc INFO                val. loss  0.0665 (mse_score: 0.0665)\n",
      "12:34 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.1323 (mse_score: 0.1323)\n",
      "12:34 madminer.utils.ml.sc INFO                val. loss  0.0658 (mse_score: 0.0658)\n",
      "12:34 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.1319 (mse_score: 0.1319)\n",
      "12:34 madminer.utils.ml.sc INFO                val. loss  0.0661 (mse_score: 0.0661)\n",
      "12:35 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.1314 (mse_score: 0.1314)\n",
      "12:35 madminer.utils.ml.sc INFO                val. loss  0.0658 (mse_score: 0.0658)\n",
      "12:35 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.1310 (mse_score: 0.1310)\n",
      "12:35 madminer.utils.ml.sc INFO                val. loss  0.0664 (mse_score: 0.0664)\n",
      "12:36 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.1307 (mse_score: 0.1307)\n",
      "12:36 madminer.utils.ml.sc INFO                val. loss  0.0659 (mse_score: 0.0659)\n",
      "12:36 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.1303 (mse_score: 0.1303)\n",
      "12:36 madminer.utils.ml.sc INFO                val. loss  0.0656 (mse_score: 0.0656)\n",
      "12:37 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.1300 (mse_score: 0.1300)\n",
      "12:37 madminer.utils.ml.sc INFO                val. loss  0.0653 (mse_score: 0.0653) (*)\n",
      "12:37 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.1295 (mse_score: 0.1295)\n",
      "12:37 madminer.utils.ml.sc INFO                val. loss  0.0660 (mse_score: 0.0660)\n",
      "12:38 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.1293 (mse_score: 0.1293)\n",
      "12:38 madminer.utils.ml.sc INFO                val. loss  0.0659 (mse_score: 0.0659)\n",
      "12:39 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.1289 (mse_score: 0.1289)\n",
      "12:39 madminer.utils.ml.sc INFO                val. loss  0.0656 (mse_score: 0.0656)\n",
      "12:39 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.1286 (mse_score: 0.1286)\n",
      "12:39 madminer.utils.ml.sc INFO                val. loss  0.0653 (mse_score: 0.0653)\n",
      "12:40 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.1284 (mse_score: 0.1284)\n",
      "12:40 madminer.utils.ml.sc INFO                val. loss  0.0656 (mse_score: 0.0656)\n",
      "12:40 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.1281 (mse_score: 0.1281)\n",
      "12:40 madminer.utils.ml.sc INFO                val. loss  0.0654 (mse_score: 0.0654)\n",
      "12:41 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.1278 (mse_score: 0.1278)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41 madminer.utils.ml.sc INFO                val. loss  0.0661 (mse_score: 0.0661)\n",
      "12:41 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.1276 (mse_score: 0.1276)\n",
      "12:41 madminer.utils.ml.sc INFO                val. loss  0.0655 (mse_score: 0.0655)\n",
      "12:42 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.1274 (mse_score: 0.1274)\n",
      "12:42 madminer.utils.ml.sc INFO                val. loss  0.0657 (mse_score: 0.0657)\n",
      "12:43 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.1271 (mse_score: 0.1271)\n",
      "12:43 madminer.utils.ml.sc INFO                val. loss  0.0659 (mse_score: 0.0659)\n",
      "12:43 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.1269 (mse_score: 0.1269)\n",
      "12:43 madminer.utils.ml.sc INFO                val. loss  0.0656 (mse_score: 0.0656)\n",
      "12:44 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.1267 (mse_score: 0.1267)\n",
      "12:44 madminer.utils.ml.sc INFO                val. loss  0.0653 (mse_score: 0.0653) (*)\n",
      "12:44 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "12:44 madminer.utils.ml.sc INFO    Finished training\n",
      "12:44 madminer.ml          INFO    Training estimator 5 / 10 in ensemble\n",
      "12:44 madminer.ml          INFO    Starting training\n",
      "12:44 madminer.ml          INFO      Method:                 sally\n",
      "12:44 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_4.npy\n",
      "12:44 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_4.npy\n",
      "12:44 madminer.ml          INFO      Features:               all\n",
      "12:44 madminer.ml          INFO      Method:                 sally\n",
      "12:44 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "12:44 madminer.ml          INFO      Activation function:    tanh\n",
      "12:44 madminer.ml          INFO      Batch size:             128\n",
      "12:44 madminer.ml          INFO      Trainer:                amsgrad\n",
      "12:44 madminer.ml          INFO      Epochs:                 50\n",
      "12:44 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "12:44 madminer.ml          INFO      Validation split:       0.5\n",
      "12:44 madminer.ml          INFO      Early stopping:         True\n",
      "12:44 madminer.ml          INFO      Scale inputs:           True\n",
      "12:44 madminer.ml          INFO      Shuffle labels          False\n",
      "12:44 madminer.ml          INFO      Regularization:         None\n",
      "12:44 madminer.ml          INFO      Samples:                all\n",
      "12:44 madminer.ml          INFO    Loading training data\n",
      "12:44 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "12:44 madminer.ml          INFO    Rescaling inputs\n",
      "12:44 madminer.ml          INFO    Creating model for method sally\n",
      "12:44 madminer.ml          INFO    Training model\n",
      "12:44 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0998 (mse_score: 0.0998)\n",
      "12:44 madminer.utils.ml.sc INFO                val. loss  0.0963 (mse_score: 0.0963) (*)\n",
      "12:45 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0956 (mse_score: 0.0956)\n",
      "12:45 madminer.utils.ml.sc INFO                val. loss  0.0930 (mse_score: 0.0930) (*)\n",
      "12:45 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0929 (mse_score: 0.0929)\n",
      "12:45 madminer.utils.ml.sc INFO                val. loss  0.0913 (mse_score: 0.0913) (*)\n",
      "12:46 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0910 (mse_score: 0.0910)\n",
      "12:46 madminer.utils.ml.sc INFO                val. loss  0.0896 (mse_score: 0.0896) (*)\n",
      "12:47 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0906 (mse_score: 0.0906)\n",
      "12:47 madminer.utils.ml.sc INFO                val. loss  0.0898 (mse_score: 0.0898)\n",
      "12:47 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0879 (mse_score: 0.0879)\n",
      "12:47 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "12:48 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0870 (mse_score: 0.0870)\n",
      "12:48 madminer.utils.ml.sc INFO                val. loss  0.0889 (mse_score: 0.0889) (*)\n",
      "12:48 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0862 (mse_score: 0.0862)\n",
      "12:48 madminer.utils.ml.sc INFO                val. loss  0.0882 (mse_score: 0.0882) (*)\n",
      "12:49 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0845 (mse_score: 0.0845)\n",
      "12:49 madminer.utils.ml.sc INFO                val. loss  0.0875 (mse_score: 0.0875) (*)\n",
      "12:49 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0838 (mse_score: 0.0838)\n",
      "12:49 madminer.utils.ml.sc INFO                val. loss  0.0877 (mse_score: 0.0877)\n",
      "12:50 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0828 (mse_score: 0.0828)\n",
      "12:50 madminer.utils.ml.sc INFO                val. loss  0.0872 (mse_score: 0.0872) (*)\n",
      "12:50 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0815 (mse_score: 0.0815)\n",
      "12:50 madminer.utils.ml.sc INFO                val. loss  0.0876 (mse_score: 0.0876)\n",
      "12:51 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0807 (mse_score: 0.0807)\n",
      "12:51 madminer.utils.ml.sc INFO                val. loss  0.0876 (mse_score: 0.0876)\n",
      "12:52 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0795 (mse_score: 0.0795)\n",
      "12:52 madminer.utils.ml.sc INFO                val. loss  0.0875 (mse_score: 0.0875)\n",
      "12:52 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0785 (mse_score: 0.0785)\n",
      "12:52 madminer.utils.ml.sc INFO                val. loss  0.0869 (mse_score: 0.0869) (*)\n",
      "12:53 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0781 (mse_score: 0.0781)\n",
      "12:53 madminer.utils.ml.sc INFO                val. loss  0.0864 (mse_score: 0.0864) (*)\n",
      "12:53 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0767 (mse_score: 0.0767)\n",
      "12:53 madminer.utils.ml.sc INFO                val. loss  0.0865 (mse_score: 0.0865)\n",
      "12:54 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0761 (mse_score: 0.0761)\n",
      "12:54 madminer.utils.ml.sc INFO                val. loss  0.0860 (mse_score: 0.0860) (*)\n",
      "12:54 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0754 (mse_score: 0.0754)\n",
      "12:54 madminer.utils.ml.sc INFO                val. loss  0.0855 (mse_score: 0.0855) (*)\n",
      "12:55 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0751 (mse_score: 0.0751)\n",
      "12:55 madminer.utils.ml.sc INFO                val. loss  0.0936 (mse_score: 0.0936)\n",
      "12:55 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0743 (mse_score: 0.0743)\n",
      "12:55 madminer.utils.ml.sc INFO                val. loss  0.0859 (mse_score: 0.0859)\n",
      "12:56 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0726 (mse_score: 0.0726)\n",
      "12:56 madminer.utils.ml.sc INFO                val. loss  0.0860 (mse_score: 0.0860)\n",
      "12:57 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0715 (mse_score: 0.0715)\n",
      "12:57 madminer.utils.ml.sc INFO                val. loss  0.0859 (mse_score: 0.0859)\n",
      "12:57 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0711 (mse_score: 0.0711)\n",
      "12:57 madminer.utils.ml.sc INFO                val. loss  0.0860 (mse_score: 0.0860)\n",
      "12:58 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0704 (mse_score: 0.0704)\n",
      "12:58 madminer.utils.ml.sc INFO                val. loss  0.0855 (mse_score: 0.0855) (*)\n",
      "12:58 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0696 (mse_score: 0.0696)\n",
      "12:58 madminer.utils.ml.sc INFO                val. loss  0.0856 (mse_score: 0.0856)\n",
      "12:59 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0691 (mse_score: 0.0691)\n",
      "12:59 madminer.utils.ml.sc INFO                val. loss  0.0865 (mse_score: 0.0865)\n",
      "12:59 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0685 (mse_score: 0.0685)\n",
      "12:59 madminer.utils.ml.sc INFO                val. loss  0.0852 (mse_score: 0.0852) (*)\n",
      "13:00 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0678 (mse_score: 0.0678)\n",
      "13:00 madminer.utils.ml.sc INFO                val. loss  0.0853 (mse_score: 0.0853)\n",
      "13:01 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0672 (mse_score: 0.0672)\n",
      "13:01 madminer.utils.ml.sc INFO                val. loss  0.0859 (mse_score: 0.0859)\n",
      "13:01 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0667 (mse_score: 0.0667)\n",
      "13:01 madminer.utils.ml.sc INFO                val. loss  0.0859 (mse_score: 0.0859)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:02 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0662 (mse_score: 0.0662)\n",
      "13:02 madminer.utils.ml.sc INFO                val. loss  0.0858 (mse_score: 0.0858)\n",
      "13:02 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0656 (mse_score: 0.0656)\n",
      "13:02 madminer.utils.ml.sc INFO                val. loss  0.0861 (mse_score: 0.0861)\n",
      "13:03 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0651 (mse_score: 0.0651)\n",
      "13:03 madminer.utils.ml.sc INFO                val. loss  0.0855 (mse_score: 0.0855)\n",
      "13:03 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0646 (mse_score: 0.0646)\n",
      "13:03 madminer.utils.ml.sc INFO                val. loss  0.0858 (mse_score: 0.0858)\n",
      "13:04 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0644 (mse_score: 0.0644)\n",
      "13:04 madminer.utils.ml.sc INFO                val. loss  0.0856 (mse_score: 0.0856)\n",
      "13:05 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0638 (mse_score: 0.0638)\n",
      "13:05 madminer.utils.ml.sc INFO                val. loss  0.0866 (mse_score: 0.0866)\n",
      "13:05 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0634 (mse_score: 0.0634)\n",
      "13:05 madminer.utils.ml.sc INFO                val. loss  0.0857 (mse_score: 0.0857)\n",
      "13:06 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0629 (mse_score: 0.0629)\n",
      "13:06 madminer.utils.ml.sc INFO                val. loss  0.0852 (mse_score: 0.0852)\n",
      "13:06 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0626 (mse_score: 0.0626)\n",
      "13:06 madminer.utils.ml.sc INFO                val. loss  0.0857 (mse_score: 0.0857)\n",
      "13:07 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0622 (mse_score: 0.0622)\n",
      "13:07 madminer.utils.ml.sc INFO                val. loss  0.0854 (mse_score: 0.0854)\n",
      "13:07 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0619 (mse_score: 0.0619)\n",
      "13:07 madminer.utils.ml.sc INFO                val. loss  0.0856 (mse_score: 0.0856)\n",
      "13:07 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0618 (mse_score: 0.0618)\n",
      "13:07 madminer.utils.ml.sc INFO                val. loss  0.0855 (mse_score: 0.0855)\n",
      "13:08 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0611 (mse_score: 0.0611)\n",
      "13:08 madminer.utils.ml.sc INFO                val. loss  0.0856 (mse_score: 0.0856)\n",
      "13:08 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0611 (mse_score: 0.0611)\n",
      "13:08 madminer.utils.ml.sc INFO                val. loss  0.0853 (mse_score: 0.0853)\n",
      "13:09 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0606 (mse_score: 0.0606)\n",
      "13:09 madminer.utils.ml.sc INFO                val. loss  0.0857 (mse_score: 0.0857)\n",
      "13:09 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0604 (mse_score: 0.0604)\n",
      "13:09 madminer.utils.ml.sc INFO                val. loss  0.0852 (mse_score: 0.0852)\n",
      "13:10 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0601 (mse_score: 0.0601)\n",
      "13:10 madminer.utils.ml.sc INFO                val. loss  0.0854 (mse_score: 0.0854)\n",
      "13:10 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0599 (mse_score: 0.0599)\n",
      "13:10 madminer.utils.ml.sc INFO                val. loss  0.0854 (mse_score: 0.0854)\n",
      "13:11 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0598 (mse_score: 0.0598)\n",
      "13:11 madminer.utils.ml.sc INFO                val. loss  0.0853 (mse_score: 0.0853)\n",
      "13:11 madminer.utils.ml.sc INFO    Early stopping after epoch 28, with loss 0.09 compared to final loss 0.09\n",
      "13:11 madminer.utils.ml.sc INFO    Finished training\n",
      "13:11 madminer.ml          INFO    Training estimator 6 / 10 in ensemble\n",
      "13:11 madminer.ml          INFO    Starting training\n",
      "13:11 madminer.ml          INFO      Method:                 sally\n",
      "13:11 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_5.npy\n",
      "13:11 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_5.npy\n",
      "13:11 madminer.ml          INFO      Features:               all\n",
      "13:11 madminer.ml          INFO      Method:                 sally\n",
      "13:11 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "13:11 madminer.ml          INFO      Activation function:    tanh\n",
      "13:11 madminer.ml          INFO      Batch size:             128\n",
      "13:11 madminer.ml          INFO      Trainer:                amsgrad\n",
      "13:11 madminer.ml          INFO      Epochs:                 50\n",
      "13:11 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "13:11 madminer.ml          INFO      Validation split:       0.5\n",
      "13:11 madminer.ml          INFO      Early stopping:         True\n",
      "13:11 madminer.ml          INFO      Scale inputs:           True\n",
      "13:11 madminer.ml          INFO      Shuffle labels          False\n",
      "13:11 madminer.ml          INFO      Regularization:         None\n",
      "13:11 madminer.ml          INFO      Samples:                all\n",
      "13:11 madminer.ml          INFO    Loading training data\n",
      "13:11 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "13:11 madminer.ml          INFO    Rescaling inputs\n",
      "13:11 madminer.ml          INFO    Creating model for method sally\n",
      "13:11 madminer.ml          INFO    Training model\n",
      "13:11 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1551 (mse_score: 0.1551)\n",
      "13:11 madminer.utils.ml.sc INFO                val. loss  0.0888 (mse_score: 0.0888) (*)\n",
      "13:12 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1532 (mse_score: 0.1532)\n",
      "13:12 madminer.utils.ml.sc INFO                val. loss  0.0887 (mse_score: 0.0887) (*)\n",
      "13:12 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1515 (mse_score: 0.1515)\n",
      "13:12 madminer.utils.ml.sc INFO                val. loss  0.0857 (mse_score: 0.0857) (*)\n",
      "13:13 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1502 (mse_score: 0.1502)\n",
      "13:13 madminer.utils.ml.sc INFO                val. loss  0.0853 (mse_score: 0.0853) (*)\n",
      "13:13 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1481 (mse_score: 0.1481)\n",
      "13:13 madminer.utils.ml.sc INFO                val. loss  0.0837 (mse_score: 0.0837) (*)\n",
      "13:13 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1478 (mse_score: 0.1478)\n",
      "13:13 madminer.utils.ml.sc INFO                val. loss  0.0831 (mse_score: 0.0831) (*)\n",
      "13:14 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1458 (mse_score: 0.1458)\n",
      "13:14 madminer.utils.ml.sc INFO                val. loss  0.0825 (mse_score: 0.0825) (*)\n",
      "13:14 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1448 (mse_score: 0.1448)\n",
      "13:14 madminer.utils.ml.sc INFO                val. loss  0.0815 (mse_score: 0.0815) (*)\n",
      "13:15 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1440 (mse_score: 0.1440)\n",
      "13:15 madminer.utils.ml.sc INFO                val. loss  0.0822 (mse_score: 0.0822)\n",
      "13:15 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.1417 (mse_score: 0.1417)\n",
      "13:15 madminer.utils.ml.sc INFO                val. loss  0.0805 (mse_score: 0.0805) (*)\n",
      "13:16 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.1400 (mse_score: 0.1400)\n",
      "13:16 madminer.utils.ml.sc INFO                val. loss  0.0812 (mse_score: 0.0812)\n",
      "13:16 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.1394 (mse_score: 0.1394)\n",
      "13:16 madminer.utils.ml.sc INFO                val. loss  0.0800 (mse_score: 0.0800) (*)\n",
      "13:17 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.1376 (mse_score: 0.1376)\n",
      "13:17 madminer.utils.ml.sc INFO                val. loss  0.0791 (mse_score: 0.0791) (*)\n",
      "13:17 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.1363 (mse_score: 0.1363)\n",
      "13:17 madminer.utils.ml.sc INFO                val. loss  0.0799 (mse_score: 0.0799)\n",
      "13:17 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.1352 (mse_score: 0.1352)\n",
      "13:17 madminer.utils.ml.sc INFO                val. loss  0.0803 (mse_score: 0.0803)\n",
      "13:18 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.1341 (mse_score: 0.1341)\n",
      "13:18 madminer.utils.ml.sc INFO                val. loss  0.0798 (mse_score: 0.0798)\n",
      "13:18 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.1332 (mse_score: 0.1332)\n",
      "13:18 madminer.utils.ml.sc INFO                val. loss  0.0801 (mse_score: 0.0801)\n",
      "13:19 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.1321 (mse_score: 0.1321)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:19 madminer.utils.ml.sc INFO                val. loss  0.0795 (mse_score: 0.0795)\n",
      "13:19 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.1311 (mse_score: 0.1311)\n",
      "13:19 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789) (*)\n",
      "13:20 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.1305 (mse_score: 0.1305)\n",
      "13:20 madminer.utils.ml.sc INFO                val. loss  0.0792 (mse_score: 0.0792)\n",
      "13:20 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.1297 (mse_score: 0.1297)\n",
      "13:20 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788) (*)\n",
      "13:21 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.1287 (mse_score: 0.1287)\n",
      "13:21 madminer.utils.ml.sc INFO                val. loss  0.0791 (mse_score: 0.0791)\n",
      "13:21 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.1278 (mse_score: 0.1278)\n",
      "13:21 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787) (*)\n",
      "13:22 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.1271 (mse_score: 0.1271)\n",
      "13:22 madminer.utils.ml.sc INFO                val. loss  0.0794 (mse_score: 0.0794)\n",
      "13:22 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.1265 (mse_score: 0.1265)\n",
      "13:22 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788)\n",
      "13:22 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.1258 (mse_score: 0.1258)\n",
      "13:22 madminer.utils.ml.sc INFO                val. loss  0.0795 (mse_score: 0.0795)\n",
      "13:23 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.1253 (mse_score: 0.1253)\n",
      "13:23 madminer.utils.ml.sc INFO                val. loss  0.0786 (mse_score: 0.0786) (*)\n",
      "13:23 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.1245 (mse_score: 0.1245)\n",
      "13:23 madminer.utils.ml.sc INFO                val. loss  0.0786 (mse_score: 0.0786)\n",
      "13:24 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.1239 (mse_score: 0.1239)\n",
      "13:24 madminer.utils.ml.sc INFO                val. loss  0.0791 (mse_score: 0.0791)\n",
      "13:24 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.1233 (mse_score: 0.1233)\n",
      "13:24 madminer.utils.ml.sc INFO                val. loss  0.0783 (mse_score: 0.0783) (*)\n",
      "13:25 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.1227 (mse_score: 0.1227)\n",
      "13:25 madminer.utils.ml.sc INFO                val. loss  0.0782 (mse_score: 0.0782) (*)\n",
      "13:25 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.1222 (mse_score: 0.1222)\n",
      "13:25 madminer.utils.ml.sc INFO                val. loss  0.0786 (mse_score: 0.0786)\n",
      "13:25 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.1216 (mse_score: 0.1216)\n",
      "13:25 madminer.utils.ml.sc INFO                val. loss  0.0785 (mse_score: 0.0785)\n",
      "13:26 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.1212 (mse_score: 0.1212)\n",
      "13:26 madminer.utils.ml.sc INFO                val. loss  0.0783 (mse_score: 0.0783)\n",
      "13:26 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.1208 (mse_score: 0.1208)\n",
      "13:26 madminer.utils.ml.sc INFO                val. loss  0.0786 (mse_score: 0.0786)\n",
      "13:27 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.1215 (mse_score: 0.1215)\n",
      "13:27 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n",
      "13:27 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.1197 (mse_score: 0.1197)\n",
      "13:27 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "13:28 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.1194 (mse_score: 0.1194)\n",
      "13:28 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788)\n",
      "13:28 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.1189 (mse_score: 0.1189)\n",
      "13:28 madminer.utils.ml.sc INFO                val. loss  0.0785 (mse_score: 0.0785)\n",
      "13:29 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.1184 (mse_score: 0.1184)\n",
      "13:29 madminer.utils.ml.sc INFO                val. loss  0.0781 (mse_score: 0.0781) (*)\n",
      "13:29 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.1181 (mse_score: 0.1181)\n",
      "13:29 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788)\n",
      "13:29 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.1178 (mse_score: 0.1178)\n",
      "13:29 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787)\n",
      "13:30 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.1175 (mse_score: 0.1175)\n",
      "13:30 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788)\n",
      "13:30 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.1172 (mse_score: 0.1172)\n",
      "13:30 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787)\n",
      "13:31 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.1168 (mse_score: 0.1168)\n",
      "13:31 madminer.utils.ml.sc INFO                val. loss  0.0783 (mse_score: 0.0783)\n",
      "13:31 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.1164 (mse_score: 0.1164)\n",
      "13:31 madminer.utils.ml.sc INFO                val. loss  0.0783 (mse_score: 0.0783)\n",
      "13:32 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.1164 (mse_score: 0.1164)\n",
      "13:32 madminer.utils.ml.sc INFO                val. loss  0.0784 (mse_score: 0.0784)\n",
      "13:32 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.1158 (mse_score: 0.1158)\n",
      "13:32 madminer.utils.ml.sc INFO                val. loss  0.0784 (mse_score: 0.0784)\n",
      "13:33 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.1157 (mse_score: 0.1157)\n",
      "13:33 madminer.utils.ml.sc INFO                val. loss  0.0785 (mse_score: 0.0785)\n",
      "13:33 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.1154 (mse_score: 0.1154)\n",
      "13:33 madminer.utils.ml.sc INFO                val. loss  0.0783 (mse_score: 0.0783)\n",
      "13:33 madminer.utils.ml.sc INFO    Early stopping after epoch 40, with loss 0.08 compared to final loss 0.08\n",
      "13:33 madminer.utils.ml.sc INFO    Finished training\n",
      "13:33 madminer.ml          INFO    Training estimator 7 / 10 in ensemble\n",
      "13:33 madminer.ml          INFO    Starting training\n",
      "13:33 madminer.ml          INFO      Method:                 sally\n",
      "13:33 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_6.npy\n",
      "13:33 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_6.npy\n",
      "13:33 madminer.ml          INFO      Features:               all\n",
      "13:33 madminer.ml          INFO      Method:                 sally\n",
      "13:33 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "13:33 madminer.ml          INFO      Activation function:    tanh\n",
      "13:33 madminer.ml          INFO      Batch size:             128\n",
      "13:33 madminer.ml          INFO      Trainer:                amsgrad\n",
      "13:33 madminer.ml          INFO      Epochs:                 50\n",
      "13:33 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "13:33 madminer.ml          INFO      Validation split:       0.5\n",
      "13:33 madminer.ml          INFO      Early stopping:         True\n",
      "13:33 madminer.ml          INFO      Scale inputs:           True\n",
      "13:33 madminer.ml          INFO      Shuffle labels          False\n",
      "13:33 madminer.ml          INFO      Regularization:         None\n",
      "13:33 madminer.ml          INFO      Samples:                all\n",
      "13:33 madminer.ml          INFO    Loading training data\n",
      "13:33 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "13:33 madminer.ml          INFO    Rescaling inputs\n",
      "13:33 madminer.ml          INFO    Creating model for method sally\n",
      "13:33 madminer.ml          INFO    Training model\n",
      "13:34 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1262 (mse_score: 0.1262)\n",
      "13:34 madminer.utils.ml.sc INFO                val. loss  0.1187 (mse_score: 0.1187) (*)\n",
      "13:34 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1229 (mse_score: 0.1229)\n",
      "13:34 madminer.utils.ml.sc INFO                val. loss  0.1164 (mse_score: 0.1164) (*)\n",
      "13:35 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1201 (mse_score: 0.1201)\n",
      "13:35 madminer.utils.ml.sc INFO                val. loss  0.1137 (mse_score: 0.1137) (*)\n",
      "13:35 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1183 (mse_score: 0.1183)\n",
      "13:35 madminer.utils.ml.sc INFO                val. loss  0.1156 (mse_score: 0.1156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:36 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1160 (mse_score: 0.1160)\n",
      "13:36 madminer.utils.ml.sc INFO                val. loss  0.1114 (mse_score: 0.1114) (*)\n",
      "13:36 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1148 (mse_score: 0.1148)\n",
      "13:36 madminer.utils.ml.sc INFO                val. loss  0.1102 (mse_score: 0.1102) (*)\n",
      "13:36 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1120 (mse_score: 0.1120)\n",
      "13:36 madminer.utils.ml.sc INFO                val. loss  0.1095 (mse_score: 0.1095) (*)\n",
      "13:37 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1104 (mse_score: 0.1104)\n",
      "13:37 madminer.utils.ml.sc INFO                val. loss  0.1134 (mse_score: 0.1134)\n",
      "13:37 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1114 (mse_score: 0.1114)\n",
      "13:37 madminer.utils.ml.sc INFO                val. loss  0.1115 (mse_score: 0.1115)\n",
      "13:38 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.1075 (mse_score: 0.1075)\n",
      "13:38 madminer.utils.ml.sc INFO                val. loss  0.1125 (mse_score: 0.1125)\n",
      "13:38 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.1064 (mse_score: 0.1064)\n",
      "13:38 madminer.utils.ml.sc INFO                val. loss  0.1077 (mse_score: 0.1077) (*)\n",
      "13:39 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.1053 (mse_score: 0.1053)\n",
      "13:39 madminer.utils.ml.sc INFO                val. loss  0.1079 (mse_score: 0.1079)\n",
      "13:39 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.1035 (mse_score: 0.1035)\n",
      "13:39 madminer.utils.ml.sc INFO                val. loss  0.1071 (mse_score: 0.1071) (*)\n",
      "13:40 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.1019 (mse_score: 0.1019)\n",
      "13:40 madminer.utils.ml.sc INFO                val. loss  0.1070 (mse_score: 0.1070) (*)\n",
      "13:40 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.1007 (mse_score: 0.1007)\n",
      "13:40 madminer.utils.ml.sc INFO                val. loss  0.1067 (mse_score: 0.1067) (*)\n",
      "13:41 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0995 (mse_score: 0.0995)\n",
      "13:41 madminer.utils.ml.sc INFO                val. loss  0.1065 (mse_score: 0.1065) (*)\n",
      "13:41 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0984 (mse_score: 0.0984)\n",
      "13:41 madminer.utils.ml.sc INFO                val. loss  0.1061 (mse_score: 0.1061) (*)\n",
      "13:41 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0974 (mse_score: 0.0974)\n",
      "13:41 madminer.utils.ml.sc INFO                val. loss  0.1061 (mse_score: 0.1061) (*)\n",
      "13:42 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0962 (mse_score: 0.0962)\n",
      "13:42 madminer.utils.ml.sc INFO                val. loss  0.1060 (mse_score: 0.1060) (*)\n",
      "13:42 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0949 (mse_score: 0.0949)\n",
      "13:42 madminer.utils.ml.sc INFO                val. loss  0.1066 (mse_score: 0.1066)\n",
      "13:43 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0943 (mse_score: 0.0943)\n",
      "13:43 madminer.utils.ml.sc INFO                val. loss  0.1071 (mse_score: 0.1071)\n",
      "13:43 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0934 (mse_score: 0.0934)\n",
      "13:43 madminer.utils.ml.sc INFO                val. loss  0.1050 (mse_score: 0.1050) (*)\n",
      "13:44 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0927 (mse_score: 0.0927)\n",
      "13:44 madminer.utils.ml.sc INFO                val. loss  0.1058 (mse_score: 0.1058)\n",
      "13:44 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0919 (mse_score: 0.0919)\n",
      "13:44 madminer.utils.ml.sc INFO                val. loss  0.1060 (mse_score: 0.1060)\n",
      "13:45 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0912 (mse_score: 0.0912)\n",
      "13:45 madminer.utils.ml.sc INFO                val. loss  0.1059 (mse_score: 0.1059)\n",
      "13:45 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0905 (mse_score: 0.0905)\n",
      "13:45 madminer.utils.ml.sc INFO                val. loss  0.1063 (mse_score: 0.1063)\n",
      "13:46 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0899 (mse_score: 0.0899)\n",
      "13:46 madminer.utils.ml.sc INFO                val. loss  0.1057 (mse_score: 0.1057)\n",
      "13:46 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0891 (mse_score: 0.0891)\n",
      "13:46 madminer.utils.ml.sc INFO                val. loss  0.1057 (mse_score: 0.1057)\n",
      "13:47 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0885 (mse_score: 0.0885)\n",
      "13:47 madminer.utils.ml.sc INFO                val. loss  0.1057 (mse_score: 0.1057)\n",
      "13:47 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0882 (mse_score: 0.0882)\n",
      "13:47 madminer.utils.ml.sc INFO                val. loss  0.1056 (mse_score: 0.1056)\n",
      "13:48 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0874 (mse_score: 0.0874)\n",
      "13:48 madminer.utils.ml.sc INFO                val. loss  0.1062 (mse_score: 0.1062)\n",
      "13:48 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0870 (mse_score: 0.0870)\n",
      "13:48 madminer.utils.ml.sc INFO                val. loss  0.1058 (mse_score: 0.1058)\n",
      "13:49 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0864 (mse_score: 0.0864)\n",
      "13:49 madminer.utils.ml.sc INFO                val. loss  0.1059 (mse_score: 0.1059)\n",
      "13:50 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0859 (mse_score: 0.0859)\n",
      "13:50 madminer.utils.ml.sc INFO                val. loss  0.1062 (mse_score: 0.1062)\n",
      "13:50 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0855 (mse_score: 0.0855)\n",
      "13:50 madminer.utils.ml.sc INFO                val. loss  0.1055 (mse_score: 0.1055)\n",
      "13:51 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0851 (mse_score: 0.0851)\n",
      "13:51 madminer.utils.ml.sc INFO                val. loss  0.1062 (mse_score: 0.1062)\n",
      "13:51 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0846 (mse_score: 0.0846)\n",
      "13:51 madminer.utils.ml.sc INFO                val. loss  0.1060 (mse_score: 0.1060)\n",
      "13:52 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0842 (mse_score: 0.0842)\n",
      "13:52 madminer.utils.ml.sc INFO                val. loss  0.1056 (mse_score: 0.1056)\n",
      "13:52 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0838 (mse_score: 0.0838)\n",
      "13:52 madminer.utils.ml.sc INFO                val. loss  0.1060 (mse_score: 0.1060)\n",
      "13:53 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0833 (mse_score: 0.0833)\n",
      "13:53 madminer.utils.ml.sc INFO                val. loss  0.1059 (mse_score: 0.1059)\n",
      "13:53 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0830 (mse_score: 0.0830)\n",
      "13:53 madminer.utils.ml.sc INFO                val. loss  0.1059 (mse_score: 0.1059)\n",
      "13:54 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0827 (mse_score: 0.0827)\n",
      "13:54 madminer.utils.ml.sc INFO                val. loss  0.1058 (mse_score: 0.1058)\n",
      "13:54 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0824 (mse_score: 0.0824)\n",
      "13:54 madminer.utils.ml.sc INFO                val. loss  0.1063 (mse_score: 0.1063)\n",
      "13:55 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0820 (mse_score: 0.0820)\n",
      "13:55 madminer.utils.ml.sc INFO                val. loss  0.1055 (mse_score: 0.1055)\n",
      "13:55 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0818 (mse_score: 0.0818)\n",
      "13:55 madminer.utils.ml.sc INFO                val. loss  0.1054 (mse_score: 0.1054)\n",
      "13:56 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0815 (mse_score: 0.0815)\n",
      "13:56 madminer.utils.ml.sc INFO                val. loss  0.1060 (mse_score: 0.1060)\n",
      "13:56 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0811 (mse_score: 0.0811)\n",
      "13:56 madminer.utils.ml.sc INFO                val. loss  0.1058 (mse_score: 0.1058)\n",
      "13:57 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0809 (mse_score: 0.0809)\n",
      "13:57 madminer.utils.ml.sc INFO                val. loss  0.1065 (mse_score: 0.1065)\n",
      "13:57 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0807 (mse_score: 0.0807)\n",
      "13:57 madminer.utils.ml.sc INFO                val. loss  0.1061 (mse_score: 0.1061)\n",
      "13:58 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0804 (mse_score: 0.0804)\n",
      "13:58 madminer.utils.ml.sc INFO                val. loss  0.1063 (mse_score: 0.1063)\n",
      "13:58 madminer.utils.ml.sc INFO    Early stopping after epoch 22, with loss 0.11 compared to final loss 0.11\n",
      "13:58 madminer.utils.ml.sc INFO    Finished training\n",
      "13:58 madminer.ml          INFO    Training estimator 8 / 10 in ensemble\n",
      "13:58 madminer.ml          INFO    Starting training\n",
      "13:58 madminer.ml          INFO      Method:                 sally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:58 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_7.npy\n",
      "13:58 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_7.npy\n",
      "13:58 madminer.ml          INFO      Features:               all\n",
      "13:58 madminer.ml          INFO      Method:                 sally\n",
      "13:58 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "13:58 madminer.ml          INFO      Activation function:    tanh\n",
      "13:58 madminer.ml          INFO      Batch size:             128\n",
      "13:58 madminer.ml          INFO      Trainer:                amsgrad\n",
      "13:58 madminer.ml          INFO      Epochs:                 50\n",
      "13:58 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "13:58 madminer.ml          INFO      Validation split:       0.5\n",
      "13:58 madminer.ml          INFO      Early stopping:         True\n",
      "13:58 madminer.ml          INFO      Scale inputs:           True\n",
      "13:58 madminer.ml          INFO      Shuffle labels          False\n",
      "13:58 madminer.ml          INFO      Regularization:         None\n",
      "13:58 madminer.ml          INFO      Samples:                all\n",
      "13:58 madminer.ml          INFO    Loading training data\n",
      "13:58 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "13:58 madminer.ml          INFO    Rescaling inputs\n",
      "13:58 madminer.ml          INFO    Creating model for method sally\n",
      "13:58 madminer.ml          INFO    Training model\n",
      "13:59 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0809 (mse_score: 0.0809)\n",
      "13:59 madminer.utils.ml.sc INFO                val. loss  0.0890 (mse_score: 0.0890) (*)\n",
      "14:00 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0773 (mse_score: 0.0773)\n",
      "14:00 madminer.utils.ml.sc INFO                val. loss  0.0849 (mse_score: 0.0849) (*)\n",
      "14:00 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0743 (mse_score: 0.0743)\n",
      "14:00 madminer.utils.ml.sc INFO                val. loss  0.0906 (mse_score: 0.0906)\n",
      "14:01 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0730 (mse_score: 0.0730)\n",
      "14:01 madminer.utils.ml.sc INFO                val. loss  0.0824 (mse_score: 0.0824) (*)\n",
      "14:02 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0712 (mse_score: 0.0712)\n",
      "14:02 madminer.utils.ml.sc INFO                val. loss  0.0803 (mse_score: 0.0803) (*)\n",
      "14:02 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0697 (mse_score: 0.0697)\n",
      "14:02 madminer.utils.ml.sc INFO                val. loss  0.0818 (mse_score: 0.0818)\n",
      "14:03 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0689 (mse_score: 0.0689)\n",
      "14:03 madminer.utils.ml.sc INFO                val. loss  0.0791 (mse_score: 0.0791) (*)\n",
      "14:03 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0674 (mse_score: 0.0674)\n",
      "14:03 madminer.utils.ml.sc INFO                val. loss  0.0797 (mse_score: 0.0797)\n",
      "14:04 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0662 (mse_score: 0.0662)\n",
      "14:04 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787) (*)\n",
      "14:04 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0654 (mse_score: 0.0654)\n",
      "14:04 madminer.utils.ml.sc INFO                val. loss  0.0781 (mse_score: 0.0781) (*)\n",
      "14:05 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0643 (mse_score: 0.0643)\n",
      "14:05 madminer.utils.ml.sc INFO                val. loss  0.0773 (mse_score: 0.0773) (*)\n",
      "14:06 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0632 (mse_score: 0.0632)\n",
      "14:06 madminer.utils.ml.sc INFO                val. loss  0.0795 (mse_score: 0.0795)\n",
      "14:06 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0618 (mse_score: 0.0618)\n",
      "14:06 madminer.utils.ml.sc INFO                val. loss  0.0807 (mse_score: 0.0807)\n",
      "14:07 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0612 (mse_score: 0.0612)\n",
      "14:07 madminer.utils.ml.sc INFO                val. loss  0.0776 (mse_score: 0.0776)\n",
      "14:07 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0600 (mse_score: 0.0600)\n",
      "14:07 madminer.utils.ml.sc INFO                val. loss  0.0764 (mse_score: 0.0764) (*)\n",
      "14:08 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0592 (mse_score: 0.0592)\n",
      "14:08 madminer.utils.ml.sc INFO                val. loss  0.0771 (mse_score: 0.0771)\n",
      "14:08 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0582 (mse_score: 0.0582)\n",
      "14:08 madminer.utils.ml.sc INFO                val. loss  0.0759 (mse_score: 0.0759) (*)\n",
      "14:09 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0577 (mse_score: 0.0577)\n",
      "14:09 madminer.utils.ml.sc INFO                val. loss  0.0759 (mse_score: 0.0759) (*)\n",
      "14:09 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0567 (mse_score: 0.0567)\n",
      "14:09 madminer.utils.ml.sc INFO                val. loss  0.0758 (mse_score: 0.0758) (*)\n",
      "14:10 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0560 (mse_score: 0.0560)\n",
      "14:10 madminer.utils.ml.sc INFO                val. loss  0.0769 (mse_score: 0.0769)\n",
      "14:10 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0554 (mse_score: 0.0554)\n",
      "14:10 madminer.utils.ml.sc INFO                val. loss  0.0760 (mse_score: 0.0760)\n",
      "14:10 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0547 (mse_score: 0.0547)\n",
      "14:10 madminer.utils.ml.sc INFO                val. loss  0.0763 (mse_score: 0.0763)\n",
      "14:11 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0539 (mse_score: 0.0539)\n",
      "14:11 madminer.utils.ml.sc INFO                val. loss  0.0754 (mse_score: 0.0754) (*)\n",
      "14:11 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0534 (mse_score: 0.0534)\n",
      "14:11 madminer.utils.ml.sc INFO                val. loss  0.0750 (mse_score: 0.0750) (*)\n",
      "14:12 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0528 (mse_score: 0.0528)\n",
      "14:12 madminer.utils.ml.sc INFO                val. loss  0.0761 (mse_score: 0.0761)\n",
      "14:12 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0522 (mse_score: 0.0522)\n",
      "14:12 madminer.utils.ml.sc INFO                val. loss  0.0746 (mse_score: 0.0746) (*)\n",
      "14:13 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0516 (mse_score: 0.0516)\n",
      "14:13 madminer.utils.ml.sc INFO                val. loss  0.0752 (mse_score: 0.0752)\n",
      "14:13 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0511 (mse_score: 0.0511)\n",
      "14:13 madminer.utils.ml.sc INFO                val. loss  0.0746 (mse_score: 0.0746) (*)\n",
      "14:14 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0507 (mse_score: 0.0507)\n",
      "14:14 madminer.utils.ml.sc INFO                val. loss  0.0751 (mse_score: 0.0751)\n",
      "14:14 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0502 (mse_score: 0.0502)\n",
      "14:14 madminer.utils.ml.sc INFO                val. loss  0.0745 (mse_score: 0.0745) (*)\n",
      "14:15 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0499 (mse_score: 0.0499)\n",
      "14:15 madminer.utils.ml.sc INFO                val. loss  0.0755 (mse_score: 0.0755)\n",
      "14:15 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0494 (mse_score: 0.0494)\n",
      "14:15 madminer.utils.ml.sc INFO                val. loss  0.0748 (mse_score: 0.0748)\n",
      "14:16 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0489 (mse_score: 0.0489)\n",
      "14:16 madminer.utils.ml.sc INFO                val. loss  0.0749 (mse_score: 0.0749)\n",
      "14:16 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0487 (mse_score: 0.0487)\n",
      "14:16 madminer.utils.ml.sc INFO                val. loss  0.0745 (mse_score: 0.0745) (*)\n",
      "14:17 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0482 (mse_score: 0.0482)\n",
      "14:17 madminer.utils.ml.sc INFO                val. loss  0.0756 (mse_score: 0.0756)\n",
      "14:17 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0479 (mse_score: 0.0479)\n",
      "14:17 madminer.utils.ml.sc INFO                val. loss  0.0752 (mse_score: 0.0752)\n",
      "14:18 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0475 (mse_score: 0.0475)\n",
      "14:18 madminer.utils.ml.sc INFO                val. loss  0.0744 (mse_score: 0.0744) (*)\n",
      "14:18 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0472 (mse_score: 0.0472)\n",
      "14:18 madminer.utils.ml.sc INFO                val. loss  0.0745 (mse_score: 0.0745)\n",
      "14:19 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0471 (mse_score: 0.0471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:19 madminer.utils.ml.sc INFO                val. loss  0.0749 (mse_score: 0.0749)\n",
      "14:19 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0468 (mse_score: 0.0468)\n",
      "14:19 madminer.utils.ml.sc INFO                val. loss  0.0749 (mse_score: 0.0749)\n",
      "14:20 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0465 (mse_score: 0.0465)\n",
      "14:20 madminer.utils.ml.sc INFO                val. loss  0.0748 (mse_score: 0.0748)\n",
      "14:20 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0462 (mse_score: 0.0462)\n",
      "14:20 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "14:21 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0460 (mse_score: 0.0460)\n",
      "14:21 madminer.utils.ml.sc INFO                val. loss  0.0743 (mse_score: 0.0743) (*)\n",
      "14:21 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0458 (mse_score: 0.0458)\n",
      "14:21 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "14:22 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0456 (mse_score: 0.0456)\n",
      "14:22 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "14:22 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0454 (mse_score: 0.0454)\n",
      "14:22 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "14:23 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0452 (mse_score: 0.0452)\n",
      "14:23 madminer.utils.ml.sc INFO                val. loss  0.0745 (mse_score: 0.0745)\n",
      "14:23 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0450 (mse_score: 0.0450)\n",
      "14:23 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "14:24 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0448 (mse_score: 0.0448)\n",
      "14:24 madminer.utils.ml.sc INFO                val. loss  0.0744 (mse_score: 0.0744)\n",
      "14:24 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0447 (mse_score: 0.0447)\n",
      "14:24 madminer.utils.ml.sc INFO                val. loss  0.0746 (mse_score: 0.0746)\n",
      "14:24 madminer.utils.ml.sc INFO    Early stopping after epoch 43, with loss 0.07 compared to final loss 0.07\n",
      "14:24 madminer.utils.ml.sc INFO    Finished training\n",
      "14:24 madminer.ml          INFO    Training estimator 9 / 10 in ensemble\n",
      "14:24 madminer.ml          INFO    Starting training\n",
      "14:24 madminer.ml          INFO      Method:                 sally\n",
      "14:24 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_8.npy\n",
      "14:24 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_8.npy\n",
      "14:24 madminer.ml          INFO      Features:               all\n",
      "14:24 madminer.ml          INFO      Method:                 sally\n",
      "14:24 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "14:24 madminer.ml          INFO      Activation function:    tanh\n",
      "14:24 madminer.ml          INFO      Batch size:             128\n",
      "14:24 madminer.ml          INFO      Trainer:                amsgrad\n",
      "14:24 madminer.ml          INFO      Epochs:                 50\n",
      "14:24 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "14:24 madminer.ml          INFO      Validation split:       0.5\n",
      "14:24 madminer.ml          INFO      Early stopping:         True\n",
      "14:24 madminer.ml          INFO      Scale inputs:           True\n",
      "14:24 madminer.ml          INFO      Shuffle labels          False\n",
      "14:24 madminer.ml          INFO      Regularization:         None\n",
      "14:24 madminer.ml          INFO      Samples:                all\n",
      "14:24 madminer.ml          INFO    Loading training data\n",
      "14:24 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "14:24 madminer.ml          INFO    Rescaling inputs\n",
      "14:24 madminer.ml          INFO    Creating model for method sally\n",
      "14:24 madminer.ml          INFO    Training model\n",
      "14:25 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1179 (mse_score: 0.1179)\n",
      "14:25 madminer.utils.ml.sc INFO                val. loss  0.0992 (mse_score: 0.0992) (*)\n",
      "14:25 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1141 (mse_score: 0.1141)\n",
      "14:25 madminer.utils.ml.sc INFO                val. loss  0.0961 (mse_score: 0.0961) (*)\n",
      "14:26 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1118 (mse_score: 0.1118)\n",
      "14:26 madminer.utils.ml.sc INFO                val. loss  0.0936 (mse_score: 0.0936) (*)\n",
      "14:26 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1084 (mse_score: 0.1084)\n",
      "14:26 madminer.utils.ml.sc INFO                val. loss  0.0917 (mse_score: 0.0917) (*)\n",
      "14:27 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1081 (mse_score: 0.1081)\n",
      "14:27 madminer.utils.ml.sc INFO                val. loss  0.0904 (mse_score: 0.0904) (*)\n",
      "14:27 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1044 (mse_score: 0.1044)\n",
      "14:27 madminer.utils.ml.sc INFO                val. loss  0.0894 (mse_score: 0.0894) (*)\n",
      "14:28 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1070 (mse_score: 0.1070)\n",
      "14:28 madminer.utils.ml.sc INFO                val. loss  0.0920 (mse_score: 0.0920)\n",
      "14:29 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1011 (mse_score: 0.1011)\n",
      "14:29 madminer.utils.ml.sc INFO                val. loss  0.0882 (mse_score: 0.0882) (*)\n",
      "14:29 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1001 (mse_score: 0.1001)\n",
      "14:29 madminer.utils.ml.sc INFO                val. loss  0.0884 (mse_score: 0.0884)\n",
      "14:30 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0985 (mse_score: 0.0985)\n",
      "14:30 madminer.utils.ml.sc INFO                val. loss  0.0910 (mse_score: 0.0910)\n",
      "14:30 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0977 (mse_score: 0.0977)\n",
      "14:30 madminer.utils.ml.sc INFO                val. loss  0.0877 (mse_score: 0.0877) (*)\n",
      "14:31 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0959 (mse_score: 0.0959)\n",
      "14:31 madminer.utils.ml.sc INFO                val. loss  0.0872 (mse_score: 0.0872) (*)\n",
      "14:31 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0941 (mse_score: 0.0941)\n",
      "14:31 madminer.utils.ml.sc INFO                val. loss  0.0871 (mse_score: 0.0871) (*)\n",
      "14:32 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0926 (mse_score: 0.0926)\n",
      "14:32 madminer.utils.ml.sc INFO                val. loss  0.0885 (mse_score: 0.0885)\n",
      "14:32 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0913 (mse_score: 0.0913)\n",
      "14:32 madminer.utils.ml.sc INFO                val. loss  0.0867 (mse_score: 0.0867) (*)\n",
      "14:33 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0899 (mse_score: 0.0899)\n",
      "14:33 madminer.utils.ml.sc INFO                val. loss  0.0865 (mse_score: 0.0865) (*)\n",
      "14:33 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0891 (mse_score: 0.0891)\n",
      "14:33 madminer.utils.ml.sc INFO                val. loss  0.0865 (mse_score: 0.0865) (*)\n",
      "14:34 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0875 (mse_score: 0.0875)\n",
      "14:34 madminer.utils.ml.sc INFO                val. loss  0.0870 (mse_score: 0.0870)\n",
      "14:34 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0863 (mse_score: 0.0863)\n",
      "14:34 madminer.utils.ml.sc INFO                val. loss  0.0879 (mse_score: 0.0879)\n",
      "14:35 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0851 (mse_score: 0.0851)\n",
      "14:35 madminer.utils.ml.sc INFO                val. loss  0.0880 (mse_score: 0.0880)\n",
      "14:36 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0843 (mse_score: 0.0843)\n",
      "14:36 madminer.utils.ml.sc INFO                val. loss  0.0870 (mse_score: 0.0870)\n",
      "14:36 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0829 (mse_score: 0.0829)\n",
      "14:36 madminer.utils.ml.sc INFO                val. loss  0.0878 (mse_score: 0.0878)\n",
      "14:37 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0821 (mse_score: 0.0821)\n",
      "14:37 madminer.utils.ml.sc INFO                val. loss  0.0878 (mse_score: 0.0878)\n",
      "14:38 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0807 (mse_score: 0.0807)\n",
      "14:38 madminer.utils.ml.sc INFO                val. loss  0.0877 (mse_score: 0.0877)\n",
      "14:38 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0798 (mse_score: 0.0798)\n",
      "14:38 madminer.utils.ml.sc INFO                val. loss  0.0873 (mse_score: 0.0873)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:39 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0790 (mse_score: 0.0790)\n",
      "14:39 madminer.utils.ml.sc INFO                val. loss  0.0889 (mse_score: 0.0889)\n",
      "14:40 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0783 (mse_score: 0.0783)\n",
      "14:40 madminer.utils.ml.sc INFO                val. loss  0.0880 (mse_score: 0.0880)\n",
      "14:40 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0771 (mse_score: 0.0771)\n",
      "14:40 madminer.utils.ml.sc INFO                val. loss  0.0889 (mse_score: 0.0889)\n",
      "14:41 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0761 (mse_score: 0.0761)\n",
      "14:41 madminer.utils.ml.sc INFO                val. loss  0.0880 (mse_score: 0.0880)\n",
      "14:41 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0754 (mse_score: 0.0754)\n",
      "14:41 madminer.utils.ml.sc INFO                val. loss  0.0886 (mse_score: 0.0886)\n",
      "14:42 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0748 (mse_score: 0.0748)\n",
      "14:42 madminer.utils.ml.sc INFO                val. loss  0.0891 (mse_score: 0.0891)\n",
      "14:43 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0739 (mse_score: 0.0739)\n",
      "14:43 madminer.utils.ml.sc INFO                val. loss  0.0894 (mse_score: 0.0894)\n",
      "14:43 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0733 (mse_score: 0.0733)\n",
      "14:43 madminer.utils.ml.sc INFO                val. loss  0.0891 (mse_score: 0.0891)\n",
      "14:44 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0727 (mse_score: 0.0727)\n",
      "14:44 madminer.utils.ml.sc INFO                val. loss  0.0895 (mse_score: 0.0895)\n",
      "14:44 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0722 (mse_score: 0.0722)\n",
      "14:44 madminer.utils.ml.sc INFO                val. loss  0.0889 (mse_score: 0.0889)\n",
      "14:45 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0715 (mse_score: 0.0715)\n",
      "14:45 madminer.utils.ml.sc INFO                val. loss  0.0893 (mse_score: 0.0893)\n",
      "14:46 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0708 (mse_score: 0.0708)\n",
      "14:46 madminer.utils.ml.sc INFO                val. loss  0.0895 (mse_score: 0.0895)\n",
      "14:46 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0703 (mse_score: 0.0703)\n",
      "14:46 madminer.utils.ml.sc INFO                val. loss  0.0886 (mse_score: 0.0886)\n",
      "14:47 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0699 (mse_score: 0.0699)\n",
      "14:47 madminer.utils.ml.sc INFO                val. loss  0.0904 (mse_score: 0.0904)\n",
      "14:47 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0695 (mse_score: 0.0695)\n",
      "14:47 madminer.utils.ml.sc INFO                val. loss  0.0901 (mse_score: 0.0901)\n",
      "14:48 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0690 (mse_score: 0.0690)\n",
      "14:48 madminer.utils.ml.sc INFO                val. loss  0.0893 (mse_score: 0.0893)\n",
      "14:49 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0686 (mse_score: 0.0686)\n",
      "14:49 madminer.utils.ml.sc INFO                val. loss  0.0894 (mse_score: 0.0894)\n",
      "14:49 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0681 (mse_score: 0.0681)\n",
      "14:49 madminer.utils.ml.sc INFO                val. loss  0.0896 (mse_score: 0.0896)\n",
      "14:50 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0677 (mse_score: 0.0677)\n",
      "14:50 madminer.utils.ml.sc INFO                val. loss  0.0905 (mse_score: 0.0905)\n",
      "14:50 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0674 (mse_score: 0.0674)\n",
      "14:50 madminer.utils.ml.sc INFO                val. loss  0.0908 (mse_score: 0.0908)\n",
      "14:51 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0670 (mse_score: 0.0670)\n",
      "14:51 madminer.utils.ml.sc INFO                val. loss  0.0901 (mse_score: 0.0901)\n",
      "14:52 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0668 (mse_score: 0.0668)\n",
      "14:52 madminer.utils.ml.sc INFO                val. loss  0.0899 (mse_score: 0.0899)\n",
      "14:52 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0664 (mse_score: 0.0664)\n",
      "14:52 madminer.utils.ml.sc INFO                val. loss  0.0900 (mse_score: 0.0900)\n",
      "14:53 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0662 (mse_score: 0.0662)\n",
      "14:53 madminer.utils.ml.sc INFO                val. loss  0.0903 (mse_score: 0.0903)\n",
      "14:53 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0659 (mse_score: 0.0659)\n",
      "14:53 madminer.utils.ml.sc INFO                val. loss  0.0901 (mse_score: 0.0901)\n",
      "14:53 madminer.utils.ml.sc INFO    Early stopping after epoch 17, with loss 0.09 compared to final loss 0.09\n",
      "14:53 madminer.utils.ml.sc INFO    Finished training\n",
      "14:53 madminer.ml          INFO    Training estimator 10 / 10 in ensemble\n",
      "14:53 madminer.ml          INFO    Starting training\n",
      "14:53 madminer.ml          INFO      Method:                 sally\n",
      "14:53 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_9.npy\n",
      "14:53 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_9.npy\n",
      "14:53 madminer.ml          INFO      Features:               all\n",
      "14:53 madminer.ml          INFO      Method:                 sally\n",
      "14:53 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "14:53 madminer.ml          INFO      Activation function:    tanh\n",
      "14:53 madminer.ml          INFO      Batch size:             128\n",
      "14:53 madminer.ml          INFO      Trainer:                amsgrad\n",
      "14:53 madminer.ml          INFO      Epochs:                 50\n",
      "14:53 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "14:53 madminer.ml          INFO      Validation split:       0.5\n",
      "14:53 madminer.ml          INFO      Early stopping:         True\n",
      "14:53 madminer.ml          INFO      Scale inputs:           True\n",
      "14:53 madminer.ml          INFO      Shuffle labels          False\n",
      "14:53 madminer.ml          INFO      Regularization:         None\n",
      "14:53 madminer.ml          INFO      Samples:                all\n",
      "14:53 madminer.ml          INFO    Loading training data\n",
      "14:53 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "14:53 madminer.ml          INFO    Rescaling inputs\n",
      "14:53 madminer.ml          INFO    Creating model for method sally\n",
      "14:53 madminer.ml          INFO    Training model\n",
      "14:54 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1190 (mse_score: 0.1190)\n",
      "14:54 madminer.utils.ml.sc INFO                val. loss  0.0827 (mse_score: 0.0827) (*)\n",
      "14:55 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1142 (mse_score: 0.1142)\n",
      "14:55 madminer.utils.ml.sc INFO                val. loss  0.0807 (mse_score: 0.0807) (*)\n",
      "14:55 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1122 (mse_score: 0.1122)\n",
      "14:55 madminer.utils.ml.sc INFO                val. loss  0.0777 (mse_score: 0.0777) (*)\n",
      "14:56 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1087 (mse_score: 0.1087)\n",
      "14:56 madminer.utils.ml.sc INFO                val. loss  0.0764 (mse_score: 0.0764) (*)\n",
      "14:57 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1073 (mse_score: 0.1073)\n",
      "14:57 madminer.utils.ml.sc INFO                val. loss  0.0759 (mse_score: 0.0759) (*)\n",
      "14:58 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1060 (mse_score: 0.1060)\n",
      "14:58 madminer.utils.ml.sc INFO                val. loss  0.0741 (mse_score: 0.0741) (*)\n",
      "14:58 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1030 (mse_score: 0.1030)\n",
      "14:58 madminer.utils.ml.sc INFO                val. loss  0.0731 (mse_score: 0.0731) (*)\n",
      "14:59 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1025 (mse_score: 0.1025)\n",
      "14:59 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "15:00 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1020 (mse_score: 0.1020)\n",
      "15:00 madminer.utils.ml.sc INFO                val. loss  0.0725 (mse_score: 0.0725) (*)\n",
      "15:00 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0999 (mse_score: 0.0999)\n",
      "15:00 madminer.utils.ml.sc INFO                val. loss  0.0724 (mse_score: 0.0724) (*)\n",
      "15:01 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0980 (mse_score: 0.0980)\n",
      "15:01 madminer.utils.ml.sc INFO                val. loss  0.0726 (mse_score: 0.0726)\n",
      "15:02 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0968 (mse_score: 0.0968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:02 madminer.utils.ml.sc INFO                val. loss  0.0716 (mse_score: 0.0716) (*)\n",
      "15:02 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0956 (mse_score: 0.0956)\n",
      "15:02 madminer.utils.ml.sc INFO                val. loss  0.0727 (mse_score: 0.0727)\n",
      "15:03 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0951 (mse_score: 0.0951)\n",
      "15:03 madminer.utils.ml.sc INFO                val. loss  0.0719 (mse_score: 0.0719)\n",
      "15:04 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0936 (mse_score: 0.0936)\n",
      "15:04 madminer.utils.ml.sc INFO                val. loss  0.0728 (mse_score: 0.0728)\n",
      "15:05 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0924 (mse_score: 0.0924)\n",
      "15:05 madminer.utils.ml.sc INFO                val. loss  0.0713 (mse_score: 0.0713) (*)\n",
      "15:05 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0907 (mse_score: 0.0907)\n",
      "15:05 madminer.utils.ml.sc INFO                val. loss  0.0715 (mse_score: 0.0715)\n",
      "15:06 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0896 (mse_score: 0.0896)\n",
      "15:06 madminer.utils.ml.sc INFO                val. loss  0.0722 (mse_score: 0.0722)\n",
      "15:07 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0890 (mse_score: 0.0890)\n",
      "15:07 madminer.utils.ml.sc INFO                val. loss  0.0716 (mse_score: 0.0716)\n",
      "15:08 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0880 (mse_score: 0.0880)\n",
      "15:08 madminer.utils.ml.sc INFO                val. loss  0.0711 (mse_score: 0.0711) (*)\n",
      "15:08 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0865 (mse_score: 0.0865)\n",
      "15:08 madminer.utils.ml.sc INFO                val. loss  0.0715 (mse_score: 0.0715)\n",
      "15:09 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0856 (mse_score: 0.0856)\n",
      "15:09 madminer.utils.ml.sc INFO                val. loss  0.0713 (mse_score: 0.0713)\n",
      "15:10 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0850 (mse_score: 0.0850)\n",
      "15:10 madminer.utils.ml.sc INFO                val. loss  0.0704 (mse_score: 0.0704) (*)\n",
      "15:10 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0842 (mse_score: 0.0842)\n",
      "15:10 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "15:11 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0833 (mse_score: 0.0833)\n",
      "15:11 madminer.utils.ml.sc INFO                val. loss  0.0713 (mse_score: 0.0713)\n",
      "15:11 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0830 (mse_score: 0.0830)\n",
      "15:11 madminer.utils.ml.sc INFO                val. loss  0.0709 (mse_score: 0.0709)\n",
      "15:12 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0817 (mse_score: 0.0817)\n",
      "15:12 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "15:12 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0814 (mse_score: 0.0814)\n",
      "15:12 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "15:13 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0806 (mse_score: 0.0806)\n",
      "15:13 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "15:13 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0801 (mse_score: 0.0801)\n",
      "15:13 madminer.utils.ml.sc INFO                val. loss  0.0711 (mse_score: 0.0711)\n",
      "15:14 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0792 (mse_score: 0.0792)\n",
      "15:14 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "15:15 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0788 (mse_score: 0.0788)\n",
      "15:15 madminer.utils.ml.sc INFO                val. loss  0.0705 (mse_score: 0.0705)\n",
      "15:15 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0783 (mse_score: 0.0783)\n",
      "15:15 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "15:16 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0777 (mse_score: 0.0777)\n",
      "15:16 madminer.utils.ml.sc INFO                val. loss  0.0704 (mse_score: 0.0704)\n",
      "15:16 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0774 (mse_score: 0.0774)\n",
      "15:16 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701) (*)\n",
      "15:17 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0769 (mse_score: 0.0769)\n",
      "15:17 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "15:18 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0764 (mse_score: 0.0764)\n",
      "15:18 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706)\n",
      "15:18 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0760 (mse_score: 0.0760)\n",
      "15:18 madminer.utils.ml.sc INFO                val. loss  0.0704 (mse_score: 0.0704)\n",
      "15:19 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0757 (mse_score: 0.0757)\n",
      "15:19 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "15:19 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0752 (mse_score: 0.0752)\n",
      "15:19 madminer.utils.ml.sc INFO                val. loss  0.0705 (mse_score: 0.0705)\n",
      "15:20 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0748 (mse_score: 0.0748)\n",
      "15:20 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701)\n",
      "15:21 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0745 (mse_score: 0.0745)\n",
      "15:21 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "15:21 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0741 (mse_score: 0.0741)\n",
      "15:21 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706)\n",
      "15:22 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0738 (mse_score: 0.0738)\n",
      "15:22 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706)\n",
      "15:22 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0735 (mse_score: 0.0735)\n",
      "15:22 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "15:23 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0734 (mse_score: 0.0734)\n",
      "15:23 madminer.utils.ml.sc INFO                val. loss  0.0703 (mse_score: 0.0703)\n",
      "15:23 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0730 (mse_score: 0.0730)\n",
      "15:23 madminer.utils.ml.sc INFO                val. loss  0.0705 (mse_score: 0.0705)\n",
      "15:24 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0728 (mse_score: 0.0728)\n",
      "15:24 madminer.utils.ml.sc INFO                val. loss  0.0705 (mse_score: 0.0705)\n",
      "15:25 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0725 (mse_score: 0.0725)\n",
      "15:25 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706)\n",
      "15:25 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0722 (mse_score: 0.0722)\n",
      "15:25 madminer.utils.ml.sc INFO                val. loss  0.0704 (mse_score: 0.0704)\n",
      "15:25 madminer.utils.ml.sc INFO    Early stopping after epoch 35, with loss 0.07 compared to final loss 0.07\n",
      "15:25 madminer.utils.ml.sc INFO    Finished training\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all',\n",
    "    use_tight_cuts=False,\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25 madminer.ml          INFO    Training 10 estimators in ensemble\n",
      "15:25 madminer.ml          INFO    Training estimator 1 / 10 in ensemble\n",
      "15:25 madminer.ml          INFO    Starting training\n",
      "15:25 madminer.ml          INFO      Method:                 sally\n",
      "15:25 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_0.npy\n",
      "15:25 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_0.npy\n",
      "15:25 madminer.ml          INFO      Features:               all\n",
      "15:25 madminer.ml          INFO      Method:                 sally\n",
      "15:25 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "15:25 madminer.ml          INFO      Activation function:    tanh\n",
      "15:25 madminer.ml          INFO      Batch size:             128\n",
      "15:25 madminer.ml          INFO      Trainer:                amsgrad\n",
      "15:25 madminer.ml          INFO      Epochs:                 50\n",
      "15:25 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "15:25 madminer.ml          INFO      Validation split:       0.5\n",
      "15:25 madminer.ml          INFO      Early stopping:         True\n",
      "15:25 madminer.ml          INFO      Scale inputs:           True\n",
      "15:25 madminer.ml          INFO      Shuffle labels          False\n",
      "15:25 madminer.ml          INFO      Regularization:         None\n",
      "15:25 madminer.ml          INFO      Samples:                all\n",
      "15:25 madminer.ml          INFO    Loading training data\n",
      "15:25 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "15:25 madminer.ml          INFO    Rescaling inputs\n",
      "15:25 madminer.ml          INFO    Creating model for method sally\n",
      "15:25 madminer.ml          INFO    Training model\n",
      "15:26 madminer.utils.ml.sc INFO      Epoch 01: train loss 302.8785 (mse_score: 302.8785)\n",
      "15:26 madminer.utils.ml.sc INFO                val. loss  278.0260 (mse_score: 278.0260) (*)\n",
      "15:26 madminer.utils.ml.sc INFO      Epoch 02: train loss 287.4224 (mse_score: 287.4224)\n",
      "15:26 madminer.utils.ml.sc INFO                val. loss  272.2711 (mse_score: 272.2711) (*)\n",
      "15:27 madminer.utils.ml.sc INFO      Epoch 03: train loss 282.2311 (mse_score: 282.2311)\n",
      "15:27 madminer.utils.ml.sc INFO                val. loss  266.6593 (mse_score: 266.6593) (*)\n",
      "15:27 madminer.utils.ml.sc INFO      Epoch 04: train loss 278.9399 (mse_score: 278.9399)\n",
      "15:27 madminer.utils.ml.sc INFO                val. loss  264.5046 (mse_score: 264.5046) (*)\n",
      "15:28 madminer.utils.ml.sc INFO      Epoch 05: train loss 276.8221 (mse_score: 276.8221)\n",
      "15:28 madminer.utils.ml.sc INFO                val. loss  262.8069 (mse_score: 262.8069) (*)\n",
      "15:28 madminer.utils.ml.sc INFO      Epoch 06: train loss 275.2873 (mse_score: 275.2873)\n",
      "15:28 madminer.utils.ml.sc INFO                val. loss  262.1117 (mse_score: 262.1117) (*)\n",
      "15:29 madminer.utils.ml.sc INFO      Epoch 07: train loss 274.0664 (mse_score: 274.0664)\n",
      "15:29 madminer.utils.ml.sc INFO                val. loss  260.9581 (mse_score: 260.9581) (*)\n",
      "15:30 madminer.utils.ml.sc INFO      Epoch 08: train loss 273.2516 (mse_score: 273.2516)\n",
      "15:30 madminer.utils.ml.sc INFO                val. loss  260.2577 (mse_score: 260.2577) (*)\n",
      "15:30 madminer.utils.ml.sc INFO      Epoch 09: train loss 272.4434 (mse_score: 272.4434)\n",
      "15:30 madminer.utils.ml.sc INFO                val. loss  259.4103 (mse_score: 259.4103) (*)\n",
      "15:31 madminer.utils.ml.sc INFO      Epoch 10: train loss 271.6164 (mse_score: 271.6164)\n",
      "15:31 madminer.utils.ml.sc INFO                val. loss  259.0797 (mse_score: 259.0797) (*)\n",
      "15:31 madminer.utils.ml.sc INFO      Epoch 11: train loss 270.9769 (mse_score: 270.9769)\n",
      "15:31 madminer.utils.ml.sc INFO                val. loss  258.5646 (mse_score: 258.5646) (*)\n",
      "15:32 madminer.utils.ml.sc INFO      Epoch 12: train loss 270.3621 (mse_score: 270.3621)\n",
      "15:32 madminer.utils.ml.sc INFO                val. loss  258.0782 (mse_score: 258.0782) (*)\n",
      "15:32 madminer.utils.ml.sc INFO      Epoch 13: train loss 269.7628 (mse_score: 269.7628)\n",
      "15:32 madminer.utils.ml.sc INFO                val. loss  257.4893 (mse_score: 257.4893) (*)\n",
      "15:33 madminer.utils.ml.sc INFO      Epoch 14: train loss 269.1207 (mse_score: 269.1207)\n",
      "15:33 madminer.utils.ml.sc INFO                val. loss  257.4708 (mse_score: 257.4708) (*)\n",
      "15:33 madminer.utils.ml.sc INFO      Epoch 15: train loss 268.5305 (mse_score: 268.5305)\n",
      "15:33 madminer.utils.ml.sc INFO                val. loss  256.9914 (mse_score: 256.9914) (*)\n",
      "15:34 madminer.utils.ml.sc INFO      Epoch 16: train loss 268.1015 (mse_score: 268.1015)\n",
      "15:34 madminer.utils.ml.sc INFO                val. loss  256.5376 (mse_score: 256.5376) (*)\n",
      "15:35 madminer.utils.ml.sc INFO      Epoch 17: train loss 267.6226 (mse_score: 267.6226)\n",
      "15:35 madminer.utils.ml.sc INFO                val. loss  256.3110 (mse_score: 256.3110) (*)\n",
      "15:35 madminer.utils.ml.sc INFO      Epoch 18: train loss 267.1529 (mse_score: 267.1529)\n",
      "15:35 madminer.utils.ml.sc INFO                val. loss  256.1567 (mse_score: 256.1567) (*)\n",
      "15:36 madminer.utils.ml.sc INFO      Epoch 19: train loss 266.6377 (mse_score: 266.6377)\n",
      "15:36 madminer.utils.ml.sc INFO                val. loss  255.9657 (mse_score: 255.9657) (*)\n",
      "15:36 madminer.utils.ml.sc INFO      Epoch 20: train loss 266.2802 (mse_score: 266.2802)\n",
      "15:36 madminer.utils.ml.sc INFO                val. loss  255.4273 (mse_score: 255.4273) (*)\n",
      "15:37 madminer.utils.ml.sc INFO      Epoch 21: train loss 265.9040 (mse_score: 265.9040)\n",
      "15:37 madminer.utils.ml.sc INFO                val. loss  255.3191 (mse_score: 255.3191) (*)\n",
      "15:37 madminer.utils.ml.sc INFO      Epoch 22: train loss 265.5343 (mse_score: 265.5343)\n",
      "15:37 madminer.utils.ml.sc INFO                val. loss  254.9887 (mse_score: 254.9887) (*)\n",
      "15:38 madminer.utils.ml.sc INFO      Epoch 23: train loss 265.3301 (mse_score: 265.3301)\n",
      "15:38 madminer.utils.ml.sc INFO                val. loss  254.9124 (mse_score: 254.9124) (*)\n",
      "15:38 madminer.utils.ml.sc INFO      Epoch 24: train loss 264.9721 (mse_score: 264.9721)\n",
      "15:38 madminer.utils.ml.sc INFO                val. loss  254.8001 (mse_score: 254.8001) (*)\n",
      "15:39 madminer.utils.ml.sc INFO      Epoch 25: train loss 264.7361 (mse_score: 264.7361)\n",
      "15:39 madminer.utils.ml.sc INFO                val. loss  254.7389 (mse_score: 254.7389) (*)\n",
      "15:39 madminer.utils.ml.sc INFO      Epoch 26: train loss 264.3701 (mse_score: 264.3701)\n",
      "15:39 madminer.utils.ml.sc INFO                val. loss  254.8428 (mse_score: 254.8428)\n",
      "15:40 madminer.utils.ml.sc INFO      Epoch 27: train loss 264.2262 (mse_score: 264.2262)\n",
      "15:40 madminer.utils.ml.sc INFO                val. loss  254.6429 (mse_score: 254.6429) (*)\n",
      "15:40 madminer.utils.ml.sc INFO      Epoch 28: train loss 264.0126 (mse_score: 264.0126)\n",
      "15:40 madminer.utils.ml.sc INFO                val. loss  254.3615 (mse_score: 254.3615) (*)\n",
      "15:41 madminer.utils.ml.sc INFO      Epoch 29: train loss 263.7305 (mse_score: 263.7305)\n",
      "15:41 madminer.utils.ml.sc INFO                val. loss  254.1893 (mse_score: 254.1893) (*)\n",
      "15:41 madminer.utils.ml.sc INFO      Epoch 30: train loss 263.5049 (mse_score: 263.5049)\n",
      "15:41 madminer.utils.ml.sc INFO                val. loss  254.0856 (mse_score: 254.0856) (*)\n",
      "15:42 madminer.utils.ml.sc INFO      Epoch 31: train loss 263.3451 (mse_score: 263.3451)\n",
      "15:42 madminer.utils.ml.sc INFO                val. loss  254.0437 (mse_score: 254.0437) (*)\n",
      "15:42 madminer.utils.ml.sc INFO      Epoch 32: train loss 263.1628 (mse_score: 263.1628)\n",
      "15:42 madminer.utils.ml.sc INFO                val. loss  253.9107 (mse_score: 253.9107) (*)\n",
      "15:43 madminer.utils.ml.sc INFO      Epoch 33: train loss 263.0710 (mse_score: 263.0710)\n",
      "15:43 madminer.utils.ml.sc INFO                val. loss  253.8662 (mse_score: 253.8662) (*)\n",
      "15:43 madminer.utils.ml.sc INFO      Epoch 34: train loss 262.8429 (mse_score: 262.8429)\n",
      "15:43 madminer.utils.ml.sc INFO                val. loss  253.8623 (mse_score: 253.8623) (*)\n",
      "15:44 madminer.utils.ml.sc INFO      Epoch 35: train loss 262.7613 (mse_score: 262.7613)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:44 madminer.utils.ml.sc INFO                val. loss  253.7271 (mse_score: 253.7271) (*)\n",
      "15:44 madminer.utils.ml.sc INFO      Epoch 36: train loss 262.5822 (mse_score: 262.5822)\n",
      "15:44 madminer.utils.ml.sc INFO                val. loss  253.7075 (mse_score: 253.7075) (*)\n",
      "15:45 madminer.utils.ml.sc INFO      Epoch 37: train loss 262.4245 (mse_score: 262.4245)\n",
      "15:45 madminer.utils.ml.sc INFO                val. loss  253.8875 (mse_score: 253.8875)\n",
      "15:45 madminer.utils.ml.sc INFO      Epoch 38: train loss 262.2970 (mse_score: 262.2970)\n",
      "15:45 madminer.utils.ml.sc INFO                val. loss  253.5056 (mse_score: 253.5056) (*)\n",
      "15:46 madminer.utils.ml.sc INFO      Epoch 39: train loss 262.2857 (mse_score: 262.2857)\n",
      "15:46 madminer.utils.ml.sc INFO                val. loss  253.4244 (mse_score: 253.4244) (*)\n",
      "15:47 madminer.utils.ml.sc INFO      Epoch 40: train loss 262.1305 (mse_score: 262.1305)\n",
      "15:47 madminer.utils.ml.sc INFO                val. loss  253.3862 (mse_score: 253.3862) (*)\n",
      "15:47 madminer.utils.ml.sc INFO      Epoch 41: train loss 261.9573 (mse_score: 261.9573)\n",
      "15:47 madminer.utils.ml.sc INFO                val. loss  253.4048 (mse_score: 253.4048)\n",
      "15:48 madminer.utils.ml.sc INFO      Epoch 42: train loss 261.9089 (mse_score: 261.9089)\n",
      "15:48 madminer.utils.ml.sc INFO                val. loss  253.3062 (mse_score: 253.3062) (*)\n",
      "15:48 madminer.utils.ml.sc INFO      Epoch 43: train loss 261.7912 (mse_score: 261.7912)\n",
      "15:48 madminer.utils.ml.sc INFO                val. loss  253.3131 (mse_score: 253.3131)\n",
      "15:49 madminer.utils.ml.sc INFO      Epoch 44: train loss 261.7127 (mse_score: 261.7127)\n",
      "15:49 madminer.utils.ml.sc INFO                val. loss  253.3158 (mse_score: 253.3158)\n",
      "15:49 madminer.utils.ml.sc INFO      Epoch 45: train loss 261.5855 (mse_score: 261.5855)\n",
      "15:49 madminer.utils.ml.sc INFO                val. loss  253.1936 (mse_score: 253.1936) (*)\n",
      "15:50 madminer.utils.ml.sc INFO      Epoch 46: train loss 261.5334 (mse_score: 261.5334)\n",
      "15:50 madminer.utils.ml.sc INFO                val. loss  253.1577 (mse_score: 253.1577) (*)\n",
      "15:51 madminer.utils.ml.sc INFO      Epoch 47: train loss 261.4101 (mse_score: 261.4101)\n",
      "15:51 madminer.utils.ml.sc INFO                val. loss  253.0652 (mse_score: 253.0652) (*)\n",
      "15:51 madminer.utils.ml.sc INFO      Epoch 48: train loss 261.3813 (mse_score: 261.3813)\n",
      "15:51 madminer.utils.ml.sc INFO                val. loss  253.1133 (mse_score: 253.1133)\n",
      "15:52 madminer.utils.ml.sc INFO      Epoch 49: train loss 261.3138 (mse_score: 261.3138)\n",
      "15:52 madminer.utils.ml.sc INFO                val. loss  253.1186 (mse_score: 253.1186)\n",
      "15:52 madminer.utils.ml.sc INFO      Epoch 50: train loss 261.1860 (mse_score: 261.1860)\n",
      "15:52 madminer.utils.ml.sc INFO                val. loss  253.1083 (mse_score: 253.1083)\n",
      "15:52 madminer.utils.ml.sc INFO    Early stopping after epoch 47, with loss 253.07 compared to final loss 253.11\n",
      "15:52 madminer.utils.ml.sc INFO    Finished training\n",
      "15:52 madminer.ml          INFO    Training estimator 2 / 10 in ensemble\n",
      "15:52 madminer.ml          INFO    Starting training\n",
      "15:52 madminer.ml          INFO      Method:                 sally\n",
      "15:52 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_1.npy\n",
      "15:52 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_1.npy\n",
      "15:52 madminer.ml          INFO      Features:               all\n",
      "15:52 madminer.ml          INFO      Method:                 sally\n",
      "15:52 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "15:52 madminer.ml          INFO      Activation function:    tanh\n",
      "15:52 madminer.ml          INFO      Batch size:             128\n",
      "15:52 madminer.ml          INFO      Trainer:                amsgrad\n",
      "15:52 madminer.ml          INFO      Epochs:                 50\n",
      "15:52 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "15:52 madminer.ml          INFO      Validation split:       0.5\n",
      "15:52 madminer.ml          INFO      Early stopping:         True\n",
      "15:52 madminer.ml          INFO      Scale inputs:           True\n",
      "15:52 madminer.ml          INFO      Shuffle labels          False\n",
      "15:52 madminer.ml          INFO      Regularization:         None\n",
      "15:52 madminer.ml          INFO      Samples:                all\n",
      "15:52 madminer.ml          INFO    Loading training data\n",
      "15:53 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "15:53 madminer.ml          INFO    Rescaling inputs\n",
      "15:53 madminer.ml          INFO    Creating model for method sally\n",
      "15:53 madminer.ml          INFO    Training model\n",
      "15:53 madminer.utils.ml.sc INFO      Epoch 01: train loss 286.1834 (mse_score: 286.1834)\n",
      "15:53 madminer.utils.ml.sc INFO                val. loss  272.5783 (mse_score: 272.5783) (*)\n",
      "15:54 madminer.utils.ml.sc INFO      Epoch 02: train loss 270.9032 (mse_score: 270.9032)\n",
      "15:54 madminer.utils.ml.sc INFO                val. loss  265.8859 (mse_score: 265.8859) (*)\n",
      "15:54 madminer.utils.ml.sc INFO      Epoch 03: train loss 265.7344 (mse_score: 265.7344)\n",
      "15:54 madminer.utils.ml.sc INFO                val. loss  262.4905 (mse_score: 262.4905) (*)\n",
      "15:55 madminer.utils.ml.sc INFO      Epoch 04: train loss 262.4617 (mse_score: 262.4617)\n",
      "15:55 madminer.utils.ml.sc INFO                val. loss  259.5979 (mse_score: 259.5979) (*)\n",
      "15:55 madminer.utils.ml.sc INFO      Epoch 05: train loss 260.4014 (mse_score: 260.4014)\n",
      "15:55 madminer.utils.ml.sc INFO                val. loss  257.9183 (mse_score: 257.9183) (*)\n",
      "15:56 madminer.utils.ml.sc INFO      Epoch 06: train loss 259.1158 (mse_score: 259.1158)\n",
      "15:56 madminer.utils.ml.sc INFO                val. loss  256.8992 (mse_score: 256.8992) (*)\n",
      "15:56 madminer.utils.ml.sc INFO      Epoch 07: train loss 258.1447 (mse_score: 258.1447)\n",
      "15:56 madminer.utils.ml.sc INFO                val. loss  256.8861 (mse_score: 256.8861) (*)\n",
      "15:57 madminer.utils.ml.sc INFO      Epoch 08: train loss 257.5555 (mse_score: 257.5555)\n",
      "15:57 madminer.utils.ml.sc INFO                val. loss  256.6564 (mse_score: 256.6564) (*)\n",
      "15:57 madminer.utils.ml.sc INFO      Epoch 09: train loss 257.0267 (mse_score: 257.0267)\n",
      "15:57 madminer.utils.ml.sc INFO                val. loss  255.2740 (mse_score: 255.2740) (*)\n",
      "15:58 madminer.utils.ml.sc INFO      Epoch 10: train loss 256.4421 (mse_score: 256.4421)\n",
      "15:58 madminer.utils.ml.sc INFO                val. loss  255.0236 (mse_score: 255.0236) (*)\n",
      "15:58 madminer.utils.ml.sc INFO      Epoch 11: train loss 255.9881 (mse_score: 255.9881)\n",
      "15:58 madminer.utils.ml.sc INFO                val. loss  255.0729 (mse_score: 255.0729)\n",
      "15:59 madminer.utils.ml.sc INFO      Epoch 12: train loss 255.4749 (mse_score: 255.4749)\n",
      "15:59 madminer.utils.ml.sc INFO                val. loss  254.4448 (mse_score: 254.4448) (*)\n",
      "15:59 madminer.utils.ml.sc INFO      Epoch 13: train loss 255.0762 (mse_score: 255.0762)\n",
      "15:59 madminer.utils.ml.sc INFO                val. loss  254.0986 (mse_score: 254.0986) (*)\n",
      "16:00 madminer.utils.ml.sc INFO      Epoch 14: train loss 255.0215 (mse_score: 255.0215)\n",
      "16:00 madminer.utils.ml.sc INFO                val. loss  253.8108 (mse_score: 253.8108) (*)\n",
      "16:00 madminer.utils.ml.sc INFO      Epoch 15: train loss 254.0834 (mse_score: 254.0834)\n",
      "16:00 madminer.utils.ml.sc INFO                val. loss  253.3583 (mse_score: 253.3583) (*)\n",
      "16:01 madminer.utils.ml.sc INFO      Epoch 16: train loss 253.6967 (mse_score: 253.6967)\n",
      "16:01 madminer.utils.ml.sc INFO                val. loss  253.3686 (mse_score: 253.3686)\n",
      "16:01 madminer.utils.ml.sc INFO      Epoch 17: train loss 253.2830 (mse_score: 253.2830)\n",
      "16:01 madminer.utils.ml.sc INFO                val. loss  252.9082 (mse_score: 252.9082) (*)\n",
      "16:02 madminer.utils.ml.sc INFO      Epoch 18: train loss 252.8686 (mse_score: 252.8686)\n",
      "16:02 madminer.utils.ml.sc INFO                val. loss  253.1283 (mse_score: 253.1283)\n",
      "16:02 madminer.utils.ml.sc INFO      Epoch 19: train loss 252.5471 (mse_score: 252.5471)\n",
      "16:02 madminer.utils.ml.sc INFO                val. loss  252.3523 (mse_score: 252.3523) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:03 madminer.utils.ml.sc INFO      Epoch 20: train loss 252.1509 (mse_score: 252.1509)\n",
      "16:03 madminer.utils.ml.sc INFO                val. loss  252.0124 (mse_score: 252.0124) (*)\n",
      "16:03 madminer.utils.ml.sc INFO      Epoch 21: train loss 251.8498 (mse_score: 251.8498)\n",
      "16:03 madminer.utils.ml.sc INFO                val. loss  252.2749 (mse_score: 252.2749)\n",
      "16:04 madminer.utils.ml.sc INFO      Epoch 22: train loss 251.4309 (mse_score: 251.4309)\n",
      "16:04 madminer.utils.ml.sc INFO                val. loss  251.7232 (mse_score: 251.7232) (*)\n",
      "16:04 madminer.utils.ml.sc INFO      Epoch 23: train loss 251.1628 (mse_score: 251.1628)\n",
      "16:04 madminer.utils.ml.sc INFO                val. loss  251.5305 (mse_score: 251.5305) (*)\n",
      "16:05 madminer.utils.ml.sc INFO      Epoch 24: train loss 250.7896 (mse_score: 250.7896)\n",
      "16:05 madminer.utils.ml.sc INFO                val. loss  251.3452 (mse_score: 251.3452) (*)\n",
      "16:05 madminer.utils.ml.sc INFO      Epoch 25: train loss 250.5703 (mse_score: 250.5703)\n",
      "16:05 madminer.utils.ml.sc INFO                val. loss  251.0905 (mse_score: 251.0905) (*)\n",
      "16:06 madminer.utils.ml.sc INFO      Epoch 26: train loss 250.2532 (mse_score: 250.2532)\n",
      "16:06 madminer.utils.ml.sc INFO                val. loss  251.2640 (mse_score: 251.2640)\n",
      "16:06 madminer.utils.ml.sc INFO      Epoch 27: train loss 250.1631 (mse_score: 250.1631)\n",
      "16:06 madminer.utils.ml.sc INFO                val. loss  250.8466 (mse_score: 250.8466) (*)\n",
      "16:07 madminer.utils.ml.sc INFO      Epoch 28: train loss 249.7813 (mse_score: 249.7813)\n",
      "16:07 madminer.utils.ml.sc INFO                val. loss  250.8707 (mse_score: 250.8707)\n",
      "16:07 madminer.utils.ml.sc INFO      Epoch 29: train loss 249.6015 (mse_score: 249.6015)\n",
      "16:07 madminer.utils.ml.sc INFO                val. loss  250.6212 (mse_score: 250.6212) (*)\n",
      "16:08 madminer.utils.ml.sc INFO      Epoch 30: train loss 249.3395 (mse_score: 249.3395)\n",
      "16:08 madminer.utils.ml.sc INFO                val. loss  250.5838 (mse_score: 250.5838) (*)\n",
      "16:09 madminer.utils.ml.sc INFO      Epoch 31: train loss 249.2048 (mse_score: 249.2048)\n",
      "16:09 madminer.utils.ml.sc INFO                val. loss  250.2768 (mse_score: 250.2768) (*)\n",
      "16:09 madminer.utils.ml.sc INFO      Epoch 32: train loss 248.9672 (mse_score: 248.9672)\n",
      "16:09 madminer.utils.ml.sc INFO                val. loss  250.3467 (mse_score: 250.3467)\n",
      "16:10 madminer.utils.ml.sc INFO      Epoch 33: train loss 248.7917 (mse_score: 248.7917)\n",
      "16:10 madminer.utils.ml.sc INFO                val. loss  250.2580 (mse_score: 250.2580) (*)\n",
      "16:10 madminer.utils.ml.sc INFO      Epoch 34: train loss 248.6491 (mse_score: 248.6491)\n",
      "16:10 madminer.utils.ml.sc INFO                val. loss  250.1203 (mse_score: 250.1203) (*)\n",
      "16:11 madminer.utils.ml.sc INFO      Epoch 35: train loss 248.5426 (mse_score: 248.5426)\n",
      "16:11 madminer.utils.ml.sc INFO                val. loss  249.9593 (mse_score: 249.9593) (*)\n",
      "16:11 madminer.utils.ml.sc INFO      Epoch 36: train loss 248.5811 (mse_score: 248.5811)\n",
      "16:11 madminer.utils.ml.sc INFO                val. loss  249.8107 (mse_score: 249.8107) (*)\n",
      "16:12 madminer.utils.ml.sc INFO      Epoch 37: train loss 248.2023 (mse_score: 248.2023)\n",
      "16:12 madminer.utils.ml.sc INFO                val. loss  249.8733 (mse_score: 249.8733)\n",
      "16:12 madminer.utils.ml.sc INFO      Epoch 38: train loss 248.0488 (mse_score: 248.0488)\n",
      "16:12 madminer.utils.ml.sc INFO                val. loss  249.6527 (mse_score: 249.6527) (*)\n",
      "16:13 madminer.utils.ml.sc INFO      Epoch 39: train loss 247.9107 (mse_score: 247.9107)\n",
      "16:13 madminer.utils.ml.sc INFO                val. loss  249.5581 (mse_score: 249.5581) (*)\n",
      "16:14 madminer.utils.ml.sc INFO      Epoch 40: train loss 248.1205 (mse_score: 248.1205)\n",
      "16:14 madminer.utils.ml.sc INFO                val. loss  249.5949 (mse_score: 249.5949)\n",
      "16:14 madminer.utils.ml.sc INFO      Epoch 41: train loss 247.7613 (mse_score: 247.7613)\n",
      "16:14 madminer.utils.ml.sc INFO                val. loss  249.5157 (mse_score: 249.5157) (*)\n",
      "16:15 madminer.utils.ml.sc INFO      Epoch 42: train loss 247.5483 (mse_score: 247.5483)\n",
      "16:15 madminer.utils.ml.sc INFO                val. loss  249.4182 (mse_score: 249.4182) (*)\n",
      "16:15 madminer.utils.ml.sc INFO      Epoch 43: train loss 247.3690 (mse_score: 247.3690)\n",
      "16:15 madminer.utils.ml.sc INFO                val. loss  249.4606 (mse_score: 249.4606)\n",
      "16:16 madminer.utils.ml.sc INFO      Epoch 44: train loss 247.2918 (mse_score: 247.2918)\n",
      "16:16 madminer.utils.ml.sc INFO                val. loss  249.4273 (mse_score: 249.4273)\n",
      "16:16 madminer.utils.ml.sc INFO      Epoch 45: train loss 247.1996 (mse_score: 247.1996)\n",
      "16:16 madminer.utils.ml.sc INFO                val. loss  249.4489 (mse_score: 249.4489)\n",
      "16:17 madminer.utils.ml.sc INFO      Epoch 46: train loss 247.2296 (mse_score: 247.2296)\n",
      "16:17 madminer.utils.ml.sc INFO                val. loss  249.2675 (mse_score: 249.2675) (*)\n",
      "16:17 madminer.utils.ml.sc INFO      Epoch 47: train loss 247.0842 (mse_score: 247.0842)\n",
      "16:17 madminer.utils.ml.sc INFO                val. loss  249.2966 (mse_score: 249.2966)\n",
      "16:18 madminer.utils.ml.sc INFO      Epoch 48: train loss 247.0022 (mse_score: 247.0022)\n",
      "16:18 madminer.utils.ml.sc INFO                val. loss  249.3569 (mse_score: 249.3569)\n",
      "16:18 madminer.utils.ml.sc INFO      Epoch 49: train loss 247.4607 (mse_score: 247.4607)\n",
      "16:18 madminer.utils.ml.sc INFO                val. loss  249.1989 (mse_score: 249.1989) (*)\n",
      "16:19 madminer.utils.ml.sc INFO      Epoch 50: train loss 246.8183 (mse_score: 246.8183)\n",
      "16:19 madminer.utils.ml.sc INFO                val. loss  249.0928 (mse_score: 249.0928) (*)\n",
      "16:19 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "16:19 madminer.utils.ml.sc INFO    Finished training\n",
      "16:19 madminer.ml          INFO    Training estimator 3 / 10 in ensemble\n",
      "16:19 madminer.ml          INFO    Starting training\n",
      "16:19 madminer.ml          INFO      Method:                 sally\n",
      "16:19 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_2.npy\n",
      "16:19 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_2.npy\n",
      "16:19 madminer.ml          INFO      Features:               all\n",
      "16:19 madminer.ml          INFO      Method:                 sally\n",
      "16:19 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "16:19 madminer.ml          INFO      Activation function:    tanh\n",
      "16:19 madminer.ml          INFO      Batch size:             128\n",
      "16:19 madminer.ml          INFO      Trainer:                amsgrad\n",
      "16:19 madminer.ml          INFO      Epochs:                 50\n",
      "16:19 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:19 madminer.ml          INFO      Validation split:       0.5\n",
      "16:19 madminer.ml          INFO      Early stopping:         True\n",
      "16:19 madminer.ml          INFO      Scale inputs:           True\n",
      "16:19 madminer.ml          INFO      Shuffle labels          False\n",
      "16:19 madminer.ml          INFO      Regularization:         None\n",
      "16:19 madminer.ml          INFO      Samples:                all\n",
      "16:19 madminer.ml          INFO    Loading training data\n",
      "16:19 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "16:19 madminer.ml          INFO    Rescaling inputs\n",
      "16:19 madminer.ml          INFO    Creating model for method sally\n",
      "16:19 madminer.ml          INFO    Training model\n",
      "16:19 madminer.utils.ml.sc INFO      Epoch 01: train loss 297.4147 (mse_score: 297.4147)\n",
      "16:19 madminer.utils.ml.sc INFO                val. loss  298.2118 (mse_score: 298.2118) (*)\n",
      "16:20 madminer.utils.ml.sc INFO      Epoch 02: train loss 281.9429 (mse_score: 281.9429)\n",
      "16:20 madminer.utils.ml.sc INFO                val. loss  290.2446 (mse_score: 290.2446) (*)\n",
      "16:20 madminer.utils.ml.sc INFO      Epoch 03: train loss 276.8987 (mse_score: 276.8987)\n",
      "16:20 madminer.utils.ml.sc INFO                val. loss  285.6117 (mse_score: 285.6117) (*)\n",
      "16:21 madminer.utils.ml.sc INFO      Epoch 04: train loss 273.1778 (mse_score: 273.1778)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:21 madminer.utils.ml.sc INFO                val. loss  283.6238 (mse_score: 283.6238) (*)\n",
      "16:22 madminer.utils.ml.sc INFO      Epoch 05: train loss 270.9149 (mse_score: 270.9149)\n",
      "16:22 madminer.utils.ml.sc INFO                val. loss  281.6333 (mse_score: 281.6333) (*)\n",
      "16:23 madminer.utils.ml.sc INFO      Epoch 06: train loss 269.5475 (mse_score: 269.5475)\n",
      "16:23 madminer.utils.ml.sc INFO                val. loss  280.4470 (mse_score: 280.4470) (*)\n",
      "16:23 madminer.utils.ml.sc INFO      Epoch 07: train loss 268.3876 (mse_score: 268.3876)\n",
      "16:23 madminer.utils.ml.sc INFO                val. loss  279.9627 (mse_score: 279.9627) (*)\n",
      "16:24 madminer.utils.ml.sc INFO      Epoch 08: train loss 267.5080 (mse_score: 267.5080)\n",
      "16:24 madminer.utils.ml.sc INFO                val. loss  278.8818 (mse_score: 278.8818) (*)\n",
      "16:25 madminer.utils.ml.sc INFO      Epoch 09: train loss 266.6388 (mse_score: 266.6388)\n",
      "16:25 madminer.utils.ml.sc INFO                val. loss  278.6518 (mse_score: 278.6518) (*)\n",
      "16:25 madminer.utils.ml.sc INFO      Epoch 10: train loss 266.0553 (mse_score: 266.0553)\n",
      "16:25 madminer.utils.ml.sc INFO                val. loss  277.8283 (mse_score: 277.8283) (*)\n",
      "16:26 madminer.utils.ml.sc INFO      Epoch 11: train loss 265.3556 (mse_score: 265.3556)\n",
      "16:26 madminer.utils.ml.sc INFO                val. loss  277.4083 (mse_score: 277.4083) (*)\n",
      "16:27 madminer.utils.ml.sc INFO      Epoch 12: train loss 264.7986 (mse_score: 264.7986)\n",
      "16:27 madminer.utils.ml.sc INFO                val. loss  277.0026 (mse_score: 277.0026) (*)\n",
      "16:27 madminer.utils.ml.sc INFO      Epoch 13: train loss 264.0885 (mse_score: 264.0885)\n",
      "16:27 madminer.utils.ml.sc INFO                val. loss  276.6500 (mse_score: 276.6500) (*)\n",
      "16:28 madminer.utils.ml.sc INFO      Epoch 14: train loss 263.5026 (mse_score: 263.5026)\n",
      "16:28 madminer.utils.ml.sc INFO                val. loss  276.3856 (mse_score: 276.3856) (*)\n",
      "16:29 madminer.utils.ml.sc INFO      Epoch 15: train loss 263.1008 (mse_score: 263.1008)\n",
      "16:29 madminer.utils.ml.sc INFO                val. loss  276.1054 (mse_score: 276.1054) (*)\n",
      "16:29 madminer.utils.ml.sc INFO      Epoch 16: train loss 262.5084 (mse_score: 262.5084)\n",
      "16:29 madminer.utils.ml.sc INFO                val. loss  275.9989 (mse_score: 275.9989) (*)\n",
      "16:30 madminer.utils.ml.sc INFO      Epoch 17: train loss 262.0832 (mse_score: 262.0832)\n",
      "16:30 madminer.utils.ml.sc INFO                val. loss  275.2609 (mse_score: 275.2609) (*)\n",
      "16:31 madminer.utils.ml.sc INFO      Epoch 18: train loss 261.7189 (mse_score: 261.7189)\n",
      "16:31 madminer.utils.ml.sc INFO                val. loss  274.8028 (mse_score: 274.8028) (*)\n",
      "16:31 madminer.utils.ml.sc INFO      Epoch 19: train loss 261.3035 (mse_score: 261.3035)\n",
      "16:31 madminer.utils.ml.sc INFO                val. loss  274.8130 (mse_score: 274.8130)\n",
      "16:32 madminer.utils.ml.sc INFO      Epoch 20: train loss 260.9354 (mse_score: 260.9354)\n",
      "16:32 madminer.utils.ml.sc INFO                val. loss  274.6224 (mse_score: 274.6224) (*)\n",
      "16:33 madminer.utils.ml.sc INFO      Epoch 21: train loss 260.5801 (mse_score: 260.5801)\n",
      "16:33 madminer.utils.ml.sc INFO                val. loss  274.2236 (mse_score: 274.2236) (*)\n",
      "16:33 madminer.utils.ml.sc INFO      Epoch 22: train loss 260.3786 (mse_score: 260.3786)\n",
      "16:33 madminer.utils.ml.sc INFO                val. loss  274.1154 (mse_score: 274.1154) (*)\n",
      "16:34 madminer.utils.ml.sc INFO      Epoch 23: train loss 260.0155 (mse_score: 260.0155)\n",
      "16:34 madminer.utils.ml.sc INFO                val. loss  273.8755 (mse_score: 273.8755) (*)\n",
      "16:35 madminer.utils.ml.sc INFO      Epoch 24: train loss 259.7940 (mse_score: 259.7940)\n",
      "16:35 madminer.utils.ml.sc INFO                val. loss  273.6991 (mse_score: 273.6991) (*)\n",
      "16:35 madminer.utils.ml.sc INFO      Epoch 25: train loss 259.4433 (mse_score: 259.4433)\n",
      "16:35 madminer.utils.ml.sc INFO                val. loss  273.7751 (mse_score: 273.7751)\n",
      "16:36 madminer.utils.ml.sc INFO      Epoch 26: train loss 259.2813 (mse_score: 259.2813)\n",
      "16:36 madminer.utils.ml.sc INFO                val. loss  273.5639 (mse_score: 273.5639) (*)\n",
      "16:37 madminer.utils.ml.sc INFO      Epoch 27: train loss 259.1714 (mse_score: 259.1714)\n",
      "16:37 madminer.utils.ml.sc INFO                val. loss  273.4197 (mse_score: 273.4197) (*)\n",
      "16:38 madminer.utils.ml.sc INFO      Epoch 28: train loss 258.6707 (mse_score: 258.6707)\n",
      "16:38 madminer.utils.ml.sc INFO                val. loss  273.3933 (mse_score: 273.3933) (*)\n",
      "16:38 madminer.utils.ml.sc INFO      Epoch 29: train loss 258.5447 (mse_score: 258.5447)\n",
      "16:38 madminer.utils.ml.sc INFO                val. loss  273.3476 (mse_score: 273.3476) (*)\n",
      "16:39 madminer.utils.ml.sc INFO      Epoch 30: train loss 258.2586 (mse_score: 258.2586)\n",
      "16:39 madminer.utils.ml.sc INFO                val. loss  273.2509 (mse_score: 273.2509) (*)\n",
      "16:40 madminer.utils.ml.sc INFO      Epoch 31: train loss 258.1496 (mse_score: 258.1496)\n",
      "16:40 madminer.utils.ml.sc INFO                val. loss  273.2152 (mse_score: 273.2152) (*)\n",
      "16:40 madminer.utils.ml.sc INFO      Epoch 32: train loss 257.9828 (mse_score: 257.9828)\n",
      "16:40 madminer.utils.ml.sc INFO                val. loss  273.0287 (mse_score: 273.0287) (*)\n",
      "16:41 madminer.utils.ml.sc INFO      Epoch 33: train loss 257.7549 (mse_score: 257.7549)\n",
      "16:41 madminer.utils.ml.sc INFO                val. loss  272.8995 (mse_score: 272.8995) (*)\n",
      "16:41 madminer.utils.ml.sc INFO      Epoch 34: train loss 257.6341 (mse_score: 257.6341)\n",
      "16:41 madminer.utils.ml.sc INFO                val. loss  272.8606 (mse_score: 272.8606) (*)\n",
      "16:42 madminer.utils.ml.sc INFO      Epoch 35: train loss 257.5338 (mse_score: 257.5338)\n",
      "16:42 madminer.utils.ml.sc INFO                val. loss  272.7259 (mse_score: 272.7259) (*)\n",
      "16:43 madminer.utils.ml.sc INFO      Epoch 36: train loss 257.2540 (mse_score: 257.2540)\n",
      "16:43 madminer.utils.ml.sc INFO                val. loss  272.8603 (mse_score: 272.8603)\n",
      "16:43 madminer.utils.ml.sc INFO      Epoch 37: train loss 257.1542 (mse_score: 257.1542)\n",
      "16:43 madminer.utils.ml.sc INFO                val. loss  272.6528 (mse_score: 272.6528) (*)\n",
      "16:44 madminer.utils.ml.sc INFO      Epoch 38: train loss 257.1072 (mse_score: 257.1072)\n",
      "16:44 madminer.utils.ml.sc INFO                val. loss  272.6037 (mse_score: 272.6037) (*)\n",
      "16:45 madminer.utils.ml.sc INFO      Epoch 39: train loss 256.9857 (mse_score: 256.9857)\n",
      "16:45 madminer.utils.ml.sc INFO                val. loss  272.5326 (mse_score: 272.5326) (*)\n",
      "16:46 madminer.utils.ml.sc INFO      Epoch 40: train loss 256.8454 (mse_score: 256.8454)\n",
      "16:46 madminer.utils.ml.sc INFO                val. loss  272.5165 (mse_score: 272.5165) (*)\n",
      "16:46 madminer.utils.ml.sc INFO      Epoch 41: train loss 256.7843 (mse_score: 256.7843)\n",
      "16:46 madminer.utils.ml.sc INFO                val. loss  272.5668 (mse_score: 272.5668)\n",
      "16:47 madminer.utils.ml.sc INFO      Epoch 42: train loss 256.6231 (mse_score: 256.6231)\n",
      "16:47 madminer.utils.ml.sc INFO                val. loss  272.4621 (mse_score: 272.4621) (*)\n",
      "16:47 madminer.utils.ml.sc INFO      Epoch 43: train loss 256.6057 (mse_score: 256.6057)\n",
      "16:47 madminer.utils.ml.sc INFO                val. loss  272.3546 (mse_score: 272.3546) (*)\n",
      "16:48 madminer.utils.ml.sc INFO      Epoch 44: train loss 256.4071 (mse_score: 256.4071)\n",
      "16:48 madminer.utils.ml.sc INFO                val. loss  272.4008 (mse_score: 272.4008)\n",
      "16:49 madminer.utils.ml.sc INFO      Epoch 45: train loss 256.3866 (mse_score: 256.3866)\n",
      "16:49 madminer.utils.ml.sc INFO                val. loss  272.3341 (mse_score: 272.3341) (*)\n",
      "16:49 madminer.utils.ml.sc INFO      Epoch 46: train loss 256.2692 (mse_score: 256.2692)\n",
      "16:49 madminer.utils.ml.sc INFO                val. loss  272.2777 (mse_score: 272.2777) (*)\n",
      "16:50 madminer.utils.ml.sc INFO      Epoch 47: train loss 256.1468 (mse_score: 256.1468)\n",
      "16:50 madminer.utils.ml.sc INFO                val. loss  274.5213 (mse_score: 274.5213)\n",
      "16:50 madminer.utils.ml.sc INFO      Epoch 48: train loss 256.0318 (mse_score: 256.0318)\n",
      "16:50 madminer.utils.ml.sc INFO                val. loss  272.2903 (mse_score: 272.2903)\n",
      "16:51 madminer.utils.ml.sc INFO      Epoch 49: train loss 255.9863 (mse_score: 255.9863)\n",
      "16:51 madminer.utils.ml.sc INFO                val. loss  272.3062 (mse_score: 272.3062)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:52 madminer.utils.ml.sc INFO      Epoch 50: train loss 255.9868 (mse_score: 255.9868)\n",
      "16:52 madminer.utils.ml.sc INFO                val. loss  272.2426 (mse_score: 272.2426) (*)\n",
      "16:52 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "16:52 madminer.utils.ml.sc INFO    Finished training\n",
      "16:52 madminer.ml          INFO    Training estimator 4 / 10 in ensemble\n",
      "16:52 madminer.ml          INFO    Starting training\n",
      "16:52 madminer.ml          INFO      Method:                 sally\n",
      "16:52 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_3.npy\n",
      "16:52 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_3.npy\n",
      "16:52 madminer.ml          INFO      Features:               all\n",
      "16:52 madminer.ml          INFO      Method:                 sally\n",
      "16:52 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "16:52 madminer.ml          INFO      Activation function:    tanh\n",
      "16:52 madminer.ml          INFO      Batch size:             128\n",
      "16:52 madminer.ml          INFO      Trainer:                amsgrad\n",
      "16:52 madminer.ml          INFO      Epochs:                 50\n",
      "16:52 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:52 madminer.ml          INFO      Validation split:       0.5\n",
      "16:52 madminer.ml          INFO      Early stopping:         True\n",
      "16:52 madminer.ml          INFO      Scale inputs:           True\n",
      "16:52 madminer.ml          INFO      Shuffle labels          False\n",
      "16:52 madminer.ml          INFO      Regularization:         None\n",
      "16:52 madminer.ml          INFO      Samples:                all\n",
      "16:52 madminer.ml          INFO    Loading training data\n",
      "16:52 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "16:52 madminer.ml          INFO    Rescaling inputs\n",
      "16:52 madminer.ml          INFO    Creating model for method sally\n",
      "16:52 madminer.ml          INFO    Training model\n",
      "16:52 madminer.utils.ml.sc INFO      Epoch 01: train loss 286.8878 (mse_score: 286.8878)\n",
      "16:52 madminer.utils.ml.sc INFO                val. loss  268.1140 (mse_score: 268.1140) (*)\n",
      "16:53 madminer.utils.ml.sc INFO      Epoch 02: train loss 270.6842 (mse_score: 270.6842)\n",
      "16:53 madminer.utils.ml.sc INFO                val. loss  261.1664 (mse_score: 261.1664) (*)\n",
      "16:54 madminer.utils.ml.sc INFO      Epoch 03: train loss 265.0036 (mse_score: 265.0036)\n",
      "16:54 madminer.utils.ml.sc INFO                val. loss  256.6182 (mse_score: 256.6182) (*)\n",
      "16:54 madminer.utils.ml.sc INFO      Epoch 04: train loss 261.6625 (mse_score: 261.6625)\n",
      "16:54 madminer.utils.ml.sc INFO                val. loss  254.7763 (mse_score: 254.7763) (*)\n",
      "16:55 madminer.utils.ml.sc INFO      Epoch 05: train loss 260.0670 (mse_score: 260.0670)\n",
      "16:55 madminer.utils.ml.sc INFO                val. loss  253.1648 (mse_score: 253.1648) (*)\n",
      "16:55 madminer.utils.ml.sc INFO      Epoch 06: train loss 258.6945 (mse_score: 258.6945)\n",
      "16:55 madminer.utils.ml.sc INFO                val. loss  252.4366 (mse_score: 252.4366) (*)\n",
      "16:56 madminer.utils.ml.sc INFO      Epoch 07: train loss 257.6485 (mse_score: 257.6485)\n",
      "16:56 madminer.utils.ml.sc INFO                val. loss  252.1157 (mse_score: 252.1157) (*)\n",
      "16:57 madminer.utils.ml.sc INFO      Epoch 08: train loss 256.8897 (mse_score: 256.8897)\n",
      "16:57 madminer.utils.ml.sc INFO                val. loss  250.9971 (mse_score: 250.9971) (*)\n",
      "16:57 madminer.utils.ml.sc INFO      Epoch 09: train loss 256.1849 (mse_score: 256.1849)\n",
      "16:57 madminer.utils.ml.sc INFO                val. loss  250.8554 (mse_score: 250.8554) (*)\n",
      "16:58 madminer.utils.ml.sc INFO      Epoch 10: train loss 255.7194 (mse_score: 255.7194)\n",
      "16:58 madminer.utils.ml.sc INFO                val. loss  250.1391 (mse_score: 250.1391) (*)\n",
      "16:58 madminer.utils.ml.sc INFO      Epoch 11: train loss 255.0991 (mse_score: 255.0991)\n",
      "16:58 madminer.utils.ml.sc INFO                val. loss  249.9981 (mse_score: 249.9981) (*)\n",
      "16:59 madminer.utils.ml.sc INFO      Epoch 12: train loss 254.6211 (mse_score: 254.6211)\n",
      "16:59 madminer.utils.ml.sc INFO                val. loss  249.9324 (mse_score: 249.9324) (*)\n",
      "17:00 madminer.utils.ml.sc INFO      Epoch 13: train loss 254.1269 (mse_score: 254.1269)\n",
      "17:00 madminer.utils.ml.sc INFO                val. loss  249.1661 (mse_score: 249.1661) (*)\n",
      "17:00 madminer.utils.ml.sc INFO      Epoch 14: train loss 253.9229 (mse_score: 253.9229)\n",
      "17:00 madminer.utils.ml.sc INFO                val. loss  248.7220 (mse_score: 248.7220) (*)\n",
      "17:01 madminer.utils.ml.sc INFO      Epoch 15: train loss 253.2622 (mse_score: 253.2622)\n",
      "17:01 madminer.utils.ml.sc INFO                val. loss  248.6988 (mse_score: 248.6988) (*)\n",
      "17:01 madminer.utils.ml.sc INFO      Epoch 16: train loss 252.8301 (mse_score: 252.8301)\n",
      "17:01 madminer.utils.ml.sc INFO                val. loss  248.3291 (mse_score: 248.3291) (*)\n",
      "17:02 madminer.utils.ml.sc INFO      Epoch 17: train loss 252.5297 (mse_score: 252.5297)\n",
      "17:02 madminer.utils.ml.sc INFO                val. loss  248.1588 (mse_score: 248.1588) (*)\n",
      "17:02 madminer.utils.ml.sc INFO      Epoch 18: train loss 252.0443 (mse_score: 252.0443)\n",
      "17:02 madminer.utils.ml.sc INFO                val. loss  248.1495 (mse_score: 248.1495) (*)\n",
      "17:03 madminer.utils.ml.sc INFO      Epoch 19: train loss 251.6334 (mse_score: 251.6334)\n",
      "17:03 madminer.utils.ml.sc INFO                val. loss  247.6268 (mse_score: 247.6268) (*)\n",
      "17:04 madminer.utils.ml.sc INFO      Epoch 20: train loss 251.2991 (mse_score: 251.2991)\n",
      "17:04 madminer.utils.ml.sc INFO                val. loss  247.3685 (mse_score: 247.3685) (*)\n",
      "17:04 madminer.utils.ml.sc INFO      Epoch 21: train loss 251.0102 (mse_score: 251.0102)\n",
      "17:04 madminer.utils.ml.sc INFO                val. loss  246.9886 (mse_score: 246.9886) (*)\n",
      "17:05 madminer.utils.ml.sc INFO      Epoch 22: train loss 250.6998 (mse_score: 250.6998)\n",
      "17:05 madminer.utils.ml.sc INFO                val. loss  246.6930 (mse_score: 246.6930) (*)\n",
      "17:05 madminer.utils.ml.sc INFO      Epoch 23: train loss 250.2844 (mse_score: 250.2844)\n",
      "17:05 madminer.utils.ml.sc INFO                val. loss  246.9401 (mse_score: 246.9401)\n",
      "17:06 madminer.utils.ml.sc INFO      Epoch 24: train loss 250.1166 (mse_score: 250.1166)\n",
      "17:06 madminer.utils.ml.sc INFO                val. loss  246.4749 (mse_score: 246.4749) (*)\n",
      "17:06 madminer.utils.ml.sc INFO      Epoch 25: train loss 249.7883 (mse_score: 249.7883)\n",
      "17:06 madminer.utils.ml.sc INFO                val. loss  246.5673 (mse_score: 246.5673)\n",
      "17:07 madminer.utils.ml.sc INFO      Epoch 26: train loss 249.5891 (mse_score: 249.5891)\n",
      "17:07 madminer.utils.ml.sc INFO                val. loss  246.4878 (mse_score: 246.4878)\n",
      "17:08 madminer.utils.ml.sc INFO      Epoch 27: train loss 249.2985 (mse_score: 249.2985)\n",
      "17:08 madminer.utils.ml.sc INFO                val. loss  246.1380 (mse_score: 246.1380) (*)\n",
      "17:08 madminer.utils.ml.sc INFO      Epoch 28: train loss 249.1085 (mse_score: 249.1085)\n",
      "17:08 madminer.utils.ml.sc INFO                val. loss  246.1049 (mse_score: 246.1049) (*)\n",
      "17:09 madminer.utils.ml.sc INFO      Epoch 29: train loss 248.9334 (mse_score: 248.9334)\n",
      "17:09 madminer.utils.ml.sc INFO                val. loss  245.9164 (mse_score: 245.9164) (*)\n",
      "17:10 madminer.utils.ml.sc INFO      Epoch 30: train loss 248.7609 (mse_score: 248.7609)\n",
      "17:10 madminer.utils.ml.sc INFO                val. loss  245.9482 (mse_score: 245.9482)\n",
      "17:10 madminer.utils.ml.sc INFO      Epoch 31: train loss 248.5446 (mse_score: 248.5446)\n",
      "17:10 madminer.utils.ml.sc INFO                val. loss  245.5339 (mse_score: 245.5339) (*)\n",
      "17:11 madminer.utils.ml.sc INFO      Epoch 32: train loss 248.3548 (mse_score: 248.3548)\n",
      "17:11 madminer.utils.ml.sc INFO                val. loss  245.6520 (mse_score: 245.6520)\n",
      "17:12 madminer.utils.ml.sc INFO      Epoch 33: train loss 248.1977 (mse_score: 248.1977)\n",
      "17:12 madminer.utils.ml.sc INFO                val. loss  245.7996 (mse_score: 245.7996)\n",
      "17:13 madminer.utils.ml.sc INFO      Epoch 34: train loss 248.1309 (mse_score: 248.1309)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:13 madminer.utils.ml.sc INFO                val. loss  245.4858 (mse_score: 245.4858) (*)\n",
      "17:13 madminer.utils.ml.sc INFO      Epoch 35: train loss 247.9030 (mse_score: 247.9030)\n",
      "17:13 madminer.utils.ml.sc INFO                val. loss  245.4008 (mse_score: 245.4008) (*)\n",
      "17:14 madminer.utils.ml.sc INFO      Epoch 36: train loss 247.7416 (mse_score: 247.7416)\n",
      "17:14 madminer.utils.ml.sc INFO                val. loss  245.2282 (mse_score: 245.2282) (*)\n",
      "17:15 madminer.utils.ml.sc INFO      Epoch 37: train loss 247.5932 (mse_score: 247.5932)\n",
      "17:15 madminer.utils.ml.sc INFO                val. loss  245.2515 (mse_score: 245.2515)\n",
      "17:15 madminer.utils.ml.sc INFO      Epoch 38: train loss 247.4086 (mse_score: 247.4086)\n",
      "17:15 madminer.utils.ml.sc INFO                val. loss  245.4403 (mse_score: 245.4403)\n",
      "17:16 madminer.utils.ml.sc INFO      Epoch 39: train loss 247.3162 (mse_score: 247.3162)\n",
      "17:16 madminer.utils.ml.sc INFO                val. loss  245.2853 (mse_score: 245.2853)\n",
      "17:16 madminer.utils.ml.sc INFO      Epoch 40: train loss 247.2774 (mse_score: 247.2774)\n",
      "17:16 madminer.utils.ml.sc INFO                val. loss  245.1657 (mse_score: 245.1657) (*)\n",
      "17:17 madminer.utils.ml.sc INFO      Epoch 41: train loss 247.1064 (mse_score: 247.1064)\n",
      "17:17 madminer.utils.ml.sc INFO                val. loss  245.0352 (mse_score: 245.0352) (*)\n",
      "17:17 madminer.utils.ml.sc INFO      Epoch 42: train loss 247.0353 (mse_score: 247.0353)\n",
      "17:17 madminer.utils.ml.sc INFO                val. loss  245.2390 (mse_score: 245.2390)\n",
      "17:18 madminer.utils.ml.sc INFO      Epoch 43: train loss 246.9667 (mse_score: 246.9667)\n",
      "17:18 madminer.utils.ml.sc INFO                val. loss  244.9754 (mse_score: 244.9754) (*)\n",
      "17:19 madminer.utils.ml.sc INFO      Epoch 44: train loss 246.8128 (mse_score: 246.8128)\n",
      "17:19 madminer.utils.ml.sc INFO                val. loss  245.0215 (mse_score: 245.0215)\n",
      "17:19 madminer.utils.ml.sc INFO      Epoch 45: train loss 246.7154 (mse_score: 246.7154)\n",
      "17:19 madminer.utils.ml.sc INFO                val. loss  244.9786 (mse_score: 244.9786)\n",
      "17:20 madminer.utils.ml.sc INFO      Epoch 46: train loss 246.6673 (mse_score: 246.6673)\n",
      "17:20 madminer.utils.ml.sc INFO                val. loss  244.8611 (mse_score: 244.8611) (*)\n",
      "17:20 madminer.utils.ml.sc INFO      Epoch 47: train loss 246.6329 (mse_score: 246.6329)\n",
      "17:20 madminer.utils.ml.sc INFO                val. loss  244.7694 (mse_score: 244.7694) (*)\n",
      "17:21 madminer.utils.ml.sc INFO      Epoch 48: train loss 246.5307 (mse_score: 246.5307)\n",
      "17:21 madminer.utils.ml.sc INFO                val. loss  244.7914 (mse_score: 244.7914)\n",
      "17:21 madminer.utils.ml.sc INFO      Epoch 49: train loss 246.5167 (mse_score: 246.5167)\n",
      "17:21 madminer.utils.ml.sc INFO                val. loss  245.1260 (mse_score: 245.1260)\n",
      "17:22 madminer.utils.ml.sc INFO      Epoch 50: train loss 246.3512 (mse_score: 246.3512)\n",
      "17:22 madminer.utils.ml.sc INFO                val. loss  244.8157 (mse_score: 244.8157)\n",
      "17:22 madminer.utils.ml.sc INFO    Early stopping after epoch 47, with loss 244.77 compared to final loss 244.82\n",
      "17:22 madminer.utils.ml.sc INFO    Finished training\n",
      "17:22 madminer.ml          INFO    Training estimator 5 / 10 in ensemble\n",
      "17:22 madminer.ml          INFO    Starting training\n",
      "17:22 madminer.ml          INFO      Method:                 sally\n",
      "17:22 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_4.npy\n",
      "17:22 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_4.npy\n",
      "17:22 madminer.ml          INFO      Features:               all\n",
      "17:22 madminer.ml          INFO      Method:                 sally\n",
      "17:22 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "17:22 madminer.ml          INFO      Activation function:    tanh\n",
      "17:22 madminer.ml          INFO      Batch size:             128\n",
      "17:22 madminer.ml          INFO      Trainer:                amsgrad\n",
      "17:22 madminer.ml          INFO      Epochs:                 50\n",
      "17:22 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:22 madminer.ml          INFO      Validation split:       0.5\n",
      "17:22 madminer.ml          INFO      Early stopping:         True\n",
      "17:22 madminer.ml          INFO      Scale inputs:           True\n",
      "17:22 madminer.ml          INFO      Shuffle labels          False\n",
      "17:22 madminer.ml          INFO      Regularization:         None\n",
      "17:22 madminer.ml          INFO      Samples:                all\n",
      "17:22 madminer.ml          INFO    Loading training data\n",
      "17:22 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "17:22 madminer.ml          INFO    Rescaling inputs\n",
      "17:22 madminer.ml          INFO    Creating model for method sally\n",
      "17:22 madminer.ml          INFO    Training model\n",
      "17:23 madminer.utils.ml.sc INFO      Epoch 01: train loss 298.1253 (mse_score: 298.1253)\n",
      "17:23 madminer.utils.ml.sc INFO                val. loss  291.5474 (mse_score: 291.5474) (*)\n",
      "17:23 madminer.utils.ml.sc INFO      Epoch 02: train loss 282.2965 (mse_score: 282.2965)\n",
      "17:23 madminer.utils.ml.sc INFO                val. loss  284.3648 (mse_score: 284.3648) (*)\n",
      "17:23 madminer.utils.ml.sc INFO      Epoch 03: train loss 276.3479 (mse_score: 276.3479)\n",
      "17:23 madminer.utils.ml.sc INFO                val. loss  279.5736 (mse_score: 279.5736) (*)\n",
      "17:24 madminer.utils.ml.sc INFO      Epoch 04: train loss 272.7979 (mse_score: 272.7979)\n",
      "17:24 madminer.utils.ml.sc INFO                val. loss  276.9705 (mse_score: 276.9705) (*)\n",
      "17:24 madminer.utils.ml.sc INFO      Epoch 05: train loss 270.7061 (mse_score: 270.7061)\n",
      "17:24 madminer.utils.ml.sc INFO                val. loss  276.4110 (mse_score: 276.4110) (*)\n",
      "17:25 madminer.utils.ml.sc INFO      Epoch 06: train loss 269.4041 (mse_score: 269.4041)\n",
      "17:25 madminer.utils.ml.sc INFO                val. loss  275.0890 (mse_score: 275.0890) (*)\n",
      "17:25 madminer.utils.ml.sc INFO      Epoch 07: train loss 268.4371 (mse_score: 268.4371)\n",
      "17:25 madminer.utils.ml.sc INFO                val. loss  274.0561 (mse_score: 274.0561) (*)\n",
      "17:26 madminer.utils.ml.sc INFO      Epoch 08: train loss 267.6131 (mse_score: 267.6131)\n",
      "17:26 madminer.utils.ml.sc INFO                val. loss  273.8704 (mse_score: 273.8704) (*)\n",
      "17:26 madminer.utils.ml.sc INFO      Epoch 09: train loss 266.8297 (mse_score: 266.8297)\n",
      "17:26 madminer.utils.ml.sc INFO                val. loss  273.0250 (mse_score: 273.0250) (*)\n",
      "17:27 madminer.utils.ml.sc INFO      Epoch 10: train loss 266.1032 (mse_score: 266.1032)\n",
      "17:27 madminer.utils.ml.sc INFO                val. loss  272.8218 (mse_score: 272.8218) (*)\n",
      "17:27 madminer.utils.ml.sc INFO      Epoch 11: train loss 265.7272 (mse_score: 265.7272)\n",
      "17:27 madminer.utils.ml.sc INFO                val. loss  272.5090 (mse_score: 272.5090) (*)\n",
      "17:28 madminer.utils.ml.sc INFO      Epoch 12: train loss 264.7950 (mse_score: 264.7950)\n",
      "17:28 madminer.utils.ml.sc INFO                val. loss  271.8966 (mse_score: 271.8966) (*)\n",
      "17:28 madminer.utils.ml.sc INFO      Epoch 13: train loss 264.1013 (mse_score: 264.1013)\n",
      "17:28 madminer.utils.ml.sc INFO                val. loss  271.3247 (mse_score: 271.3247) (*)\n",
      "17:29 madminer.utils.ml.sc INFO      Epoch 14: train loss 263.5320 (mse_score: 263.5320)\n",
      "17:29 madminer.utils.ml.sc INFO                val. loss  270.9773 (mse_score: 270.9773) (*)\n",
      "17:29 madminer.utils.ml.sc INFO      Epoch 15: train loss 262.9365 (mse_score: 262.9365)\n",
      "17:29 madminer.utils.ml.sc INFO                val. loss  270.5457 (mse_score: 270.5457) (*)\n",
      "17:30 madminer.utils.ml.sc INFO      Epoch 16: train loss 262.5058 (mse_score: 262.5058)\n",
      "17:30 madminer.utils.ml.sc INFO                val. loss  270.1333 (mse_score: 270.1333) (*)\n",
      "17:31 madminer.utils.ml.sc INFO      Epoch 17: train loss 262.0318 (mse_score: 262.0318)\n",
      "17:31 madminer.utils.ml.sc INFO                val. loss  269.9929 (mse_score: 269.9929) (*)\n",
      "17:31 madminer.utils.ml.sc INFO      Epoch 18: train loss 261.6011 (mse_score: 261.6011)\n",
      "17:31 madminer.utils.ml.sc INFO                val. loss  269.5330 (mse_score: 269.5330) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:32 madminer.utils.ml.sc INFO      Epoch 19: train loss 261.0652 (mse_score: 261.0652)\n",
      "17:32 madminer.utils.ml.sc INFO                val. loss  269.6048 (mse_score: 269.6048)\n",
      "17:32 madminer.utils.ml.sc INFO      Epoch 20: train loss 260.8468 (mse_score: 260.8468)\n",
      "17:32 madminer.utils.ml.sc INFO                val. loss  269.5124 (mse_score: 269.5124) (*)\n",
      "17:33 madminer.utils.ml.sc INFO      Epoch 21: train loss 260.4646 (mse_score: 260.4646)\n",
      "17:33 madminer.utils.ml.sc INFO                val. loss  269.1707 (mse_score: 269.1707) (*)\n",
      "17:33 madminer.utils.ml.sc INFO      Epoch 22: train loss 260.1426 (mse_score: 260.1426)\n",
      "17:33 madminer.utils.ml.sc INFO                val. loss  269.0805 (mse_score: 269.0805) (*)\n",
      "17:34 madminer.utils.ml.sc INFO      Epoch 23: train loss 260.1466 (mse_score: 260.1466)\n",
      "17:34 madminer.utils.ml.sc INFO                val. loss  268.8386 (mse_score: 268.8386) (*)\n",
      "17:34 madminer.utils.ml.sc INFO      Epoch 24: train loss 259.7131 (mse_score: 259.7131)\n",
      "17:34 madminer.utils.ml.sc INFO                val. loss  268.8198 (mse_score: 268.8198) (*)\n",
      "17:35 madminer.utils.ml.sc INFO      Epoch 25: train loss 259.3634 (mse_score: 259.3634)\n",
      "17:35 madminer.utils.ml.sc INFO                val. loss  268.6585 (mse_score: 268.6585) (*)\n",
      "17:35 madminer.utils.ml.sc INFO      Epoch 26: train loss 259.1222 (mse_score: 259.1222)\n",
      "17:35 madminer.utils.ml.sc INFO                val. loss  268.4419 (mse_score: 268.4419) (*)\n",
      "17:36 madminer.utils.ml.sc INFO      Epoch 27: train loss 259.0419 (mse_score: 259.0419)\n",
      "17:36 madminer.utils.ml.sc INFO                val. loss  268.5005 (mse_score: 268.5005)\n",
      "17:36 madminer.utils.ml.sc INFO      Epoch 28: train loss 258.7568 (mse_score: 258.7568)\n",
      "17:36 madminer.utils.ml.sc INFO                val. loss  268.3634 (mse_score: 268.3634) (*)\n",
      "17:37 madminer.utils.ml.sc INFO      Epoch 29: train loss 258.4912 (mse_score: 258.4912)\n",
      "17:37 madminer.utils.ml.sc INFO                val. loss  268.3563 (mse_score: 268.3563) (*)\n",
      "17:37 madminer.utils.ml.sc INFO      Epoch 30: train loss 258.3493 (mse_score: 258.3493)\n",
      "17:37 madminer.utils.ml.sc INFO                val. loss  268.1451 (mse_score: 268.1451) (*)\n",
      "17:38 madminer.utils.ml.sc INFO      Epoch 31: train loss 258.1820 (mse_score: 258.1820)\n",
      "17:38 madminer.utils.ml.sc INFO                val. loss  267.9304 (mse_score: 267.9304) (*)\n",
      "17:38 madminer.utils.ml.sc INFO      Epoch 32: train loss 258.0276 (mse_score: 258.0276)\n",
      "17:38 madminer.utils.ml.sc INFO                val. loss  268.0342 (mse_score: 268.0342)\n",
      "17:38 madminer.utils.ml.sc INFO      Epoch 33: train loss 257.7921 (mse_score: 257.7921)\n",
      "17:38 madminer.utils.ml.sc INFO                val. loss  267.8058 (mse_score: 267.8058) (*)\n",
      "17:39 madminer.utils.ml.sc INFO      Epoch 34: train loss 257.7265 (mse_score: 257.7265)\n",
      "17:39 madminer.utils.ml.sc INFO                val. loss  267.7456 (mse_score: 267.7456) (*)\n",
      "17:39 madminer.utils.ml.sc INFO      Epoch 35: train loss 257.6048 (mse_score: 257.6048)\n",
      "17:39 madminer.utils.ml.sc INFO                val. loss  267.7789 (mse_score: 267.7789)\n",
      "17:40 madminer.utils.ml.sc INFO      Epoch 36: train loss 257.3987 (mse_score: 257.3987)\n",
      "17:40 madminer.utils.ml.sc INFO                val. loss  267.7282 (mse_score: 267.7282) (*)\n",
      "17:40 madminer.utils.ml.sc INFO      Epoch 37: train loss 257.2725 (mse_score: 257.2725)\n",
      "17:40 madminer.utils.ml.sc INFO                val. loss  267.7348 (mse_score: 267.7348)\n",
      "17:41 madminer.utils.ml.sc INFO      Epoch 38: train loss 257.2391 (mse_score: 257.2391)\n",
      "17:41 madminer.utils.ml.sc INFO                val. loss  267.5170 (mse_score: 267.5170) (*)\n",
      "17:41 madminer.utils.ml.sc INFO      Epoch 39: train loss 257.0054 (mse_score: 257.0054)\n",
      "17:41 madminer.utils.ml.sc INFO                val. loss  267.4785 (mse_score: 267.4785) (*)\n",
      "17:42 madminer.utils.ml.sc INFO      Epoch 40: train loss 257.0052 (mse_score: 257.0052)\n",
      "17:42 madminer.utils.ml.sc INFO                val. loss  267.4135 (mse_score: 267.4135) (*)\n",
      "17:42 madminer.utils.ml.sc INFO      Epoch 41: train loss 256.8077 (mse_score: 256.8077)\n",
      "17:42 madminer.utils.ml.sc INFO                val. loss  267.4405 (mse_score: 267.4405)\n",
      "17:43 madminer.utils.ml.sc INFO      Epoch 42: train loss 256.7102 (mse_score: 256.7102)\n",
      "17:43 madminer.utils.ml.sc INFO                val. loss  267.3872 (mse_score: 267.3872) (*)\n",
      "17:43 madminer.utils.ml.sc INFO      Epoch 43: train loss 256.6397 (mse_score: 256.6397)\n",
      "17:43 madminer.utils.ml.sc INFO                val. loss  267.2733 (mse_score: 267.2733) (*)\n",
      "17:44 madminer.utils.ml.sc INFO      Epoch 44: train loss 256.5296 (mse_score: 256.5296)\n",
      "17:44 madminer.utils.ml.sc INFO                val. loss  267.3102 (mse_score: 267.3102)\n",
      "17:44 madminer.utils.ml.sc INFO      Epoch 45: train loss 256.4890 (mse_score: 256.4890)\n",
      "17:44 madminer.utils.ml.sc INFO                val. loss  267.2090 (mse_score: 267.2090) (*)\n",
      "17:44 madminer.utils.ml.sc INFO      Epoch 46: train loss 256.4550 (mse_score: 256.4550)\n",
      "17:44 madminer.utils.ml.sc INFO                val. loss  267.2492 (mse_score: 267.2492)\n",
      "17:45 madminer.utils.ml.sc INFO      Epoch 47: train loss 256.3208 (mse_score: 256.3208)\n",
      "17:45 madminer.utils.ml.sc INFO                val. loss  267.1659 (mse_score: 267.1659) (*)\n",
      "17:45 madminer.utils.ml.sc INFO      Epoch 48: train loss 256.2382 (mse_score: 256.2382)\n",
      "17:45 madminer.utils.ml.sc INFO                val. loss  267.0886 (mse_score: 267.0886) (*)\n",
      "17:46 madminer.utils.ml.sc INFO      Epoch 49: train loss 256.2185 (mse_score: 256.2185)\n",
      "17:46 madminer.utils.ml.sc INFO                val. loss  266.9981 (mse_score: 266.9981) (*)\n",
      "17:46 madminer.utils.ml.sc INFO      Epoch 50: train loss 256.0796 (mse_score: 256.0796)\n",
      "17:46 madminer.utils.ml.sc INFO                val. loss  267.0107 (mse_score: 267.0107)\n",
      "17:46 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 267.00 compared to final loss 267.01\n",
      "17:46 madminer.utils.ml.sc INFO    Finished training\n",
      "17:46 madminer.ml          INFO    Training estimator 6 / 10 in ensemble\n",
      "17:46 madminer.ml          INFO    Starting training\n",
      "17:46 madminer.ml          INFO      Method:                 sally\n",
      "17:46 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_5.npy\n",
      "17:46 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_5.npy\n",
      "17:46 madminer.ml          INFO      Features:               all\n",
      "17:46 madminer.ml          INFO      Method:                 sally\n",
      "17:46 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "17:46 madminer.ml          INFO      Activation function:    tanh\n",
      "17:46 madminer.ml          INFO      Batch size:             128\n",
      "17:46 madminer.ml          INFO      Trainer:                amsgrad\n",
      "17:46 madminer.ml          INFO      Epochs:                 50\n",
      "17:46 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:46 madminer.ml          INFO      Validation split:       0.5\n",
      "17:46 madminer.ml          INFO      Early stopping:         True\n",
      "17:46 madminer.ml          INFO      Scale inputs:           True\n",
      "17:46 madminer.ml          INFO      Shuffle labels          False\n",
      "17:46 madminer.ml          INFO      Regularization:         None\n",
      "17:46 madminer.ml          INFO      Samples:                all\n",
      "17:46 madminer.ml          INFO    Loading training data\n",
      "17:46 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "17:46 madminer.ml          INFO    Rescaling inputs\n",
      "17:46 madminer.ml          INFO    Creating model for method sally\n",
      "17:46 madminer.ml          INFO    Training model\n",
      "17:47 madminer.utils.ml.sc INFO      Epoch 01: train loss 299.8994 (mse_score: 299.8994)\n",
      "17:47 madminer.utils.ml.sc INFO                val. loss  287.8350 (mse_score: 287.8350) (*)\n",
      "17:47 madminer.utils.ml.sc INFO      Epoch 02: train loss 284.2582 (mse_score: 284.2582)\n",
      "17:47 madminer.utils.ml.sc INFO                val. loss  280.7270 (mse_score: 280.7270) (*)\n",
      "17:48 madminer.utils.ml.sc INFO      Epoch 03: train loss 280.0887 (mse_score: 280.0887)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:48 madminer.utils.ml.sc INFO                val. loss  278.0704 (mse_score: 278.0704) (*)\n",
      "17:48 madminer.utils.ml.sc INFO      Epoch 04: train loss 276.9508 (mse_score: 276.9508)\n",
      "17:48 madminer.utils.ml.sc INFO                val. loss  274.9510 (mse_score: 274.9510) (*)\n",
      "17:49 madminer.utils.ml.sc INFO      Epoch 05: train loss 274.4346 (mse_score: 274.4346)\n",
      "17:49 madminer.utils.ml.sc INFO                val. loss  273.2393 (mse_score: 273.2393) (*)\n",
      "17:49 madminer.utils.ml.sc INFO      Epoch 06: train loss 272.8614 (mse_score: 272.8614)\n",
      "17:49 madminer.utils.ml.sc INFO                val. loss  272.6515 (mse_score: 272.6515) (*)\n",
      "17:50 madminer.utils.ml.sc INFO      Epoch 07: train loss 271.7413 (mse_score: 271.7413)\n",
      "17:50 madminer.utils.ml.sc INFO                val. loss  271.5044 (mse_score: 271.5044) (*)\n",
      "17:50 madminer.utils.ml.sc INFO      Epoch 08: train loss 270.9304 (mse_score: 270.9304)\n",
      "17:50 madminer.utils.ml.sc INFO                val. loss  270.8160 (mse_score: 270.8160) (*)\n",
      "17:51 madminer.utils.ml.sc INFO      Epoch 09: train loss 270.2084 (mse_score: 270.2084)\n",
      "17:51 madminer.utils.ml.sc INFO                val. loss  269.9476 (mse_score: 269.9476) (*)\n",
      "17:51 madminer.utils.ml.sc INFO      Epoch 10: train loss 269.5972 (mse_score: 269.5972)\n",
      "17:51 madminer.utils.ml.sc INFO                val. loss  269.9625 (mse_score: 269.9625)\n",
      "17:51 madminer.utils.ml.sc INFO      Epoch 11: train loss 268.8485 (mse_score: 268.8485)\n",
      "17:51 madminer.utils.ml.sc INFO                val. loss  269.4466 (mse_score: 269.4466) (*)\n",
      "17:52 madminer.utils.ml.sc INFO      Epoch 12: train loss 268.3494 (mse_score: 268.3494)\n",
      "17:52 madminer.utils.ml.sc INFO                val. loss  268.9485 (mse_score: 268.9485) (*)\n",
      "19:26 madminer.utils.ml.sc INFO      Epoch 13: train loss 267.6600 (mse_score: 267.6600)\n",
      "19:26 madminer.utils.ml.sc INFO                val. loss  268.7592 (mse_score: 268.7592) (*)\n",
      "19:27 madminer.utils.ml.sc INFO      Epoch 14: train loss 267.3011 (mse_score: 267.3011)\n",
      "19:27 madminer.utils.ml.sc INFO                val. loss  268.2302 (mse_score: 268.2302) (*)\n",
      "19:27 madminer.utils.ml.sc INFO      Epoch 15: train loss 266.8823 (mse_score: 266.8823)\n",
      "19:27 madminer.utils.ml.sc INFO                val. loss  267.7350 (mse_score: 267.7350) (*)\n",
      "19:28 madminer.utils.ml.sc INFO      Epoch 16: train loss 266.3069 (mse_score: 266.3069)\n",
      "19:28 madminer.utils.ml.sc INFO                val. loss  267.4075 (mse_score: 267.4075) (*)\n",
      "19:28 madminer.utils.ml.sc INFO      Epoch 17: train loss 265.9891 (mse_score: 265.9891)\n",
      "19:28 madminer.utils.ml.sc INFO                val. loss  267.3360 (mse_score: 267.3360) (*)\n",
      "19:29 madminer.utils.ml.sc INFO      Epoch 18: train loss 265.4561 (mse_score: 265.4561)\n",
      "19:29 madminer.utils.ml.sc INFO                val. loss  267.4495 (mse_score: 267.4495)\n",
      "19:29 madminer.utils.ml.sc INFO      Epoch 19: train loss 265.0625 (mse_score: 265.0625)\n",
      "19:29 madminer.utils.ml.sc INFO                val. loss  266.9177 (mse_score: 266.9177) (*)\n",
      "19:29 madminer.utils.ml.sc INFO      Epoch 20: train loss 264.7288 (mse_score: 264.7288)\n",
      "19:29 madminer.utils.ml.sc INFO                val. loss  266.8117 (mse_score: 266.8117) (*)\n",
      "19:30 madminer.utils.ml.sc INFO      Epoch 21: train loss 264.4510 (mse_score: 264.4510)\n",
      "19:30 madminer.utils.ml.sc INFO                val. loss  266.3936 (mse_score: 266.3936) (*)\n",
      "19:30 madminer.utils.ml.sc INFO      Epoch 22: train loss 264.0617 (mse_score: 264.0617)\n",
      "19:30 madminer.utils.ml.sc INFO                val. loss  266.4173 (mse_score: 266.4173)\n",
      "19:31 madminer.utils.ml.sc INFO      Epoch 23: train loss 263.7966 (mse_score: 263.7966)\n",
      "19:31 madminer.utils.ml.sc INFO                val. loss  266.2070 (mse_score: 266.2070) (*)\n",
      "19:31 madminer.utils.ml.sc INFO      Epoch 24: train loss 263.5540 (mse_score: 263.5540)\n",
      "19:31 madminer.utils.ml.sc INFO                val. loss  265.9340 (mse_score: 265.9340) (*)\n",
      "19:31 madminer.utils.ml.sc INFO      Epoch 25: train loss 263.2302 (mse_score: 263.2302)\n",
      "19:31 madminer.utils.ml.sc INFO                val. loss  265.8963 (mse_score: 265.8963) (*)\n",
      "19:32 madminer.utils.ml.sc INFO      Epoch 26: train loss 262.9977 (mse_score: 262.9977)\n",
      "19:32 madminer.utils.ml.sc INFO                val. loss  265.8116 (mse_score: 265.8116) (*)\n",
      "19:32 madminer.utils.ml.sc INFO      Epoch 27: train loss 262.8832 (mse_score: 262.8832)\n",
      "19:32 madminer.utils.ml.sc INFO                val. loss  265.7350 (mse_score: 265.7350) (*)\n",
      "19:33 madminer.utils.ml.sc INFO      Epoch 28: train loss 262.6402 (mse_score: 262.6402)\n",
      "19:33 madminer.utils.ml.sc INFO                val. loss  265.4769 (mse_score: 265.4769) (*)\n",
      "19:33 madminer.utils.ml.sc INFO      Epoch 29: train loss 262.6647 (mse_score: 262.6647)\n",
      "19:33 madminer.utils.ml.sc INFO                val. loss  265.2876 (mse_score: 265.2876) (*)\n",
      "19:33 madminer.utils.ml.sc INFO      Epoch 30: train loss 262.3499 (mse_score: 262.3499)\n",
      "19:33 madminer.utils.ml.sc INFO                val. loss  265.3207 (mse_score: 265.3207)\n",
      "19:34 madminer.utils.ml.sc INFO      Epoch 31: train loss 262.0466 (mse_score: 262.0466)\n",
      "19:34 madminer.utils.ml.sc INFO                val. loss  265.2382 (mse_score: 265.2382) (*)\n",
      "19:34 madminer.utils.ml.sc INFO      Epoch 32: train loss 261.8937 (mse_score: 261.8937)\n",
      "19:34 madminer.utils.ml.sc INFO                val. loss  265.1971 (mse_score: 265.1971) (*)\n",
      "19:35 madminer.utils.ml.sc INFO      Epoch 33: train loss 261.7528 (mse_score: 261.7528)\n",
      "19:35 madminer.utils.ml.sc INFO                val. loss  264.8820 (mse_score: 264.8820) (*)\n",
      "19:35 madminer.utils.ml.sc INFO      Epoch 34: train loss 261.5740 (mse_score: 261.5740)\n",
      "19:35 madminer.utils.ml.sc INFO                val. loss  264.9737 (mse_score: 264.9737)\n",
      "19:35 madminer.utils.ml.sc INFO      Epoch 35: train loss 261.4439 (mse_score: 261.4439)\n",
      "19:35 madminer.utils.ml.sc INFO                val. loss  264.9101 (mse_score: 264.9101)\n",
      "19:36 madminer.utils.ml.sc INFO      Epoch 36: train loss 261.5067 (mse_score: 261.5067)\n",
      "19:36 madminer.utils.ml.sc INFO                val. loss  264.7878 (mse_score: 264.7878) (*)\n",
      "19:36 madminer.utils.ml.sc INFO      Epoch 37: train loss 261.1655 (mse_score: 261.1655)\n",
      "19:36 madminer.utils.ml.sc INFO                val. loss  264.6759 (mse_score: 264.6759) (*)\n",
      "19:37 madminer.utils.ml.sc INFO      Epoch 38: train loss 260.9621 (mse_score: 260.9621)\n",
      "19:37 madminer.utils.ml.sc INFO                val. loss  264.6878 (mse_score: 264.6878)\n",
      "19:37 madminer.utils.ml.sc INFO      Epoch 39: train loss 260.8689 (mse_score: 260.8689)\n",
      "19:37 madminer.utils.ml.sc INFO                val. loss  264.8958 (mse_score: 264.8958)\n",
      "19:38 madminer.utils.ml.sc INFO      Epoch 40: train loss 260.8143 (mse_score: 260.8143)\n",
      "19:38 madminer.utils.ml.sc INFO                val. loss  264.5541 (mse_score: 264.5541) (*)\n",
      "19:38 madminer.utils.ml.sc INFO      Epoch 41: train loss 260.6772 (mse_score: 260.6772)\n",
      "19:38 madminer.utils.ml.sc INFO                val. loss  264.5371 (mse_score: 264.5371) (*)\n",
      "19:38 madminer.utils.ml.sc INFO      Epoch 42: train loss 260.5801 (mse_score: 260.5801)\n",
      "19:38 madminer.utils.ml.sc INFO                val. loss  264.5155 (mse_score: 264.5155) (*)\n",
      "19:39 madminer.utils.ml.sc INFO      Epoch 43: train loss 260.5112 (mse_score: 260.5112)\n",
      "19:39 madminer.utils.ml.sc INFO                val. loss  264.4783 (mse_score: 264.4783) (*)\n",
      "19:39 madminer.utils.ml.sc INFO      Epoch 44: train loss 260.4048 (mse_score: 260.4048)\n",
      "19:39 madminer.utils.ml.sc INFO                val. loss  264.3509 (mse_score: 264.3509) (*)\n",
      "19:40 madminer.utils.ml.sc INFO      Epoch 45: train loss 260.3964 (mse_score: 260.3964)\n",
      "19:40 madminer.utils.ml.sc INFO                val. loss  264.4807 (mse_score: 264.4807)\n",
      "19:40 madminer.utils.ml.sc INFO      Epoch 46: train loss 260.2551 (mse_score: 260.2551)\n",
      "19:40 madminer.utils.ml.sc INFO                val. loss  264.3650 (mse_score: 264.3650)\n",
      "19:40 madminer.utils.ml.sc INFO      Epoch 47: train loss 260.1671 (mse_score: 260.1671)\n",
      "19:40 madminer.utils.ml.sc INFO                val. loss  264.2891 (mse_score: 264.2891) (*)\n",
      "19:41 madminer.utils.ml.sc INFO      Epoch 48: train loss 260.0804 (mse_score: 260.0804)\n",
      "19:41 madminer.utils.ml.sc INFO                val. loss  264.2461 (mse_score: 264.2461) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:41 madminer.utils.ml.sc INFO      Epoch 49: train loss 259.9967 (mse_score: 259.9967)\n",
      "19:41 madminer.utils.ml.sc INFO                val. loss  264.2564 (mse_score: 264.2564)\n",
      "19:42 madminer.utils.ml.sc INFO      Epoch 50: train loss 259.9395 (mse_score: 259.9395)\n",
      "19:42 madminer.utils.ml.sc INFO                val. loss  264.2274 (mse_score: 264.2274) (*)\n",
      "19:42 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "19:42 madminer.utils.ml.sc INFO    Finished training\n",
      "19:42 madminer.ml          INFO    Training estimator 7 / 10 in ensemble\n",
      "19:42 madminer.ml          INFO    Starting training\n",
      "19:42 madminer.ml          INFO      Method:                 sally\n",
      "19:42 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_6.npy\n",
      "19:42 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_6.npy\n",
      "19:42 madminer.ml          INFO      Features:               all\n",
      "19:42 madminer.ml          INFO      Method:                 sally\n",
      "19:42 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "19:42 madminer.ml          INFO      Activation function:    tanh\n",
      "19:42 madminer.ml          INFO      Batch size:             128\n",
      "19:42 madminer.ml          INFO      Trainer:                amsgrad\n",
      "19:42 madminer.ml          INFO      Epochs:                 50\n",
      "19:42 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "19:42 madminer.ml          INFO      Validation split:       0.5\n",
      "19:42 madminer.ml          INFO      Early stopping:         True\n",
      "19:42 madminer.ml          INFO      Scale inputs:           True\n",
      "19:42 madminer.ml          INFO      Shuffle labels          False\n",
      "19:42 madminer.ml          INFO      Regularization:         None\n",
      "19:42 madminer.ml          INFO      Samples:                all\n",
      "19:42 madminer.ml          INFO    Loading training data\n",
      "19:42 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "19:42 madminer.ml          INFO    Rescaling inputs\n",
      "19:42 madminer.ml          INFO    Creating model for method sally\n",
      "19:42 madminer.ml          INFO    Training model\n",
      "19:42 madminer.utils.ml.sc INFO      Epoch 01: train loss 278.3664 (mse_score: 278.3664)\n",
      "19:42 madminer.utils.ml.sc INFO                val. loss  281.8569 (mse_score: 281.8569) (*)\n",
      "19:42 madminer.utils.ml.sc INFO      Epoch 02: train loss 261.9348 (mse_score: 261.9348)\n",
      "19:42 madminer.utils.ml.sc INFO                val. loss  275.2585 (mse_score: 275.2585) (*)\n",
      "19:43 madminer.utils.ml.sc INFO      Epoch 03: train loss 256.9429 (mse_score: 256.9429)\n",
      "19:43 madminer.utils.ml.sc INFO                val. loss  271.4334 (mse_score: 271.4334) (*)\n",
      "19:43 madminer.utils.ml.sc INFO      Epoch 04: train loss 253.7923 (mse_score: 253.7923)\n",
      "19:43 madminer.utils.ml.sc INFO                val. loss  269.5176 (mse_score: 269.5176) (*)\n",
      "19:44 madminer.utils.ml.sc INFO      Epoch 05: train loss 251.5132 (mse_score: 251.5132)\n",
      "19:44 madminer.utils.ml.sc INFO                val. loss  267.1204 (mse_score: 267.1204) (*)\n",
      "19:44 madminer.utils.ml.sc INFO      Epoch 06: train loss 250.0254 (mse_score: 250.0254)\n",
      "19:44 madminer.utils.ml.sc INFO                val. loss  266.2237 (mse_score: 266.2237) (*)\n",
      "19:45 madminer.utils.ml.sc INFO      Epoch 07: train loss 248.9923 (mse_score: 248.9923)\n",
      "19:45 madminer.utils.ml.sc INFO                val. loss  265.4967 (mse_score: 265.4967) (*)\n",
      "19:45 madminer.utils.ml.sc INFO      Epoch 08: train loss 248.1726 (mse_score: 248.1726)\n",
      "19:45 madminer.utils.ml.sc INFO                val. loss  264.7938 (mse_score: 264.7938) (*)\n",
      "19:46 madminer.utils.ml.sc INFO      Epoch 09: train loss 247.2097 (mse_score: 247.2097)\n",
      "19:46 madminer.utils.ml.sc INFO                val. loss  264.0968 (mse_score: 264.0968) (*)\n",
      "19:46 madminer.utils.ml.sc INFO      Epoch 10: train loss 246.5876 (mse_score: 246.5876)\n",
      "19:46 madminer.utils.ml.sc INFO                val. loss  263.9206 (mse_score: 263.9206) (*)\n",
      "19:46 madminer.utils.ml.sc INFO      Epoch 11: train loss 245.8892 (mse_score: 245.8892)\n",
      "19:46 madminer.utils.ml.sc INFO                val. loss  263.3222 (mse_score: 263.3222) (*)\n",
      "19:47 madminer.utils.ml.sc INFO      Epoch 12: train loss 245.5256 (mse_score: 245.5256)\n",
      "19:47 madminer.utils.ml.sc INFO                val. loss  262.9373 (mse_score: 262.9373) (*)\n",
      "19:47 madminer.utils.ml.sc INFO      Epoch 13: train loss 244.9088 (mse_score: 244.9088)\n",
      "19:47 madminer.utils.ml.sc INFO                val. loss  262.6811 (mse_score: 262.6811) (*)\n",
      "19:48 madminer.utils.ml.sc INFO      Epoch 14: train loss 244.3526 (mse_score: 244.3526)\n",
      "19:48 madminer.utils.ml.sc INFO                val. loss  262.1764 (mse_score: 262.1764) (*)\n",
      "19:48 madminer.utils.ml.sc INFO      Epoch 15: train loss 243.8286 (mse_score: 243.8286)\n",
      "19:48 madminer.utils.ml.sc INFO                val. loss  262.1647 (mse_score: 262.1647) (*)\n",
      "19:49 madminer.utils.ml.sc INFO      Epoch 16: train loss 243.4938 (mse_score: 243.4938)\n",
      "19:49 madminer.utils.ml.sc INFO                val. loss  262.0734 (mse_score: 262.0734) (*)\n",
      "19:49 madminer.utils.ml.sc INFO      Epoch 17: train loss 243.0088 (mse_score: 243.0088)\n",
      "19:49 madminer.utils.ml.sc INFO                val. loss  261.6503 (mse_score: 261.6503) (*)\n",
      "19:50 madminer.utils.ml.sc INFO      Epoch 18: train loss 242.6631 (mse_score: 242.6631)\n",
      "19:50 madminer.utils.ml.sc INFO                val. loss  261.1660 (mse_score: 261.1660) (*)\n",
      "19:50 madminer.utils.ml.sc INFO      Epoch 19: train loss 242.2139 (mse_score: 242.2139)\n",
      "19:50 madminer.utils.ml.sc INFO                val. loss  260.9915 (mse_score: 260.9915) (*)\n",
      "19:50 madminer.utils.ml.sc INFO      Epoch 20: train loss 241.8337 (mse_score: 241.8337)\n",
      "19:50 madminer.utils.ml.sc INFO                val. loss  261.0628 (mse_score: 261.0628)\n",
      "19:51 madminer.utils.ml.sc INFO      Epoch 21: train loss 241.5796 (mse_score: 241.5796)\n",
      "19:51 madminer.utils.ml.sc INFO                val. loss  260.7586 (mse_score: 260.7586) (*)\n",
      "19:51 madminer.utils.ml.sc INFO      Epoch 22: train loss 241.1636 (mse_score: 241.1636)\n",
      "19:51 madminer.utils.ml.sc INFO                val. loss  260.5800 (mse_score: 260.5800) (*)\n",
      "19:52 madminer.utils.ml.sc INFO      Epoch 23: train loss 240.9587 (mse_score: 240.9587)\n",
      "19:52 madminer.utils.ml.sc INFO                val. loss  260.2868 (mse_score: 260.2868) (*)\n",
      "19:52 madminer.utils.ml.sc INFO      Epoch 24: train loss 240.5861 (mse_score: 240.5861)\n",
      "19:52 madminer.utils.ml.sc INFO                val. loss  260.2024 (mse_score: 260.2024) (*)\n",
      "19:52 madminer.utils.ml.sc INFO      Epoch 25: train loss 240.3128 (mse_score: 240.3128)\n",
      "19:52 madminer.utils.ml.sc INFO                val. loss  260.1222 (mse_score: 260.1222) (*)\n",
      "19:53 madminer.utils.ml.sc INFO      Epoch 26: train loss 240.1343 (mse_score: 240.1343)\n",
      "19:53 madminer.utils.ml.sc INFO                val. loss  259.8567 (mse_score: 259.8567) (*)\n",
      "19:53 madminer.utils.ml.sc INFO      Epoch 27: train loss 239.8274 (mse_score: 239.8274)\n",
      "19:53 madminer.utils.ml.sc INFO                val. loss  260.5295 (mse_score: 260.5295)\n",
      "19:54 madminer.utils.ml.sc INFO      Epoch 28: train loss 239.8320 (mse_score: 239.8320)\n",
      "19:54 madminer.utils.ml.sc INFO                val. loss  259.7298 (mse_score: 259.7298) (*)\n",
      "19:54 madminer.utils.ml.sc INFO      Epoch 29: train loss 239.4159 (mse_score: 239.4159)\n",
      "19:54 madminer.utils.ml.sc INFO                val. loss  259.6195 (mse_score: 259.6195) (*)\n",
      "19:54 madminer.utils.ml.sc INFO      Epoch 30: train loss 239.2251 (mse_score: 239.2251)\n",
      "19:54 madminer.utils.ml.sc INFO                val. loss  259.5245 (mse_score: 259.5245) (*)\n",
      "19:55 madminer.utils.ml.sc INFO      Epoch 31: train loss 239.0908 (mse_score: 239.0908)\n",
      "19:55 madminer.utils.ml.sc INFO                val. loss  259.5273 (mse_score: 259.5273)\n",
      "19:55 madminer.utils.ml.sc INFO      Epoch 32: train loss 238.8647 (mse_score: 238.8647)\n",
      "19:55 madminer.utils.ml.sc INFO                val. loss  259.3887 (mse_score: 259.3887) (*)\n",
      "19:56 madminer.utils.ml.sc INFO      Epoch 33: train loss 238.6770 (mse_score: 238.6770)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:56 madminer.utils.ml.sc INFO                val. loss  259.2796 (mse_score: 259.2796) (*)\n",
      "19:56 madminer.utils.ml.sc INFO      Epoch 34: train loss 238.6089 (mse_score: 238.6089)\n",
      "19:56 madminer.utils.ml.sc INFO                val. loss  259.2264 (mse_score: 259.2264) (*)\n",
      "19:56 madminer.utils.ml.sc INFO      Epoch 35: train loss 238.4262 (mse_score: 238.4262)\n",
      "19:56 madminer.utils.ml.sc INFO                val. loss  259.1667 (mse_score: 259.1667) (*)\n",
      "19:57 madminer.utils.ml.sc INFO      Epoch 36: train loss 238.2753 (mse_score: 238.2753)\n",
      "19:57 madminer.utils.ml.sc INFO                val. loss  259.4229 (mse_score: 259.4229)\n",
      "19:57 madminer.utils.ml.sc INFO      Epoch 37: train loss 238.1563 (mse_score: 238.1563)\n",
      "19:57 madminer.utils.ml.sc INFO                val. loss  258.9189 (mse_score: 258.9189) (*)\n",
      "19:58 madminer.utils.ml.sc INFO      Epoch 38: train loss 238.0240 (mse_score: 238.0240)\n",
      "19:58 madminer.utils.ml.sc INFO                val. loss  258.9192 (mse_score: 258.9192)\n",
      "19:58 madminer.utils.ml.sc INFO      Epoch 39: train loss 237.8751 (mse_score: 237.8751)\n",
      "19:58 madminer.utils.ml.sc INFO                val. loss  259.0748 (mse_score: 259.0748)\n",
      "19:58 madminer.utils.ml.sc INFO      Epoch 40: train loss 237.7663 (mse_score: 237.7663)\n",
      "19:58 madminer.utils.ml.sc INFO                val. loss  258.9404 (mse_score: 258.9404)\n",
      "19:59 madminer.utils.ml.sc INFO      Epoch 41: train loss 237.6679 (mse_score: 237.6679)\n",
      "19:59 madminer.utils.ml.sc INFO                val. loss  258.8593 (mse_score: 258.8593) (*)\n",
      "19:59 madminer.utils.ml.sc INFO      Epoch 42: train loss 237.5773 (mse_score: 237.5773)\n",
      "19:59 madminer.utils.ml.sc INFO                val. loss  258.7275 (mse_score: 258.7275) (*)\n",
      "20:00 madminer.utils.ml.sc INFO      Epoch 43: train loss 237.4496 (mse_score: 237.4496)\n",
      "20:00 madminer.utils.ml.sc INFO                val. loss  258.7259 (mse_score: 258.7259) (*)\n",
      "20:00 madminer.utils.ml.sc INFO      Epoch 44: train loss 237.4081 (mse_score: 237.4081)\n",
      "20:00 madminer.utils.ml.sc INFO                val. loss  258.6106 (mse_score: 258.6106) (*)\n",
      "20:00 madminer.utils.ml.sc INFO      Epoch 45: train loss 237.3144 (mse_score: 237.3144)\n",
      "20:00 madminer.utils.ml.sc INFO                val. loss  258.6094 (mse_score: 258.6094) (*)\n",
      "20:01 madminer.utils.ml.sc INFO      Epoch 46: train loss 237.2282 (mse_score: 237.2282)\n",
      "20:01 madminer.utils.ml.sc INFO                val. loss  258.7431 (mse_score: 258.7431)\n",
      "20:01 madminer.utils.ml.sc INFO      Epoch 47: train loss 237.1730 (mse_score: 237.1730)\n",
      "20:01 madminer.utils.ml.sc INFO                val. loss  258.5588 (mse_score: 258.5588) (*)\n",
      "20:02 madminer.utils.ml.sc INFO      Epoch 48: train loss 237.0473 (mse_score: 237.0473)\n",
      "20:02 madminer.utils.ml.sc INFO                val. loss  258.4730 (mse_score: 258.4730) (*)\n",
      "20:02 madminer.utils.ml.sc INFO      Epoch 49: train loss 236.9838 (mse_score: 236.9838)\n",
      "20:02 madminer.utils.ml.sc INFO                val. loss  258.5799 (mse_score: 258.5799)\n",
      "20:03 madminer.utils.ml.sc INFO      Epoch 50: train loss 236.9483 (mse_score: 236.9483)\n",
      "20:03 madminer.utils.ml.sc INFO                val. loss  258.4635 (mse_score: 258.4635) (*)\n",
      "20:03 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "20:03 madminer.utils.ml.sc INFO    Finished training\n",
      "20:03 madminer.ml          INFO    Training estimator 8 / 10 in ensemble\n",
      "20:03 madminer.ml          INFO    Starting training\n",
      "20:03 madminer.ml          INFO      Method:                 sally\n",
      "20:03 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_7.npy\n",
      "20:03 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_7.npy\n",
      "20:03 madminer.ml          INFO      Features:               all\n",
      "20:03 madminer.ml          INFO      Method:                 sally\n",
      "20:03 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "20:03 madminer.ml          INFO      Activation function:    tanh\n",
      "20:03 madminer.ml          INFO      Batch size:             128\n",
      "20:03 madminer.ml          INFO      Trainer:                amsgrad\n",
      "20:03 madminer.ml          INFO      Epochs:                 50\n",
      "20:03 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "20:03 madminer.ml          INFO      Validation split:       0.5\n",
      "20:03 madminer.ml          INFO      Early stopping:         True\n",
      "20:03 madminer.ml          INFO      Scale inputs:           True\n",
      "20:03 madminer.ml          INFO      Shuffle labels          False\n",
      "20:03 madminer.ml          INFO      Regularization:         None\n",
      "20:03 madminer.ml          INFO      Samples:                all\n",
      "20:03 madminer.ml          INFO    Loading training data\n",
      "20:03 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "20:03 madminer.ml          INFO    Rescaling inputs\n",
      "20:03 madminer.ml          INFO    Creating model for method sally\n",
      "20:03 madminer.ml          INFO    Training model\n",
      "20:03 madminer.utils.ml.sc INFO      Epoch 01: train loss 297.4070 (mse_score: 297.4070)\n",
      "20:03 madminer.utils.ml.sc INFO                val. loss  287.2986 (mse_score: 287.2986) (*)\n",
      "20:03 madminer.utils.ml.sc INFO      Epoch 02: train loss 282.1615 (mse_score: 282.1615)\n",
      "20:03 madminer.utils.ml.sc INFO                val. loss  279.5598 (mse_score: 279.5598) (*)\n",
      "20:04 madminer.utils.ml.sc INFO      Epoch 03: train loss 277.2471 (mse_score: 277.2471)\n",
      "20:04 madminer.utils.ml.sc INFO                val. loss  276.2476 (mse_score: 276.2476) (*)\n",
      "20:04 madminer.utils.ml.sc INFO      Epoch 04: train loss 274.4685 (mse_score: 274.4685)\n",
      "20:04 madminer.utils.ml.sc INFO                val. loss  274.2587 (mse_score: 274.2587) (*)\n",
      "20:05 madminer.utils.ml.sc INFO      Epoch 05: train loss 272.4442 (mse_score: 272.4442)\n",
      "20:05 madminer.utils.ml.sc INFO                val. loss  272.7005 (mse_score: 272.7005) (*)\n",
      "20:05 madminer.utils.ml.sc INFO      Epoch 06: train loss 270.9708 (mse_score: 270.9708)\n",
      "20:05 madminer.utils.ml.sc INFO                val. loss  271.7258 (mse_score: 271.7258) (*)\n",
      "20:06 madminer.utils.ml.sc INFO      Epoch 07: train loss 269.8408 (mse_score: 269.8408)\n",
      "20:06 madminer.utils.ml.sc INFO                val. loss  270.4236 (mse_score: 270.4236) (*)\n",
      "20:06 madminer.utils.ml.sc INFO      Epoch 08: train loss 268.9593 (mse_score: 268.9593)\n",
      "20:06 madminer.utils.ml.sc INFO                val. loss  269.8711 (mse_score: 269.8711) (*)\n",
      "20:06 madminer.utils.ml.sc INFO      Epoch 09: train loss 268.0941 (mse_score: 268.0941)\n",
      "20:06 madminer.utils.ml.sc INFO                val. loss  269.3040 (mse_score: 269.3040) (*)\n",
      "20:07 madminer.utils.ml.sc INFO      Epoch 10: train loss 267.2669 (mse_score: 267.2669)\n",
      "20:07 madminer.utils.ml.sc INFO                val. loss  268.7806 (mse_score: 268.7806) (*)\n",
      "20:07 madminer.utils.ml.sc INFO      Epoch 11: train loss 266.6460 (mse_score: 266.6460)\n",
      "20:07 madminer.utils.ml.sc INFO                val. loss  268.4319 (mse_score: 268.4319) (*)\n",
      "20:08 madminer.utils.ml.sc INFO      Epoch 12: train loss 266.2485 (mse_score: 266.2485)\n",
      "20:08 madminer.utils.ml.sc INFO                val. loss  268.3440 (mse_score: 268.3440) (*)\n",
      "20:08 madminer.utils.ml.sc INFO      Epoch 13: train loss 265.5169 (mse_score: 265.5169)\n",
      "20:08 madminer.utils.ml.sc INFO                val. loss  267.6005 (mse_score: 267.6005) (*)\n",
      "20:08 madminer.utils.ml.sc INFO      Epoch 14: train loss 265.0574 (mse_score: 265.0574)\n",
      "20:08 madminer.utils.ml.sc INFO                val. loss  267.1603 (mse_score: 267.1603) (*)\n",
      "20:09 madminer.utils.ml.sc INFO      Epoch 15: train loss 264.4841 (mse_score: 264.4841)\n",
      "20:09 madminer.utils.ml.sc INFO                val. loss  266.8697 (mse_score: 266.8697) (*)\n",
      "20:09 madminer.utils.ml.sc INFO      Epoch 16: train loss 264.0337 (mse_score: 264.0337)\n",
      "20:09 madminer.utils.ml.sc INFO                val. loss  266.6541 (mse_score: 266.6541) (*)\n",
      "20:10 madminer.utils.ml.sc INFO      Epoch 17: train loss 263.6047 (mse_score: 263.6047)\n",
      "20:10 madminer.utils.ml.sc INFO                val. loss  266.3533 (mse_score: 266.3533) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:10 madminer.utils.ml.sc INFO      Epoch 18: train loss 263.2996 (mse_score: 263.2996)\n",
      "20:10 madminer.utils.ml.sc INFO                val. loss  265.7558 (mse_score: 265.7558) (*)\n",
      "20:11 madminer.utils.ml.sc INFO      Epoch 19: train loss 262.8149 (mse_score: 262.8149)\n",
      "20:11 madminer.utils.ml.sc INFO                val. loss  265.5088 (mse_score: 265.5088) (*)\n",
      "20:11 madminer.utils.ml.sc INFO      Epoch 20: train loss 262.5174 (mse_score: 262.5174)\n",
      "20:11 madminer.utils.ml.sc INFO                val. loss  265.3616 (mse_score: 265.3616) (*)\n",
      "20:11 madminer.utils.ml.sc INFO      Epoch 21: train loss 262.1321 (mse_score: 262.1321)\n",
      "20:11 madminer.utils.ml.sc INFO                val. loss  265.2632 (mse_score: 265.2632) (*)\n",
      "20:12 madminer.utils.ml.sc INFO      Epoch 22: train loss 261.8404 (mse_score: 261.8404)\n",
      "20:12 madminer.utils.ml.sc INFO                val. loss  265.2124 (mse_score: 265.2124) (*)\n",
      "20:12 madminer.utils.ml.sc INFO      Epoch 23: train loss 261.6357 (mse_score: 261.6357)\n",
      "20:12 madminer.utils.ml.sc INFO                val. loss  264.8583 (mse_score: 264.8583) (*)\n",
      "20:13 madminer.utils.ml.sc INFO      Epoch 24: train loss 261.4006 (mse_score: 261.4006)\n",
      "20:13 madminer.utils.ml.sc INFO                val. loss  264.7749 (mse_score: 264.7749) (*)\n",
      "20:13 madminer.utils.ml.sc INFO      Epoch 25: train loss 261.0565 (mse_score: 261.0565)\n",
      "20:13 madminer.utils.ml.sc INFO                val. loss  265.1458 (mse_score: 265.1458)\n",
      "20:13 madminer.utils.ml.sc INFO      Epoch 26: train loss 260.8455 (mse_score: 260.8455)\n",
      "20:13 madminer.utils.ml.sc INFO                val. loss  264.4668 (mse_score: 264.4668) (*)\n",
      "20:14 madminer.utils.ml.sc INFO      Epoch 27: train loss 260.4860 (mse_score: 260.4860)\n",
      "20:14 madminer.utils.ml.sc INFO                val. loss  264.2814 (mse_score: 264.2814) (*)\n",
      "20:14 madminer.utils.ml.sc INFO      Epoch 28: train loss 260.3993 (mse_score: 260.3993)\n",
      "20:14 madminer.utils.ml.sc INFO                val. loss  264.0359 (mse_score: 264.0359) (*)\n",
      "20:15 madminer.utils.ml.sc INFO      Epoch 29: train loss 260.1357 (mse_score: 260.1357)\n",
      "20:15 madminer.utils.ml.sc INFO                val. loss  264.0791 (mse_score: 264.0791)\n",
      "20:15 madminer.utils.ml.sc INFO      Epoch 30: train loss 260.0496 (mse_score: 260.0496)\n",
      "20:15 madminer.utils.ml.sc INFO                val. loss  264.1497 (mse_score: 264.1497)\n",
      "20:16 madminer.utils.ml.sc INFO      Epoch 31: train loss 259.8631 (mse_score: 259.8631)\n",
      "20:16 madminer.utils.ml.sc INFO                val. loss  264.0291 (mse_score: 264.0291) (*)\n",
      "20:16 madminer.utils.ml.sc INFO      Epoch 32: train loss 259.6804 (mse_score: 259.6804)\n",
      "20:16 madminer.utils.ml.sc INFO                val. loss  263.8409 (mse_score: 263.8409) (*)\n",
      "20:16 madminer.utils.ml.sc INFO      Epoch 33: train loss 259.5847 (mse_score: 259.5847)\n",
      "20:16 madminer.utils.ml.sc INFO                val. loss  263.8741 (mse_score: 263.8741)\n",
      "20:17 madminer.utils.ml.sc INFO      Epoch 34: train loss 259.4570 (mse_score: 259.4570)\n",
      "20:17 madminer.utils.ml.sc INFO                val. loss  263.7398 (mse_score: 263.7398) (*)\n",
      "20:17 madminer.utils.ml.sc INFO      Epoch 35: train loss 259.2946 (mse_score: 259.2946)\n",
      "20:17 madminer.utils.ml.sc INFO                val. loss  263.5833 (mse_score: 263.5833) (*)\n",
      "20:18 madminer.utils.ml.sc INFO      Epoch 36: train loss 259.2656 (mse_score: 259.2656)\n",
      "20:18 madminer.utils.ml.sc INFO                val. loss  263.7708 (mse_score: 263.7708)\n",
      "20:18 madminer.utils.ml.sc INFO      Epoch 37: train loss 258.9974 (mse_score: 258.9974)\n",
      "20:18 madminer.utils.ml.sc INFO                val. loss  263.3924 (mse_score: 263.3924) (*)\n",
      "20:19 madminer.utils.ml.sc INFO      Epoch 38: train loss 258.9308 (mse_score: 258.9308)\n",
      "20:19 madminer.utils.ml.sc INFO                val. loss  263.3551 (mse_score: 263.3551) (*)\n",
      "20:19 madminer.utils.ml.sc INFO      Epoch 39: train loss 258.6984 (mse_score: 258.6984)\n",
      "20:19 madminer.utils.ml.sc INFO                val. loss  263.2701 (mse_score: 263.2701) (*)\n",
      "20:19 madminer.utils.ml.sc INFO      Epoch 40: train loss 258.6919 (mse_score: 258.6919)\n",
      "20:19 madminer.utils.ml.sc INFO                val. loss  263.3335 (mse_score: 263.3335)\n",
      "20:20 madminer.utils.ml.sc INFO      Epoch 41: train loss 258.5262 (mse_score: 258.5262)\n",
      "20:20 madminer.utils.ml.sc INFO                val. loss  263.2262 (mse_score: 263.2262) (*)\n",
      "20:20 madminer.utils.ml.sc INFO      Epoch 42: train loss 258.4532 (mse_score: 258.4532)\n",
      "20:20 madminer.utils.ml.sc INFO                val. loss  263.2186 (mse_score: 263.2186) (*)\n",
      "20:21 madminer.utils.ml.sc INFO      Epoch 43: train loss 258.6795 (mse_score: 258.6795)\n",
      "20:21 madminer.utils.ml.sc INFO                val. loss  263.0549 (mse_score: 263.0549) (*)\n",
      "20:21 madminer.utils.ml.sc INFO      Epoch 44: train loss 258.1985 (mse_score: 258.1985)\n",
      "20:21 madminer.utils.ml.sc INFO                val. loss  263.1909 (mse_score: 263.1909)\n",
      "20:22 madminer.utils.ml.sc INFO      Epoch 45: train loss 258.2419 (mse_score: 258.2419)\n",
      "20:22 madminer.utils.ml.sc INFO                val. loss  262.9869 (mse_score: 262.9869) (*)\n",
      "20:22 madminer.utils.ml.sc INFO      Epoch 46: train loss 258.1368 (mse_score: 258.1368)\n",
      "20:22 madminer.utils.ml.sc INFO                val. loss  263.1410 (mse_score: 263.1410)\n",
      "20:23 madminer.utils.ml.sc INFO      Epoch 47: train loss 258.1958 (mse_score: 258.1958)\n",
      "20:23 madminer.utils.ml.sc INFO                val. loss  262.9871 (mse_score: 262.9871)\n",
      "20:23 madminer.utils.ml.sc INFO      Epoch 48: train loss 257.9859 (mse_score: 257.9859)\n",
      "20:23 madminer.utils.ml.sc INFO                val. loss  262.9494 (mse_score: 262.9494) (*)\n",
      "20:23 madminer.utils.ml.sc INFO      Epoch 49: train loss 257.9610 (mse_score: 257.9610)\n",
      "20:23 madminer.utils.ml.sc INFO                val. loss  262.9345 (mse_score: 262.9345) (*)\n",
      "20:24 madminer.utils.ml.sc INFO      Epoch 50: train loss 257.8634 (mse_score: 257.8634)\n",
      "20:24 madminer.utils.ml.sc INFO                val. loss  262.8805 (mse_score: 262.8805) (*)\n",
      "20:24 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "20:24 madminer.utils.ml.sc INFO    Finished training\n",
      "20:24 madminer.ml          INFO    Training estimator 9 / 10 in ensemble\n",
      "20:24 madminer.ml          INFO    Starting training\n",
      "20:24 madminer.ml          INFO      Method:                 sally\n",
      "20:24 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_8.npy\n",
      "20:24 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_8.npy\n",
      "20:24 madminer.ml          INFO      Features:               all\n",
      "20:24 madminer.ml          INFO      Method:                 sally\n",
      "20:24 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "20:24 madminer.ml          INFO      Activation function:    tanh\n",
      "20:24 madminer.ml          INFO      Batch size:             128\n",
      "20:24 madminer.ml          INFO      Trainer:                amsgrad\n",
      "20:24 madminer.ml          INFO      Epochs:                 50\n",
      "20:24 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "20:24 madminer.ml          INFO      Validation split:       0.5\n",
      "20:24 madminer.ml          INFO      Early stopping:         True\n",
      "20:24 madminer.ml          INFO      Scale inputs:           True\n",
      "20:24 madminer.ml          INFO      Shuffle labels          False\n",
      "20:24 madminer.ml          INFO      Regularization:         None\n",
      "20:24 madminer.ml          INFO      Samples:                all\n",
      "20:24 madminer.ml          INFO    Loading training data\n",
      "20:24 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "20:24 madminer.ml          INFO    Rescaling inputs\n",
      "20:24 madminer.ml          INFO    Creating model for method sally\n",
      "20:24 madminer.ml          INFO    Training model\n",
      "20:24 madminer.utils.ml.sc INFO      Epoch 01: train loss 293.0349 (mse_score: 293.0349)\n",
      "20:24 madminer.utils.ml.sc INFO                val. loss  277.6399 (mse_score: 277.6399) (*)\n",
      "20:25 madminer.utils.ml.sc INFO      Epoch 02: train loss 277.1644 (mse_score: 277.1644)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:25 madminer.utils.ml.sc INFO                val. loss  270.9861 (mse_score: 270.9861) (*)\n",
      "20:25 madminer.utils.ml.sc INFO      Epoch 03: train loss 272.7414 (mse_score: 272.7414)\n",
      "20:25 madminer.utils.ml.sc INFO                val. loss  268.3376 (mse_score: 268.3376) (*)\n",
      "20:26 madminer.utils.ml.sc INFO      Epoch 04: train loss 270.3052 (mse_score: 270.3052)\n",
      "20:26 madminer.utils.ml.sc INFO                val. loss  266.1925 (mse_score: 266.1925) (*)\n",
      "20:26 madminer.utils.ml.sc INFO      Epoch 05: train loss 268.0857 (mse_score: 268.0857)\n",
      "20:26 madminer.utils.ml.sc INFO                val. loss  264.3746 (mse_score: 264.3746) (*)\n",
      "20:26 madminer.utils.ml.sc INFO      Epoch 06: train loss 266.4020 (mse_score: 266.4020)\n",
      "20:26 madminer.utils.ml.sc INFO                val. loss  263.2851 (mse_score: 263.2851) (*)\n",
      "20:27 madminer.utils.ml.sc INFO      Epoch 07: train loss 265.0294 (mse_score: 265.0294)\n",
      "20:27 madminer.utils.ml.sc INFO                val. loss  262.1027 (mse_score: 262.1027) (*)\n",
      "20:27 madminer.utils.ml.sc INFO      Epoch 08: train loss 263.9531 (mse_score: 263.9531)\n",
      "20:27 madminer.utils.ml.sc INFO                val. loss  261.7145 (mse_score: 261.7145) (*)\n",
      "20:28 madminer.utils.ml.sc INFO      Epoch 09: train loss 263.0219 (mse_score: 263.0219)\n",
      "20:28 madminer.utils.ml.sc INFO                val. loss  261.4086 (mse_score: 261.4086) (*)\n",
      "20:28 madminer.utils.ml.sc INFO      Epoch 10: train loss 262.2455 (mse_score: 262.2455)\n",
      "20:28 madminer.utils.ml.sc INFO                val. loss  260.7972 (mse_score: 260.7972) (*)\n",
      "20:29 madminer.utils.ml.sc INFO      Epoch 11: train loss 261.7269 (mse_score: 261.7269)\n",
      "20:29 madminer.utils.ml.sc INFO                val. loss  260.3714 (mse_score: 260.3714) (*)\n",
      "20:29 madminer.utils.ml.sc INFO      Epoch 12: train loss 261.0869 (mse_score: 261.0869)\n",
      "20:29 madminer.utils.ml.sc INFO                val. loss  259.6977 (mse_score: 259.6977) (*)\n",
      "20:30 madminer.utils.ml.sc INFO      Epoch 13: train loss 260.6138 (mse_score: 260.6138)\n",
      "20:30 madminer.utils.ml.sc INFO                val. loss  259.3619 (mse_score: 259.3619) (*)\n",
      "20:30 madminer.utils.ml.sc INFO      Epoch 14: train loss 260.0283 (mse_score: 260.0283)\n",
      "20:30 madminer.utils.ml.sc INFO                val. loss  259.0937 (mse_score: 259.0937) (*)\n",
      "20:30 madminer.utils.ml.sc INFO      Epoch 15: train loss 259.6066 (mse_score: 259.6066)\n",
      "20:30 madminer.utils.ml.sc INFO                val. loss  258.7638 (mse_score: 258.7638) (*)\n",
      "20:31 madminer.utils.ml.sc INFO      Epoch 16: train loss 259.0873 (mse_score: 259.0873)\n",
      "20:31 madminer.utils.ml.sc INFO                val. loss  258.2608 (mse_score: 258.2608) (*)\n",
      "20:31 madminer.utils.ml.sc INFO      Epoch 17: train loss 259.7353 (mse_score: 259.7353)\n",
      "20:31 madminer.utils.ml.sc INFO                val. loss  258.4147 (mse_score: 258.4147)\n",
      "20:32 madminer.utils.ml.sc INFO      Epoch 18: train loss 258.2919 (mse_score: 258.2919)\n",
      "20:32 madminer.utils.ml.sc INFO                val. loss  257.5695 (mse_score: 257.5695) (*)\n",
      "20:32 madminer.utils.ml.sc INFO      Epoch 19: train loss 257.7745 (mse_score: 257.7745)\n",
      "20:32 madminer.utils.ml.sc INFO                val. loss  257.3882 (mse_score: 257.3882) (*)\n",
      "20:33 madminer.utils.ml.sc INFO      Epoch 20: train loss 257.4637 (mse_score: 257.4637)\n",
      "20:33 madminer.utils.ml.sc INFO                val. loss  257.6142 (mse_score: 257.6142)\n",
      "20:33 madminer.utils.ml.sc INFO      Epoch 21: train loss 256.9628 (mse_score: 256.9628)\n",
      "20:33 madminer.utils.ml.sc INFO                val. loss  257.1894 (mse_score: 257.1894) (*)\n",
      "20:33 madminer.utils.ml.sc INFO      Epoch 22: train loss 256.6417 (mse_score: 256.6417)\n",
      "20:33 madminer.utils.ml.sc INFO                val. loss  256.7770 (mse_score: 256.7770) (*)\n",
      "20:34 madminer.utils.ml.sc INFO      Epoch 23: train loss 256.4053 (mse_score: 256.4053)\n",
      "20:34 madminer.utils.ml.sc INFO                val. loss  256.5936 (mse_score: 256.5936) (*)\n",
      "20:34 madminer.utils.ml.sc INFO      Epoch 24: train loss 256.0638 (mse_score: 256.0638)\n",
      "20:34 madminer.utils.ml.sc INFO                val. loss  256.3635 (mse_score: 256.3635) (*)\n",
      "20:35 madminer.utils.ml.sc INFO      Epoch 25: train loss 255.7381 (mse_score: 255.7381)\n",
      "20:35 madminer.utils.ml.sc INFO                val. loss  256.2876 (mse_score: 256.2876) (*)\n",
      "20:35 madminer.utils.ml.sc INFO      Epoch 26: train loss 255.4676 (mse_score: 255.4676)\n",
      "20:35 madminer.utils.ml.sc INFO                val. loss  256.1268 (mse_score: 256.1268) (*)\n",
      "20:36 madminer.utils.ml.sc INFO      Epoch 27: train loss 255.2828 (mse_score: 255.2828)\n",
      "20:36 madminer.utils.ml.sc INFO                val. loss  255.9590 (mse_score: 255.9590) (*)\n",
      "20:36 madminer.utils.ml.sc INFO      Epoch 28: train loss 254.9873 (mse_score: 254.9873)\n",
      "20:36 madminer.utils.ml.sc INFO                val. loss  255.7790 (mse_score: 255.7790) (*)\n",
      "20:36 madminer.utils.ml.sc INFO      Epoch 29: train loss 254.7642 (mse_score: 254.7642)\n",
      "20:36 madminer.utils.ml.sc INFO                val. loss  255.7582 (mse_score: 255.7582) (*)\n",
      "20:37 madminer.utils.ml.sc INFO      Epoch 30: train loss 254.8641 (mse_score: 254.8641)\n",
      "20:37 madminer.utils.ml.sc INFO                val. loss  255.5664 (mse_score: 255.5664) (*)\n",
      "20:37 madminer.utils.ml.sc INFO      Epoch 31: train loss 254.3878 (mse_score: 254.3878)\n",
      "20:37 madminer.utils.ml.sc INFO                val. loss  255.4749 (mse_score: 255.4749) (*)\n",
      "20:38 madminer.utils.ml.sc INFO      Epoch 32: train loss 254.1861 (mse_score: 254.1861)\n",
      "20:38 madminer.utils.ml.sc INFO                val. loss  255.4526 (mse_score: 255.4526) (*)\n",
      "20:38 madminer.utils.ml.sc INFO      Epoch 33: train loss 254.0201 (mse_score: 254.0201)\n",
      "20:38 madminer.utils.ml.sc INFO                val. loss  255.2456 (mse_score: 255.2456) (*)\n",
      "20:39 madminer.utils.ml.sc INFO      Epoch 34: train loss 253.8420 (mse_score: 253.8420)\n",
      "20:39 madminer.utils.ml.sc INFO                val. loss  255.1802 (mse_score: 255.1802) (*)\n",
      "20:39 madminer.utils.ml.sc INFO      Epoch 35: train loss 253.6439 (mse_score: 253.6439)\n",
      "20:39 madminer.utils.ml.sc INFO                val. loss  255.2254 (mse_score: 255.2254)\n",
      "20:39 madminer.utils.ml.sc INFO      Epoch 36: train loss 253.5238 (mse_score: 253.5238)\n",
      "20:39 madminer.utils.ml.sc INFO                val. loss  255.0295 (mse_score: 255.0295) (*)\n",
      "20:40 madminer.utils.ml.sc INFO      Epoch 37: train loss 253.3637 (mse_score: 253.3637)\n",
      "20:40 madminer.utils.ml.sc INFO                val. loss  255.0884 (mse_score: 255.0884)\n",
      "20:40 madminer.utils.ml.sc INFO      Epoch 38: train loss 253.1976 (mse_score: 253.1976)\n",
      "20:40 madminer.utils.ml.sc INFO                val. loss  254.8995 (mse_score: 254.8995) (*)\n",
      "20:41 madminer.utils.ml.sc INFO      Epoch 39: train loss 253.0935 (mse_score: 253.0935)\n",
      "20:41 madminer.utils.ml.sc INFO                val. loss  254.8611 (mse_score: 254.8611) (*)\n",
      "20:41 madminer.utils.ml.sc INFO      Epoch 40: train loss 252.9699 (mse_score: 252.9699)\n",
      "20:41 madminer.utils.ml.sc INFO                val. loss  254.7168 (mse_score: 254.7168) (*)\n",
      "20:42 madminer.utils.ml.sc INFO      Epoch 41: train loss 252.8396 (mse_score: 252.8396)\n",
      "20:42 madminer.utils.ml.sc INFO                val. loss  254.7050 (mse_score: 254.7050) (*)\n",
      "20:42 madminer.utils.ml.sc INFO      Epoch 42: train loss 252.6921 (mse_score: 252.6921)\n",
      "20:42 madminer.utils.ml.sc INFO                val. loss  254.6937 (mse_score: 254.6937) (*)\n",
      "20:43 madminer.utils.ml.sc INFO      Epoch 43: train loss 252.6073 (mse_score: 252.6073)\n",
      "20:43 madminer.utils.ml.sc INFO                val. loss  254.5997 (mse_score: 254.5997) (*)\n",
      "20:43 madminer.utils.ml.sc INFO      Epoch 44: train loss 252.5792 (mse_score: 252.5792)\n",
      "20:43 madminer.utils.ml.sc INFO                val. loss  254.5380 (mse_score: 254.5380) (*)\n",
      "20:43 madminer.utils.ml.sc INFO      Epoch 45: train loss 252.4506 (mse_score: 252.4506)\n",
      "20:43 madminer.utils.ml.sc INFO                val. loss  254.4890 (mse_score: 254.4890) (*)\n",
      "20:44 madminer.utils.ml.sc INFO      Epoch 46: train loss 252.3200 (mse_score: 252.3200)\n",
      "20:44 madminer.utils.ml.sc INFO                val. loss  254.5393 (mse_score: 254.5393)\n",
      "20:44 madminer.utils.ml.sc INFO      Epoch 47: train loss 252.2709 (mse_score: 252.2709)\n",
      "20:44 madminer.utils.ml.sc INFO                val. loss  254.5279 (mse_score: 254.5279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:45 madminer.utils.ml.sc INFO      Epoch 48: train loss 252.2439 (mse_score: 252.2439)\n",
      "20:45 madminer.utils.ml.sc INFO                val. loss  254.4962 (mse_score: 254.4962)\n",
      "20:45 madminer.utils.ml.sc INFO      Epoch 49: train loss 252.7665 (mse_score: 252.7665)\n",
      "20:45 madminer.utils.ml.sc INFO                val. loss  254.3336 (mse_score: 254.3336) (*)\n",
      "20:45 madminer.utils.ml.sc INFO      Epoch 50: train loss 252.0742 (mse_score: 252.0742)\n",
      "20:45 madminer.utils.ml.sc INFO                val. loss  254.2798 (mse_score: 254.2798) (*)\n",
      "20:45 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "20:45 madminer.utils.ml.sc INFO    Finished training\n",
      "20:45 madminer.ml          INFO    Training estimator 10 / 10 in ensemble\n",
      "20:45 madminer.ml          INFO    Starting training\n",
      "20:45 madminer.ml          INFO      Method:                 sally\n",
      "20:45 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_9.npy\n",
      "20:45 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_9.npy\n",
      "20:45 madminer.ml          INFO      Features:               all\n",
      "20:45 madminer.ml          INFO      Method:                 sally\n",
      "20:45 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "20:45 madminer.ml          INFO      Activation function:    tanh\n",
      "20:45 madminer.ml          INFO      Batch size:             128\n",
      "20:45 madminer.ml          INFO      Trainer:                amsgrad\n",
      "20:45 madminer.ml          INFO      Epochs:                 50\n",
      "20:45 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "20:45 madminer.ml          INFO      Validation split:       0.5\n",
      "20:45 madminer.ml          INFO      Early stopping:         True\n",
      "20:45 madminer.ml          INFO      Scale inputs:           True\n",
      "20:45 madminer.ml          INFO      Shuffle labels          False\n",
      "20:45 madminer.ml          INFO      Regularization:         None\n",
      "20:45 madminer.ml          INFO      Samples:                all\n",
      "20:45 madminer.ml          INFO    Loading training data\n",
      "20:45 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "20:45 madminer.ml          INFO    Rescaling inputs\n",
      "20:46 madminer.ml          INFO    Creating model for method sally\n",
      "20:46 madminer.ml          INFO    Training model\n",
      "20:46 madminer.utils.ml.sc INFO      Epoch 01: train loss 297.0427 (mse_score: 297.0427)\n",
      "20:46 madminer.utils.ml.sc INFO                val. loss  282.0383 (mse_score: 282.0383) (*)\n",
      "20:46 madminer.utils.ml.sc INFO      Epoch 02: train loss 281.3698 (mse_score: 281.3698)\n",
      "20:46 madminer.utils.ml.sc INFO                val. loss  274.5006 (mse_score: 274.5006) (*)\n",
      "20:47 madminer.utils.ml.sc INFO      Epoch 03: train loss 275.9635 (mse_score: 275.9635)\n",
      "20:47 madminer.utils.ml.sc INFO                val. loss  269.6877 (mse_score: 269.6877) (*)\n",
      "20:47 madminer.utils.ml.sc INFO      Epoch 04: train loss 272.4100 (mse_score: 272.4100)\n",
      "20:47 madminer.utils.ml.sc INFO                val. loss  267.6941 (mse_score: 267.6941) (*)\n",
      "20:47 madminer.utils.ml.sc INFO      Epoch 05: train loss 270.4320 (mse_score: 270.4320)\n",
      "20:47 madminer.utils.ml.sc INFO                val. loss  265.9651 (mse_score: 265.9651) (*)\n",
      "20:48 madminer.utils.ml.sc INFO      Epoch 06: train loss 269.3758 (mse_score: 269.3758)\n",
      "20:48 madminer.utils.ml.sc INFO                val. loss  265.6224 (mse_score: 265.6224) (*)\n",
      "20:48 madminer.utils.ml.sc INFO      Epoch 07: train loss 268.3631 (mse_score: 268.3631)\n",
      "20:48 madminer.utils.ml.sc INFO                val. loss  264.2904 (mse_score: 264.2904) (*)\n",
      "20:48 madminer.utils.ml.sc INFO      Epoch 08: train loss 267.4942 (mse_score: 267.4942)\n",
      "20:48 madminer.utils.ml.sc INFO                val. loss  263.8519 (mse_score: 263.8519) (*)\n",
      "20:48 madminer.utils.ml.sc INFO      Epoch 09: train loss 266.8735 (mse_score: 266.8735)\n",
      "20:48 madminer.utils.ml.sc INFO                val. loss  263.4631 (mse_score: 263.4631) (*)\n",
      "20:49 madminer.utils.ml.sc INFO      Epoch 10: train loss 266.1426 (mse_score: 266.1426)\n",
      "20:49 madminer.utils.ml.sc INFO                val. loss  262.7216 (mse_score: 262.7216) (*)\n",
      "20:49 madminer.utils.ml.sc INFO      Epoch 11: train loss 265.6053 (mse_score: 265.6053)\n",
      "20:49 madminer.utils.ml.sc INFO                val. loss  262.4728 (mse_score: 262.4728) (*)\n",
      "20:49 madminer.utils.ml.sc INFO      Epoch 12: train loss 264.9552 (mse_score: 264.9552)\n",
      "20:49 madminer.utils.ml.sc INFO                val. loss  261.9859 (mse_score: 261.9859) (*)\n",
      "20:50 madminer.utils.ml.sc INFO      Epoch 13: train loss 264.2250 (mse_score: 264.2250)\n",
      "20:50 madminer.utils.ml.sc INFO                val. loss  261.2447 (mse_score: 261.2447) (*)\n",
      "20:50 madminer.utils.ml.sc INFO      Epoch 14: train loss 263.8032 (mse_score: 263.8032)\n",
      "20:50 madminer.utils.ml.sc INFO                val. loss  260.9604 (mse_score: 260.9604) (*)\n",
      "20:50 madminer.utils.ml.sc INFO      Epoch 15: train loss 263.3372 (mse_score: 263.3372)\n",
      "20:50 madminer.utils.ml.sc INFO                val. loss  260.8673 (mse_score: 260.8673) (*)\n",
      "20:50 madminer.utils.ml.sc INFO      Epoch 16: train loss 262.7526 (mse_score: 262.7526)\n",
      "20:50 madminer.utils.ml.sc INFO                val. loss  260.6683 (mse_score: 260.6683) (*)\n",
      "20:51 madminer.utils.ml.sc INFO      Epoch 17: train loss 262.3443 (mse_score: 262.3443)\n",
      "20:51 madminer.utils.ml.sc INFO                val. loss  260.2961 (mse_score: 260.2961) (*)\n",
      "20:51 madminer.utils.ml.sc INFO      Epoch 18: train loss 262.1413 (mse_score: 262.1413)\n",
      "20:51 madminer.utils.ml.sc INFO                val. loss  260.0916 (mse_score: 260.0916) (*)\n",
      "20:51 madminer.utils.ml.sc INFO      Epoch 19: train loss 261.6838 (mse_score: 261.6838)\n",
      "20:51 madminer.utils.ml.sc INFO                val. loss  260.0953 (mse_score: 260.0953)\n",
      "20:52 madminer.utils.ml.sc INFO      Epoch 20: train loss 261.4820 (mse_score: 261.4820)\n",
      "20:52 madminer.utils.ml.sc INFO                val. loss  259.6753 (mse_score: 259.6753) (*)\n",
      "20:52 madminer.utils.ml.sc INFO      Epoch 21: train loss 261.1513 (mse_score: 261.1513)\n",
      "20:52 madminer.utils.ml.sc INFO                val. loss  259.4621 (mse_score: 259.4621) (*)\n",
      "20:52 madminer.utils.ml.sc INFO      Epoch 22: train loss 260.9130 (mse_score: 260.9130)\n",
      "20:52 madminer.utils.ml.sc INFO                val. loss  259.2981 (mse_score: 259.2981) (*)\n",
      "20:52 madminer.utils.ml.sc INFO      Epoch 23: train loss 260.7315 (mse_score: 260.7315)\n",
      "20:52 madminer.utils.ml.sc INFO                val. loss  259.4208 (mse_score: 259.4208)\n",
      "20:53 madminer.utils.ml.sc INFO      Epoch 24: train loss 260.3119 (mse_score: 260.3119)\n",
      "20:53 madminer.utils.ml.sc INFO                val. loss  258.8924 (mse_score: 258.8924) (*)\n",
      "20:53 madminer.utils.ml.sc INFO      Epoch 25: train loss 260.0985 (mse_score: 260.0985)\n",
      "20:53 madminer.utils.ml.sc INFO                val. loss  258.7372 (mse_score: 258.7372) (*)\n",
      "20:53 madminer.utils.ml.sc INFO      Epoch 26: train loss 259.8372 (mse_score: 259.8372)\n",
      "20:53 madminer.utils.ml.sc INFO                val. loss  258.6492 (mse_score: 258.6492) (*)\n",
      "20:54 madminer.utils.ml.sc INFO      Epoch 27: train loss 259.6863 (mse_score: 259.6863)\n",
      "20:54 madminer.utils.ml.sc INFO                val. loss  258.8088 (mse_score: 258.8088)\n",
      "20:54 madminer.utils.ml.sc INFO      Epoch 28: train loss 259.3889 (mse_score: 259.3889)\n",
      "20:54 madminer.utils.ml.sc INFO                val. loss  258.4926 (mse_score: 258.4926) (*)\n",
      "20:54 madminer.utils.ml.sc INFO      Epoch 29: train loss 259.2491 (mse_score: 259.2491)\n",
      "20:54 madminer.utils.ml.sc INFO                val. loss  258.5551 (mse_score: 258.5551)\n",
      "20:55 madminer.utils.ml.sc INFO      Epoch 30: train loss 259.0319 (mse_score: 259.0319)\n",
      "20:55 madminer.utils.ml.sc INFO                val. loss  258.2040 (mse_score: 258.2040) (*)\n",
      "20:55 madminer.utils.ml.sc INFO      Epoch 31: train loss 258.8606 (mse_score: 258.8606)\n",
      "20:55 madminer.utils.ml.sc INFO                val. loss  258.2991 (mse_score: 258.2991)\n",
      "20:55 madminer.utils.ml.sc INFO      Epoch 32: train loss 258.8830 (mse_score: 258.8830)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:55 madminer.utils.ml.sc INFO                val. loss  258.1081 (mse_score: 258.1081) (*)\n",
      "20:56 madminer.utils.ml.sc INFO      Epoch 33: train loss 258.5743 (mse_score: 258.5743)\n",
      "20:56 madminer.utils.ml.sc INFO                val. loss  258.0223 (mse_score: 258.0223) (*)\n",
      "20:56 madminer.utils.ml.sc INFO      Epoch 34: train loss 258.4303 (mse_score: 258.4303)\n",
      "20:56 madminer.utils.ml.sc INFO                val. loss  257.9549 (mse_score: 257.9549) (*)\n",
      "20:56 madminer.utils.ml.sc INFO      Epoch 35: train loss 258.2704 (mse_score: 258.2704)\n",
      "20:56 madminer.utils.ml.sc INFO                val. loss  258.5780 (mse_score: 258.5780)\n",
      "20:56 madminer.utils.ml.sc INFO      Epoch 36: train loss 258.1322 (mse_score: 258.1322)\n",
      "20:56 madminer.utils.ml.sc INFO                val. loss  257.7945 (mse_score: 257.7945) (*)\n",
      "20:57 madminer.utils.ml.sc INFO      Epoch 37: train loss 258.0049 (mse_score: 258.0049)\n",
      "20:57 madminer.utils.ml.sc INFO                val. loss  257.6562 (mse_score: 257.6562) (*)\n",
      "20:57 madminer.utils.ml.sc INFO      Epoch 38: train loss 257.9022 (mse_score: 257.9022)\n",
      "20:57 madminer.utils.ml.sc INFO                val. loss  257.6957 (mse_score: 257.6957)\n",
      "20:57 madminer.utils.ml.sc INFO      Epoch 39: train loss 257.7660 (mse_score: 257.7660)\n",
      "20:57 madminer.utils.ml.sc INFO                val. loss  257.6805 (mse_score: 257.6805)\n",
      "20:58 madminer.utils.ml.sc INFO      Epoch 40: train loss 257.7122 (mse_score: 257.7122)\n",
      "20:58 madminer.utils.ml.sc INFO                val. loss  257.5370 (mse_score: 257.5370) (*)\n",
      "20:58 madminer.utils.ml.sc INFO      Epoch 41: train loss 257.5722 (mse_score: 257.5722)\n",
      "20:58 madminer.utils.ml.sc INFO                val. loss  257.5706 (mse_score: 257.5706)\n",
      "20:58 madminer.utils.ml.sc INFO      Epoch 42: train loss 257.5765 (mse_score: 257.5765)\n",
      "20:58 madminer.utils.ml.sc INFO                val. loss  257.6698 (mse_score: 257.6698)\n",
      "20:58 madminer.utils.ml.sc INFO      Epoch 43: train loss 257.4436 (mse_score: 257.4436)\n",
      "20:58 madminer.utils.ml.sc INFO                val. loss  257.6815 (mse_score: 257.6815)\n",
      "20:59 madminer.utils.ml.sc INFO      Epoch 44: train loss 257.3324 (mse_score: 257.3324)\n",
      "20:59 madminer.utils.ml.sc INFO                val. loss  257.4702 (mse_score: 257.4702) (*)\n",
      "20:59 madminer.utils.ml.sc INFO      Epoch 45: train loss 257.2354 (mse_score: 257.2354)\n",
      "20:59 madminer.utils.ml.sc INFO                val. loss  257.4641 (mse_score: 257.4641) (*)\n",
      "20:59 madminer.utils.ml.sc INFO      Epoch 46: train loss 257.1789 (mse_score: 257.1789)\n",
      "20:59 madminer.utils.ml.sc INFO                val. loss  257.4372 (mse_score: 257.4372) (*)\n",
      "21:00 madminer.utils.ml.sc INFO      Epoch 47: train loss 257.1198 (mse_score: 257.1198)\n",
      "21:00 madminer.utils.ml.sc INFO                val. loss  257.3739 (mse_score: 257.3739) (*)\n",
      "21:00 madminer.utils.ml.sc INFO      Epoch 48: train loss 256.9948 (mse_score: 256.9948)\n",
      "21:00 madminer.utils.ml.sc INFO                val. loss  257.3180 (mse_score: 257.3180) (*)\n",
      "21:00 madminer.utils.ml.sc INFO      Epoch 49: train loss 256.9134 (mse_score: 256.9134)\n",
      "21:00 madminer.utils.ml.sc INFO                val. loss  257.2550 (mse_score: 257.2550) (*)\n",
      "21:00 madminer.utils.ml.sc INFO      Epoch 50: train loss 256.8407 (mse_score: 256.8407)\n",
      "21:00 madminer.utils.ml.sc INFO                val. loss  257.2544 (mse_score: 257.2544) (*)\n",
      "21:00 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "21:00 madminer.utils.ml.sc INFO    Finished training\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all_tight',\n",
    "    use_tight_cuts=True,\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal observable basis (no jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_obs = [0,1] + list(range(4,12)) + list(range(16,33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:00 madminer.ml          INFO    Training 10 estimators in ensemble\n",
      "21:00 madminer.ml          INFO    Training estimator 1 / 10 in ensemble\n",
      "21:00 madminer.ml          INFO    Starting training\n",
      "21:00 madminer.ml          INFO      Method:                 sally\n",
      "21:00 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_0.npy\n",
      "21:00 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_0.npy\n",
      "21:00 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "21:00 madminer.ml          INFO      Method:                 sally\n",
      "21:00 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "21:00 madminer.ml          INFO      Activation function:    tanh\n",
      "21:00 madminer.ml          INFO      Batch size:             128\n",
      "21:00 madminer.ml          INFO      Trainer:                amsgrad\n",
      "21:00 madminer.ml          INFO      Epochs:                 50\n",
      "21:00 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "21:00 madminer.ml          INFO      Validation split:       0.5\n",
      "21:00 madminer.ml          INFO      Early stopping:         True\n",
      "21:00 madminer.ml          INFO      Scale inputs:           True\n",
      "21:00 madminer.ml          INFO      Shuffle labels          False\n",
      "21:00 madminer.ml          INFO      Regularization:         None\n",
      "21:00 madminer.ml          INFO      Samples:                all\n",
      "21:00 madminer.ml          INFO    Loading training data\n",
      "21:01 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "21:01 madminer.ml          INFO    Rescaling inputs\n",
      "21:01 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "21:01 madminer.ml          INFO    Creating model for method sally\n",
      "21:01 madminer.ml          INFO    Training model\n",
      "21:01 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1250 (mse_score: 0.1250)\n",
      "21:01 madminer.utils.ml.sc INFO                val. loss  0.0935 (mse_score: 0.0935) (*)\n",
      "21:01 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1214 (mse_score: 0.1214)\n",
      "21:01 madminer.utils.ml.sc INFO                val. loss  0.0901 (mse_score: 0.0901) (*)\n",
      "21:02 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1189 (mse_score: 0.1189)\n",
      "21:02 madminer.utils.ml.sc INFO                val. loss  0.0897 (mse_score: 0.0897) (*)\n",
      "21:02 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1175 (mse_score: 0.1175)\n",
      "21:02 madminer.utils.ml.sc INFO                val. loss  0.0873 (mse_score: 0.0873) (*)\n",
      "21:02 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1152 (mse_score: 0.1152)\n",
      "21:02 madminer.utils.ml.sc INFO                val. loss  0.0902 (mse_score: 0.0902)\n",
      "21:02 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1153 (mse_score: 0.1153)\n",
      "21:02 madminer.utils.ml.sc INFO                val. loss  0.0857 (mse_score: 0.0857) (*)\n",
      "21:03 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1135 (mse_score: 0.1135)\n",
      "21:03 madminer.utils.ml.sc INFO                val. loss  0.0846 (mse_score: 0.0846) (*)\n",
      "21:03 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1115 (mse_score: 0.1115)\n",
      "21:03 madminer.utils.ml.sc INFO                val. loss  0.0840 (mse_score: 0.0840) (*)\n",
      "21:03 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1109 (mse_score: 0.1109)\n",
      "21:03 madminer.utils.ml.sc INFO                val. loss  0.0833 (mse_score: 0.0833) (*)\n",
      "21:04 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.1092 (mse_score: 0.1092)\n",
      "21:04 madminer.utils.ml.sc INFO                val. loss  0.0819 (mse_score: 0.0819) (*)\n",
      "21:04 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.1083 (mse_score: 0.1083)\n",
      "21:04 madminer.utils.ml.sc INFO                val. loss  0.0819 (mse_score: 0.0819)\n",
      "21:04 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.1071 (mse_score: 0.1071)\n",
      "21:04 madminer.utils.ml.sc INFO                val. loss  0.0817 (mse_score: 0.0817) (*)\n",
      "21:05 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.1061 (mse_score: 0.1061)\n",
      "21:05 madminer.utils.ml.sc INFO                val. loss  0.0815 (mse_score: 0.0815) (*)\n",
      "21:05 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.1060 (mse_score: 0.1060)\n",
      "21:05 madminer.utils.ml.sc INFO                val. loss  0.0807 (mse_score: 0.0807) (*)\n",
      "21:05 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.1044 (mse_score: 0.1044)\n",
      "21:05 madminer.utils.ml.sc INFO                val. loss  0.0808 (mse_score: 0.0808)\n",
      "21:06 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.1037 (mse_score: 0.1037)\n",
      "21:06 madminer.utils.ml.sc INFO                val. loss  0.0803 (mse_score: 0.0803) (*)\n",
      "21:06 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.1029 (mse_score: 0.1029)\n",
      "21:06 madminer.utils.ml.sc INFO                val. loss  0.0809 (mse_score: 0.0809)\n",
      "21:06 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.1021 (mse_score: 0.1021)\n",
      "21:06 madminer.utils.ml.sc INFO                val. loss  0.0804 (mse_score: 0.0804)\n",
      "21:07 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.1012 (mse_score: 0.1012)\n",
      "21:07 madminer.utils.ml.sc INFO                val. loss  0.0798 (mse_score: 0.0798) (*)\n",
      "21:07 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.1005 (mse_score: 0.1005)\n",
      "21:07 madminer.utils.ml.sc INFO                val. loss  0.0802 (mse_score: 0.0802)\n",
      "21:07 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0994 (mse_score: 0.0994)\n",
      "21:07 madminer.utils.ml.sc INFO                val. loss  0.0794 (mse_score: 0.0794) (*)\n",
      "21:08 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0989 (mse_score: 0.0989)\n",
      "21:08 madminer.utils.ml.sc INFO                val. loss  0.0810 (mse_score: 0.0810)\n",
      "21:08 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0982 (mse_score: 0.0982)\n",
      "21:08 madminer.utils.ml.sc INFO                val. loss  0.0799 (mse_score: 0.0799)\n",
      "21:08 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0974 (mse_score: 0.0974)\n",
      "21:08 madminer.utils.ml.sc INFO                val. loss  0.0797 (mse_score: 0.0797)\n",
      "21:09 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0967 (mse_score: 0.0967)\n",
      "21:09 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790) (*)\n",
      "21:09 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0963 (mse_score: 0.0963)\n",
      "21:09 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788) (*)\n",
      "21:09 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0957 (mse_score: 0.0957)\n",
      "21:09 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n",
      "21:10 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0953 (mse_score: 0.0953)\n",
      "21:10 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "21:10 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0944 (mse_score: 0.0944)\n",
      "21:10 madminer.utils.ml.sc INFO                val. loss  0.0786 (mse_score: 0.0786) (*)\n",
      "21:10 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0940 (mse_score: 0.0940)\n",
      "21:10 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n",
      "21:10 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0933 (mse_score: 0.0933)\n",
      "21:10 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "21:11 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0930 (mse_score: 0.0930)\n",
      "21:11 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788)\n",
      "21:11 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0927 (mse_score: 0.0927)\n",
      "21:11 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n",
      "21:11 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0921 (mse_score: 0.0921)\n",
      "21:11 madminer.utils.ml.sc INFO                val. loss  0.0791 (mse_score: 0.0791)\n",
      "21:12 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0917 (mse_score: 0.0917)\n",
      "21:12 madminer.utils.ml.sc INFO                val. loss  0.0793 (mse_score: 0.0793)\n",
      "21:12 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0914 (mse_score: 0.0914)\n",
      "21:12 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:12 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0910 (mse_score: 0.0910)\n",
      "21:12 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787)\n",
      "21:13 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0906 (mse_score: 0.0906)\n",
      "21:13 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n",
      "21:13 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0902 (mse_score: 0.0902)\n",
      "21:13 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "21:13 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0899 (mse_score: 0.0899)\n",
      "21:13 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "21:14 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0897 (mse_score: 0.0897)\n",
      "21:14 madminer.utils.ml.sc INFO                val. loss  0.0791 (mse_score: 0.0791)\n",
      "21:14 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0893 (mse_score: 0.0893)\n",
      "21:14 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787)\n",
      "21:14 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0890 (mse_score: 0.0890)\n",
      "21:14 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787)\n",
      "21:15 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0887 (mse_score: 0.0887)\n",
      "21:15 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "21:15 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0885 (mse_score: 0.0885)\n",
      "21:15 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "21:15 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0882 (mse_score: 0.0882)\n",
      "21:15 madminer.utils.ml.sc INFO                val. loss  0.0787 (mse_score: 0.0787)\n",
      "21:16 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0879 (mse_score: 0.0879)\n",
      "21:16 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790)\n",
      "21:16 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0877 (mse_score: 0.0877)\n",
      "21:16 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n",
      "21:16 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0875 (mse_score: 0.0875)\n",
      "21:16 madminer.utils.ml.sc INFO                val. loss  0.0788 (mse_score: 0.0788)\n",
      "21:17 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0873 (mse_score: 0.0873)\n",
      "21:17 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789)\n",
      "21:17 madminer.utils.ml.sc INFO    Early stopping after epoch 29, with loss 0.08 compared to final loss 0.08\n",
      "21:17 madminer.utils.ml.sc INFO    Finished training\n",
      "21:17 madminer.ml          INFO    Training estimator 2 / 10 in ensemble\n",
      "21:17 madminer.ml          INFO    Starting training\n",
      "21:17 madminer.ml          INFO      Method:                 sally\n",
      "21:17 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_1.npy\n",
      "21:17 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_1.npy\n",
      "21:17 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "21:17 madminer.ml          INFO      Method:                 sally\n",
      "21:17 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "21:17 madminer.ml          INFO      Activation function:    tanh\n",
      "21:17 madminer.ml          INFO      Batch size:             128\n",
      "21:17 madminer.ml          INFO      Trainer:                amsgrad\n",
      "21:17 madminer.ml          INFO      Epochs:                 50\n",
      "21:17 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "21:17 madminer.ml          INFO      Validation split:       0.5\n",
      "21:17 madminer.ml          INFO      Early stopping:         True\n",
      "21:17 madminer.ml          INFO      Scale inputs:           True\n",
      "21:17 madminer.ml          INFO      Shuffle labels          False\n",
      "21:17 madminer.ml          INFO      Regularization:         None\n",
      "21:17 madminer.ml          INFO      Samples:                all\n",
      "21:17 madminer.ml          INFO    Loading training data\n",
      "21:17 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "21:17 madminer.ml          INFO    Rescaling inputs\n",
      "21:17 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "21:17 madminer.ml          INFO    Creating model for method sally\n",
      "21:17 madminer.ml          INFO    Training model\n",
      "21:17 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1292 (mse_score: 0.1292)\n",
      "21:17 madminer.utils.ml.sc INFO                val. loss  0.1431 (mse_score: 0.1431) (*)\n",
      "21:17 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1256 (mse_score: 0.1256)\n",
      "21:17 madminer.utils.ml.sc INFO                val. loss  0.1408 (mse_score: 0.1408) (*)\n",
      "21:18 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1237 (mse_score: 0.1237)\n",
      "21:18 madminer.utils.ml.sc INFO                val. loss  0.1387 (mse_score: 0.1387) (*)\n",
      "21:18 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1224 (mse_score: 0.1224)\n",
      "21:18 madminer.utils.ml.sc INFO                val. loss  0.1381 (mse_score: 0.1381) (*)\n",
      "21:18 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1206 (mse_score: 0.1206)\n",
      "21:18 madminer.utils.ml.sc INFO                val. loss  0.1366 (mse_score: 0.1366) (*)\n",
      "21:19 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1201 (mse_score: 0.1201)\n",
      "21:19 madminer.utils.ml.sc INFO                val. loss  0.1368 (mse_score: 0.1368)\n",
      "21:19 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1188 (mse_score: 0.1188)\n",
      "21:19 madminer.utils.ml.sc INFO                val. loss  0.1349 (mse_score: 0.1349) (*)\n",
      "21:19 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1176 (mse_score: 0.1176)\n",
      "21:19 madminer.utils.ml.sc INFO                val. loss  0.1354 (mse_score: 0.1354)\n",
      "21:20 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1167 (mse_score: 0.1167)\n",
      "21:20 madminer.utils.ml.sc INFO                val. loss  0.1358 (mse_score: 0.1358)\n",
      "21:20 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.1152 (mse_score: 0.1152)\n",
      "21:20 madminer.utils.ml.sc INFO                val. loss  0.1341 (mse_score: 0.1341) (*)\n",
      "21:20 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.1148 (mse_score: 0.1148)\n",
      "21:20 madminer.utils.ml.sc INFO                val. loss  0.1351 (mse_score: 0.1351)\n",
      "21:21 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.1127 (mse_score: 0.1127)\n",
      "21:21 madminer.utils.ml.sc INFO                val. loss  0.1474 (mse_score: 0.1474)\n",
      "21:21 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.1123 (mse_score: 0.1123)\n",
      "21:21 madminer.utils.ml.sc INFO                val. loss  0.1339 (mse_score: 0.1339) (*)\n",
      "21:21 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.1115 (mse_score: 0.1115)\n",
      "21:21 madminer.utils.ml.sc INFO                val. loss  0.1334 (mse_score: 0.1334) (*)\n",
      "21:21 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.1101 (mse_score: 0.1101)\n",
      "21:21 madminer.utils.ml.sc INFO                val. loss  0.1331 (mse_score: 0.1331) (*)\n",
      "21:22 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.1090 (mse_score: 0.1090)\n",
      "21:22 madminer.utils.ml.sc INFO                val. loss  0.1345 (mse_score: 0.1345)\n",
      "21:22 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.1079 (mse_score: 0.1079)\n",
      "21:22 madminer.utils.ml.sc INFO                val. loss  0.1343 (mse_score: 0.1343)\n",
      "21:22 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.1073 (mse_score: 0.1073)\n",
      "21:22 madminer.utils.ml.sc INFO                val. loss  0.1337 (mse_score: 0.1337)\n",
      "21:23 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.1064 (mse_score: 0.1064)\n",
      "21:23 madminer.utils.ml.sc INFO                val. loss  0.1336 (mse_score: 0.1336)\n",
      "21:23 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.1059 (mse_score: 0.1059)\n",
      "21:23 madminer.utils.ml.sc INFO                val. loss  0.1332 (mse_score: 0.1332)\n",
      "21:23 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.1051 (mse_score: 0.1051)\n",
      "21:23 madminer.utils.ml.sc INFO                val. loss  0.1330 (mse_score: 0.1330) (*)\n",
      "21:24 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.1040 (mse_score: 0.1040)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:24 madminer.utils.ml.sc INFO                val. loss  0.1335 (mse_score: 0.1335)\n",
      "21:24 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.1029 (mse_score: 0.1029)\n",
      "21:24 madminer.utils.ml.sc INFO                val. loss  0.1324 (mse_score: 0.1324) (*)\n",
      "21:24 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.1024 (mse_score: 0.1024)\n",
      "21:24 madminer.utils.ml.sc INFO                val. loss  0.1332 (mse_score: 0.1332)\n",
      "21:25 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.1018 (mse_score: 0.1018)\n",
      "21:25 madminer.utils.ml.sc INFO                val. loss  0.1334 (mse_score: 0.1334)\n",
      "21:25 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.1012 (mse_score: 0.1012)\n",
      "21:25 madminer.utils.ml.sc INFO                val. loss  0.1338 (mse_score: 0.1338)\n",
      "21:25 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.1005 (mse_score: 0.1005)\n",
      "21:25 madminer.utils.ml.sc INFO                val. loss  0.1335 (mse_score: 0.1335)\n",
      "21:26 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0998 (mse_score: 0.0998)\n",
      "21:26 madminer.utils.ml.sc INFO                val. loss  0.1352 (mse_score: 0.1352)\n",
      "21:26 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0993 (mse_score: 0.0993)\n",
      "21:26 madminer.utils.ml.sc INFO                val. loss  0.1335 (mse_score: 0.1335)\n",
      "21:26 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0987 (mse_score: 0.0987)\n",
      "21:26 madminer.utils.ml.sc INFO                val. loss  0.1331 (mse_score: 0.1331)\n",
      "21:27 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0982 (mse_score: 0.0982)\n",
      "21:27 madminer.utils.ml.sc INFO                val. loss  0.1359 (mse_score: 0.1359)\n",
      "21:27 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0976 (mse_score: 0.0976)\n",
      "21:27 madminer.utils.ml.sc INFO                val. loss  0.1344 (mse_score: 0.1344)\n",
      "21:27 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0970 (mse_score: 0.0970)\n",
      "21:27 madminer.utils.ml.sc INFO                val. loss  0.1331 (mse_score: 0.1331)\n",
      "21:28 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0965 (mse_score: 0.0965)\n",
      "21:28 madminer.utils.ml.sc INFO                val. loss  0.1349 (mse_score: 0.1349)\n",
      "21:28 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0963 (mse_score: 0.0963)\n",
      "21:28 madminer.utils.ml.sc INFO                val. loss  0.1339 (mse_score: 0.1339)\n",
      "21:28 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0958 (mse_score: 0.0958)\n",
      "21:28 madminer.utils.ml.sc INFO                val. loss  0.1341 (mse_score: 0.1341)\n",
      "21:29 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0954 (mse_score: 0.0954)\n",
      "21:29 madminer.utils.ml.sc INFO                val. loss  0.1346 (mse_score: 0.1346)\n",
      "21:29 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0950 (mse_score: 0.0950)\n",
      "21:29 madminer.utils.ml.sc INFO                val. loss  0.1341 (mse_score: 0.1341)\n",
      "21:29 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0944 (mse_score: 0.0944)\n",
      "21:29 madminer.utils.ml.sc INFO                val. loss  0.1351 (mse_score: 0.1351)\n",
      "21:30 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0942 (mse_score: 0.0942)\n",
      "21:30 madminer.utils.ml.sc INFO                val. loss  0.1336 (mse_score: 0.1336)\n",
      "21:30 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0938 (mse_score: 0.0938)\n",
      "21:30 madminer.utils.ml.sc INFO                val. loss  0.1346 (mse_score: 0.1346)\n",
      "21:30 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0934 (mse_score: 0.0934)\n",
      "21:30 madminer.utils.ml.sc INFO                val. loss  0.1345 (mse_score: 0.1345)\n",
      "21:30 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0930 (mse_score: 0.0930)\n",
      "21:30 madminer.utils.ml.sc INFO                val. loss  0.1372 (mse_score: 0.1372)\n",
      "21:31 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0927 (mse_score: 0.0927)\n",
      "21:31 madminer.utils.ml.sc INFO                val. loss  0.1347 (mse_score: 0.1347)\n",
      "21:31 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0925 (mse_score: 0.0925)\n",
      "21:31 madminer.utils.ml.sc INFO                val. loss  0.1368 (mse_score: 0.1368)\n",
      "21:31 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0922 (mse_score: 0.0922)\n",
      "21:31 madminer.utils.ml.sc INFO                val. loss  0.1344 (mse_score: 0.1344)\n",
      "21:32 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0919 (mse_score: 0.0919)\n",
      "21:32 madminer.utils.ml.sc INFO                val. loss  0.1344 (mse_score: 0.1344)\n",
      "21:32 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0917 (mse_score: 0.0917)\n",
      "21:32 madminer.utils.ml.sc INFO                val. loss  0.1348 (mse_score: 0.1348)\n",
      "21:32 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0914 (mse_score: 0.0914)\n",
      "21:32 madminer.utils.ml.sc INFO                val. loss  0.1352 (mse_score: 0.1352)\n",
      "21:33 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0911 (mse_score: 0.0911)\n",
      "21:33 madminer.utils.ml.sc INFO                val. loss  0.1350 (mse_score: 0.1350)\n",
      "21:33 madminer.utils.ml.sc INFO    Early stopping after epoch 23, with loss 0.13 compared to final loss 0.13\n",
      "21:33 madminer.utils.ml.sc INFO    Finished training\n",
      "21:33 madminer.ml          INFO    Training estimator 3 / 10 in ensemble\n",
      "21:33 madminer.ml          INFO    Starting training\n",
      "21:33 madminer.ml          INFO      Method:                 sally\n",
      "21:33 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_2.npy\n",
      "21:33 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_2.npy\n",
      "21:33 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "21:33 madminer.ml          INFO      Method:                 sally\n",
      "21:33 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "21:33 madminer.ml          INFO      Activation function:    tanh\n",
      "21:33 madminer.ml          INFO      Batch size:             128\n",
      "21:33 madminer.ml          INFO      Trainer:                amsgrad\n",
      "21:33 madminer.ml          INFO      Epochs:                 50\n",
      "21:33 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "21:33 madminer.ml          INFO      Validation split:       0.5\n",
      "21:33 madminer.ml          INFO      Early stopping:         True\n",
      "21:33 madminer.ml          INFO      Scale inputs:           True\n",
      "21:33 madminer.ml          INFO      Shuffle labels          False\n",
      "21:33 madminer.ml          INFO      Regularization:         None\n",
      "21:33 madminer.ml          INFO      Samples:                all\n",
      "21:33 madminer.ml          INFO    Loading training data\n",
      "21:33 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "21:33 madminer.ml          INFO    Rescaling inputs\n",
      "21:33 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "21:33 madminer.ml          INFO    Creating model for method sally\n",
      "21:33 madminer.ml          INFO    Training model\n",
      "21:33 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1036 (mse_score: 0.1036)\n",
      "21:33 madminer.utils.ml.sc INFO                val. loss  0.0841 (mse_score: 0.0841) (*)\n",
      "21:33 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0997 (mse_score: 0.0997)\n",
      "21:33 madminer.utils.ml.sc INFO                val. loss  0.0818 (mse_score: 0.0818) (*)\n",
      "21:34 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0974 (mse_score: 0.0974)\n",
      "21:34 madminer.utils.ml.sc INFO                val. loss  0.0794 (mse_score: 0.0794) (*)\n",
      "21:34 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0953 (mse_score: 0.0953)\n",
      "21:34 madminer.utils.ml.sc INFO                val. loss  0.0790 (mse_score: 0.0790) (*)\n",
      "21:34 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0930 (mse_score: 0.0930)\n",
      "21:34 madminer.utils.ml.sc INFO                val. loss  0.0785 (mse_score: 0.0785) (*)\n",
      "21:35 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0913 (mse_score: 0.0913)\n",
      "21:35 madminer.utils.ml.sc INFO                val. loss  0.0771 (mse_score: 0.0771) (*)\n",
      "21:35 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0911 (mse_score: 0.0911)\n",
      "21:35 madminer.utils.ml.sc INFO                val. loss  0.0784 (mse_score: 0.0784)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:35 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0898 (mse_score: 0.0898)\n",
      "21:35 madminer.utils.ml.sc INFO                val. loss  0.0786 (mse_score: 0.0786)\n",
      "21:36 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0878 (mse_score: 0.0878)\n",
      "21:36 madminer.utils.ml.sc INFO                val. loss  0.0770 (mse_score: 0.0770) (*)\n",
      "21:36 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0873 (mse_score: 0.0873)\n",
      "21:36 madminer.utils.ml.sc INFO                val. loss  0.0755 (mse_score: 0.0755) (*)\n",
      "21:36 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0866 (mse_score: 0.0866)\n",
      "21:36 madminer.utils.ml.sc INFO                val. loss  0.0755 (mse_score: 0.0755)\n",
      "21:37 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0846 (mse_score: 0.0846)\n",
      "21:37 madminer.utils.ml.sc INFO                val. loss  0.0769 (mse_score: 0.0769)\n",
      "21:37 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0846 (mse_score: 0.0846)\n",
      "21:37 madminer.utils.ml.sc INFO                val. loss  0.0756 (mse_score: 0.0756)\n",
      "21:37 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0825 (mse_score: 0.0825)\n",
      "21:37 madminer.utils.ml.sc INFO                val. loss  0.0750 (mse_score: 0.0750) (*)\n",
      "21:38 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0814 (mse_score: 0.0814)\n",
      "21:38 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747) (*)\n",
      "21:38 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0809 (mse_score: 0.0809)\n",
      "21:38 madminer.utils.ml.sc INFO                val. loss  0.0748 (mse_score: 0.0748)\n",
      "21:38 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0797 (mse_score: 0.0797)\n",
      "21:38 madminer.utils.ml.sc INFO                val. loss  0.0754 (mse_score: 0.0754)\n",
      "21:39 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0792 (mse_score: 0.0792)\n",
      "21:39 madminer.utils.ml.sc INFO                val. loss  0.0745 (mse_score: 0.0745) (*)\n",
      "21:39 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0778 (mse_score: 0.0778)\n",
      "21:39 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "21:39 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0780 (mse_score: 0.0780)\n",
      "21:39 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "21:40 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0763 (mse_score: 0.0763)\n",
      "21:40 madminer.utils.ml.sc INFO                val. loss  0.0749 (mse_score: 0.0749)\n",
      "21:40 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0757 (mse_score: 0.0757)\n",
      "21:40 madminer.utils.ml.sc INFO                val. loss  0.0757 (mse_score: 0.0757)\n",
      "21:40 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0750 (mse_score: 0.0750)\n",
      "21:40 madminer.utils.ml.sc INFO                val. loss  0.0749 (mse_score: 0.0749)\n",
      "21:40 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0745 (mse_score: 0.0745)\n",
      "21:40 madminer.utils.ml.sc INFO                val. loss  0.0754 (mse_score: 0.0754)\n",
      "21:41 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0740 (mse_score: 0.0740)\n",
      "21:41 madminer.utils.ml.sc INFO                val. loss  0.0745 (mse_score: 0.0745) (*)\n",
      "21:41 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0730 (mse_score: 0.0730)\n",
      "21:41 madminer.utils.ml.sc INFO                val. loss  0.0743 (mse_score: 0.0743) (*)\n",
      "21:41 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0724 (mse_score: 0.0724)\n",
      "21:41 madminer.utils.ml.sc INFO                val. loss  0.0754 (mse_score: 0.0754)\n",
      "21:42 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0719 (mse_score: 0.0719)\n",
      "21:42 madminer.utils.ml.sc INFO                val. loss  0.0739 (mse_score: 0.0739) (*)\n",
      "21:42 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0716 (mse_score: 0.0716)\n",
      "21:42 madminer.utils.ml.sc INFO                val. loss  0.0755 (mse_score: 0.0755)\n",
      "21:42 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0709 (mse_score: 0.0709)\n",
      "21:42 madminer.utils.ml.sc INFO                val. loss  0.0745 (mse_score: 0.0745)\n",
      "21:43 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0704 (mse_score: 0.0704)\n",
      "21:43 madminer.utils.ml.sc INFO                val. loss  0.0746 (mse_score: 0.0746)\n",
      "21:43 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0698 (mse_score: 0.0698)\n",
      "21:43 madminer.utils.ml.sc INFO                val. loss  0.0751 (mse_score: 0.0751)\n",
      "21:43 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0692 (mse_score: 0.0692)\n",
      "21:43 madminer.utils.ml.sc INFO                val. loss  0.0748 (mse_score: 0.0748)\n",
      "21:44 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0690 (mse_score: 0.0690)\n",
      "21:44 madminer.utils.ml.sc INFO                val. loss  0.0754 (mse_score: 0.0754)\n",
      "21:44 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0685 (mse_score: 0.0685)\n",
      "21:44 madminer.utils.ml.sc INFO                val. loss  0.0751 (mse_score: 0.0751)\n",
      "21:44 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0679 (mse_score: 0.0679)\n",
      "21:44 madminer.utils.ml.sc INFO                val. loss  0.0746 (mse_score: 0.0746)\n",
      "21:45 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0677 (mse_score: 0.0677)\n",
      "21:45 madminer.utils.ml.sc INFO                val. loss  0.0753 (mse_score: 0.0753)\n",
      "21:45 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0672 (mse_score: 0.0672)\n",
      "21:45 madminer.utils.ml.sc INFO                val. loss  0.0752 (mse_score: 0.0752)\n",
      "21:45 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0669 (mse_score: 0.0669)\n",
      "21:45 madminer.utils.ml.sc INFO                val. loss  0.0751 (mse_score: 0.0751)\n",
      "21:46 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0667 (mse_score: 0.0667)\n",
      "21:46 madminer.utils.ml.sc INFO                val. loss  0.0754 (mse_score: 0.0754)\n",
      "21:46 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0661 (mse_score: 0.0661)\n",
      "21:46 madminer.utils.ml.sc INFO                val. loss  0.0750 (mse_score: 0.0750)\n",
      "21:46 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0659 (mse_score: 0.0659)\n",
      "21:46 madminer.utils.ml.sc INFO                val. loss  0.0748 (mse_score: 0.0748)\n",
      "21:47 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0657 (mse_score: 0.0657)\n",
      "21:47 madminer.utils.ml.sc INFO                val. loss  0.0750 (mse_score: 0.0750)\n",
      "21:47 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0652 (mse_score: 0.0652)\n",
      "21:47 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747)\n",
      "21:47 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0650 (mse_score: 0.0650)\n",
      "21:47 madminer.utils.ml.sc INFO                val. loss  0.0765 (mse_score: 0.0765)\n",
      "21:48 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0648 (mse_score: 0.0648)\n",
      "21:48 madminer.utils.ml.sc INFO                val. loss  0.0748 (mse_score: 0.0748)\n",
      "21:48 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0646 (mse_score: 0.0646)\n",
      "21:48 madminer.utils.ml.sc INFO                val. loss  0.0751 (mse_score: 0.0751)\n",
      "21:48 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0643 (mse_score: 0.0643)\n",
      "21:48 madminer.utils.ml.sc INFO                val. loss  0.0752 (mse_score: 0.0752)\n",
      "21:49 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0640 (mse_score: 0.0640)\n",
      "21:49 madminer.utils.ml.sc INFO                val. loss  0.0762 (mse_score: 0.0762)\n",
      "21:49 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0638 (mse_score: 0.0638)\n",
      "21:49 madminer.utils.ml.sc INFO                val. loss  0.0751 (mse_score: 0.0751)\n",
      "21:49 madminer.utils.ml.sc INFO    Early stopping after epoch 28, with loss 0.07 compared to final loss 0.08\n",
      "21:49 madminer.utils.ml.sc INFO    Finished training\n",
      "21:49 madminer.ml          INFO    Training estimator 4 / 10 in ensemble\n",
      "21:49 madminer.ml          INFO    Starting training\n",
      "21:49 madminer.ml          INFO      Method:                 sally\n",
      "21:49 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_3.npy\n",
      "21:49 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_3.npy\n",
      "21:49 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:49 madminer.ml          INFO      Method:                 sally\n",
      "21:49 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "21:49 madminer.ml          INFO      Activation function:    tanh\n",
      "21:49 madminer.ml          INFO      Batch size:             128\n",
      "21:49 madminer.ml          INFO      Trainer:                amsgrad\n",
      "21:49 madminer.ml          INFO      Epochs:                 50\n",
      "21:49 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "21:49 madminer.ml          INFO      Validation split:       0.5\n",
      "21:49 madminer.ml          INFO      Early stopping:         True\n",
      "21:49 madminer.ml          INFO      Scale inputs:           True\n",
      "21:49 madminer.ml          INFO      Shuffle labels          False\n",
      "21:49 madminer.ml          INFO      Regularization:         None\n",
      "21:49 madminer.ml          INFO      Samples:                all\n",
      "21:49 madminer.ml          INFO    Loading training data\n",
      "21:49 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "21:49 madminer.ml          INFO    Rescaling inputs\n",
      "21:49 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "21:49 madminer.ml          INFO    Creating model for method sally\n",
      "21:49 madminer.ml          INFO    Training model\n",
      "21:49 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1586 (mse_score: 0.1586)\n",
      "21:49 madminer.utils.ml.sc INFO                val. loss  0.0841 (mse_score: 0.0841) (*)\n",
      "21:50 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1551 (mse_score: 0.1551)\n",
      "21:50 madminer.utils.ml.sc INFO                val. loss  0.0809 (mse_score: 0.0809) (*)\n",
      "21:50 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1525 (mse_score: 0.1525)\n",
      "21:50 madminer.utils.ml.sc INFO                val. loss  0.0805 (mse_score: 0.0805) (*)\n",
      "21:50 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1508 (mse_score: 0.1508)\n",
      "21:50 madminer.utils.ml.sc INFO                val. loss  0.0776 (mse_score: 0.0776) (*)\n",
      "21:50 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1488 (mse_score: 0.1488)\n",
      "21:50 madminer.utils.ml.sc INFO                val. loss  0.0775 (mse_score: 0.0775) (*)\n",
      "21:51 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1487 (mse_score: 0.1487)\n",
      "21:51 madminer.utils.ml.sc INFO                val. loss  0.0762 (mse_score: 0.0762) (*)\n",
      "21:51 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1464 (mse_score: 0.1464)\n",
      "21:51 madminer.utils.ml.sc INFO                val. loss  0.0765 (mse_score: 0.0765)\n",
      "21:51 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1450 (mse_score: 0.1450)\n",
      "21:51 madminer.utils.ml.sc INFO                val. loss  0.0752 (mse_score: 0.0752) (*)\n",
      "21:52 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1445 (mse_score: 0.1445)\n",
      "21:52 madminer.utils.ml.sc INFO                val. loss  0.0750 (mse_score: 0.0750) (*)\n",
      "21:52 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.1438 (mse_score: 0.1438)\n",
      "21:52 madminer.utils.ml.sc INFO                val. loss  0.0743 (mse_score: 0.0743) (*)\n",
      "21:52 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.1428 (mse_score: 0.1428)\n",
      "21:52 madminer.utils.ml.sc INFO                val. loss  0.0737 (mse_score: 0.0737) (*)\n",
      "21:53 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.1413 (mse_score: 0.1413)\n",
      "21:53 madminer.utils.ml.sc INFO                val. loss  0.0732 (mse_score: 0.0732) (*)\n",
      "21:53 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.1403 (mse_score: 0.1403)\n",
      "21:53 madminer.utils.ml.sc INFO                val. loss  0.0733 (mse_score: 0.0733)\n",
      "21:53 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.1398 (mse_score: 0.1398)\n",
      "21:53 madminer.utils.ml.sc INFO                val. loss  0.0730 (mse_score: 0.0730) (*)\n",
      "21:54 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.1386 (mse_score: 0.1386)\n",
      "21:54 madminer.utils.ml.sc INFO                val. loss  0.0727 (mse_score: 0.0727) (*)\n",
      "21:54 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.1375 (mse_score: 0.1375)\n",
      "21:54 madminer.utils.ml.sc INFO                val. loss  0.0731 (mse_score: 0.0731)\n",
      "21:54 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.1369 (mse_score: 0.1369)\n",
      "21:54 madminer.utils.ml.sc INFO                val. loss  0.0711 (mse_score: 0.0711) (*)\n",
      "21:55 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.1360 (mse_score: 0.1360)\n",
      "21:55 madminer.utils.ml.sc INFO                val. loss  0.0725 (mse_score: 0.0725)\n",
      "21:55 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.1357 (mse_score: 0.1357)\n",
      "21:55 madminer.utils.ml.sc INFO                val. loss  0.0720 (mse_score: 0.0720)\n",
      "21:55 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.1344 (mse_score: 0.1344)\n",
      "21:55 madminer.utils.ml.sc INFO                val. loss  0.0725 (mse_score: 0.0725)\n",
      "21:56 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.1338 (mse_score: 0.1338)\n",
      "21:56 madminer.utils.ml.sc INFO                val. loss  0.0722 (mse_score: 0.0722)\n",
      "21:56 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.1331 (mse_score: 0.1331)\n",
      "21:56 madminer.utils.ml.sc INFO                val. loss  0.0717 (mse_score: 0.0717)\n",
      "21:56 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.1325 (mse_score: 0.1325)\n",
      "21:56 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708) (*)\n",
      "21:57 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.1318 (mse_score: 0.1318)\n",
      "21:57 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "21:57 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.1313 (mse_score: 0.1313)\n",
      "21:57 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707) (*)\n",
      "21:57 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.1307 (mse_score: 0.1307)\n",
      "21:57 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706) (*)\n",
      "21:58 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.1303 (mse_score: 0.1303)\n",
      "21:58 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "21:58 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.1297 (mse_score: 0.1297)\n",
      "21:58 madminer.utils.ml.sc INFO                val. loss  0.0704 (mse_score: 0.0704) (*)\n",
      "21:58 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.1294 (mse_score: 0.1294)\n",
      "21:58 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "21:59 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.1288 (mse_score: 0.1288)\n",
      "21:59 madminer.utils.ml.sc INFO                val. loss  0.0703 (mse_score: 0.0703) (*)\n",
      "21:59 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.1285 (mse_score: 0.1285)\n",
      "21:59 madminer.utils.ml.sc INFO                val. loss  0.0704 (mse_score: 0.0704)\n",
      "21:59 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.1280 (mse_score: 0.1280)\n",
      "21:59 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706)\n",
      "22:00 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.1276 (mse_score: 0.1276)\n",
      "22:00 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "22:00 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.1272 (mse_score: 0.1272)\n",
      "22:00 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701) (*)\n",
      "22:00 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.1269 (mse_score: 0.1269)\n",
      "22:00 madminer.utils.ml.sc INFO                val. loss  0.0700 (mse_score: 0.0700) (*)\n",
      "22:01 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.1266 (mse_score: 0.1266)\n",
      "22:01 madminer.utils.ml.sc INFO                val. loss  0.0702 (mse_score: 0.0702)\n",
      "22:01 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.1262 (mse_score: 0.1262)\n",
      "22:01 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701)\n",
      "22:01 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.1259 (mse_score: 0.1259)\n",
      "22:01 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701)\n",
      "22:02 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.1256 (mse_score: 0.1256)\n",
      "22:02 madminer.utils.ml.sc INFO                val. loss  0.0703 (mse_score: 0.0703)\n",
      "22:02 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.1253 (mse_score: 0.1253)\n",
      "22:02 madminer.utils.ml.sc INFO                val. loss  0.0700 (mse_score: 0.0700) (*)\n",
      "22:02 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.1251 (mse_score: 0.1251)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:02 madminer.utils.ml.sc INFO                val. loss  0.0702 (mse_score: 0.0702)\n",
      "22:02 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.1248 (mse_score: 0.1248)\n",
      "22:02 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701)\n",
      "22:03 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.1245 (mse_score: 0.1245)\n",
      "22:03 madminer.utils.ml.sc INFO                val. loss  0.0702 (mse_score: 0.0702)\n",
      "22:03 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.1242 (mse_score: 0.1242)\n",
      "22:03 madminer.utils.ml.sc INFO                val. loss  0.0698 (mse_score: 0.0698) (*)\n",
      "22:03 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.1240 (mse_score: 0.1240)\n",
      "22:03 madminer.utils.ml.sc INFO                val. loss  0.0701 (mse_score: 0.0701)\n",
      "22:04 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.1238 (mse_score: 0.1238)\n",
      "22:04 madminer.utils.ml.sc INFO                val. loss  0.0700 (mse_score: 0.0700)\n",
      "22:04 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.1236 (mse_score: 0.1236)\n",
      "22:04 madminer.utils.ml.sc INFO                val. loss  0.0700 (mse_score: 0.0700)\n",
      "22:04 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.1234 (mse_score: 0.1234)\n",
      "22:04 madminer.utils.ml.sc INFO                val. loss  0.0698 (mse_score: 0.0698) (*)\n",
      "22:05 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.1232 (mse_score: 0.1232)\n",
      "22:05 madminer.utils.ml.sc INFO                val. loss  0.0698 (mse_score: 0.0698)\n",
      "22:05 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.1230 (mse_score: 0.1230)\n",
      "22:05 madminer.utils.ml.sc INFO                val. loss  0.0699 (mse_score: 0.0699)\n",
      "22:05 madminer.utils.ml.sc INFO    Early stopping after epoch 48, with loss 0.07 compared to final loss 0.07\n",
      "22:05 madminer.utils.ml.sc INFO    Finished training\n",
      "22:05 madminer.ml          INFO    Training estimator 5 / 10 in ensemble\n",
      "22:05 madminer.ml          INFO    Starting training\n",
      "22:05 madminer.ml          INFO      Method:                 sally\n",
      "22:05 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_4.npy\n",
      "22:05 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_4.npy\n",
      "22:05 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "22:05 madminer.ml          INFO      Method:                 sally\n",
      "22:05 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "22:05 madminer.ml          INFO      Activation function:    tanh\n",
      "22:05 madminer.ml          INFO      Batch size:             128\n",
      "22:05 madminer.ml          INFO      Trainer:                amsgrad\n",
      "22:05 madminer.ml          INFO      Epochs:                 50\n",
      "22:05 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:05 madminer.ml          INFO      Validation split:       0.5\n",
      "22:05 madminer.ml          INFO      Early stopping:         True\n",
      "22:05 madminer.ml          INFO      Scale inputs:           True\n",
      "22:05 madminer.ml          INFO      Shuffle labels          False\n",
      "22:05 madminer.ml          INFO      Regularization:         None\n",
      "22:05 madminer.ml          INFO      Samples:                all\n",
      "22:05 madminer.ml          INFO    Loading training data\n",
      "22:05 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "22:05 madminer.ml          INFO    Rescaling inputs\n",
      "22:05 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "22:05 madminer.ml          INFO    Creating model for method sally\n",
      "22:05 madminer.ml          INFO    Training model\n",
      "22:05 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1117 (mse_score: 0.1117)\n",
      "22:05 madminer.utils.ml.sc INFO                val. loss  0.0848 (mse_score: 0.0848) (*)\n",
      "22:06 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1084 (mse_score: 0.1084)\n",
      "22:06 madminer.utils.ml.sc INFO                val. loss  0.0841 (mse_score: 0.0841) (*)\n",
      "22:06 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1065 (mse_score: 0.1065)\n",
      "22:06 madminer.utils.ml.sc INFO                val. loss  0.0800 (mse_score: 0.0800) (*)\n",
      "22:06 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1055 (mse_score: 0.1055)\n",
      "22:06 madminer.utils.ml.sc INFO                val. loss  0.0789 (mse_score: 0.0789) (*)\n",
      "22:07 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1044 (mse_score: 0.1044)\n",
      "22:07 madminer.utils.ml.sc INFO                val. loss  0.0783 (mse_score: 0.0783) (*)\n",
      "22:07 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1023 (mse_score: 0.1023)\n",
      "22:07 madminer.utils.ml.sc INFO                val. loss  0.0784 (mse_score: 0.0784)\n",
      "22:07 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1015 (mse_score: 0.1015)\n",
      "22:07 madminer.utils.ml.sc INFO                val. loss  0.0791 (mse_score: 0.0791)\n",
      "22:08 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1002 (mse_score: 0.1002)\n",
      "22:08 madminer.utils.ml.sc INFO                val. loss  0.0784 (mse_score: 0.0784)\n",
      "22:08 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0996 (mse_score: 0.0996)\n",
      "22:08 madminer.utils.ml.sc INFO                val. loss  0.0782 (mse_score: 0.0782) (*)\n",
      "22:08 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0978 (mse_score: 0.0978)\n",
      "22:08 madminer.utils.ml.sc INFO                val. loss  0.0799 (mse_score: 0.0799)\n",
      "22:09 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0972 (mse_score: 0.0972)\n",
      "22:09 madminer.utils.ml.sc INFO                val. loss  0.0764 (mse_score: 0.0764) (*)\n",
      "22:09 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0960 (mse_score: 0.0960)\n",
      "22:09 madminer.utils.ml.sc INFO                val. loss  0.0778 (mse_score: 0.0778)\n",
      "22:09 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0951 (mse_score: 0.0951)\n",
      "22:09 madminer.utils.ml.sc INFO                val. loss  0.0976 (mse_score: 0.0976)\n",
      "22:10 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0945 (mse_score: 0.0945)\n",
      "22:10 madminer.utils.ml.sc INFO                val. loss  0.0759 (mse_score: 0.0759) (*)\n",
      "22:10 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0931 (mse_score: 0.0931)\n",
      "22:10 madminer.utils.ml.sc INFO                val. loss  0.0756 (mse_score: 0.0756) (*)\n",
      "22:10 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0926 (mse_score: 0.0926)\n",
      "22:10 madminer.utils.ml.sc INFO                val. loss  0.0760 (mse_score: 0.0760)\n",
      "22:11 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0916 (mse_score: 0.0916)\n",
      "22:11 madminer.utils.ml.sc INFO                val. loss  0.0761 (mse_score: 0.0761)\n",
      "22:11 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0907 (mse_score: 0.0907)\n",
      "22:11 madminer.utils.ml.sc INFO                val. loss  0.0763 (mse_score: 0.0763)\n",
      "22:11 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0901 (mse_score: 0.0901)\n",
      "22:11 madminer.utils.ml.sc INFO                val. loss  0.0763 (mse_score: 0.0763)\n",
      "22:12 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0891 (mse_score: 0.0891)\n",
      "22:12 madminer.utils.ml.sc INFO                val. loss  0.0769 (mse_score: 0.0769)\n",
      "22:12 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0884 (mse_score: 0.0884)\n",
      "22:12 madminer.utils.ml.sc INFO                val. loss  0.0754 (mse_score: 0.0754) (*)\n",
      "22:12 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0878 (mse_score: 0.0878)\n",
      "22:12 madminer.utils.ml.sc INFO                val. loss  0.0769 (mse_score: 0.0769)\n",
      "22:12 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0872 (mse_score: 0.0872)\n",
      "22:12 madminer.utils.ml.sc INFO                val. loss  0.0765 (mse_score: 0.0765)\n",
      "22:13 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0865 (mse_score: 0.0865)\n",
      "22:13 madminer.utils.ml.sc INFO                val. loss  0.0764 (mse_score: 0.0764)\n",
      "22:13 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0859 (mse_score: 0.0859)\n",
      "22:13 madminer.utils.ml.sc INFO                val. loss  0.0776 (mse_score: 0.0776)\n",
      "22:13 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0853 (mse_score: 0.0853)\n",
      "22:13 madminer.utils.ml.sc INFO                val. loss  0.0761 (mse_score: 0.0761)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:14 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0847 (mse_score: 0.0847)\n",
      "22:14 madminer.utils.ml.sc INFO                val. loss  0.0759 (mse_score: 0.0759)\n",
      "22:14 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0841 (mse_score: 0.0841)\n",
      "22:14 madminer.utils.ml.sc INFO                val. loss  0.0756 (mse_score: 0.0756)\n",
      "22:14 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0836 (mse_score: 0.0836)\n",
      "22:14 madminer.utils.ml.sc INFO                val. loss  0.0761 (mse_score: 0.0761)\n",
      "22:15 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0830 (mse_score: 0.0830)\n",
      "22:15 madminer.utils.ml.sc INFO                val. loss  0.0762 (mse_score: 0.0762)\n",
      "22:15 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0825 (mse_score: 0.0825)\n",
      "22:15 madminer.utils.ml.sc INFO                val. loss  0.0760 (mse_score: 0.0760)\n",
      "22:15 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0820 (mse_score: 0.0820)\n",
      "22:15 madminer.utils.ml.sc INFO                val. loss  0.0759 (mse_score: 0.0759)\n",
      "22:16 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0813 (mse_score: 0.0813)\n",
      "22:16 madminer.utils.ml.sc INFO                val. loss  0.0760 (mse_score: 0.0760)\n",
      "22:16 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0809 (mse_score: 0.0809)\n",
      "22:16 madminer.utils.ml.sc INFO                val. loss  0.0773 (mse_score: 0.0773)\n",
      "22:16 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0807 (mse_score: 0.0807)\n",
      "22:16 madminer.utils.ml.sc INFO                val. loss  0.0770 (mse_score: 0.0770)\n",
      "22:17 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0801 (mse_score: 0.0801)\n",
      "22:17 madminer.utils.ml.sc INFO                val. loss  0.0761 (mse_score: 0.0761)\n",
      "22:17 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0797 (mse_score: 0.0797)\n",
      "22:17 madminer.utils.ml.sc INFO                val. loss  0.0769 (mse_score: 0.0769)\n",
      "22:17 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0793 (mse_score: 0.0793)\n",
      "22:17 madminer.utils.ml.sc INFO                val. loss  0.0768 (mse_score: 0.0768)\n",
      "22:18 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0789 (mse_score: 0.0789)\n",
      "22:18 madminer.utils.ml.sc INFO                val. loss  0.0768 (mse_score: 0.0768)\n",
      "22:18 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0785 (mse_score: 0.0785)\n",
      "22:18 madminer.utils.ml.sc INFO                val. loss  0.0774 (mse_score: 0.0774)\n",
      "22:18 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0781 (mse_score: 0.0781)\n",
      "22:18 madminer.utils.ml.sc INFO                val. loss  0.0775 (mse_score: 0.0775)\n",
      "22:19 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0778 (mse_score: 0.0778)\n",
      "22:19 madminer.utils.ml.sc INFO                val. loss  0.0770 (mse_score: 0.0770)\n",
      "22:19 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0775 (mse_score: 0.0775)\n",
      "22:19 madminer.utils.ml.sc INFO                val. loss  0.0767 (mse_score: 0.0767)\n",
      "22:19 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0773 (mse_score: 0.0773)\n",
      "22:19 madminer.utils.ml.sc INFO                val. loss  0.0763 (mse_score: 0.0763)\n",
      "22:20 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0770 (mse_score: 0.0770)\n",
      "22:20 madminer.utils.ml.sc INFO                val. loss  0.0769 (mse_score: 0.0769)\n",
      "22:20 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0766 (mse_score: 0.0766)\n",
      "22:20 madminer.utils.ml.sc INFO                val. loss  0.0761 (mse_score: 0.0761)\n",
      "22:20 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0764 (mse_score: 0.0764)\n",
      "22:20 madminer.utils.ml.sc INFO                val. loss  0.0765 (mse_score: 0.0765)\n",
      "22:21 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0762 (mse_score: 0.0762)\n",
      "22:21 madminer.utils.ml.sc INFO                val. loss  0.0774 (mse_score: 0.0774)\n",
      "22:21 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0759 (mse_score: 0.0759)\n",
      "22:21 madminer.utils.ml.sc INFO                val. loss  0.0770 (mse_score: 0.0770)\n",
      "22:21 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0757 (mse_score: 0.0757)\n",
      "22:21 madminer.utils.ml.sc INFO                val. loss  0.0771 (mse_score: 0.0771)\n",
      "22:21 madminer.utils.ml.sc INFO    Early stopping after epoch 21, with loss 0.08 compared to final loss 0.08\n",
      "22:21 madminer.utils.ml.sc INFO    Finished training\n",
      "22:21 madminer.ml          INFO    Training estimator 6 / 10 in ensemble\n",
      "22:21 madminer.ml          INFO    Starting training\n",
      "22:21 madminer.ml          INFO      Method:                 sally\n",
      "22:21 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_5.npy\n",
      "22:21 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_5.npy\n",
      "22:21 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "22:21 madminer.ml          INFO      Method:                 sally\n",
      "22:21 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "22:21 madminer.ml          INFO      Activation function:    tanh\n",
      "22:21 madminer.ml          INFO      Batch size:             128\n",
      "22:21 madminer.ml          INFO      Trainer:                amsgrad\n",
      "22:21 madminer.ml          INFO      Epochs:                 50\n",
      "22:21 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:21 madminer.ml          INFO      Validation split:       0.5\n",
      "22:21 madminer.ml          INFO      Early stopping:         True\n",
      "22:21 madminer.ml          INFO      Scale inputs:           True\n",
      "22:21 madminer.ml          INFO      Shuffle labels          False\n",
      "22:21 madminer.ml          INFO      Regularization:         None\n",
      "22:21 madminer.ml          INFO      Samples:                all\n",
      "22:21 madminer.ml          INFO    Loading training data\n",
      "22:21 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "22:21 madminer.ml          INFO    Rescaling inputs\n",
      "22:21 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "22:21 madminer.ml          INFO    Creating model for method sally\n",
      "22:21 madminer.ml          INFO    Training model\n",
      "22:22 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0863 (mse_score: 0.0863)\n",
      "22:22 madminer.utils.ml.sc INFO                val. loss  0.1574 (mse_score: 0.1574) (*)\n",
      "22:22 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0829 (mse_score: 0.0829)\n",
      "22:22 madminer.utils.ml.sc INFO                val. loss  0.1541 (mse_score: 0.1541) (*)\n",
      "22:22 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0805 (mse_score: 0.0805)\n",
      "22:22 madminer.utils.ml.sc INFO                val. loss  0.1508 (mse_score: 0.1508) (*)\n",
      "22:22 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0790 (mse_score: 0.0790)\n",
      "22:22 madminer.utils.ml.sc INFO                val. loss  0.1491 (mse_score: 0.1491) (*)\n",
      "22:23 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0780 (mse_score: 0.0780)\n",
      "22:23 madminer.utils.ml.sc INFO                val. loss  0.1479 (mse_score: 0.1479) (*)\n",
      "22:23 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0766 (mse_score: 0.0766)\n",
      "22:23 madminer.utils.ml.sc INFO                val. loss  0.1480 (mse_score: 0.1480)\n",
      "22:23 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0750 (mse_score: 0.0750)\n",
      "22:23 madminer.utils.ml.sc INFO                val. loss  0.1476 (mse_score: 0.1476) (*)\n",
      "22:24 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0740 (mse_score: 0.0740)\n",
      "22:24 madminer.utils.ml.sc INFO                val. loss  0.1455 (mse_score: 0.1455) (*)\n",
      "22:24 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0737 (mse_score: 0.0737)\n",
      "22:24 madminer.utils.ml.sc INFO                val. loss  0.1456 (mse_score: 0.1456)\n",
      "22:24 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0725 (mse_score: 0.0725)\n",
      "22:24 madminer.utils.ml.sc INFO                val. loss  0.1452 (mse_score: 0.1452) (*)\n",
      "22:25 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0707 (mse_score: 0.0707)\n",
      "22:25 madminer.utils.ml.sc INFO                val. loss  0.1442 (mse_score: 0.1442) (*)\n",
      "22:25 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0699 (mse_score: 0.0699)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:25 madminer.utils.ml.sc INFO                val. loss  0.1441 (mse_score: 0.1441) (*)\n",
      "22:25 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0690 (mse_score: 0.0690)\n",
      "22:25 madminer.utils.ml.sc INFO                val. loss  0.1429 (mse_score: 0.1429) (*)\n",
      "22:26 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0687 (mse_score: 0.0687)\n",
      "22:26 madminer.utils.ml.sc INFO                val. loss  0.1419 (mse_score: 0.1419) (*)\n",
      "22:26 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0673 (mse_score: 0.0673)\n",
      "22:26 madminer.utils.ml.sc INFO                val. loss  0.1428 (mse_score: 0.1428)\n",
      "22:26 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0666 (mse_score: 0.0666)\n",
      "22:26 madminer.utils.ml.sc INFO                val. loss  0.1471 (mse_score: 0.1471)\n",
      "22:27 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0658 (mse_score: 0.0658)\n",
      "22:27 madminer.utils.ml.sc INFO                val. loss  0.1414 (mse_score: 0.1414) (*)\n",
      "22:27 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0651 (mse_score: 0.0651)\n",
      "22:27 madminer.utils.ml.sc INFO                val. loss  0.1415 (mse_score: 0.1415)\n",
      "22:27 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0645 (mse_score: 0.0645)\n",
      "22:27 madminer.utils.ml.sc INFO                val. loss  0.1407 (mse_score: 0.1407) (*)\n",
      "22:28 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0634 (mse_score: 0.0634)\n",
      "22:28 madminer.utils.ml.sc INFO                val. loss  0.1408 (mse_score: 0.1408)\n",
      "22:28 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0630 (mse_score: 0.0630)\n",
      "22:28 madminer.utils.ml.sc INFO                val. loss  0.1412 (mse_score: 0.1412)\n",
      "22:28 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0622 (mse_score: 0.0622)\n",
      "22:28 madminer.utils.ml.sc INFO                val. loss  0.1402 (mse_score: 0.1402) (*)\n",
      "22:29 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0615 (mse_score: 0.0615)\n",
      "22:29 madminer.utils.ml.sc INFO                val. loss  0.1405 (mse_score: 0.1405)\n",
      "22:29 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0609 (mse_score: 0.0609)\n",
      "22:29 madminer.utils.ml.sc INFO                val. loss  0.1413 (mse_score: 0.1413)\n",
      "22:29 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0603 (mse_score: 0.0603)\n",
      "22:29 madminer.utils.ml.sc INFO                val. loss  0.1400 (mse_score: 0.1400) (*)\n",
      "22:30 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0598 (mse_score: 0.0598)\n",
      "22:30 madminer.utils.ml.sc INFO                val. loss  0.1426 (mse_score: 0.1426)\n",
      "22:30 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0593 (mse_score: 0.0593)\n",
      "22:30 madminer.utils.ml.sc INFO                val. loss  0.1409 (mse_score: 0.1409)\n",
      "22:30 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0587 (mse_score: 0.0587)\n",
      "22:30 madminer.utils.ml.sc INFO                val. loss  0.1402 (mse_score: 0.1402)\n",
      "22:31 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0582 (mse_score: 0.0582)\n",
      "22:31 madminer.utils.ml.sc INFO                val. loss  0.1395 (mse_score: 0.1395) (*)\n",
      "22:31 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0578 (mse_score: 0.0578)\n",
      "22:31 madminer.utils.ml.sc INFO                val. loss  0.1399 (mse_score: 0.1399)\n",
      "22:31 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0574 (mse_score: 0.0574)\n",
      "22:31 madminer.utils.ml.sc INFO                val. loss  0.1403 (mse_score: 0.1403)\n",
      "22:31 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0569 (mse_score: 0.0569)\n",
      "22:31 madminer.utils.ml.sc INFO                val. loss  0.1399 (mse_score: 0.1399)\n",
      "22:32 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0566 (mse_score: 0.0566)\n",
      "22:32 madminer.utils.ml.sc INFO                val. loss  0.1400 (mse_score: 0.1400)\n",
      "22:32 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0561 (mse_score: 0.0561)\n",
      "22:32 madminer.utils.ml.sc INFO                val. loss  0.1397 (mse_score: 0.1397)\n",
      "22:32 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0557 (mse_score: 0.0557)\n",
      "22:32 madminer.utils.ml.sc INFO                val. loss  0.1394 (mse_score: 0.1394) (*)\n",
      "22:33 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0554 (mse_score: 0.0554)\n",
      "22:33 madminer.utils.ml.sc INFO                val. loss  0.1399 (mse_score: 0.1399)\n",
      "22:33 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0550 (mse_score: 0.0550)\n",
      "22:33 madminer.utils.ml.sc INFO                val. loss  0.1393 (mse_score: 0.1393) (*)\n",
      "22:33 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0547 (mse_score: 0.0547)\n",
      "22:33 madminer.utils.ml.sc INFO                val. loss  0.1393 (mse_score: 0.1393) (*)\n",
      "22:34 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0544 (mse_score: 0.0544)\n",
      "22:34 madminer.utils.ml.sc INFO                val. loss  0.1396 (mse_score: 0.1396)\n",
      "22:34 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0541 (mse_score: 0.0541)\n",
      "22:34 madminer.utils.ml.sc INFO                val. loss  0.1402 (mse_score: 0.1402)\n",
      "22:34 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0538 (mse_score: 0.0538)\n",
      "22:34 madminer.utils.ml.sc INFO                val. loss  0.1398 (mse_score: 0.1398)\n",
      "22:35 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0535 (mse_score: 0.0535)\n",
      "22:35 madminer.utils.ml.sc INFO                val. loss  0.1397 (mse_score: 0.1397)\n",
      "22:35 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0533 (mse_score: 0.0533)\n",
      "22:35 madminer.utils.ml.sc INFO                val. loss  0.1391 (mse_score: 0.1391) (*)\n",
      "22:35 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0531 (mse_score: 0.0531)\n",
      "22:35 madminer.utils.ml.sc INFO                val. loss  0.1389 (mse_score: 0.1389) (*)\n",
      "22:36 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0528 (mse_score: 0.0528)\n",
      "22:36 madminer.utils.ml.sc INFO                val. loss  0.1399 (mse_score: 0.1399)\n",
      "22:36 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0527 (mse_score: 0.0527)\n",
      "22:36 madminer.utils.ml.sc INFO                val. loss  0.1399 (mse_score: 0.1399)\n",
      "22:36 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0524 (mse_score: 0.0524)\n",
      "22:36 madminer.utils.ml.sc INFO                val. loss  0.1392 (mse_score: 0.1392)\n",
      "22:37 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0523 (mse_score: 0.0523)\n",
      "22:37 madminer.utils.ml.sc INFO                val. loss  0.1393 (mse_score: 0.1393)\n",
      "22:37 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0521 (mse_score: 0.0521)\n",
      "22:37 madminer.utils.ml.sc INFO                val. loss  0.1396 (mse_score: 0.1396)\n",
      "22:37 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0519 (mse_score: 0.0519)\n",
      "22:37 madminer.utils.ml.sc INFO                val. loss  0.1391 (mse_score: 0.1391)\n",
      "22:37 madminer.utils.ml.sc INFO    Early stopping after epoch 44, with loss 0.14 compared to final loss 0.14\n",
      "22:37 madminer.utils.ml.sc INFO    Finished training\n",
      "22:37 madminer.ml          INFO    Training estimator 7 / 10 in ensemble\n",
      "22:37 madminer.ml          INFO    Starting training\n",
      "22:37 madminer.ml          INFO      Method:                 sally\n",
      "22:37 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_6.npy\n",
      "22:37 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_6.npy\n",
      "22:37 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "22:37 madminer.ml          INFO      Method:                 sally\n",
      "22:37 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "22:37 madminer.ml          INFO      Activation function:    tanh\n",
      "22:37 madminer.ml          INFO      Batch size:             128\n",
      "22:37 madminer.ml          INFO      Trainer:                amsgrad\n",
      "22:37 madminer.ml          INFO      Epochs:                 50\n",
      "22:37 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:37 madminer.ml          INFO      Validation split:       0.5\n",
      "22:37 madminer.ml          INFO      Early stopping:         True\n",
      "22:37 madminer.ml          INFO      Scale inputs:           True\n",
      "22:37 madminer.ml          INFO      Shuffle labels          False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:37 madminer.ml          INFO      Regularization:         None\n",
      "22:37 madminer.ml          INFO      Samples:                all\n",
      "22:37 madminer.ml          INFO    Loading training data\n",
      "22:37 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "22:37 madminer.ml          INFO    Rescaling inputs\n",
      "22:37 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "22:37 madminer.ml          INFO    Creating model for method sally\n",
      "22:37 madminer.ml          INFO    Training model\n",
      "22:38 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1176 (mse_score: 0.1176)\n",
      "22:38 madminer.utils.ml.sc INFO                val. loss  0.1255 (mse_score: 0.1255) (*)\n",
      "22:38 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1135 (mse_score: 0.1135)\n",
      "22:38 madminer.utils.ml.sc INFO                val. loss  0.1283 (mse_score: 0.1283)\n",
      "22:38 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1112 (mse_score: 0.1112)\n",
      "22:38 madminer.utils.ml.sc INFO                val. loss  0.1205 (mse_score: 0.1205) (*)\n",
      "22:39 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1082 (mse_score: 0.1082)\n",
      "22:39 madminer.utils.ml.sc INFO                val. loss  0.1210 (mse_score: 0.1210)\n",
      "22:39 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1073 (mse_score: 0.1073)\n",
      "22:39 madminer.utils.ml.sc INFO                val. loss  0.1186 (mse_score: 0.1186) (*)\n",
      "22:39 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1068 (mse_score: 0.1068)\n",
      "22:39 madminer.utils.ml.sc INFO                val. loss  0.1211 (mse_score: 0.1211)\n",
      "22:40 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.1042 (mse_score: 0.1042)\n",
      "22:40 madminer.utils.ml.sc INFO                val. loss  0.1169 (mse_score: 0.1169) (*)\n",
      "22:40 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.1023 (mse_score: 0.1023)\n",
      "22:40 madminer.utils.ml.sc INFO                val. loss  0.1160 (mse_score: 0.1160) (*)\n",
      "22:40 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.1007 (mse_score: 0.1007)\n",
      "22:40 madminer.utils.ml.sc INFO                val. loss  0.1159 (mse_score: 0.1159) (*)\n",
      "22:41 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0993 (mse_score: 0.0993)\n",
      "22:41 madminer.utils.ml.sc INFO                val. loss  0.1182 (mse_score: 0.1182)\n",
      "22:41 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0978 (mse_score: 0.0978)\n",
      "22:41 madminer.utils.ml.sc INFO                val. loss  0.1184 (mse_score: 0.1184)\n",
      "22:41 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0968 (mse_score: 0.0968)\n",
      "22:41 madminer.utils.ml.sc INFO                val. loss  0.1146 (mse_score: 0.1146) (*)\n",
      "22:42 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0958 (mse_score: 0.0958)\n",
      "22:42 madminer.utils.ml.sc INFO                val. loss  0.1157 (mse_score: 0.1157)\n",
      "22:42 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0944 (mse_score: 0.0944)\n",
      "22:42 madminer.utils.ml.sc INFO                val. loss  0.1149 (mse_score: 0.1149)\n",
      "22:42 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0930 (mse_score: 0.0930)\n",
      "22:42 madminer.utils.ml.sc INFO                val. loss  0.1146 (mse_score: 0.1146) (*)\n",
      "22:42 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0919 (mse_score: 0.0919)\n",
      "22:42 madminer.utils.ml.sc INFO                val. loss  0.1152 (mse_score: 0.1152)\n",
      "22:43 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0913 (mse_score: 0.0913)\n",
      "22:43 madminer.utils.ml.sc INFO                val. loss  0.1169 (mse_score: 0.1169)\n",
      "22:43 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0905 (mse_score: 0.0905)\n",
      "22:43 madminer.utils.ml.sc INFO                val. loss  0.1153 (mse_score: 0.1153)\n",
      "22:43 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0894 (mse_score: 0.0894)\n",
      "22:43 madminer.utils.ml.sc INFO                val. loss  0.1155 (mse_score: 0.1155)\n",
      "22:44 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0887 (mse_score: 0.0887)\n",
      "22:44 madminer.utils.ml.sc INFO                val. loss  0.1157 (mse_score: 0.1157)\n",
      "22:44 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0877 (mse_score: 0.0877)\n",
      "22:44 madminer.utils.ml.sc INFO                val. loss  0.1141 (mse_score: 0.1141) (*)\n",
      "22:44 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0872 (mse_score: 0.0872)\n",
      "22:44 madminer.utils.ml.sc INFO                val. loss  0.1155 (mse_score: 0.1155)\n",
      "23:17 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0862 (mse_score: 0.0862)\n",
      "23:17 madminer.utils.ml.sc INFO                val. loss  0.1140 (mse_score: 0.1140) (*)\n",
      "23:17 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0855 (mse_score: 0.0855)\n",
      "23:17 madminer.utils.ml.sc INFO                val. loss  0.1148 (mse_score: 0.1148)\n",
      "23:17 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0850 (mse_score: 0.0850)\n",
      "23:17 madminer.utils.ml.sc INFO                val. loss  0.1149 (mse_score: 0.1149)\n",
      "23:48 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0843 (mse_score: 0.0843)\n",
      "23:48 madminer.utils.ml.sc INFO                val. loss  0.1155 (mse_score: 0.1155)\n",
      "23:48 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0836 (mse_score: 0.0836)\n",
      "23:48 madminer.utils.ml.sc INFO                val. loss  0.1154 (mse_score: 0.1154)\n",
      "23:49 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0830 (mse_score: 0.0830)\n",
      "23:49 madminer.utils.ml.sc INFO                val. loss  0.1145 (mse_score: 0.1145)\n",
      "00:25 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0823 (mse_score: 0.0823)\n",
      "00:25 madminer.utils.ml.sc INFO                val. loss  0.1152 (mse_score: 0.1152)\n",
      "00:25 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0818 (mse_score: 0.0818)\n",
      "00:25 madminer.utils.ml.sc INFO                val. loss  0.1149 (mse_score: 0.1149)\n",
      "00:26 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0814 (mse_score: 0.0814)\n",
      "00:26 madminer.utils.ml.sc INFO                val. loss  0.1152 (mse_score: 0.1152)\n",
      "00:57 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0807 (mse_score: 0.0807)\n",
      "00:57 madminer.utils.ml.sc INFO                val. loss  0.1136 (mse_score: 0.1136) (*)\n",
      "00:58 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0802 (mse_score: 0.0802)\n",
      "00:58 madminer.utils.ml.sc INFO                val. loss  0.1146 (mse_score: 0.1146)\n",
      "01:33 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0799 (mse_score: 0.0799)\n",
      "01:33 madminer.utils.ml.sc INFO                val. loss  0.1147 (mse_score: 0.1147)\n",
      "01:33 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0794 (mse_score: 0.0794)\n",
      "01:33 madminer.utils.ml.sc INFO                val. loss  0.1155 (mse_score: 0.1155)\n",
      "01:34 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0789 (mse_score: 0.0789)\n",
      "01:34 madminer.utils.ml.sc INFO                val. loss  0.1153 (mse_score: 0.1153)\n",
      "02:12 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0786 (mse_score: 0.0786)\n",
      "02:12 madminer.utils.ml.sc INFO                val. loss  0.1162 (mse_score: 0.1162)\n",
      "02:13 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0781 (mse_score: 0.0781)\n",
      "02:13 madminer.utils.ml.sc INFO                val. loss  0.1147 (mse_score: 0.1147)\n",
      "02:13 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0777 (mse_score: 0.0777)\n",
      "02:13 madminer.utils.ml.sc INFO                val. loss  0.1143 (mse_score: 0.1143)\n",
      "02:47 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0774 (mse_score: 0.0774)\n",
      "02:47 madminer.utils.ml.sc INFO                val. loss  0.1158 (mse_score: 0.1158)\n",
      "02:48 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0770 (mse_score: 0.0770)\n",
      "02:48 madminer.utils.ml.sc INFO                val. loss  0.1151 (mse_score: 0.1151)\n",
      "03:23 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0767 (mse_score: 0.0767)\n",
      "03:23 madminer.utils.ml.sc INFO                val. loss  0.1156 (mse_score: 0.1156)\n",
      "03:24 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0764 (mse_score: 0.0764)\n",
      "03:24 madminer.utils.ml.sc INFO                val. loss  0.1152 (mse_score: 0.1152)\n",
      "03:24 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0761 (mse_score: 0.0761)\n",
      "03:24 madminer.utils.ml.sc INFO                val. loss  0.1157 (mse_score: 0.1157)\n",
      "03:24 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0758 (mse_score: 0.0758)\n",
      "03:24 madminer.utils.ml.sc INFO                val. loss  0.1156 (mse_score: 0.1156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:25 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0755 (mse_score: 0.0755)\n",
      "03:25 madminer.utils.ml.sc INFO                val. loss  0.1156 (mse_score: 0.1156)\n",
      "03:56 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0752 (mse_score: 0.0752)\n",
      "03:56 madminer.utils.ml.sc INFO                val. loss  0.1163 (mse_score: 0.1163)\n",
      "03:56 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0750 (mse_score: 0.0750)\n",
      "03:56 madminer.utils.ml.sc INFO                val. loss  0.1153 (mse_score: 0.1153)\n",
      "04:29 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0747 (mse_score: 0.0747)\n",
      "04:29 madminer.utils.ml.sc INFO                val. loss  0.1158 (mse_score: 0.1158)\n",
      "04:30 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0746 (mse_score: 0.0746)\n",
      "04:30 madminer.utils.ml.sc INFO                val. loss  0.1161 (mse_score: 0.1161)\n",
      "04:30 madminer.utils.ml.sc INFO    Early stopping after epoch 32, with loss 0.11 compared to final loss 0.12\n",
      "04:30 madminer.utils.ml.sc INFO    Finished training\n",
      "04:30 madminer.ml          INFO    Training estimator 8 / 10 in ensemble\n",
      "04:30 madminer.ml          INFO    Starting training\n",
      "04:30 madminer.ml          INFO      Method:                 sally\n",
      "04:30 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_7.npy\n",
      "04:30 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_7.npy\n",
      "04:30 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "04:30 madminer.ml          INFO      Method:                 sally\n",
      "04:30 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "04:30 madminer.ml          INFO      Activation function:    tanh\n",
      "04:30 madminer.ml          INFO      Batch size:             128\n",
      "04:30 madminer.ml          INFO      Trainer:                amsgrad\n",
      "04:30 madminer.ml          INFO      Epochs:                 50\n",
      "04:30 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "04:30 madminer.ml          INFO      Validation split:       0.5\n",
      "04:30 madminer.ml          INFO      Early stopping:         True\n",
      "04:30 madminer.ml          INFO      Scale inputs:           True\n",
      "04:30 madminer.ml          INFO      Shuffle labels          False\n",
      "04:30 madminer.ml          INFO      Regularization:         None\n",
      "04:30 madminer.ml          INFO      Samples:                all\n",
      "04:30 madminer.ml          INFO    Loading training data\n",
      "04:30 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "04:30 madminer.ml          INFO    Rescaling inputs\n",
      "04:30 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "04:30 madminer.ml          INFO    Creating model for method sally\n",
      "04:30 madminer.ml          INFO    Training model\n",
      "04:30 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0869 (mse_score: 0.0869)\n",
      "04:30 madminer.utils.ml.sc INFO                val. loss  0.0812 (mse_score: 0.0812) (*)\n",
      "05:06 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0823 (mse_score: 0.0823)\n",
      "05:06 madminer.utils.ml.sc INFO                val. loss  0.0784 (mse_score: 0.0784) (*)\n",
      "05:07 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0795 (mse_score: 0.0795)\n",
      "05:07 madminer.utils.ml.sc INFO                val. loss  0.0766 (mse_score: 0.0766) (*)\n",
      "05:41 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0779 (mse_score: 0.0779)\n",
      "05:41 madminer.utils.ml.sc INFO                val. loss  0.0757 (mse_score: 0.0757) (*)\n",
      "05:41 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0769 (mse_score: 0.0769)\n",
      "05:41 madminer.utils.ml.sc INFO                val. loss  0.0747 (mse_score: 0.0747) (*)\n",
      "05:42 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0751 (mse_score: 0.0751)\n",
      "05:42 madminer.utils.ml.sc INFO                val. loss  0.0744 (mse_score: 0.0744) (*)\n",
      "05:42 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0730 (mse_score: 0.0730)\n",
      "05:42 madminer.utils.ml.sc INFO                val. loss  0.0769 (mse_score: 0.0769)\n",
      "05:42 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0724 (mse_score: 0.0724)\n",
      "05:42 madminer.utils.ml.sc INFO                val. loss  0.0724 (mse_score: 0.0724) (*)\n",
      "06:16 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0718 (mse_score: 0.0718)\n",
      "06:16 madminer.utils.ml.sc INFO                val. loss  0.0727 (mse_score: 0.0727)\n",
      "06:17 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0698 (mse_score: 0.0698)\n",
      "06:17 madminer.utils.ml.sc INFO                val. loss  0.0724 (mse_score: 0.0724)\n",
      "06:57 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0694 (mse_score: 0.0694)\n",
      "06:57 madminer.utils.ml.sc INFO                val. loss  0.0720 (mse_score: 0.0720) (*)\n",
      "06:57 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0684 (mse_score: 0.0684)\n",
      "06:57 madminer.utils.ml.sc INFO                val. loss  0.0717 (mse_score: 0.0717) (*)\n",
      "06:58 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0672 (mse_score: 0.0672)\n",
      "06:58 madminer.utils.ml.sc INFO                val. loss  0.0725 (mse_score: 0.0725)\n",
      "06:58 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0663 (mse_score: 0.0663)\n",
      "06:58 madminer.utils.ml.sc INFO                val. loss  0.0721 (mse_score: 0.0721)\n",
      "06:58 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0664 (mse_score: 0.0664)\n",
      "06:58 madminer.utils.ml.sc INFO                val. loss  0.0720 (mse_score: 0.0720)\n",
      "07:31 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0653 (mse_score: 0.0653)\n",
      "07:31 madminer.utils.ml.sc INFO                val. loss  0.0713 (mse_score: 0.0713) (*)\n",
      "07:32 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0644 (mse_score: 0.0644)\n",
      "07:32 madminer.utils.ml.sc INFO                val. loss  0.0727 (mse_score: 0.0727)\n",
      "08:03 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0634 (mse_score: 0.0634)\n",
      "08:03 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710) (*)\n",
      "08:03 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0626 (mse_score: 0.0626)\n",
      "08:03 madminer.utils.ml.sc INFO                val. loss  0.0713 (mse_score: 0.0713)\n",
      "08:16 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0617 (mse_score: 0.0617)\n",
      "08:16 madminer.utils.ml.sc INFO                val. loss  0.0712 (mse_score: 0.0712)\n",
      "08:43 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0612 (mse_score: 0.0612)\n",
      "08:43 madminer.utils.ml.sc INFO                val. loss  0.0712 (mse_score: 0.0712)\n",
      "08:44 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0607 (mse_score: 0.0607)\n",
      "08:44 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706) (*)\n",
      "08:44 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0597 (mse_score: 0.0597)\n",
      "08:44 madminer.utils.ml.sc INFO                val. loss  0.0705 (mse_score: 0.0705) (*)\n",
      "08:44 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0592 (mse_score: 0.0592)\n",
      "08:44 madminer.utils.ml.sc INFO                val. loss  0.0711 (mse_score: 0.0711)\n",
      "08:45 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0586 (mse_score: 0.0586)\n",
      "08:45 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706)\n",
      "08:45 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0581 (mse_score: 0.0581)\n",
      "08:45 madminer.utils.ml.sc INFO                val. loss  0.0711 (mse_score: 0.0711)\n",
      "08:45 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0575 (mse_score: 0.0575)\n",
      "08:45 madminer.utils.ml.sc INFO                val. loss  0.0703 (mse_score: 0.0703) (*)\n",
      "08:45 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0570 (mse_score: 0.0570)\n",
      "08:45 madminer.utils.ml.sc INFO                val. loss  0.0705 (mse_score: 0.0705)\n",
      "08:46 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0565 (mse_score: 0.0565)\n",
      "08:46 madminer.utils.ml.sc INFO                val. loss  0.0709 (mse_score: 0.0709)\n",
      "08:46 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0561 (mse_score: 0.0561)\n",
      "08:46 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "08:46 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0557 (mse_score: 0.0557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:46 madminer.utils.ml.sc INFO                val. loss  0.0706 (mse_score: 0.0706)\n",
      "08:47 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0552 (mse_score: 0.0552)\n",
      "08:47 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "08:47 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0548 (mse_score: 0.0548)\n",
      "08:47 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "08:47 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0545 (mse_score: 0.0545)\n",
      "08:47 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "08:48 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0541 (mse_score: 0.0541)\n",
      "08:48 madminer.utils.ml.sc INFO                val. loss  0.0709 (mse_score: 0.0709)\n",
      "08:48 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0537 (mse_score: 0.0537)\n",
      "08:48 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "08:48 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0534 (mse_score: 0.0534)\n",
      "08:48 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "08:49 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0531 (mse_score: 0.0531)\n",
      "08:49 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "08:49 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0529 (mse_score: 0.0529)\n",
      "08:49 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "08:49 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0525 (mse_score: 0.0525)\n",
      "08:49 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "08:50 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0522 (mse_score: 0.0522)\n",
      "08:50 madminer.utils.ml.sc INFO                val. loss  0.0709 (mse_score: 0.0709)\n",
      "08:50 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0520 (mse_score: 0.0520)\n",
      "08:50 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "08:50 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0518 (mse_score: 0.0518)\n",
      "08:50 madminer.utils.ml.sc INFO                val. loss  0.0711 (mse_score: 0.0711)\n",
      "08:51 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0514 (mse_score: 0.0514)\n",
      "08:51 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "08:51 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0513 (mse_score: 0.0513)\n",
      "08:51 madminer.utils.ml.sc INFO                val. loss  0.0707 (mse_score: 0.0707)\n",
      "08:51 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0511 (mse_score: 0.0511)\n",
      "08:51 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "08:52 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0509 (mse_score: 0.0509)\n",
      "08:52 madminer.utils.ml.sc INFO                val. loss  0.0709 (mse_score: 0.0709)\n",
      "08:52 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0507 (mse_score: 0.0507)\n",
      "08:52 madminer.utils.ml.sc INFO                val. loss  0.0712 (mse_score: 0.0712)\n",
      "08:52 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0505 (mse_score: 0.0505)\n",
      "08:52 madminer.utils.ml.sc INFO                val. loss  0.0708 (mse_score: 0.0708)\n",
      "08:52 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0504 (mse_score: 0.0504)\n",
      "08:52 madminer.utils.ml.sc INFO                val. loss  0.0710 (mse_score: 0.0710)\n",
      "08:52 madminer.utils.ml.sc INFO    Early stopping after epoch 27, with loss 0.07 compared to final loss 0.07\n",
      "08:52 madminer.utils.ml.sc INFO    Finished training\n",
      "08:52 madminer.ml          INFO    Training estimator 9 / 10 in ensemble\n",
      "08:52 madminer.ml          INFO    Starting training\n",
      "08:52 madminer.ml          INFO      Method:                 sally\n",
      "08:52 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_8.npy\n",
      "08:52 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_8.npy\n",
      "08:52 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "08:52 madminer.ml          INFO      Method:                 sally\n",
      "08:52 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "08:52 madminer.ml          INFO      Activation function:    tanh\n",
      "08:52 madminer.ml          INFO      Batch size:             128\n",
      "08:52 madminer.ml          INFO      Trainer:                amsgrad\n",
      "08:52 madminer.ml          INFO      Epochs:                 50\n",
      "08:52 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "08:52 madminer.ml          INFO      Validation split:       0.5\n",
      "08:52 madminer.ml          INFO      Early stopping:         True\n",
      "08:52 madminer.ml          INFO      Scale inputs:           True\n",
      "08:52 madminer.ml          INFO      Shuffle labels          False\n",
      "08:52 madminer.ml          INFO      Regularization:         None\n",
      "08:52 madminer.ml          INFO      Samples:                all\n",
      "08:52 madminer.ml          INFO    Loading training data\n",
      "08:52 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "08:52 madminer.ml          INFO    Rescaling inputs\n",
      "08:53 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "08:53 madminer.ml          INFO    Creating model for method sally\n",
      "08:53 madminer.ml          INFO    Training model\n",
      "08:53 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.1128 (mse_score: 0.1128)\n",
      "08:53 madminer.utils.ml.sc INFO                val. loss  0.1063 (mse_score: 0.1063) (*)\n",
      "08:53 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.1097 (mse_score: 0.1097)\n",
      "08:53 madminer.utils.ml.sc INFO                val. loss  0.0996 (mse_score: 0.0996) (*)\n",
      "08:53 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.1063 (mse_score: 0.1063)\n",
      "08:53 madminer.utils.ml.sc INFO                val. loss  0.0979 (mse_score: 0.0979) (*)\n",
      "08:54 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.1053 (mse_score: 0.1053)\n",
      "08:54 madminer.utils.ml.sc INFO                val. loss  0.0965 (mse_score: 0.0965) (*)\n",
      "08:54 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.1035 (mse_score: 0.1035)\n",
      "08:54 madminer.utils.ml.sc INFO                val. loss  0.0953 (mse_score: 0.0953) (*)\n",
      "08:54 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.1015 (mse_score: 0.1015)\n",
      "08:54 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932) (*)\n",
      "08:55 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0998 (mse_score: 0.0998)\n",
      "08:55 madminer.utils.ml.sc INFO                val. loss  0.0969 (mse_score: 0.0969)\n",
      "08:55 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0987 (mse_score: 0.0987)\n",
      "08:55 madminer.utils.ml.sc INFO                val. loss  0.0924 (mse_score: 0.0924) (*)\n",
      "08:55 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0967 (mse_score: 0.0967)\n",
      "08:55 madminer.utils.ml.sc INFO                val. loss  0.0928 (mse_score: 0.0928)\n",
      "08:56 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0970 (mse_score: 0.0970)\n",
      "08:56 madminer.utils.ml.sc INFO                val. loss  0.0928 (mse_score: 0.0928)\n",
      "08:56 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0946 (mse_score: 0.0946)\n",
      "08:56 madminer.utils.ml.sc INFO                val. loss  0.0922 (mse_score: 0.0922) (*)\n",
      "08:56 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0934 (mse_score: 0.0934)\n",
      "08:56 madminer.utils.ml.sc INFO                val. loss  0.0909 (mse_score: 0.0909) (*)\n",
      "08:57 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0917 (mse_score: 0.0917)\n",
      "08:57 madminer.utils.ml.sc INFO                val. loss  0.0910 (mse_score: 0.0910)\n",
      "08:57 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0912 (mse_score: 0.0912)\n",
      "08:57 madminer.utils.ml.sc INFO                val. loss  0.0955 (mse_score: 0.0955)\n",
      "08:57 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0900 (mse_score: 0.0900)\n",
      "08:57 madminer.utils.ml.sc INFO                val. loss  0.0909 (mse_score: 0.0909)\n",
      "08:58 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0886 (mse_score: 0.0886)\n",
      "08:58 madminer.utils.ml.sc INFO                val. loss  0.0905 (mse_score: 0.0905) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:58 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0879 (mse_score: 0.0879)\n",
      "08:58 madminer.utils.ml.sc INFO                val. loss  0.0907 (mse_score: 0.0907)\n",
      "08:58 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0867 (mse_score: 0.0867)\n",
      "08:58 madminer.utils.ml.sc INFO                val. loss  0.0911 (mse_score: 0.0911)\n",
      "08:59 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0855 (mse_score: 0.0855)\n",
      "08:59 madminer.utils.ml.sc INFO                val. loss  0.0929 (mse_score: 0.0929)\n",
      "08:59 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0841 (mse_score: 0.0841)\n",
      "08:59 madminer.utils.ml.sc INFO                val. loss  0.0909 (mse_score: 0.0909)\n",
      "08:59 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0835 (mse_score: 0.0835)\n",
      "08:59 madminer.utils.ml.sc INFO                val. loss  0.0915 (mse_score: 0.0915)\n",
      "09:00 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0830 (mse_score: 0.0830)\n",
      "09:00 madminer.utils.ml.sc INFO                val. loss  0.0914 (mse_score: 0.0914)\n",
      "09:00 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0817 (mse_score: 0.0817)\n",
      "09:00 madminer.utils.ml.sc INFO                val. loss  0.0912 (mse_score: 0.0912)\n",
      "09:00 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0815 (mse_score: 0.0815)\n",
      "09:00 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "09:00 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0804 (mse_score: 0.0804)\n",
      "09:00 madminer.utils.ml.sc INFO                val. loss  0.0918 (mse_score: 0.0918)\n",
      "09:01 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0797 (mse_score: 0.0797)\n",
      "09:01 madminer.utils.ml.sc INFO                val. loss  0.0922 (mse_score: 0.0922)\n",
      "09:01 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0793 (mse_score: 0.0793)\n",
      "09:01 madminer.utils.ml.sc INFO                val. loss  0.0918 (mse_score: 0.0918)\n",
      "09:01 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0787 (mse_score: 0.0787)\n",
      "09:01 madminer.utils.ml.sc INFO                val. loss  0.0921 (mse_score: 0.0921)\n",
      "09:02 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0779 (mse_score: 0.0779)\n",
      "09:02 madminer.utils.ml.sc INFO                val. loss  0.0912 (mse_score: 0.0912)\n",
      "09:02 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0770 (mse_score: 0.0770)\n",
      "09:02 madminer.utils.ml.sc INFO                val. loss  0.0926 (mse_score: 0.0926)\n",
      "09:03 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0767 (mse_score: 0.0767)\n",
      "09:03 madminer.utils.ml.sc INFO                val. loss  0.0914 (mse_score: 0.0914)\n",
      "09:03 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0760 (mse_score: 0.0760)\n",
      "09:03 madminer.utils.ml.sc INFO                val. loss  0.0921 (mse_score: 0.0921)\n",
      "09:03 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0754 (mse_score: 0.0754)\n",
      "09:03 madminer.utils.ml.sc INFO                val. loss  0.0911 (mse_score: 0.0911)\n",
      "09:03 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0748 (mse_score: 0.0748)\n",
      "09:03 madminer.utils.ml.sc INFO                val. loss  0.0922 (mse_score: 0.0922)\n",
      "09:04 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0746 (mse_score: 0.0746)\n",
      "09:04 madminer.utils.ml.sc INFO                val. loss  0.0913 (mse_score: 0.0913)\n",
      "09:04 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0740 (mse_score: 0.0740)\n",
      "09:04 madminer.utils.ml.sc INFO                val. loss  0.0915 (mse_score: 0.0915)\n",
      "09:04 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0734 (mse_score: 0.0734)\n",
      "09:04 madminer.utils.ml.sc INFO                val. loss  0.0913 (mse_score: 0.0913)\n",
      "09:05 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0731 (mse_score: 0.0731)\n",
      "09:05 madminer.utils.ml.sc INFO                val. loss  0.0916 (mse_score: 0.0916)\n",
      "09:05 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0725 (mse_score: 0.0725)\n",
      "09:05 madminer.utils.ml.sc INFO                val. loss  0.0914 (mse_score: 0.0914)\n",
      "09:05 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0722 (mse_score: 0.0722)\n",
      "09:05 madminer.utils.ml.sc INFO                val. loss  0.0916 (mse_score: 0.0916)\n",
      "09:06 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0720 (mse_score: 0.0720)\n",
      "09:06 madminer.utils.ml.sc INFO                val. loss  0.0919 (mse_score: 0.0919)\n",
      "09:06 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0715 (mse_score: 0.0715)\n",
      "09:06 madminer.utils.ml.sc INFO                val. loss  0.0917 (mse_score: 0.0917)\n",
      "09:06 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0712 (mse_score: 0.0712)\n",
      "09:06 madminer.utils.ml.sc INFO                val. loss  0.0919 (mse_score: 0.0919)\n",
      "09:07 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0707 (mse_score: 0.0707)\n",
      "09:07 madminer.utils.ml.sc INFO                val. loss  0.0927 (mse_score: 0.0927)\n",
      "09:08 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0704 (mse_score: 0.0704)\n",
      "09:08 madminer.utils.ml.sc INFO                val. loss  0.0923 (mse_score: 0.0923)\n",
      "09:08 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0702 (mse_score: 0.0702)\n",
      "09:08 madminer.utils.ml.sc INFO                val. loss  0.0924 (mse_score: 0.0924)\n",
      "09:09 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0699 (mse_score: 0.0699)\n",
      "09:09 madminer.utils.ml.sc INFO                val. loss  0.0917 (mse_score: 0.0917)\n",
      "09:10 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0696 (mse_score: 0.0696)\n",
      "09:10 madminer.utils.ml.sc INFO                val. loss  0.0918 (mse_score: 0.0918)\n",
      "09:11 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0694 (mse_score: 0.0694)\n",
      "09:11 madminer.utils.ml.sc INFO                val. loss  0.0924 (mse_score: 0.0924)\n",
      "09:11 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0691 (mse_score: 0.0691)\n",
      "09:11 madminer.utils.ml.sc INFO                val. loss  0.0920 (mse_score: 0.0920)\n",
      "09:11 madminer.utils.ml.sc INFO    Early stopping after epoch 16, with loss 0.09 compared to final loss 0.09\n",
      "09:11 madminer.utils.ml.sc INFO    Finished training\n",
      "09:11 madminer.ml          INFO    Training estimator 10 / 10 in ensemble\n",
      "09:11 madminer.ml          INFO    Starting training\n",
      "09:11 madminer.ml          INFO      Method:                 sally\n",
      "09:11 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/x_train_9.npy\n",
      "09:11 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local/t_xz_train_9.npy\n",
      "09:11 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "09:11 madminer.ml          INFO      Method:                 sally\n",
      "09:11 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "09:11 madminer.ml          INFO      Activation function:    tanh\n",
      "09:11 madminer.ml          INFO      Batch size:             128\n",
      "09:11 madminer.ml          INFO      Trainer:                amsgrad\n",
      "09:11 madminer.ml          INFO      Epochs:                 50\n",
      "09:11 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "09:11 madminer.ml          INFO      Validation split:       0.5\n",
      "09:11 madminer.ml          INFO      Early stopping:         True\n",
      "09:11 madminer.ml          INFO      Scale inputs:           True\n",
      "09:11 madminer.ml          INFO      Shuffle labels          False\n",
      "09:11 madminer.ml          INFO      Regularization:         None\n",
      "09:11 madminer.ml          INFO      Samples:                all\n",
      "09:11 madminer.ml          INFO    Loading training data\n",
      "09:11 madminer.ml          INFO    Found 1000000 samples with 57 parameters and 33 observables\n",
      "09:11 madminer.ml          INFO    Rescaling inputs\n",
      "09:11 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "09:11 madminer.ml          INFO    Creating model for method sally\n",
      "09:11 madminer.ml          INFO    Training model\n",
      "09:12 madminer.utils.ml.sc INFO      Epoch 01: train loss 0.0929 (mse_score: 0.0929)\n",
      "09:12 madminer.utils.ml.sc INFO                val. loss  0.1070 (mse_score: 0.1070) (*)\n",
      "09:13 madminer.utils.ml.sc INFO      Epoch 02: train loss 0.0889 (mse_score: 0.0889)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:13 madminer.utils.ml.sc INFO                val. loss  0.1047 (mse_score: 0.1047) (*)\n",
      "09:13 madminer.utils.ml.sc INFO      Epoch 03: train loss 0.0869 (mse_score: 0.0869)\n",
      "09:13 madminer.utils.ml.sc INFO                val. loss  0.1019 (mse_score: 0.1019) (*)\n",
      "09:14 madminer.utils.ml.sc INFO      Epoch 04: train loss 0.0836 (mse_score: 0.0836)\n",
      "09:14 madminer.utils.ml.sc INFO                val. loss  0.0999 (mse_score: 0.0999) (*)\n",
      "09:15 madminer.utils.ml.sc INFO      Epoch 05: train loss 0.0825 (mse_score: 0.0825)\n",
      "09:15 madminer.utils.ml.sc INFO                val. loss  0.1026 (mse_score: 0.1026)\n",
      "09:15 madminer.utils.ml.sc INFO      Epoch 06: train loss 0.0805 (mse_score: 0.0805)\n",
      "09:15 madminer.utils.ml.sc INFO                val. loss  0.0982 (mse_score: 0.0982) (*)\n",
      "09:16 madminer.utils.ml.sc INFO      Epoch 07: train loss 0.0800 (mse_score: 0.0800)\n",
      "09:16 madminer.utils.ml.sc INFO                val. loss  0.0991 (mse_score: 0.0991)\n",
      "09:17 madminer.utils.ml.sc INFO      Epoch 08: train loss 0.0781 (mse_score: 0.0781)\n",
      "09:17 madminer.utils.ml.sc INFO                val. loss  0.1007 (mse_score: 0.1007)\n",
      "09:17 madminer.utils.ml.sc INFO      Epoch 09: train loss 0.0781 (mse_score: 0.0781)\n",
      "09:17 madminer.utils.ml.sc INFO                val. loss  0.0966 (mse_score: 0.0966) (*)\n",
      "09:18 madminer.utils.ml.sc INFO      Epoch 10: train loss 0.0760 (mse_score: 0.0760)\n",
      "09:18 madminer.utils.ml.sc INFO                val. loss  0.0985 (mse_score: 0.0985)\n",
      "09:18 madminer.utils.ml.sc INFO      Epoch 11: train loss 0.0742 (mse_score: 0.0742)\n",
      "09:18 madminer.utils.ml.sc INFO                val. loss  0.0951 (mse_score: 0.0951) (*)\n",
      "09:19 madminer.utils.ml.sc INFO      Epoch 12: train loss 0.0732 (mse_score: 0.0732)\n",
      "09:19 madminer.utils.ml.sc INFO                val. loss  0.0947 (mse_score: 0.0947) (*)\n",
      "09:20 madminer.utils.ml.sc INFO      Epoch 13: train loss 0.0738 (mse_score: 0.0738)\n",
      "09:20 madminer.utils.ml.sc INFO                val. loss  0.0961 (mse_score: 0.0961)\n",
      "09:20 madminer.utils.ml.sc INFO      Epoch 14: train loss 0.0722 (mse_score: 0.0722)\n",
      "09:20 madminer.utils.ml.sc INFO                val. loss  0.0987 (mse_score: 0.0987)\n",
      "09:21 madminer.utils.ml.sc INFO      Epoch 15: train loss 0.0713 (mse_score: 0.0713)\n",
      "09:21 madminer.utils.ml.sc INFO                val. loss  0.0980 (mse_score: 0.0980)\n",
      "09:22 madminer.utils.ml.sc INFO      Epoch 16: train loss 0.0704 (mse_score: 0.0704)\n",
      "09:22 madminer.utils.ml.sc INFO                val. loss  0.0959 (mse_score: 0.0959)\n",
      "09:22 madminer.utils.ml.sc INFO      Epoch 17: train loss 0.0701 (mse_score: 0.0701)\n",
      "09:22 madminer.utils.ml.sc INFO                val. loss  0.0940 (mse_score: 0.0940) (*)\n",
      "09:23 madminer.utils.ml.sc INFO      Epoch 18: train loss 0.0681 (mse_score: 0.0681)\n",
      "09:23 madminer.utils.ml.sc INFO                val. loss  0.0931 (mse_score: 0.0931) (*)\n",
      "09:24 madminer.utils.ml.sc INFO      Epoch 19: train loss 0.0674 (mse_score: 0.0674)\n",
      "09:24 madminer.utils.ml.sc INFO                val. loss  0.0939 (mse_score: 0.0939)\n",
      "09:24 madminer.utils.ml.sc INFO      Epoch 20: train loss 0.0674 (mse_score: 0.0674)\n",
      "09:24 madminer.utils.ml.sc INFO                val. loss  0.0941 (mse_score: 0.0941)\n",
      "09:25 madminer.utils.ml.sc INFO      Epoch 21: train loss 0.0660 (mse_score: 0.0660)\n",
      "09:25 madminer.utils.ml.sc INFO                val. loss  0.0933 (mse_score: 0.0933)\n",
      "09:26 madminer.utils.ml.sc INFO      Epoch 22: train loss 0.0651 (mse_score: 0.0651)\n",
      "09:26 madminer.utils.ml.sc INFO                val. loss  0.0933 (mse_score: 0.0933)\n",
      "09:27 madminer.utils.ml.sc INFO      Epoch 23: train loss 0.0643 (mse_score: 0.0643)\n",
      "09:27 madminer.utils.ml.sc INFO                val. loss  0.0938 (mse_score: 0.0938)\n",
      "09:27 madminer.utils.ml.sc INFO      Epoch 24: train loss 0.0637 (mse_score: 0.0637)\n",
      "09:27 madminer.utils.ml.sc INFO                val. loss  0.0939 (mse_score: 0.0939)\n",
      "09:28 madminer.utils.ml.sc INFO      Epoch 25: train loss 0.0628 (mse_score: 0.0628)\n",
      "09:28 madminer.utils.ml.sc INFO                val. loss  0.0936 (mse_score: 0.0936)\n",
      "09:29 madminer.utils.ml.sc INFO      Epoch 26: train loss 0.0624 (mse_score: 0.0624)\n",
      "09:29 madminer.utils.ml.sc INFO                val. loss  0.0929 (mse_score: 0.0929) (*)\n",
      "09:30 madminer.utils.ml.sc INFO      Epoch 27: train loss 0.0619 (mse_score: 0.0619)\n",
      "09:30 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "09:30 madminer.utils.ml.sc INFO      Epoch 28: train loss 0.0613 (mse_score: 0.0613)\n",
      "09:30 madminer.utils.ml.sc INFO                val. loss  0.0934 (mse_score: 0.0934)\n",
      "09:31 madminer.utils.ml.sc INFO      Epoch 29: train loss 0.0608 (mse_score: 0.0608)\n",
      "09:31 madminer.utils.ml.sc INFO                val. loss  0.0930 (mse_score: 0.0930)\n",
      "09:32 madminer.utils.ml.sc INFO      Epoch 30: train loss 0.0602 (mse_score: 0.0602)\n",
      "09:32 madminer.utils.ml.sc INFO                val. loss  0.0930 (mse_score: 0.0930)\n",
      "09:32 madminer.utils.ml.sc INFO      Epoch 31: train loss 0.0597 (mse_score: 0.0597)\n",
      "09:32 madminer.utils.ml.sc INFO                val. loss  0.0941 (mse_score: 0.0941)\n",
      "09:33 madminer.utils.ml.sc INFO      Epoch 32: train loss 0.0594 (mse_score: 0.0594)\n",
      "09:33 madminer.utils.ml.sc INFO                val. loss  0.0931 (mse_score: 0.0931)\n",
      "09:34 madminer.utils.ml.sc INFO      Epoch 33: train loss 0.0588 (mse_score: 0.0588)\n",
      "09:34 madminer.utils.ml.sc INFO                val. loss  0.0925 (mse_score: 0.0925) (*)\n",
      "09:35 madminer.utils.ml.sc INFO      Epoch 34: train loss 0.0584 (mse_score: 0.0584)\n",
      "09:35 madminer.utils.ml.sc INFO                val. loss  0.0929 (mse_score: 0.0929)\n",
      "09:35 madminer.utils.ml.sc INFO      Epoch 35: train loss 0.0581 (mse_score: 0.0581)\n",
      "09:35 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "09:36 madminer.utils.ml.sc INFO      Epoch 36: train loss 0.0576 (mse_score: 0.0576)\n",
      "09:36 madminer.utils.ml.sc INFO                val. loss  0.0928 (mse_score: 0.0928)\n",
      "09:37 madminer.utils.ml.sc INFO      Epoch 37: train loss 0.0573 (mse_score: 0.0573)\n",
      "09:37 madminer.utils.ml.sc INFO                val. loss  0.0931 (mse_score: 0.0931)\n",
      "09:37 madminer.utils.ml.sc INFO      Epoch 38: train loss 0.0569 (mse_score: 0.0569)\n",
      "09:37 madminer.utils.ml.sc INFO                val. loss  0.0926 (mse_score: 0.0926)\n",
      "09:38 madminer.utils.ml.sc INFO      Epoch 39: train loss 0.0566 (mse_score: 0.0566)\n",
      "09:38 madminer.utils.ml.sc INFO                val. loss  0.0929 (mse_score: 0.0929)\n",
      "09:38 madminer.utils.ml.sc INFO      Epoch 40: train loss 0.0564 (mse_score: 0.0564)\n",
      "09:38 madminer.utils.ml.sc INFO                val. loss  0.0931 (mse_score: 0.0931)\n",
      "09:39 madminer.utils.ml.sc INFO      Epoch 41: train loss 0.0561 (mse_score: 0.0561)\n",
      "09:39 madminer.utils.ml.sc INFO                val. loss  0.0930 (mse_score: 0.0930)\n",
      "09:40 madminer.utils.ml.sc INFO      Epoch 42: train loss 0.0558 (mse_score: 0.0558)\n",
      "09:40 madminer.utils.ml.sc INFO                val. loss  0.0930 (mse_score: 0.0930)\n",
      "09:41 madminer.utils.ml.sc INFO      Epoch 43: train loss 0.0555 (mse_score: 0.0555)\n",
      "09:41 madminer.utils.ml.sc INFO                val. loss  0.0930 (mse_score: 0.0930)\n",
      "09:42 madminer.utils.ml.sc INFO      Epoch 44: train loss 0.0552 (mse_score: 0.0552)\n",
      "09:42 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "09:43 madminer.utils.ml.sc INFO      Epoch 45: train loss 0.0550 (mse_score: 0.0550)\n",
      "09:43 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "09:44 madminer.utils.ml.sc INFO      Epoch 46: train loss 0.0547 (mse_score: 0.0547)\n",
      "09:44 madminer.utils.ml.sc INFO                val. loss  0.0939 (mse_score: 0.0939)\n",
      "09:45 madminer.utils.ml.sc INFO      Epoch 47: train loss 0.0546 (mse_score: 0.0546)\n",
      "09:45 madminer.utils.ml.sc INFO                val. loss  0.0929 (mse_score: 0.0929)\n",
      "09:45 madminer.utils.ml.sc INFO      Epoch 48: train loss 0.0544 (mse_score: 0.0544)\n",
      "09:45 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "09:46 madminer.utils.ml.sc INFO      Epoch 49: train loss 0.0542 (mse_score: 0.0542)\n",
      "09:46 madminer.utils.ml.sc INFO                val. loss  0.0932 (mse_score: 0.0932)\n",
      "09:46 madminer.utils.ml.sc INFO      Epoch 50: train loss 0.0540 (mse_score: 0.0540)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:46 madminer.utils.ml.sc INFO                val. loss  0.0931 (mse_score: 0.0931)\n",
      "09:46 madminer.utils.ml.sc INFO    Early stopping after epoch 33, with loss 0.09 compared to final loss 0.09\n",
      "09:46 madminer.utils.ml.sc INFO    Finished training\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'minimal',\n",
    "    use_tight_cuts=False,\n",
    "    features=[min_obs for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:46 madminer.ml          INFO    Training 10 estimators in ensemble\n",
      "09:46 madminer.ml          INFO    Training estimator 1 / 10 in ensemble\n",
      "09:46 madminer.ml          INFO    Starting training\n",
      "09:46 madminer.ml          INFO      Method:                 sally\n",
      "09:46 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_0.npy\n",
      "09:46 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_0.npy\n",
      "09:46 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "09:46 madminer.ml          INFO      Method:                 sally\n",
      "09:46 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "09:46 madminer.ml          INFO      Activation function:    tanh\n",
      "09:46 madminer.ml          INFO      Batch size:             128\n",
      "09:46 madminer.ml          INFO      Trainer:                amsgrad\n",
      "09:46 madminer.ml          INFO      Epochs:                 50\n",
      "09:46 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "09:46 madminer.ml          INFO      Validation split:       0.5\n",
      "09:46 madminer.ml          INFO      Early stopping:         True\n",
      "09:46 madminer.ml          INFO      Scale inputs:           True\n",
      "09:46 madminer.ml          INFO      Shuffle labels          False\n",
      "09:46 madminer.ml          INFO      Regularization:         None\n",
      "09:46 madminer.ml          INFO      Samples:                all\n",
      "09:46 madminer.ml          INFO    Loading training data\n",
      "09:46 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "09:46 madminer.ml          INFO    Rescaling inputs\n",
      "09:46 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "09:46 madminer.ml          INFO    Creating model for method sally\n",
      "09:46 madminer.ml          INFO    Training model\n",
      "09:47 madminer.utils.ml.sc INFO      Epoch 01: train loss 295.3201 (mse_score: 295.3201)\n",
      "09:47 madminer.utils.ml.sc INFO                val. loss  285.0684 (mse_score: 285.0684) (*)\n",
      "09:47 madminer.utils.ml.sc INFO      Epoch 02: train loss 279.8233 (mse_score: 279.8233)\n",
      "09:47 madminer.utils.ml.sc INFO                val. loss  276.9679 (mse_score: 276.9679) (*)\n",
      "09:48 madminer.utils.ml.sc INFO      Epoch 03: train loss 273.6390 (mse_score: 273.6390)\n",
      "09:48 madminer.utils.ml.sc INFO                val. loss  272.3929 (mse_score: 272.3929) (*)\n",
      "09:48 madminer.utils.ml.sc INFO      Epoch 04: train loss 270.4034 (mse_score: 270.4034)\n",
      "09:48 madminer.utils.ml.sc INFO                val. loss  270.8822 (mse_score: 270.8822) (*)\n",
      "09:49 madminer.utils.ml.sc INFO      Epoch 05: train loss 268.6192 (mse_score: 268.6192)\n",
      "09:49 madminer.utils.ml.sc INFO                val. loss  268.5602 (mse_score: 268.5602) (*)\n",
      "09:49 madminer.utils.ml.sc INFO      Epoch 06: train loss 267.5055 (mse_score: 267.5055)\n",
      "09:49 madminer.utils.ml.sc INFO                val. loss  267.7381 (mse_score: 267.7381) (*)\n",
      "09:50 madminer.utils.ml.sc INFO      Epoch 07: train loss 266.5750 (mse_score: 266.5750)\n",
      "09:50 madminer.utils.ml.sc INFO                val. loss  266.9950 (mse_score: 266.9950) (*)\n",
      "09:51 madminer.utils.ml.sc INFO      Epoch 08: train loss 265.7836 (mse_score: 265.7836)\n",
      "09:51 madminer.utils.ml.sc INFO                val. loss  266.7177 (mse_score: 266.7177) (*)\n",
      "09:51 madminer.utils.ml.sc INFO      Epoch 09: train loss 264.9891 (mse_score: 264.9891)\n",
      "09:51 madminer.utils.ml.sc INFO                val. loss  265.8023 (mse_score: 265.8023) (*)\n",
      "09:52 madminer.utils.ml.sc INFO      Epoch 10: train loss 264.4247 (mse_score: 264.4247)\n",
      "09:52 madminer.utils.ml.sc INFO                val. loss  265.5862 (mse_score: 265.5862) (*)\n",
      "09:53 madminer.utils.ml.sc INFO      Epoch 11: train loss 263.9130 (mse_score: 263.9130)\n",
      "09:53 madminer.utils.ml.sc INFO                val. loss  265.3051 (mse_score: 265.3051) (*)\n",
      "09:53 madminer.utils.ml.sc INFO      Epoch 12: train loss 263.4933 (mse_score: 263.4933)\n",
      "09:53 madminer.utils.ml.sc INFO                val. loss  264.8829 (mse_score: 264.8829) (*)\n",
      "09:54 madminer.utils.ml.sc INFO      Epoch 13: train loss 263.0288 (mse_score: 263.0288)\n",
      "09:54 madminer.utils.ml.sc INFO                val. loss  264.4505 (mse_score: 264.4505) (*)\n",
      "09:55 madminer.utils.ml.sc INFO      Epoch 14: train loss 262.4923 (mse_score: 262.4923)\n",
      "09:55 madminer.utils.ml.sc INFO                val. loss  264.1176 (mse_score: 264.1176) (*)\n",
      "09:55 madminer.utils.ml.sc INFO      Epoch 15: train loss 262.2024 (mse_score: 262.2024)\n",
      "09:55 madminer.utils.ml.sc INFO                val. loss  263.6887 (mse_score: 263.6887) (*)\n",
      "09:56 madminer.utils.ml.sc INFO      Epoch 16: train loss 261.7332 (mse_score: 261.7332)\n",
      "09:56 madminer.utils.ml.sc INFO                val. loss  263.4791 (mse_score: 263.4791) (*)\n",
      "09:56 madminer.utils.ml.sc INFO      Epoch 17: train loss 261.3231 (mse_score: 261.3231)\n",
      "09:56 madminer.utils.ml.sc INFO                val. loss  263.0406 (mse_score: 263.0406) (*)\n",
      "09:56 madminer.utils.ml.sc INFO      Epoch 18: train loss 261.0267 (mse_score: 261.0267)\n",
      "09:56 madminer.utils.ml.sc INFO                val. loss  262.9896 (mse_score: 262.9896) (*)\n",
      "09:57 madminer.utils.ml.sc INFO      Epoch 19: train loss 260.6719 (mse_score: 260.6719)\n",
      "09:57 madminer.utils.ml.sc INFO                val. loss  262.8265 (mse_score: 262.8265) (*)\n",
      "09:57 madminer.utils.ml.sc INFO      Epoch 20: train loss 260.3799 (mse_score: 260.3799)\n",
      "09:57 madminer.utils.ml.sc INFO                val. loss  262.6945 (mse_score: 262.6945) (*)\n",
      "09:57 madminer.utils.ml.sc INFO      Epoch 21: train loss 260.1069 (mse_score: 260.1069)\n",
      "09:57 madminer.utils.ml.sc INFO                val. loss  262.3389 (mse_score: 262.3389) (*)\n",
      "09:58 madminer.utils.ml.sc INFO      Epoch 22: train loss 259.7862 (mse_score: 259.7862)\n",
      "09:58 madminer.utils.ml.sc INFO                val. loss  262.4488 (mse_score: 262.4488)\n",
      "09:58 madminer.utils.ml.sc INFO      Epoch 23: train loss 259.5049 (mse_score: 259.5049)\n",
      "09:58 madminer.utils.ml.sc INFO                val. loss  261.9737 (mse_score: 261.9737) (*)\n",
      "10:02 madminer.utils.ml.sc INFO      Epoch 24: train loss 259.2075 (mse_score: 259.2075)\n",
      "10:02 madminer.utils.ml.sc INFO                val. loss  261.9294 (mse_score: 261.9294) (*)\n",
      "10:03 madminer.utils.ml.sc INFO      Epoch 25: train loss 258.9563 (mse_score: 258.9563)\n",
      "10:03 madminer.utils.ml.sc INFO                val. loss  261.6317 (mse_score: 261.6317) (*)\n",
      "10:03 madminer.utils.ml.sc INFO      Epoch 26: train loss 258.7705 (mse_score: 258.7705)\n",
      "10:03 madminer.utils.ml.sc INFO                val. loss  261.5523 (mse_score: 261.5523) (*)\n",
      "10:03 madminer.utils.ml.sc INFO      Epoch 27: train loss 258.4099 (mse_score: 258.4099)\n",
      "10:03 madminer.utils.ml.sc INFO                val. loss  261.4963 (mse_score: 261.4963) (*)\n",
      "10:04 madminer.utils.ml.sc INFO      Epoch 28: train loss 258.3407 (mse_score: 258.3407)\n",
      "10:04 madminer.utils.ml.sc INFO                val. loss  261.3537 (mse_score: 261.3537) (*)\n",
      "10:04 madminer.utils.ml.sc INFO      Epoch 29: train loss 258.1033 (mse_score: 258.1033)\n",
      "10:04 madminer.utils.ml.sc INFO                val. loss  261.3259 (mse_score: 261.3259) (*)\n",
      "10:04 madminer.utils.ml.sc INFO      Epoch 30: train loss 257.9396 (mse_score: 257.9396)\n",
      "10:04 madminer.utils.ml.sc INFO                val. loss  261.1614 (mse_score: 261.1614) (*)\n",
      "10:05 madminer.utils.ml.sc INFO      Epoch 31: train loss 257.6783 (mse_score: 257.6783)\n",
      "10:05 madminer.utils.ml.sc INFO                val. loss  260.9916 (mse_score: 260.9916) (*)\n",
      "10:05 madminer.utils.ml.sc INFO      Epoch 32: train loss 257.5170 (mse_score: 257.5170)\n",
      "10:05 madminer.utils.ml.sc INFO                val. loss  260.9647 (mse_score: 260.9647) (*)\n",
      "10:05 madminer.utils.ml.sc INFO      Epoch 33: train loss 257.5231 (mse_score: 257.5231)\n",
      "10:05 madminer.utils.ml.sc INFO                val. loss  260.8043 (mse_score: 260.8043) (*)\n",
      "10:06 madminer.utils.ml.sc INFO      Epoch 34: train loss 257.2932 (mse_score: 257.2932)\n",
      "10:06 madminer.utils.ml.sc INFO                val. loss  260.7844 (mse_score: 260.7844) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:06 madminer.utils.ml.sc INFO      Epoch 35: train loss 257.0865 (mse_score: 257.0865)\n",
      "10:06 madminer.utils.ml.sc INFO                val. loss  260.6751 (mse_score: 260.6751) (*)\n",
      "10:07 madminer.utils.ml.sc INFO      Epoch 36: train loss 257.0190 (mse_score: 257.0190)\n",
      "10:07 madminer.utils.ml.sc INFO                val. loss  260.7234 (mse_score: 260.7234)\n",
      "10:07 madminer.utils.ml.sc INFO      Epoch 37: train loss 256.9303 (mse_score: 256.9303)\n",
      "10:07 madminer.utils.ml.sc INFO                val. loss  260.5530 (mse_score: 260.5530) (*)\n",
      "10:07 madminer.utils.ml.sc INFO      Epoch 38: train loss 256.7424 (mse_score: 256.7424)\n",
      "10:07 madminer.utils.ml.sc INFO                val. loss  260.6688 (mse_score: 260.6688)\n",
      "10:08 madminer.utils.ml.sc INFO      Epoch 39: train loss 256.6531 (mse_score: 256.6531)\n",
      "10:08 madminer.utils.ml.sc INFO                val. loss  260.4803 (mse_score: 260.4803) (*)\n",
      "10:08 madminer.utils.ml.sc INFO      Epoch 40: train loss 256.5152 (mse_score: 256.5152)\n",
      "10:08 madminer.utils.ml.sc INFO                val. loss  260.5047 (mse_score: 260.5047)\n",
      "10:08 madminer.utils.ml.sc INFO      Epoch 41: train loss 256.4472 (mse_score: 256.4472)\n",
      "10:08 madminer.utils.ml.sc INFO                val. loss  260.3329 (mse_score: 260.3329) (*)\n",
      "10:08 madminer.utils.ml.sc INFO      Epoch 42: train loss 256.3718 (mse_score: 256.3718)\n",
      "10:08 madminer.utils.ml.sc INFO                val. loss  260.3346 (mse_score: 260.3346)\n",
      "10:09 madminer.utils.ml.sc INFO      Epoch 43: train loss 256.2310 (mse_score: 256.2310)\n",
      "10:09 madminer.utils.ml.sc INFO                val. loss  260.3026 (mse_score: 260.3026) (*)\n",
      "10:09 madminer.utils.ml.sc INFO      Epoch 44: train loss 256.1624 (mse_score: 256.1624)\n",
      "10:09 madminer.utils.ml.sc INFO                val. loss  260.3334 (mse_score: 260.3334)\n",
      "10:09 madminer.utils.ml.sc INFO      Epoch 45: train loss 256.0830 (mse_score: 256.0830)\n",
      "10:09 madminer.utils.ml.sc INFO                val. loss  260.1550 (mse_score: 260.1550) (*)\n",
      "10:10 madminer.utils.ml.sc INFO      Epoch 46: train loss 256.0380 (mse_score: 256.0380)\n",
      "10:10 madminer.utils.ml.sc INFO                val. loss  260.3030 (mse_score: 260.3030)\n",
      "10:10 madminer.utils.ml.sc INFO      Epoch 47: train loss 255.9051 (mse_score: 255.9051)\n",
      "10:10 madminer.utils.ml.sc INFO                val. loss  260.1341 (mse_score: 260.1341) (*)\n",
      "10:10 madminer.utils.ml.sc INFO      Epoch 48: train loss 255.8344 (mse_score: 255.8344)\n",
      "10:10 madminer.utils.ml.sc INFO                val. loss  260.1862 (mse_score: 260.1862)\n",
      "10:11 madminer.utils.ml.sc INFO      Epoch 49: train loss 255.8527 (mse_score: 255.8527)\n",
      "10:11 madminer.utils.ml.sc INFO                val. loss  260.2805 (mse_score: 260.2805)\n",
      "10:11 madminer.utils.ml.sc INFO      Epoch 50: train loss 255.7437 (mse_score: 255.7437)\n",
      "10:11 madminer.utils.ml.sc INFO                val. loss  260.0313 (mse_score: 260.0313) (*)\n",
      "10:11 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "10:11 madminer.utils.ml.sc INFO    Finished training\n",
      "10:11 madminer.ml          INFO    Training estimator 2 / 10 in ensemble\n",
      "10:11 madminer.ml          INFO    Starting training\n",
      "10:11 madminer.ml          INFO      Method:                 sally\n",
      "10:11 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_1.npy\n",
      "10:11 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_1.npy\n",
      "10:11 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "10:11 madminer.ml          INFO      Method:                 sally\n",
      "10:11 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "10:11 madminer.ml          INFO      Activation function:    tanh\n",
      "10:11 madminer.ml          INFO      Batch size:             128\n",
      "10:11 madminer.ml          INFO      Trainer:                amsgrad\n",
      "10:11 madminer.ml          INFO      Epochs:                 50\n",
      "10:11 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "10:11 madminer.ml          INFO      Validation split:       0.5\n",
      "10:11 madminer.ml          INFO      Early stopping:         True\n",
      "10:11 madminer.ml          INFO      Scale inputs:           True\n",
      "10:11 madminer.ml          INFO      Shuffle labels          False\n",
      "10:11 madminer.ml          INFO      Regularization:         None\n",
      "10:11 madminer.ml          INFO      Samples:                all\n",
      "10:11 madminer.ml          INFO    Loading training data\n",
      "10:11 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "10:11 madminer.ml          INFO    Rescaling inputs\n",
      "10:11 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "10:11 madminer.ml          INFO    Creating model for method sally\n",
      "10:11 madminer.ml          INFO    Training model\n",
      "10:11 madminer.utils.ml.sc INFO      Epoch 01: train loss 282.2782 (mse_score: 282.2782)\n",
      "10:11 madminer.utils.ml.sc INFO                val. loss  275.6923 (mse_score: 275.6923) (*)\n",
      "10:12 madminer.utils.ml.sc INFO      Epoch 02: train loss 267.1184 (mse_score: 267.1184)\n",
      "10:12 madminer.utils.ml.sc INFO                val. loss  269.1750 (mse_score: 269.1750) (*)\n",
      "10:12 madminer.utils.ml.sc INFO      Epoch 03: train loss 262.4151 (mse_score: 262.4151)\n",
      "10:12 madminer.utils.ml.sc INFO                val. loss  266.2217 (mse_score: 266.2217) (*)\n",
      "10:12 madminer.utils.ml.sc INFO      Epoch 04: train loss 259.1934 (mse_score: 259.1934)\n",
      "10:12 madminer.utils.ml.sc INFO                val. loss  263.4308 (mse_score: 263.4308) (*)\n",
      "10:13 madminer.utils.ml.sc INFO      Epoch 05: train loss 257.0788 (mse_score: 257.0788)\n",
      "10:13 madminer.utils.ml.sc INFO                val. loss  261.7564 (mse_score: 261.7564) (*)\n",
      "10:13 madminer.utils.ml.sc INFO      Epoch 06: train loss 255.8412 (mse_score: 255.8412)\n",
      "10:13 madminer.utils.ml.sc INFO                val. loss  260.4980 (mse_score: 260.4980) (*)\n",
      "10:13 madminer.utils.ml.sc INFO      Epoch 07: train loss 254.7383 (mse_score: 254.7383)\n",
      "10:13 madminer.utils.ml.sc INFO                val. loss  260.2183 (mse_score: 260.2183) (*)\n",
      "10:14 madminer.utils.ml.sc INFO      Epoch 08: train loss 254.0751 (mse_score: 254.0751)\n",
      "10:14 madminer.utils.ml.sc INFO                val. loss  259.7440 (mse_score: 259.7440) (*)\n",
      "10:14 madminer.utils.ml.sc INFO      Epoch 09: train loss 253.4270 (mse_score: 253.4270)\n",
      "10:14 madminer.utils.ml.sc INFO                val. loss  258.6877 (mse_score: 258.6877) (*)\n",
      "10:14 madminer.utils.ml.sc INFO      Epoch 10: train loss 252.7767 (mse_score: 252.7767)\n",
      "10:14 madminer.utils.ml.sc INFO                val. loss  258.4539 (mse_score: 258.4539) (*)\n",
      "10:15 madminer.utils.ml.sc INFO      Epoch 11: train loss 252.1161 (mse_score: 252.1161)\n",
      "10:15 madminer.utils.ml.sc INFO                val. loss  258.5217 (mse_score: 258.5217)\n",
      "10:15 madminer.utils.ml.sc INFO      Epoch 12: train loss 251.5933 (mse_score: 251.5933)\n",
      "10:15 madminer.utils.ml.sc INFO                val. loss  257.1216 (mse_score: 257.1216) (*)\n",
      "10:15 madminer.utils.ml.sc INFO      Epoch 13: train loss 250.9550 (mse_score: 250.9550)\n",
      "10:15 madminer.utils.ml.sc INFO                val. loss  256.9983 (mse_score: 256.9983) (*)\n",
      "10:16 madminer.utils.ml.sc INFO      Epoch 14: train loss 250.4644 (mse_score: 250.4644)\n",
      "10:16 madminer.utils.ml.sc INFO                val. loss  256.4582 (mse_score: 256.4582) (*)\n",
      "10:16 madminer.utils.ml.sc INFO      Epoch 15: train loss 250.0762 (mse_score: 250.0762)\n",
      "10:16 madminer.utils.ml.sc INFO                val. loss  256.3255 (mse_score: 256.3255) (*)\n",
      "10:16 madminer.utils.ml.sc INFO      Epoch 16: train loss 249.5581 (mse_score: 249.5581)\n",
      "10:16 madminer.utils.ml.sc INFO                val. loss  255.7845 (mse_score: 255.7845) (*)\n",
      "10:17 madminer.utils.ml.sc INFO      Epoch 17: train loss 249.2442 (mse_score: 249.2442)\n",
      "10:17 madminer.utils.ml.sc INFO                val. loss  255.8852 (mse_score: 255.8852)\n",
      "10:17 madminer.utils.ml.sc INFO      Epoch 18: train loss 248.8093 (mse_score: 248.8093)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:17 madminer.utils.ml.sc INFO                val. loss  255.2857 (mse_score: 255.2857) (*)\n",
      "10:17 madminer.utils.ml.sc INFO      Epoch 19: train loss 248.5034 (mse_score: 248.5034)\n",
      "10:17 madminer.utils.ml.sc INFO                val. loss  256.2963 (mse_score: 256.2963)\n",
      "10:18 madminer.utils.ml.sc INFO      Epoch 20: train loss 248.1192 (mse_score: 248.1192)\n",
      "10:18 madminer.utils.ml.sc INFO                val. loss  254.9547 (mse_score: 254.9547) (*)\n",
      "10:18 madminer.utils.ml.sc INFO      Epoch 21: train loss 247.8275 (mse_score: 247.8275)\n",
      "10:18 madminer.utils.ml.sc INFO                val. loss  254.7621 (mse_score: 254.7621) (*)\n",
      "10:18 madminer.utils.ml.sc INFO      Epoch 22: train loss 247.5048 (mse_score: 247.5048)\n",
      "10:18 madminer.utils.ml.sc INFO                val. loss  254.6041 (mse_score: 254.6041) (*)\n",
      "10:19 madminer.utils.ml.sc INFO      Epoch 23: train loss 247.2925 (mse_score: 247.2925)\n",
      "10:19 madminer.utils.ml.sc INFO                val. loss  254.2396 (mse_score: 254.2396) (*)\n",
      "10:19 madminer.utils.ml.sc INFO      Epoch 24: train loss 247.0675 (mse_score: 247.0675)\n",
      "10:19 madminer.utils.ml.sc INFO                val. loss  253.9773 (mse_score: 253.9773) (*)\n",
      "10:19 madminer.utils.ml.sc INFO      Epoch 25: train loss 246.7454 (mse_score: 246.7454)\n",
      "10:19 madminer.utils.ml.sc INFO                val. loss  253.9606 (mse_score: 253.9606) (*)\n",
      "10:20 madminer.utils.ml.sc INFO      Epoch 26: train loss 246.5129 (mse_score: 246.5129)\n",
      "10:20 madminer.utils.ml.sc INFO                val. loss  253.8734 (mse_score: 253.8734) (*)\n",
      "10:20 madminer.utils.ml.sc INFO      Epoch 27: train loss 246.3056 (mse_score: 246.3056)\n",
      "10:20 madminer.utils.ml.sc INFO                val. loss  253.8136 (mse_score: 253.8136) (*)\n",
      "10:20 madminer.utils.ml.sc INFO      Epoch 28: train loss 246.1714 (mse_score: 246.1714)\n",
      "10:20 madminer.utils.ml.sc INFO                val. loss  253.5891 (mse_score: 253.5891) (*)\n",
      "10:21 madminer.utils.ml.sc INFO      Epoch 29: train loss 245.9977 (mse_score: 245.9977)\n",
      "10:21 madminer.utils.ml.sc INFO                val. loss  253.3765 (mse_score: 253.3765) (*)\n",
      "10:21 madminer.utils.ml.sc INFO      Epoch 30: train loss 245.8537 (mse_score: 245.8537)\n",
      "10:21 madminer.utils.ml.sc INFO                val. loss  253.4298 (mse_score: 253.4298)\n",
      "10:22 madminer.utils.ml.sc INFO      Epoch 31: train loss 245.7094 (mse_score: 245.7094)\n",
      "10:22 madminer.utils.ml.sc INFO                val. loss  253.3274 (mse_score: 253.3274) (*)\n",
      "10:22 madminer.utils.ml.sc INFO      Epoch 32: train loss 245.4537 (mse_score: 245.4537)\n",
      "10:22 madminer.utils.ml.sc INFO                val. loss  253.0154 (mse_score: 253.0154) (*)\n",
      "10:22 madminer.utils.ml.sc INFO      Epoch 33: train loss 245.2840 (mse_score: 245.2840)\n",
      "10:22 madminer.utils.ml.sc INFO                val. loss  253.1478 (mse_score: 253.1478)\n",
      "10:23 madminer.utils.ml.sc INFO      Epoch 34: train loss 245.1791 (mse_score: 245.1791)\n",
      "10:23 madminer.utils.ml.sc INFO                val. loss  252.9714 (mse_score: 252.9714) (*)\n",
      "10:23 madminer.utils.ml.sc INFO      Epoch 35: train loss 245.0712 (mse_score: 245.0712)\n",
      "10:23 madminer.utils.ml.sc INFO                val. loss  253.1889 (mse_score: 253.1889)\n",
      "10:23 madminer.utils.ml.sc INFO      Epoch 36: train loss 244.9355 (mse_score: 244.9355)\n",
      "10:23 madminer.utils.ml.sc INFO                val. loss  252.8095 (mse_score: 252.8095) (*)\n",
      "10:24 madminer.utils.ml.sc INFO      Epoch 37: train loss 244.7699 (mse_score: 244.7699)\n",
      "10:24 madminer.utils.ml.sc INFO                val. loss  252.8675 (mse_score: 252.8675)\n",
      "10:24 madminer.utils.ml.sc INFO      Epoch 38: train loss 244.6940 (mse_score: 244.6940)\n",
      "10:24 madminer.utils.ml.sc INFO                val. loss  252.6909 (mse_score: 252.6909) (*)\n",
      "10:24 madminer.utils.ml.sc INFO      Epoch 39: train loss 244.5987 (mse_score: 244.5987)\n",
      "10:24 madminer.utils.ml.sc INFO                val. loss  252.9074 (mse_score: 252.9074)\n",
      "10:25 madminer.utils.ml.sc INFO      Epoch 40: train loss 244.4492 (mse_score: 244.4492)\n",
      "10:25 madminer.utils.ml.sc INFO                val. loss  252.7079 (mse_score: 252.7079)\n",
      "10:25 madminer.utils.ml.sc INFO      Epoch 41: train loss 244.3511 (mse_score: 244.3511)\n",
      "10:25 madminer.utils.ml.sc INFO                val. loss  252.6119 (mse_score: 252.6119) (*)\n",
      "10:26 madminer.utils.ml.sc INFO      Epoch 42: train loss 244.2996 (mse_score: 244.2996)\n",
      "10:26 madminer.utils.ml.sc INFO                val. loss  252.6604 (mse_score: 252.6604)\n",
      "10:26 madminer.utils.ml.sc INFO      Epoch 43: train loss 244.2021 (mse_score: 244.2021)\n",
      "10:26 madminer.utils.ml.sc INFO                val. loss  252.7333 (mse_score: 252.7333)\n",
      "10:26 madminer.utils.ml.sc INFO      Epoch 44: train loss 244.1386 (mse_score: 244.1386)\n",
      "10:26 madminer.utils.ml.sc INFO                val. loss  252.4490 (mse_score: 252.4490) (*)\n",
      "10:27 madminer.utils.ml.sc INFO      Epoch 45: train loss 244.0431 (mse_score: 244.0431)\n",
      "10:27 madminer.utils.ml.sc INFO                val. loss  252.4439 (mse_score: 252.4439) (*)\n",
      "10:27 madminer.utils.ml.sc INFO      Epoch 46: train loss 243.9772 (mse_score: 243.9772)\n",
      "10:27 madminer.utils.ml.sc INFO                val. loss  252.3460 (mse_score: 252.3460) (*)\n",
      "10:27 madminer.utils.ml.sc INFO      Epoch 47: train loss 243.8836 (mse_score: 243.8836)\n",
      "10:27 madminer.utils.ml.sc INFO                val. loss  252.5733 (mse_score: 252.5733)\n",
      "10:28 madminer.utils.ml.sc INFO      Epoch 48: train loss 243.8681 (mse_score: 243.8681)\n",
      "10:28 madminer.utils.ml.sc INFO                val. loss  252.2986 (mse_score: 252.2986) (*)\n",
      "10:28 madminer.utils.ml.sc INFO      Epoch 49: train loss 243.7514 (mse_score: 243.7514)\n",
      "10:28 madminer.utils.ml.sc INFO                val. loss  252.3392 (mse_score: 252.3392)\n",
      "10:29 madminer.utils.ml.sc INFO      Epoch 50: train loss 243.7360 (mse_score: 243.7360)\n",
      "10:29 madminer.utils.ml.sc INFO                val. loss  252.2282 (mse_score: 252.2282) (*)\n",
      "10:29 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "10:29 madminer.utils.ml.sc INFO    Finished training\n",
      "10:29 madminer.ml          INFO    Training estimator 3 / 10 in ensemble\n",
      "10:29 madminer.ml          INFO    Starting training\n",
      "10:29 madminer.ml          INFO      Method:                 sally\n",
      "10:29 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_2.npy\n",
      "10:29 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_2.npy\n",
      "10:29 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "10:29 madminer.ml          INFO      Method:                 sally\n",
      "10:29 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "10:29 madminer.ml          INFO      Activation function:    tanh\n",
      "10:29 madminer.ml          INFO      Batch size:             128\n",
      "10:29 madminer.ml          INFO      Trainer:                amsgrad\n",
      "10:29 madminer.ml          INFO      Epochs:                 50\n",
      "10:29 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "10:29 madminer.ml          INFO      Validation split:       0.5\n",
      "10:29 madminer.ml          INFO      Early stopping:         True\n",
      "10:29 madminer.ml          INFO      Scale inputs:           True\n",
      "10:29 madminer.ml          INFO      Shuffle labels          False\n",
      "10:29 madminer.ml          INFO      Regularization:         None\n",
      "10:29 madminer.ml          INFO      Samples:                all\n",
      "10:29 madminer.ml          INFO    Loading training data\n",
      "10:29 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "10:29 madminer.ml          INFO    Rescaling inputs\n",
      "10:29 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "10:29 madminer.ml          INFO    Creating model for method sally\n",
      "10:29 madminer.ml          INFO    Training model\n",
      "10:29 madminer.utils.ml.sc INFO      Epoch 01: train loss 311.5677 (mse_score: 311.5677)\n",
      "10:29 madminer.utils.ml.sc INFO                val. loss  280.7346 (mse_score: 280.7346) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:29 madminer.utils.ml.sc INFO      Epoch 02: train loss 296.5082 (mse_score: 296.5082)\n",
      "10:29 madminer.utils.ml.sc INFO                val. loss  274.0950 (mse_score: 274.0950) (*)\n",
      "10:30 madminer.utils.ml.sc INFO      Epoch 03: train loss 291.7491 (mse_score: 291.7491)\n",
      "10:30 madminer.utils.ml.sc INFO                val. loss  270.1399 (mse_score: 270.1399) (*)\n",
      "10:31 madminer.utils.ml.sc INFO      Epoch 04: train loss 288.5178 (mse_score: 288.5178)\n",
      "10:31 madminer.utils.ml.sc INFO                val. loss  267.6812 (mse_score: 267.6812) (*)\n",
      "10:31 madminer.utils.ml.sc INFO      Epoch 05: train loss 286.4256 (mse_score: 286.4256)\n",
      "10:31 madminer.utils.ml.sc INFO                val. loss  265.8938 (mse_score: 265.8938) (*)\n",
      "10:32 madminer.utils.ml.sc INFO      Epoch 06: train loss 285.1766 (mse_score: 285.1766)\n",
      "10:32 madminer.utils.ml.sc INFO                val. loss  265.8979 (mse_score: 265.8979)\n",
      "10:32 madminer.utils.ml.sc INFO      Epoch 07: train loss 284.2998 (mse_score: 284.2998)\n",
      "10:32 madminer.utils.ml.sc INFO                val. loss  264.6478 (mse_score: 264.6478) (*)\n",
      "10:33 madminer.utils.ml.sc INFO      Epoch 08: train loss 283.6847 (mse_score: 283.6847)\n",
      "10:33 madminer.utils.ml.sc INFO                val. loss  263.8116 (mse_score: 263.8116) (*)\n",
      "10:33 madminer.utils.ml.sc INFO      Epoch 09: train loss 282.9849 (mse_score: 282.9849)\n",
      "10:33 madminer.utils.ml.sc INFO                val. loss  263.2869 (mse_score: 263.2869) (*)\n",
      "10:33 madminer.utils.ml.sc INFO      Epoch 10: train loss 282.4163 (mse_score: 282.4163)\n",
      "10:33 madminer.utils.ml.sc INFO                val. loss  262.7762 (mse_score: 262.7762) (*)\n",
      "10:34 madminer.utils.ml.sc INFO      Epoch 11: train loss 281.8384 (mse_score: 281.8384)\n",
      "10:34 madminer.utils.ml.sc INFO                val. loss  263.0541 (mse_score: 263.0541)\n",
      "10:34 madminer.utils.ml.sc INFO      Epoch 12: train loss 281.3422 (mse_score: 281.3422)\n",
      "10:34 madminer.utils.ml.sc INFO                val. loss  262.2026 (mse_score: 262.2026) (*)\n",
      "10:34 madminer.utils.ml.sc INFO      Epoch 13: train loss 280.8139 (mse_score: 280.8139)\n",
      "10:34 madminer.utils.ml.sc INFO                val. loss  261.8650 (mse_score: 261.8650) (*)\n",
      "10:35 madminer.utils.ml.sc INFO      Epoch 14: train loss 280.5207 (mse_score: 280.5207)\n",
      "10:35 madminer.utils.ml.sc INFO                val. loss  261.9798 (mse_score: 261.9798)\n",
      "10:35 madminer.utils.ml.sc INFO      Epoch 15: train loss 279.9166 (mse_score: 279.9166)\n",
      "10:35 madminer.utils.ml.sc INFO                val. loss  262.0200 (mse_score: 262.0200)\n",
      "10:35 madminer.utils.ml.sc INFO      Epoch 16: train loss 279.5119 (mse_score: 279.5119)\n",
      "10:35 madminer.utils.ml.sc INFO                val. loss  260.9472 (mse_score: 260.9472) (*)\n",
      "10:36 madminer.utils.ml.sc INFO      Epoch 17: train loss 278.9957 (mse_score: 278.9957)\n",
      "10:36 madminer.utils.ml.sc INFO                val. loss  260.5939 (mse_score: 260.5939) (*)\n",
      "10:36 madminer.utils.ml.sc INFO      Epoch 18: train loss 278.6785 (mse_score: 278.6785)\n",
      "10:36 madminer.utils.ml.sc INFO                val. loss  260.4147 (mse_score: 260.4147) (*)\n",
      "10:37 madminer.utils.ml.sc INFO      Epoch 19: train loss 278.2451 (mse_score: 278.2451)\n",
      "10:37 madminer.utils.ml.sc INFO                val. loss  260.4147 (mse_score: 260.4147)\n",
      "10:37 madminer.utils.ml.sc INFO      Epoch 20: train loss 277.8638 (mse_score: 277.8638)\n",
      "10:37 madminer.utils.ml.sc INFO                val. loss  259.8058 (mse_score: 259.8058) (*)\n",
      "10:37 madminer.utils.ml.sc INFO      Epoch 21: train loss 277.5773 (mse_score: 277.5773)\n",
      "10:37 madminer.utils.ml.sc INFO                val. loss  259.4538 (mse_score: 259.4538) (*)\n",
      "10:38 madminer.utils.ml.sc INFO      Epoch 22: train loss 277.2907 (mse_score: 277.2907)\n",
      "10:38 madminer.utils.ml.sc INFO                val. loss  259.3839 (mse_score: 259.3839) (*)\n",
      "10:38 madminer.utils.ml.sc INFO      Epoch 23: train loss 276.9644 (mse_score: 276.9644)\n",
      "10:38 madminer.utils.ml.sc INFO                val. loss  259.2856 (mse_score: 259.2856) (*)\n",
      "10:38 madminer.utils.ml.sc INFO      Epoch 24: train loss 276.7548 (mse_score: 276.7548)\n",
      "10:38 madminer.utils.ml.sc INFO                val. loss  258.9636 (mse_score: 258.9636) (*)\n",
      "10:39 madminer.utils.ml.sc INFO      Epoch 25: train loss 276.4769 (mse_score: 276.4769)\n",
      "10:39 madminer.utils.ml.sc INFO                val. loss  259.3697 (mse_score: 259.3697)\n",
      "10:39 madminer.utils.ml.sc INFO      Epoch 26: train loss 276.3079 (mse_score: 276.3079)\n",
      "10:39 madminer.utils.ml.sc INFO                val. loss  258.8250 (mse_score: 258.8250) (*)\n",
      "10:40 madminer.utils.ml.sc INFO      Epoch 27: train loss 276.1274 (mse_score: 276.1274)\n",
      "10:40 madminer.utils.ml.sc INFO                val. loss  258.5262 (mse_score: 258.5262) (*)\n",
      "10:40 madminer.utils.ml.sc INFO      Epoch 28: train loss 276.0050 (mse_score: 276.0050)\n",
      "10:40 madminer.utils.ml.sc INFO                val. loss  258.3435 (mse_score: 258.3435) (*)\n",
      "10:40 madminer.utils.ml.sc INFO      Epoch 29: train loss 275.7941 (mse_score: 275.7941)\n",
      "10:40 madminer.utils.ml.sc INFO                val. loss  258.1581 (mse_score: 258.1581) (*)\n",
      "10:41 madminer.utils.ml.sc INFO      Epoch 30: train loss 275.5758 (mse_score: 275.5758)\n",
      "10:41 madminer.utils.ml.sc INFO                val. loss  258.2234 (mse_score: 258.2234)\n",
      "10:41 madminer.utils.ml.sc INFO      Epoch 31: train loss 275.4159 (mse_score: 275.4159)\n",
      "10:41 madminer.utils.ml.sc INFO                val. loss  258.3312 (mse_score: 258.3312)\n",
      "10:41 madminer.utils.ml.sc INFO      Epoch 32: train loss 275.3321 (mse_score: 275.3321)\n",
      "10:41 madminer.utils.ml.sc INFO                val. loss  258.1277 (mse_score: 258.1277) (*)\n",
      "10:42 madminer.utils.ml.sc INFO      Epoch 33: train loss 275.1307 (mse_score: 275.1307)\n",
      "10:42 madminer.utils.ml.sc INFO                val. loss  258.0152 (mse_score: 258.0152) (*)\n",
      "10:42 madminer.utils.ml.sc INFO      Epoch 34: train loss 275.0212 (mse_score: 275.0212)\n",
      "10:42 madminer.utils.ml.sc INFO                val. loss  258.0027 (mse_score: 258.0027) (*)\n",
      "10:42 madminer.utils.ml.sc INFO      Epoch 35: train loss 274.9232 (mse_score: 274.9232)\n",
      "10:42 madminer.utils.ml.sc INFO                val. loss  257.8524 (mse_score: 257.8524) (*)\n",
      "10:43 madminer.utils.ml.sc INFO      Epoch 36: train loss 274.7771 (mse_score: 274.7771)\n",
      "10:43 madminer.utils.ml.sc INFO                val. loss  257.8278 (mse_score: 257.8278) (*)\n",
      "10:43 madminer.utils.ml.sc INFO      Epoch 37: train loss 274.6943 (mse_score: 274.6943)\n",
      "10:43 madminer.utils.ml.sc INFO                val. loss  257.6962 (mse_score: 257.6962) (*)\n",
      "10:44 madminer.utils.ml.sc INFO      Epoch 38: train loss 274.5440 (mse_score: 274.5440)\n",
      "10:44 madminer.utils.ml.sc INFO                val. loss  257.7266 (mse_score: 257.7266)\n",
      "10:44 madminer.utils.ml.sc INFO      Epoch 39: train loss 274.4133 (mse_score: 274.4133)\n",
      "10:44 madminer.utils.ml.sc INFO                val. loss  257.7132 (mse_score: 257.7132)\n",
      "10:44 madminer.utils.ml.sc INFO      Epoch 40: train loss 274.4251 (mse_score: 274.4251)\n",
      "10:44 madminer.utils.ml.sc INFO                val. loss  257.6548 (mse_score: 257.6548) (*)\n",
      "10:45 madminer.utils.ml.sc INFO      Epoch 41: train loss 274.2991 (mse_score: 274.2991)\n",
      "10:45 madminer.utils.ml.sc INFO                val. loss  257.5299 (mse_score: 257.5299) (*)\n",
      "10:45 madminer.utils.ml.sc INFO      Epoch 42: train loss 274.1700 (mse_score: 274.1700)\n",
      "10:45 madminer.utils.ml.sc INFO                val. loss  257.5186 (mse_score: 257.5186) (*)\n",
      "10:45 madminer.utils.ml.sc INFO      Epoch 43: train loss 274.1603 (mse_score: 274.1603)\n",
      "10:45 madminer.utils.ml.sc INFO                val. loss  257.5272 (mse_score: 257.5272)\n",
      "10:46 madminer.utils.ml.sc INFO      Epoch 44: train loss 274.0554 (mse_score: 274.0554)\n",
      "10:46 madminer.utils.ml.sc INFO                val. loss  257.4842 (mse_score: 257.4842) (*)\n",
      "10:46 madminer.utils.ml.sc INFO      Epoch 45: train loss 273.9887 (mse_score: 273.9887)\n",
      "10:46 madminer.utils.ml.sc INFO                val. loss  257.4411 (mse_score: 257.4411) (*)\n",
      "10:46 madminer.utils.ml.sc INFO      Epoch 46: train loss 273.8893 (mse_score: 273.8893)\n",
      "10:46 madminer.utils.ml.sc INFO                val. loss  257.5664 (mse_score: 257.5664)\n",
      "10:47 madminer.utils.ml.sc INFO      Epoch 47: train loss 273.9004 (mse_score: 273.9004)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:47 madminer.utils.ml.sc INFO                val. loss  257.3092 (mse_score: 257.3092) (*)\n",
      "10:47 madminer.utils.ml.sc INFO      Epoch 48: train loss 273.7727 (mse_score: 273.7727)\n",
      "10:47 madminer.utils.ml.sc INFO                val. loss  257.3629 (mse_score: 257.3629)\n",
      "10:47 madminer.utils.ml.sc INFO      Epoch 49: train loss 273.7678 (mse_score: 273.7678)\n",
      "10:47 madminer.utils.ml.sc INFO                val. loss  257.5778 (mse_score: 257.5778)\n",
      "10:48 madminer.utils.ml.sc INFO      Epoch 50: train loss 273.6467 (mse_score: 273.6467)\n",
      "10:48 madminer.utils.ml.sc INFO                val. loss  257.2929 (mse_score: 257.2929) (*)\n",
      "10:48 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "10:48 madminer.utils.ml.sc INFO    Finished training\n",
      "10:48 madminer.ml          INFO    Training estimator 4 / 10 in ensemble\n",
      "10:48 madminer.ml          INFO    Starting training\n",
      "10:48 madminer.ml          INFO      Method:                 sally\n",
      "10:48 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_3.npy\n",
      "10:48 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_3.npy\n",
      "10:48 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "10:48 madminer.ml          INFO      Method:                 sally\n",
      "10:48 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "10:48 madminer.ml          INFO      Activation function:    tanh\n",
      "10:48 madminer.ml          INFO      Batch size:             128\n",
      "10:48 madminer.ml          INFO      Trainer:                amsgrad\n",
      "10:48 madminer.ml          INFO      Epochs:                 50\n",
      "10:48 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "10:48 madminer.ml          INFO      Validation split:       0.5\n",
      "10:48 madminer.ml          INFO      Early stopping:         True\n",
      "10:48 madminer.ml          INFO      Scale inputs:           True\n",
      "10:48 madminer.ml          INFO      Shuffle labels          False\n",
      "10:48 madminer.ml          INFO      Regularization:         None\n",
      "10:48 madminer.ml          INFO      Samples:                all\n",
      "10:48 madminer.ml          INFO    Loading training data\n",
      "10:48 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "10:48 madminer.ml          INFO    Rescaling inputs\n",
      "10:48 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "10:48 madminer.ml          INFO    Creating model for method sally\n",
      "10:48 madminer.ml          INFO    Training model\n",
      "10:48 madminer.utils.ml.sc INFO      Epoch 01: train loss 280.8128 (mse_score: 280.8128)\n",
      "10:48 madminer.utils.ml.sc INFO                val. loss  274.1304 (mse_score: 274.1304) (*)\n",
      "10:48 madminer.utils.ml.sc INFO      Epoch 02: train loss 265.6790 (mse_score: 265.6790)\n",
      "10:48 madminer.utils.ml.sc INFO                val. loss  267.0319 (mse_score: 267.0319) (*)\n",
      "10:49 madminer.utils.ml.sc INFO      Epoch 03: train loss 260.4164 (mse_score: 260.4164)\n",
      "10:49 madminer.utils.ml.sc INFO                val. loss  262.8679 (mse_score: 262.8679) (*)\n",
      "10:49 madminer.utils.ml.sc INFO      Epoch 04: train loss 256.9406 (mse_score: 256.9406)\n",
      "10:49 madminer.utils.ml.sc INFO                val. loss  260.5422 (mse_score: 260.5422) (*)\n",
      "10:50 madminer.utils.ml.sc INFO      Epoch 05: train loss 254.8254 (mse_score: 254.8254)\n",
      "10:50 madminer.utils.ml.sc INFO                val. loss  259.3237 (mse_score: 259.3237) (*)\n",
      "10:50 madminer.utils.ml.sc INFO      Epoch 06: train loss 253.4871 (mse_score: 253.4871)\n",
      "10:50 madminer.utils.ml.sc INFO                val. loss  258.4487 (mse_score: 258.4487) (*)\n",
      "10:50 madminer.utils.ml.sc INFO      Epoch 07: train loss 252.4786 (mse_score: 252.4786)\n",
      "10:50 madminer.utils.ml.sc INFO                val. loss  257.2062 (mse_score: 257.2062) (*)\n",
      "10:51 madminer.utils.ml.sc INFO      Epoch 08: train loss 251.7893 (mse_score: 251.7893)\n",
      "10:51 madminer.utils.ml.sc INFO                val. loss  256.9609 (mse_score: 256.9609) (*)\n",
      "10:51 madminer.utils.ml.sc INFO      Epoch 09: train loss 251.1105 (mse_score: 251.1105)\n",
      "10:51 madminer.utils.ml.sc INFO                val. loss  256.2772 (mse_score: 256.2772) (*)\n",
      "10:52 madminer.utils.ml.sc INFO      Epoch 10: train loss 250.7055 (mse_score: 250.7055)\n",
      "10:52 madminer.utils.ml.sc INFO                val. loss  255.9053 (mse_score: 255.9053) (*)\n",
      "10:52 madminer.utils.ml.sc INFO      Epoch 11: train loss 250.1776 (mse_score: 250.1776)\n",
      "10:52 madminer.utils.ml.sc INFO                val. loss  255.6275 (mse_score: 255.6275) (*)\n",
      "10:53 madminer.utils.ml.sc INFO      Epoch 12: train loss 249.6593 (mse_score: 249.6593)\n",
      "10:53 madminer.utils.ml.sc INFO                val. loss  255.1219 (mse_score: 255.1219) (*)\n",
      "10:53 madminer.utils.ml.sc INFO      Epoch 13: train loss 249.3234 (mse_score: 249.3234)\n",
      "10:53 madminer.utils.ml.sc INFO                val. loss  254.7292 (mse_score: 254.7292) (*)\n",
      "10:54 madminer.utils.ml.sc INFO      Epoch 14: train loss 248.8801 (mse_score: 248.8801)\n",
      "10:54 madminer.utils.ml.sc INFO                val. loss  254.5097 (mse_score: 254.5097) (*)\n",
      "10:55 madminer.utils.ml.sc INFO      Epoch 15: train loss 248.6340 (mse_score: 248.6340)\n",
      "10:55 madminer.utils.ml.sc INFO                val. loss  254.3744 (mse_score: 254.3744) (*)\n",
      "10:55 madminer.utils.ml.sc INFO      Epoch 16: train loss 248.3199 (mse_score: 248.3199)\n",
      "10:55 madminer.utils.ml.sc INFO                val. loss  254.0455 (mse_score: 254.0455) (*)\n",
      "10:56 madminer.utils.ml.sc INFO      Epoch 17: train loss 248.1162 (mse_score: 248.1162)\n",
      "10:56 madminer.utils.ml.sc INFO                val. loss  253.7907 (mse_score: 253.7907) (*)\n",
      "10:56 madminer.utils.ml.sc INFO      Epoch 18: train loss 247.6970 (mse_score: 247.6970)\n",
      "10:56 madminer.utils.ml.sc INFO                val. loss  253.6395 (mse_score: 253.6395) (*)\n",
      "10:57 madminer.utils.ml.sc INFO      Epoch 19: train loss 247.4738 (mse_score: 247.4738)\n",
      "10:57 madminer.utils.ml.sc INFO                val. loss  253.5234 (mse_score: 253.5234) (*)\n",
      "10:57 madminer.utils.ml.sc INFO      Epoch 20: train loss 247.1054 (mse_score: 247.1054)\n",
      "10:57 madminer.utils.ml.sc INFO                val. loss  253.3544 (mse_score: 253.3544) (*)\n",
      "10:58 madminer.utils.ml.sc INFO      Epoch 21: train loss 246.8207 (mse_score: 246.8207)\n",
      "10:58 madminer.utils.ml.sc INFO                val. loss  253.3812 (mse_score: 253.3812)\n",
      "10:58 madminer.utils.ml.sc INFO      Epoch 22: train loss 246.4697 (mse_score: 246.4697)\n",
      "10:58 madminer.utils.ml.sc INFO                val. loss  252.7419 (mse_score: 252.7419) (*)\n",
      "10:59 madminer.utils.ml.sc INFO      Epoch 23: train loss 246.2611 (mse_score: 246.2611)\n",
      "10:59 madminer.utils.ml.sc INFO                val. loss  252.6517 (mse_score: 252.6517) (*)\n",
      "11:00 madminer.utils.ml.sc INFO      Epoch 24: train loss 245.8241 (mse_score: 245.8241)\n",
      "11:00 madminer.utils.ml.sc INFO                val. loss  252.3582 (mse_score: 252.3582) (*)\n",
      "11:00 madminer.utils.ml.sc INFO      Epoch 25: train loss 245.5655 (mse_score: 245.5655)\n",
      "11:00 madminer.utils.ml.sc INFO                val. loss  252.1713 (mse_score: 252.1713) (*)\n",
      "11:01 madminer.utils.ml.sc INFO      Epoch 26: train loss 245.2771 (mse_score: 245.2771)\n",
      "11:01 madminer.utils.ml.sc INFO                val. loss  252.0824 (mse_score: 252.0824) (*)\n",
      "11:01 madminer.utils.ml.sc INFO      Epoch 27: train loss 245.1038 (mse_score: 245.1038)\n",
      "11:01 madminer.utils.ml.sc INFO                val. loss  251.7312 (mse_score: 251.7312) (*)\n",
      "11:02 madminer.utils.ml.sc INFO      Epoch 28: train loss 244.7724 (mse_score: 244.7724)\n",
      "11:02 madminer.utils.ml.sc INFO                val. loss  251.6628 (mse_score: 251.6628) (*)\n",
      "11:02 madminer.utils.ml.sc INFO      Epoch 29: train loss 244.5965 (mse_score: 244.5965)\n",
      "11:02 madminer.utils.ml.sc INFO                val. loss  251.6153 (mse_score: 251.6153) (*)\n",
      "11:02 madminer.utils.ml.sc INFO      Epoch 30: train loss 244.4687 (mse_score: 244.4687)\n",
      "11:02 madminer.utils.ml.sc INFO                val. loss  251.4829 (mse_score: 251.4829) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:03 madminer.utils.ml.sc INFO      Epoch 31: train loss 244.1872 (mse_score: 244.1872)\n",
      "11:03 madminer.utils.ml.sc INFO                val. loss  251.3577 (mse_score: 251.3577) (*)\n",
      "11:03 madminer.utils.ml.sc INFO      Epoch 32: train loss 244.0605 (mse_score: 244.0605)\n",
      "11:03 madminer.utils.ml.sc INFO                val. loss  251.1569 (mse_score: 251.1569) (*)\n",
      "11:04 madminer.utils.ml.sc INFO      Epoch 33: train loss 243.8777 (mse_score: 243.8777)\n",
      "11:04 madminer.utils.ml.sc INFO                val. loss  251.1956 (mse_score: 251.1956)\n",
      "11:04 madminer.utils.ml.sc INFO      Epoch 34: train loss 243.7314 (mse_score: 243.7314)\n",
      "11:04 madminer.utils.ml.sc INFO                val. loss  251.0655 (mse_score: 251.0655) (*)\n",
      "11:05 madminer.utils.ml.sc INFO      Epoch 35: train loss 243.5292 (mse_score: 243.5292)\n",
      "11:05 madminer.utils.ml.sc INFO                val. loss  251.1445 (mse_score: 251.1445)\n",
      "11:05 madminer.utils.ml.sc INFO      Epoch 36: train loss 243.5194 (mse_score: 243.5194)\n",
      "11:05 madminer.utils.ml.sc INFO                val. loss  251.0058 (mse_score: 251.0058) (*)\n",
      "11:06 madminer.utils.ml.sc INFO      Epoch 37: train loss 243.3134 (mse_score: 243.3134)\n",
      "11:06 madminer.utils.ml.sc INFO                val. loss  250.9452 (mse_score: 250.9452) (*)\n",
      "11:06 madminer.utils.ml.sc INFO      Epoch 38: train loss 243.1843 (mse_score: 243.1843)\n",
      "11:06 madminer.utils.ml.sc INFO                val. loss  250.9146 (mse_score: 250.9146) (*)\n",
      "11:07 madminer.utils.ml.sc INFO      Epoch 39: train loss 243.0992 (mse_score: 243.0992)\n",
      "11:07 madminer.utils.ml.sc INFO                val. loss  250.6855 (mse_score: 250.6855) (*)\n",
      "11:07 madminer.utils.ml.sc INFO      Epoch 40: train loss 242.9527 (mse_score: 242.9527)\n",
      "11:07 madminer.utils.ml.sc INFO                val. loss  250.7097 (mse_score: 250.7097)\n",
      "11:08 madminer.utils.ml.sc INFO      Epoch 41: train loss 242.9303 (mse_score: 242.9303)\n",
      "11:08 madminer.utils.ml.sc INFO                val. loss  250.6770 (mse_score: 250.6770) (*)\n",
      "11:08 madminer.utils.ml.sc INFO      Epoch 42: train loss 242.8047 (mse_score: 242.8047)\n",
      "11:08 madminer.utils.ml.sc INFO                val. loss  250.6724 (mse_score: 250.6724) (*)\n",
      "11:09 madminer.utils.ml.sc INFO      Epoch 43: train loss 242.6894 (mse_score: 242.6894)\n",
      "11:09 madminer.utils.ml.sc INFO                val. loss  250.6782 (mse_score: 250.6782)\n",
      "11:09 madminer.utils.ml.sc INFO      Epoch 44: train loss 242.6278 (mse_score: 242.6278)\n",
      "11:09 madminer.utils.ml.sc INFO                val. loss  250.5192 (mse_score: 250.5192) (*)\n",
      "11:10 madminer.utils.ml.sc INFO      Epoch 45: train loss 242.5442 (mse_score: 242.5442)\n",
      "11:10 madminer.utils.ml.sc INFO                val. loss  250.5063 (mse_score: 250.5063) (*)\n",
      "11:10 madminer.utils.ml.sc INFO      Epoch 46: train loss 242.4941 (mse_score: 242.4941)\n",
      "11:10 madminer.utils.ml.sc INFO                val. loss  250.4556 (mse_score: 250.4556) (*)\n",
      "11:11 madminer.utils.ml.sc INFO      Epoch 47: train loss 243.0942 (mse_score: 243.0942)\n",
      "11:11 madminer.utils.ml.sc INFO                val. loss  250.4341 (mse_score: 250.4341) (*)\n",
      "11:11 madminer.utils.ml.sc INFO      Epoch 48: train loss 242.3065 (mse_score: 242.3065)\n",
      "11:11 madminer.utils.ml.sc INFO                val. loss  250.3953 (mse_score: 250.3953) (*)\n",
      "11:12 madminer.utils.ml.sc INFO      Epoch 49: train loss 242.2640 (mse_score: 242.2640)\n",
      "11:12 madminer.utils.ml.sc INFO                val. loss  250.2779 (mse_score: 250.2779) (*)\n",
      "11:12 madminer.utils.ml.sc INFO      Epoch 50: train loss 242.1675 (mse_score: 242.1675)\n",
      "11:12 madminer.utils.ml.sc INFO                val. loss  250.3441 (mse_score: 250.3441)\n",
      "11:12 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 250.28 compared to final loss 250.34\n",
      "11:12 madminer.utils.ml.sc INFO    Finished training\n",
      "11:12 madminer.ml          INFO    Training estimator 5 / 10 in ensemble\n",
      "11:12 madminer.ml          INFO    Starting training\n",
      "11:12 madminer.ml          INFO      Method:                 sally\n",
      "11:12 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_4.npy\n",
      "11:12 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_4.npy\n",
      "11:12 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "11:12 madminer.ml          INFO      Method:                 sally\n",
      "11:12 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "11:12 madminer.ml          INFO      Activation function:    tanh\n",
      "11:12 madminer.ml          INFO      Batch size:             128\n",
      "11:12 madminer.ml          INFO      Trainer:                amsgrad\n",
      "11:12 madminer.ml          INFO      Epochs:                 50\n",
      "11:12 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "11:12 madminer.ml          INFO      Validation split:       0.5\n",
      "11:12 madminer.ml          INFO      Early stopping:         True\n",
      "11:12 madminer.ml          INFO      Scale inputs:           True\n",
      "11:12 madminer.ml          INFO      Shuffle labels          False\n",
      "11:12 madminer.ml          INFO      Regularization:         None\n",
      "11:12 madminer.ml          INFO      Samples:                all\n",
      "11:12 madminer.ml          INFO    Loading training data\n",
      "11:12 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "11:12 madminer.ml          INFO    Rescaling inputs\n",
      "11:12 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "11:12 madminer.ml          INFO    Creating model for method sally\n",
      "11:12 madminer.ml          INFO    Training model\n",
      "11:13 madminer.utils.ml.sc INFO      Epoch 01: train loss 307.0377 (mse_score: 307.0377)\n",
      "11:13 madminer.utils.ml.sc INFO                val. loss  281.4778 (mse_score: 281.4778) (*)\n",
      "11:13 madminer.utils.ml.sc INFO      Epoch 02: train loss 291.2250 (mse_score: 291.2250)\n",
      "11:13 madminer.utils.ml.sc INFO                val. loss  274.4962 (mse_score: 274.4962) (*)\n",
      "11:14 madminer.utils.ml.sc INFO      Epoch 03: train loss 285.9065 (mse_score: 285.9065)\n",
      "11:14 madminer.utils.ml.sc INFO                val. loss  270.2357 (mse_score: 270.2357) (*)\n",
      "11:14 madminer.utils.ml.sc INFO      Epoch 04: train loss 282.5505 (mse_score: 282.5505)\n",
      "11:14 madminer.utils.ml.sc INFO                val. loss  269.1711 (mse_score: 269.1711) (*)\n",
      "11:15 madminer.utils.ml.sc INFO      Epoch 05: train loss 280.7402 (mse_score: 280.7402)\n",
      "11:15 madminer.utils.ml.sc INFO                val. loss  266.4666 (mse_score: 266.4666) (*)\n",
      "11:15 madminer.utils.ml.sc INFO      Epoch 06: train loss 279.4083 (mse_score: 279.4083)\n",
      "11:15 madminer.utils.ml.sc INFO                val. loss  265.4328 (mse_score: 265.4328) (*)\n",
      "11:16 madminer.utils.ml.sc INFO      Epoch 07: train loss 278.5548 (mse_score: 278.5548)\n",
      "11:16 madminer.utils.ml.sc INFO                val. loss  265.0035 (mse_score: 265.0035) (*)\n",
      "11:16 madminer.utils.ml.sc INFO      Epoch 08: train loss 277.6706 (mse_score: 277.6706)\n",
      "11:16 madminer.utils.ml.sc INFO                val. loss  263.8566 (mse_score: 263.8566) (*)\n",
      "11:17 madminer.utils.ml.sc INFO      Epoch 09: train loss 276.9772 (mse_score: 276.9772)\n",
      "11:17 madminer.utils.ml.sc INFO                val. loss  263.5917 (mse_score: 263.5917) (*)\n",
      "11:17 madminer.utils.ml.sc INFO      Epoch 10: train loss 276.2212 (mse_score: 276.2212)\n",
      "11:17 madminer.utils.ml.sc INFO                val. loss  263.3761 (mse_score: 263.3761) (*)\n",
      "11:17 madminer.utils.ml.sc INFO      Epoch 11: train loss 275.9044 (mse_score: 275.9044)\n",
      "11:17 madminer.utils.ml.sc INFO                val. loss  262.8459 (mse_score: 262.8459) (*)\n",
      "11:18 madminer.utils.ml.sc INFO      Epoch 12: train loss 275.2567 (mse_score: 275.2567)\n",
      "11:18 madminer.utils.ml.sc INFO                val. loss  261.8474 (mse_score: 261.8474) (*)\n",
      "11:18 madminer.utils.ml.sc INFO      Epoch 13: train loss 274.5499 (mse_score: 274.5499)\n",
      "11:18 madminer.utils.ml.sc INFO                val. loss  261.8119 (mse_score: 261.8119) (*)\n",
      "11:19 madminer.utils.ml.sc INFO      Epoch 14: train loss 273.9384 (mse_score: 273.9384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:19 madminer.utils.ml.sc INFO                val. loss  261.0609 (mse_score: 261.0609) (*)\n",
      "11:19 madminer.utils.ml.sc INFO      Epoch 15: train loss 273.4763 (mse_score: 273.4763)\n",
      "11:19 madminer.utils.ml.sc INFO                val. loss  260.7117 (mse_score: 260.7117) (*)\n",
      "11:20 madminer.utils.ml.sc INFO      Epoch 16: train loss 273.1857 (mse_score: 273.1857)\n",
      "11:20 madminer.utils.ml.sc INFO                val. loss  260.3391 (mse_score: 260.3391) (*)\n",
      "11:20 madminer.utils.ml.sc INFO      Epoch 17: train loss 272.5875 (mse_score: 272.5875)\n",
      "11:20 madminer.utils.ml.sc INFO                val. loss  260.1302 (mse_score: 260.1302) (*)\n",
      "11:20 madminer.utils.ml.sc INFO      Epoch 18: train loss 272.2164 (mse_score: 272.2164)\n",
      "11:20 madminer.utils.ml.sc INFO                val. loss  259.7524 (mse_score: 259.7524) (*)\n",
      "11:21 madminer.utils.ml.sc INFO      Epoch 19: train loss 271.8263 (mse_score: 271.8263)\n",
      "11:21 madminer.utils.ml.sc INFO                val. loss  259.7439 (mse_score: 259.7439) (*)\n",
      "11:21 madminer.utils.ml.sc INFO      Epoch 20: train loss 271.6429 (mse_score: 271.6429)\n",
      "11:21 madminer.utils.ml.sc INFO                val. loss  259.5506 (mse_score: 259.5506) (*)\n",
      "11:22 madminer.utils.ml.sc INFO      Epoch 21: train loss 271.3203 (mse_score: 271.3203)\n",
      "11:22 madminer.utils.ml.sc INFO                val. loss  259.3194 (mse_score: 259.3194) (*)\n",
      "11:22 madminer.utils.ml.sc INFO      Epoch 22: train loss 271.0876 (mse_score: 271.0876)\n",
      "11:22 madminer.utils.ml.sc INFO                val. loss  259.3045 (mse_score: 259.3045) (*)\n",
      "11:23 madminer.utils.ml.sc INFO      Epoch 23: train loss 270.9313 (mse_score: 270.9313)\n",
      "11:23 madminer.utils.ml.sc INFO                val. loss  259.0405 (mse_score: 259.0405) (*)\n",
      "11:23 madminer.utils.ml.sc INFO      Epoch 24: train loss 270.7200 (mse_score: 270.7200)\n",
      "11:23 madminer.utils.ml.sc INFO                val. loss  258.8400 (mse_score: 258.8400) (*)\n",
      "11:23 madminer.utils.ml.sc INFO      Epoch 25: train loss 270.4361 (mse_score: 270.4361)\n",
      "11:23 madminer.utils.ml.sc INFO                val. loss  258.7035 (mse_score: 258.7035) (*)\n",
      "11:24 madminer.utils.ml.sc INFO      Epoch 26: train loss 270.2028 (mse_score: 270.2028)\n",
      "11:24 madminer.utils.ml.sc INFO                val. loss  258.6635 (mse_score: 258.6635) (*)\n",
      "11:24 madminer.utils.ml.sc INFO      Epoch 27: train loss 270.1289 (mse_score: 270.1289)\n",
      "11:24 madminer.utils.ml.sc INFO                val. loss  258.8013 (mse_score: 258.8013)\n",
      "11:25 madminer.utils.ml.sc INFO      Epoch 28: train loss 269.9047 (mse_score: 269.9047)\n",
      "11:25 madminer.utils.ml.sc INFO                val. loss  258.6565 (mse_score: 258.6565) (*)\n",
      "11:25 madminer.utils.ml.sc INFO      Epoch 29: train loss 269.6908 (mse_score: 269.6908)\n",
      "11:25 madminer.utils.ml.sc INFO                val. loss  258.4428 (mse_score: 258.4428) (*)\n",
      "11:25 madminer.utils.ml.sc INFO      Epoch 30: train loss 269.5315 (mse_score: 269.5315)\n",
      "11:25 madminer.utils.ml.sc INFO                val. loss  258.4536 (mse_score: 258.4536)\n",
      "11:26 madminer.utils.ml.sc INFO      Epoch 31: train loss 269.5225 (mse_score: 269.5225)\n",
      "11:26 madminer.utils.ml.sc INFO                val. loss  258.1486 (mse_score: 258.1486) (*)\n",
      "11:26 madminer.utils.ml.sc INFO      Epoch 32: train loss 269.2247 (mse_score: 269.2247)\n",
      "11:26 madminer.utils.ml.sc INFO                val. loss  258.0777 (mse_score: 258.0777) (*)\n",
      "11:27 madminer.utils.ml.sc INFO      Epoch 33: train loss 269.1328 (mse_score: 269.1328)\n",
      "11:27 madminer.utils.ml.sc INFO                val. loss  258.2732 (mse_score: 258.2732)\n",
      "11:27 madminer.utils.ml.sc INFO      Epoch 34: train loss 269.1119 (mse_score: 269.1119)\n",
      "11:27 madminer.utils.ml.sc INFO                val. loss  258.0840 (mse_score: 258.0840)\n",
      "11:28 madminer.utils.ml.sc INFO      Epoch 35: train loss 268.9421 (mse_score: 268.9421)\n",
      "11:28 madminer.utils.ml.sc INFO                val. loss  257.8340 (mse_score: 257.8340) (*)\n",
      "11:28 madminer.utils.ml.sc INFO      Epoch 36: train loss 268.8018 (mse_score: 268.8018)\n",
      "11:28 madminer.utils.ml.sc INFO                val. loss  257.8136 (mse_score: 257.8136) (*)\n",
      "11:29 madminer.utils.ml.sc INFO      Epoch 37: train loss 268.5567 (mse_score: 268.5567)\n",
      "11:29 madminer.utils.ml.sc INFO                val. loss  257.7306 (mse_score: 257.7306) (*)\n",
      "11:29 madminer.utils.ml.sc INFO      Epoch 38: train loss 268.6674 (mse_score: 268.6674)\n",
      "11:29 madminer.utils.ml.sc INFO                val. loss  257.7625 (mse_score: 257.7625)\n",
      "11:30 madminer.utils.ml.sc INFO      Epoch 39: train loss 268.4913 (mse_score: 268.4913)\n",
      "11:30 madminer.utils.ml.sc INFO                val. loss  258.1318 (mse_score: 258.1318)\n",
      "11:30 madminer.utils.ml.sc INFO      Epoch 40: train loss 268.4261 (mse_score: 268.4261)\n",
      "11:30 madminer.utils.ml.sc INFO                val. loss  257.6301 (mse_score: 257.6301) (*)\n",
      "11:31 madminer.utils.ml.sc INFO      Epoch 41: train loss 268.2345 (mse_score: 268.2345)\n",
      "11:31 madminer.utils.ml.sc INFO                val. loss  257.6917 (mse_score: 257.6917)\n",
      "11:31 madminer.utils.ml.sc INFO      Epoch 42: train loss 268.1377 (mse_score: 268.1377)\n",
      "11:31 madminer.utils.ml.sc INFO                val. loss  257.5552 (mse_score: 257.5552) (*)\n",
      "11:32 madminer.utils.ml.sc INFO      Epoch 43: train loss 268.1074 (mse_score: 268.1074)\n",
      "11:32 madminer.utils.ml.sc INFO                val. loss  258.0004 (mse_score: 258.0004)\n",
      "11:32 madminer.utils.ml.sc INFO      Epoch 44: train loss 268.0350 (mse_score: 268.0350)\n",
      "11:32 madminer.utils.ml.sc INFO                val. loss  257.5814 (mse_score: 257.5814)\n",
      "11:33 madminer.utils.ml.sc INFO      Epoch 45: train loss 267.9147 (mse_score: 267.9147)\n",
      "11:33 madminer.utils.ml.sc INFO                val. loss  257.3925 (mse_score: 257.3925) (*)\n",
      "11:33 madminer.utils.ml.sc INFO      Epoch 46: train loss 267.8828 (mse_score: 267.8828)\n",
      "11:33 madminer.utils.ml.sc INFO                val. loss  257.5014 (mse_score: 257.5014)\n",
      "11:34 madminer.utils.ml.sc INFO      Epoch 47: train loss 267.8329 (mse_score: 267.8329)\n",
      "11:34 madminer.utils.ml.sc INFO                val. loss  257.4238 (mse_score: 257.4238)\n",
      "11:34 madminer.utils.ml.sc INFO      Epoch 48: train loss 267.8379 (mse_score: 267.8379)\n",
      "11:34 madminer.utils.ml.sc INFO                val. loss  257.3112 (mse_score: 257.3112) (*)\n",
      "11:35 madminer.utils.ml.sc INFO      Epoch 49: train loss 267.6726 (mse_score: 267.6726)\n",
      "11:35 madminer.utils.ml.sc INFO                val. loss  257.3699 (mse_score: 257.3699)\n",
      "11:36 madminer.utils.ml.sc INFO      Epoch 50: train loss 267.5680 (mse_score: 267.5680)\n",
      "11:36 madminer.utils.ml.sc INFO                val. loss  257.3927 (mse_score: 257.3927)\n",
      "11:36 madminer.utils.ml.sc INFO    Early stopping after epoch 48, with loss 257.31 compared to final loss 257.39\n",
      "11:36 madminer.utils.ml.sc INFO    Finished training\n",
      "11:36 madminer.ml          INFO    Training estimator 6 / 10 in ensemble\n",
      "11:36 madminer.ml          INFO    Starting training\n",
      "11:36 madminer.ml          INFO      Method:                 sally\n",
      "11:36 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_5.npy\n",
      "11:36 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_5.npy\n",
      "11:36 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "11:36 madminer.ml          INFO      Method:                 sally\n",
      "11:36 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "11:36 madminer.ml          INFO      Activation function:    tanh\n",
      "11:36 madminer.ml          INFO      Batch size:             128\n",
      "11:36 madminer.ml          INFO      Trainer:                amsgrad\n",
      "11:36 madminer.ml          INFO      Epochs:                 50\n",
      "11:36 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "11:36 madminer.ml          INFO      Validation split:       0.5\n",
      "11:36 madminer.ml          INFO      Early stopping:         True\n",
      "11:36 madminer.ml          INFO      Scale inputs:           True\n",
      "11:36 madminer.ml          INFO      Shuffle labels          False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:36 madminer.ml          INFO      Regularization:         None\n",
      "11:36 madminer.ml          INFO      Samples:                all\n",
      "11:36 madminer.ml          INFO    Loading training data\n",
      "11:36 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "11:36 madminer.ml          INFO    Rescaling inputs\n",
      "11:36 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "11:36 madminer.ml          INFO    Creating model for method sally\n",
      "11:36 madminer.ml          INFO    Training model\n",
      "11:36 madminer.utils.ml.sc INFO      Epoch 01: train loss 299.4335 (mse_score: 299.4335)\n",
      "11:36 madminer.utils.ml.sc INFO                val. loss  285.7895 (mse_score: 285.7895) (*)\n",
      "11:37 madminer.utils.ml.sc INFO      Epoch 02: train loss 284.2818 (mse_score: 284.2818)\n",
      "11:37 madminer.utils.ml.sc INFO                val. loss  280.3249 (mse_score: 280.3249) (*)\n",
      "11:37 madminer.utils.ml.sc INFO      Epoch 03: train loss 280.2498 (mse_score: 280.2498)\n",
      "11:37 madminer.utils.ml.sc INFO                val. loss  277.0274 (mse_score: 277.0274) (*)\n",
      "11:38 madminer.utils.ml.sc INFO      Epoch 04: train loss 277.5308 (mse_score: 277.5308)\n",
      "11:38 madminer.utils.ml.sc INFO                val. loss  274.6752 (mse_score: 274.6752) (*)\n",
      "11:38 madminer.utils.ml.sc INFO      Epoch 05: train loss 275.1960 (mse_score: 275.1960)\n",
      "11:38 madminer.utils.ml.sc INFO                val. loss  272.9836 (mse_score: 272.9836) (*)\n",
      "11:39 madminer.utils.ml.sc INFO      Epoch 06: train loss 274.0804 (mse_score: 274.0804)\n",
      "11:39 madminer.utils.ml.sc INFO                val. loss  271.8143 (mse_score: 271.8143) (*)\n",
      "11:40 madminer.utils.ml.sc INFO      Epoch 07: train loss 272.5451 (mse_score: 272.5451)\n",
      "11:40 madminer.utils.ml.sc INFO                val. loss  270.8432 (mse_score: 270.8432) (*)\n",
      "11:40 madminer.utils.ml.sc INFO      Epoch 08: train loss 271.9063 (mse_score: 271.9063)\n",
      "11:40 madminer.utils.ml.sc INFO                val. loss  270.4925 (mse_score: 270.4925) (*)\n",
      "11:41 madminer.utils.ml.sc INFO      Epoch 09: train loss 271.1763 (mse_score: 271.1763)\n",
      "11:41 madminer.utils.ml.sc INFO                val. loss  269.9524 (mse_score: 269.9524) (*)\n",
      "11:41 madminer.utils.ml.sc INFO      Epoch 10: train loss 270.5820 (mse_score: 270.5820)\n",
      "11:41 madminer.utils.ml.sc INFO                val. loss  269.5206 (mse_score: 269.5206) (*)\n",
      "11:42 madminer.utils.ml.sc INFO      Epoch 11: train loss 270.1750 (mse_score: 270.1750)\n",
      "11:42 madminer.utils.ml.sc INFO                val. loss  268.8867 (mse_score: 268.8867) (*)\n",
      "11:43 madminer.utils.ml.sc INFO      Epoch 12: train loss 269.7143 (mse_score: 269.7143)\n",
      "11:43 madminer.utils.ml.sc INFO                val. loss  268.6776 (mse_score: 268.6776) (*)\n",
      "11:43 madminer.utils.ml.sc INFO      Epoch 13: train loss 269.5360 (mse_score: 269.5360)\n",
      "11:43 madminer.utils.ml.sc INFO                val. loss  268.1738 (mse_score: 268.1738) (*)\n",
      "11:44 madminer.utils.ml.sc INFO      Epoch 14: train loss 268.7416 (mse_score: 268.7416)\n",
      "11:44 madminer.utils.ml.sc INFO                val. loss  268.1658 (mse_score: 268.1658) (*)\n",
      "11:44 madminer.utils.ml.sc INFO      Epoch 15: train loss 268.6981 (mse_score: 268.6981)\n",
      "11:44 madminer.utils.ml.sc INFO                val. loss  267.7765 (mse_score: 267.7765) (*)\n",
      "11:45 madminer.utils.ml.sc INFO      Epoch 16: train loss 267.9026 (mse_score: 267.9026)\n",
      "11:45 madminer.utils.ml.sc INFO                val. loss  267.2422 (mse_score: 267.2422) (*)\n",
      "11:45 madminer.utils.ml.sc INFO      Epoch 17: train loss 267.5584 (mse_score: 267.5584)\n",
      "11:45 madminer.utils.ml.sc INFO                val. loss  267.0516 (mse_score: 267.0516) (*)\n",
      "11:46 madminer.utils.ml.sc INFO      Epoch 18: train loss 267.2395 (mse_score: 267.2395)\n",
      "11:46 madminer.utils.ml.sc INFO                val. loss  266.5473 (mse_score: 266.5473) (*)\n",
      "11:47 madminer.utils.ml.sc INFO      Epoch 19: train loss 266.8498 (mse_score: 266.8498)\n",
      "11:47 madminer.utils.ml.sc INFO                val. loss  266.2331 (mse_score: 266.2331) (*)\n",
      "11:47 madminer.utils.ml.sc INFO      Epoch 20: train loss 266.3717 (mse_score: 266.3717)\n",
      "11:47 madminer.utils.ml.sc INFO                val. loss  266.2021 (mse_score: 266.2021) (*)\n",
      "11:47 madminer.utils.ml.sc INFO      Epoch 21: train loss 266.1851 (mse_score: 266.1851)\n",
      "11:47 madminer.utils.ml.sc INFO                val. loss  265.9958 (mse_score: 265.9958) (*)\n",
      "11:48 madminer.utils.ml.sc INFO      Epoch 22: train loss 265.8271 (mse_score: 265.8271)\n",
      "11:48 madminer.utils.ml.sc INFO                val. loss  265.9012 (mse_score: 265.9012) (*)\n",
      "11:48 madminer.utils.ml.sc INFO      Epoch 23: train loss 265.5180 (mse_score: 265.5180)\n",
      "11:48 madminer.utils.ml.sc INFO                val. loss  265.4594 (mse_score: 265.4594) (*)\n",
      "11:49 madminer.utils.ml.sc INFO      Epoch 24: train loss 265.3022 (mse_score: 265.3022)\n",
      "11:49 madminer.utils.ml.sc INFO                val. loss  265.3736 (mse_score: 265.3736) (*)\n",
      "11:49 madminer.utils.ml.sc INFO      Epoch 25: train loss 265.0014 (mse_score: 265.0014)\n",
      "11:49 madminer.utils.ml.sc INFO                val. loss  265.4183 (mse_score: 265.4183)\n",
      "11:50 madminer.utils.ml.sc INFO      Epoch 26: train loss 264.7300 (mse_score: 264.7300)\n",
      "11:50 madminer.utils.ml.sc INFO                val. loss  265.2959 (mse_score: 265.2959) (*)\n",
      "11:50 madminer.utils.ml.sc INFO      Epoch 27: train loss 264.5691 (mse_score: 264.5691)\n",
      "11:50 madminer.utils.ml.sc INFO                val. loss  264.9458 (mse_score: 264.9458) (*)\n",
      "11:51 madminer.utils.ml.sc INFO      Epoch 28: train loss 264.3805 (mse_score: 264.3805)\n",
      "11:51 madminer.utils.ml.sc INFO                val. loss  264.8772 (mse_score: 264.8772) (*)\n",
      "11:51 madminer.utils.ml.sc INFO      Epoch 29: train loss 264.2124 (mse_score: 264.2124)\n",
      "11:51 madminer.utils.ml.sc INFO                val. loss  264.6487 (mse_score: 264.6487) (*)\n",
      "11:52 madminer.utils.ml.sc INFO      Epoch 30: train loss 263.9966 (mse_score: 263.9966)\n",
      "11:52 madminer.utils.ml.sc INFO                val. loss  264.6604 (mse_score: 264.6604)\n",
      "11:52 madminer.utils.ml.sc INFO      Epoch 31: train loss 263.8754 (mse_score: 263.8754)\n",
      "11:52 madminer.utils.ml.sc INFO                val. loss  264.6429 (mse_score: 264.6429) (*)\n",
      "11:53 madminer.utils.ml.sc INFO      Epoch 32: train loss 263.7283 (mse_score: 263.7283)\n",
      "11:53 madminer.utils.ml.sc INFO                val. loss  264.6624 (mse_score: 264.6624)\n",
      "11:53 madminer.utils.ml.sc INFO      Epoch 33: train loss 263.5614 (mse_score: 263.5614)\n",
      "11:53 madminer.utils.ml.sc INFO                val. loss  264.2526 (mse_score: 264.2526) (*)\n",
      "11:54 madminer.utils.ml.sc INFO      Epoch 34: train loss 263.3759 (mse_score: 263.3759)\n",
      "11:54 madminer.utils.ml.sc INFO                val. loss  264.3363 (mse_score: 264.3363)\n",
      "11:54 madminer.utils.ml.sc INFO      Epoch 35: train loss 263.2766 (mse_score: 263.2766)\n",
      "11:54 madminer.utils.ml.sc INFO                val. loss  264.4456 (mse_score: 264.4456)\n",
      "11:55 madminer.utils.ml.sc INFO      Epoch 36: train loss 263.2128 (mse_score: 263.2128)\n",
      "11:55 madminer.utils.ml.sc INFO                val. loss  264.0729 (mse_score: 264.0729) (*)\n",
      "11:55 madminer.utils.ml.sc INFO      Epoch 37: train loss 263.0338 (mse_score: 263.0338)\n",
      "11:55 madminer.utils.ml.sc INFO                val. loss  264.1392 (mse_score: 264.1392)\n",
      "11:55 madminer.utils.ml.sc INFO      Epoch 38: train loss 263.0197 (mse_score: 263.0197)\n",
      "11:55 madminer.utils.ml.sc INFO                val. loss  263.9784 (mse_score: 263.9784) (*)\n",
      "11:56 madminer.utils.ml.sc INFO      Epoch 39: train loss 262.7944 (mse_score: 262.7944)\n",
      "11:56 madminer.utils.ml.sc INFO                val. loss  264.1550 (mse_score: 264.1550)\n",
      "11:56 madminer.utils.ml.sc INFO      Epoch 40: train loss 262.6884 (mse_score: 262.6884)\n",
      "11:56 madminer.utils.ml.sc INFO                val. loss  264.0235 (mse_score: 264.0235)\n",
      "11:57 madminer.utils.ml.sc INFO      Epoch 41: train loss 262.6108 (mse_score: 262.6108)\n",
      "11:57 madminer.utils.ml.sc INFO                val. loss  263.7765 (mse_score: 263.7765) (*)\n",
      "11:57 madminer.utils.ml.sc INFO      Epoch 42: train loss 262.5198 (mse_score: 262.5198)\n",
      "11:57 madminer.utils.ml.sc INFO                val. loss  263.9095 (mse_score: 263.9095)\n",
      "11:58 madminer.utils.ml.sc INFO      Epoch 43: train loss 262.4249 (mse_score: 262.4249)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:58 madminer.utils.ml.sc INFO                val. loss  263.7023 (mse_score: 263.7023) (*)\n",
      "11:58 madminer.utils.ml.sc INFO      Epoch 44: train loss 262.3375 (mse_score: 262.3375)\n",
      "11:58 madminer.utils.ml.sc INFO                val. loss  263.7404 (mse_score: 263.7404)\n",
      "11:59 madminer.utils.ml.sc INFO      Epoch 45: train loss 262.2519 (mse_score: 262.2519)\n",
      "11:59 madminer.utils.ml.sc INFO                val. loss  263.7456 (mse_score: 263.7456)\n",
      "11:59 madminer.utils.ml.sc INFO      Epoch 46: train loss 262.2176 (mse_score: 262.2176)\n",
      "11:59 madminer.utils.ml.sc INFO                val. loss  263.7147 (mse_score: 263.7147)\n",
      "12:00 madminer.utils.ml.sc INFO      Epoch 47: train loss 262.0809 (mse_score: 262.0809)\n",
      "12:00 madminer.utils.ml.sc INFO                val. loss  263.6410 (mse_score: 263.6410) (*)\n",
      "12:01 madminer.utils.ml.sc INFO      Epoch 48: train loss 262.2684 (mse_score: 262.2684)\n",
      "12:01 madminer.utils.ml.sc INFO                val. loss  263.7691 (mse_score: 263.7691)\n",
      "12:01 madminer.utils.ml.sc INFO      Epoch 49: train loss 262.0702 (mse_score: 262.0702)\n",
      "12:01 madminer.utils.ml.sc INFO                val. loss  263.6054 (mse_score: 263.6054) (*)\n",
      "12:02 madminer.utils.ml.sc INFO      Epoch 50: train loss 261.9236 (mse_score: 261.9236)\n",
      "12:02 madminer.utils.ml.sc INFO                val. loss  263.6192 (mse_score: 263.6192)\n",
      "12:02 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 263.61 compared to final loss 263.62\n",
      "12:02 madminer.utils.ml.sc INFO    Finished training\n",
      "12:02 madminer.ml          INFO    Training estimator 7 / 10 in ensemble\n",
      "12:02 madminer.ml          INFO    Starting training\n",
      "12:02 madminer.ml          INFO      Method:                 sally\n",
      "12:02 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_6.npy\n",
      "12:02 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_6.npy\n",
      "12:02 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "12:02 madminer.ml          INFO      Method:                 sally\n",
      "12:02 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "12:02 madminer.ml          INFO      Activation function:    tanh\n",
      "12:02 madminer.ml          INFO      Batch size:             128\n",
      "12:02 madminer.ml          INFO      Trainer:                amsgrad\n",
      "12:02 madminer.ml          INFO      Epochs:                 50\n",
      "12:02 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "12:02 madminer.ml          INFO      Validation split:       0.5\n",
      "12:02 madminer.ml          INFO      Early stopping:         True\n",
      "12:02 madminer.ml          INFO      Scale inputs:           True\n",
      "12:02 madminer.ml          INFO      Shuffle labels          False\n",
      "12:02 madminer.ml          INFO      Regularization:         None\n",
      "12:02 madminer.ml          INFO      Samples:                all\n",
      "12:02 madminer.ml          INFO    Loading training data\n",
      "12:02 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "12:02 madminer.ml          INFO    Rescaling inputs\n",
      "12:02 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "12:02 madminer.ml          INFO    Creating model for method sally\n",
      "12:02 madminer.ml          INFO    Training model\n",
      "12:02 madminer.utils.ml.sc INFO      Epoch 01: train loss 293.2033 (mse_score: 293.2033)\n",
      "12:02 madminer.utils.ml.sc INFO                val. loss  267.4144 (mse_score: 267.4144) (*)\n",
      "12:03 madminer.utils.ml.sc INFO      Epoch 02: train loss 277.2714 (mse_score: 277.2714)\n",
      "12:03 madminer.utils.ml.sc INFO                val. loss  260.0523 (mse_score: 260.0523) (*)\n",
      "12:04 madminer.utils.ml.sc INFO      Epoch 03: train loss 271.8389 (mse_score: 271.8389)\n",
      "12:04 madminer.utils.ml.sc INFO                val. loss  255.7891 (mse_score: 255.7891) (*)\n",
      "12:04 madminer.utils.ml.sc INFO      Epoch 04: train loss 268.1779 (mse_score: 268.1779)\n",
      "12:04 madminer.utils.ml.sc INFO                val. loss  254.0423 (mse_score: 254.0423) (*)\n",
      "12:05 madminer.utils.ml.sc INFO      Epoch 05: train loss 266.2669 (mse_score: 266.2669)\n",
      "12:05 madminer.utils.ml.sc INFO                val. loss  252.1330 (mse_score: 252.1330) (*)\n",
      "12:05 madminer.utils.ml.sc INFO      Epoch 06: train loss 265.0624 (mse_score: 265.0624)\n",
      "12:05 madminer.utils.ml.sc INFO                val. loss  251.2647 (mse_score: 251.2647) (*)\n",
      "12:06 madminer.utils.ml.sc INFO      Epoch 07: train loss 264.1831 (mse_score: 264.1831)\n",
      "12:06 madminer.utils.ml.sc INFO                val. loss  250.4305 (mse_score: 250.4305) (*)\n",
      "12:07 madminer.utils.ml.sc INFO      Epoch 08: train loss 263.2703 (mse_score: 263.2703)\n",
      "12:07 madminer.utils.ml.sc INFO                val. loss  249.6740 (mse_score: 249.6740) (*)\n",
      "12:07 madminer.utils.ml.sc INFO      Epoch 09: train loss 262.8053 (mse_score: 262.8053)\n",
      "12:07 madminer.utils.ml.sc INFO                val. loss  249.2392 (mse_score: 249.2392) (*)\n",
      "12:08 madminer.utils.ml.sc INFO      Epoch 10: train loss 262.1045 (mse_score: 262.1045)\n",
      "12:08 madminer.utils.ml.sc INFO                val. loss  248.8905 (mse_score: 248.8905) (*)\n",
      "12:08 madminer.utils.ml.sc INFO      Epoch 11: train loss 261.5265 (mse_score: 261.5265)\n",
      "12:08 madminer.utils.ml.sc INFO                val. loss  248.5106 (mse_score: 248.5106) (*)\n",
      "12:09 madminer.utils.ml.sc INFO      Epoch 12: train loss 261.1410 (mse_score: 261.1410)\n",
      "12:09 madminer.utils.ml.sc INFO                val. loss  248.2657 (mse_score: 248.2657) (*)\n",
      "12:10 madminer.utils.ml.sc INFO      Epoch 13: train loss 260.3054 (mse_score: 260.3054)\n",
      "12:10 madminer.utils.ml.sc INFO                val. loss  247.8266 (mse_score: 247.8266) (*)\n",
      "12:10 madminer.utils.ml.sc INFO      Epoch 14: train loss 259.7696 (mse_score: 259.7696)\n",
      "12:10 madminer.utils.ml.sc INFO                val. loss  247.4275 (mse_score: 247.4275) (*)\n",
      "12:11 madminer.utils.ml.sc INFO      Epoch 15: train loss 259.1578 (mse_score: 259.1578)\n",
      "12:11 madminer.utils.ml.sc INFO                val. loss  246.9557 (mse_score: 246.9557) (*)\n",
      "12:11 madminer.utils.ml.sc INFO      Epoch 16: train loss 258.7020 (mse_score: 258.7020)\n",
      "12:11 madminer.utils.ml.sc INFO                val. loss  246.6284 (mse_score: 246.6284) (*)\n",
      "12:12 madminer.utils.ml.sc INFO      Epoch 17: train loss 258.2958 (mse_score: 258.2958)\n",
      "12:12 madminer.utils.ml.sc INFO                val. loss  246.1862 (mse_score: 246.1862) (*)\n",
      "12:13 madminer.utils.ml.sc INFO      Epoch 18: train loss 257.8499 (mse_score: 257.8499)\n",
      "12:13 madminer.utils.ml.sc INFO                val. loss  245.9667 (mse_score: 245.9667) (*)\n",
      "12:13 madminer.utils.ml.sc INFO      Epoch 19: train loss 257.4604 (mse_score: 257.4604)\n",
      "12:13 madminer.utils.ml.sc INFO                val. loss  245.5653 (mse_score: 245.5653) (*)\n",
      "12:14 madminer.utils.ml.sc INFO      Epoch 20: train loss 257.1328 (mse_score: 257.1328)\n",
      "12:14 madminer.utils.ml.sc INFO                val. loss  245.6890 (mse_score: 245.6890)\n",
      "12:15 madminer.utils.ml.sc INFO      Epoch 21: train loss 256.8201 (mse_score: 256.8201)\n",
      "12:15 madminer.utils.ml.sc INFO                val. loss  245.3621 (mse_score: 245.3621) (*)\n",
      "12:15 madminer.utils.ml.sc INFO      Epoch 22: train loss 256.5266 (mse_score: 256.5266)\n",
      "12:15 madminer.utils.ml.sc INFO                val. loss  245.1271 (mse_score: 245.1271) (*)\n",
      "12:16 madminer.utils.ml.sc INFO      Epoch 23: train loss 256.2285 (mse_score: 256.2285)\n",
      "12:16 madminer.utils.ml.sc INFO                val. loss  245.2223 (mse_score: 245.2223)\n",
      "12:16 madminer.utils.ml.sc INFO      Epoch 24: train loss 255.9663 (mse_score: 255.9663)\n",
      "12:16 madminer.utils.ml.sc INFO                val. loss  244.8137 (mse_score: 244.8137) (*)\n",
      "12:17 madminer.utils.ml.sc INFO      Epoch 25: train loss 255.7445 (mse_score: 255.7445)\n",
      "12:17 madminer.utils.ml.sc INFO                val. loss  245.0548 (mse_score: 245.0548)\n",
      "12:17 madminer.utils.ml.sc INFO      Epoch 26: train loss 255.4951 (mse_score: 255.4951)\n",
      "12:17 madminer.utils.ml.sc INFO                val. loss  244.5966 (mse_score: 244.5966) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:18 madminer.utils.ml.sc INFO      Epoch 27: train loss 255.3675 (mse_score: 255.3675)\n",
      "12:18 madminer.utils.ml.sc INFO                val. loss  244.3984 (mse_score: 244.3984) (*)\n",
      "12:19 madminer.utils.ml.sc INFO      Epoch 28: train loss 255.0921 (mse_score: 255.0921)\n",
      "12:19 madminer.utils.ml.sc INFO                val. loss  244.4713 (mse_score: 244.4713)\n",
      "12:19 madminer.utils.ml.sc INFO      Epoch 29: train loss 254.8748 (mse_score: 254.8748)\n",
      "12:19 madminer.utils.ml.sc INFO                val. loss  244.5901 (mse_score: 244.5901)\n",
      "12:20 madminer.utils.ml.sc INFO      Epoch 30: train loss 254.7202 (mse_score: 254.7202)\n",
      "12:20 madminer.utils.ml.sc INFO                val. loss  244.3342 (mse_score: 244.3342) (*)\n",
      "12:20 madminer.utils.ml.sc INFO      Epoch 31: train loss 254.5546 (mse_score: 254.5546)\n",
      "12:20 madminer.utils.ml.sc INFO                val. loss  244.1192 (mse_score: 244.1192) (*)\n",
      "12:21 madminer.utils.ml.sc INFO      Epoch 32: train loss 254.4878 (mse_score: 254.4878)\n",
      "12:21 madminer.utils.ml.sc INFO                val. loss  244.0332 (mse_score: 244.0332) (*)\n",
      "12:22 madminer.utils.ml.sc INFO      Epoch 33: train loss 254.2772 (mse_score: 254.2772)\n",
      "12:22 madminer.utils.ml.sc INFO                val. loss  243.9916 (mse_score: 243.9916) (*)\n",
      "12:22 madminer.utils.ml.sc INFO      Epoch 34: train loss 254.2231 (mse_score: 254.2231)\n",
      "12:22 madminer.utils.ml.sc INFO                val. loss  243.8299 (mse_score: 243.8299) (*)\n",
      "12:23 madminer.utils.ml.sc INFO      Epoch 35: train loss 253.9775 (mse_score: 253.9775)\n",
      "12:23 madminer.utils.ml.sc INFO                val. loss  243.8331 (mse_score: 243.8331)\n",
      "12:24 madminer.utils.ml.sc INFO      Epoch 36: train loss 253.9116 (mse_score: 253.9116)\n",
      "12:24 madminer.utils.ml.sc INFO                val. loss  243.7136 (mse_score: 243.7136) (*)\n",
      "12:24 madminer.utils.ml.sc INFO      Epoch 37: train loss 253.7791 (mse_score: 253.7791)\n",
      "12:24 madminer.utils.ml.sc INFO                val. loss  243.6131 (mse_score: 243.6131) (*)\n",
      "12:25 madminer.utils.ml.sc INFO      Epoch 38: train loss 253.6052 (mse_score: 253.6052)\n",
      "12:25 madminer.utils.ml.sc INFO                val. loss  243.6118 (mse_score: 243.6118) (*)\n",
      "12:26 madminer.utils.ml.sc INFO      Epoch 39: train loss 253.5678 (mse_score: 253.5678)\n",
      "12:26 madminer.utils.ml.sc INFO                val. loss  243.4575 (mse_score: 243.4575) (*)\n",
      "12:26 madminer.utils.ml.sc INFO      Epoch 40: train loss 253.3946 (mse_score: 253.3946)\n",
      "12:26 madminer.utils.ml.sc INFO                val. loss  243.4783 (mse_score: 243.4783)\n",
      "12:27 madminer.utils.ml.sc INFO      Epoch 41: train loss 253.3734 (mse_score: 253.3734)\n",
      "12:27 madminer.utils.ml.sc INFO                val. loss  243.4325 (mse_score: 243.4325) (*)\n",
      "12:27 madminer.utils.ml.sc INFO      Epoch 42: train loss 253.2709 (mse_score: 253.2709)\n",
      "12:27 madminer.utils.ml.sc INFO                val. loss  243.3979 (mse_score: 243.3979) (*)\n",
      "12:28 madminer.utils.ml.sc INFO      Epoch 43: train loss 253.2150 (mse_score: 253.2150)\n",
      "12:28 madminer.utils.ml.sc INFO                val. loss  243.4631 (mse_score: 243.4631)\n",
      "12:28 madminer.utils.ml.sc INFO      Epoch 44: train loss 253.0330 (mse_score: 253.0330)\n",
      "12:28 madminer.utils.ml.sc INFO                val. loss  243.3557 (mse_score: 243.3557) (*)\n",
      "12:29 madminer.utils.ml.sc INFO      Epoch 45: train loss 253.0498 (mse_score: 253.0498)\n",
      "12:29 madminer.utils.ml.sc INFO                val. loss  243.2674 (mse_score: 243.2674) (*)\n",
      "12:29 madminer.utils.ml.sc INFO      Epoch 46: train loss 252.9354 (mse_score: 252.9354)\n",
      "12:29 madminer.utils.ml.sc INFO                val. loss  243.2042 (mse_score: 243.2042) (*)\n",
      "12:30 madminer.utils.ml.sc INFO      Epoch 47: train loss 253.0037 (mse_score: 253.0037)\n",
      "12:30 madminer.utils.ml.sc INFO                val. loss  243.2881 (mse_score: 243.2881)\n",
      "12:30 madminer.utils.ml.sc INFO      Epoch 48: train loss 252.7984 (mse_score: 252.7984)\n",
      "12:30 madminer.utils.ml.sc INFO                val. loss  243.1831 (mse_score: 243.1831) (*)\n",
      "12:31 madminer.utils.ml.sc INFO      Epoch 49: train loss 252.6695 (mse_score: 252.6695)\n",
      "12:31 madminer.utils.ml.sc INFO                val. loss  243.1440 (mse_score: 243.1440) (*)\n",
      "12:31 madminer.utils.ml.sc INFO      Epoch 50: train loss 252.7837 (mse_score: 252.7837)\n",
      "12:31 madminer.utils.ml.sc INFO                val. loss  243.1646 (mse_score: 243.1646)\n",
      "12:31 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 243.14 compared to final loss 243.16\n",
      "12:31 madminer.utils.ml.sc INFO    Finished training\n",
      "12:31 madminer.ml          INFO    Training estimator 8 / 10 in ensemble\n",
      "12:31 madminer.ml          INFO    Starting training\n",
      "12:31 madminer.ml          INFO      Method:                 sally\n",
      "12:31 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_7.npy\n",
      "12:31 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_7.npy\n",
      "12:31 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "12:31 madminer.ml          INFO      Method:                 sally\n",
      "12:31 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "12:31 madminer.ml          INFO      Activation function:    tanh\n",
      "12:31 madminer.ml          INFO      Batch size:             128\n",
      "12:31 madminer.ml          INFO      Trainer:                amsgrad\n",
      "12:31 madminer.ml          INFO      Epochs:                 50\n",
      "12:31 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "12:31 madminer.ml          INFO      Validation split:       0.5\n",
      "12:31 madminer.ml          INFO      Early stopping:         True\n",
      "12:31 madminer.ml          INFO      Scale inputs:           True\n",
      "12:31 madminer.ml          INFO      Shuffle labels          False\n",
      "12:31 madminer.ml          INFO      Regularization:         None\n",
      "12:31 madminer.ml          INFO      Samples:                all\n",
      "12:31 madminer.ml          INFO    Loading training data\n",
      "12:31 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "12:31 madminer.ml          INFO    Rescaling inputs\n",
      "12:31 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "12:31 madminer.ml          INFO    Creating model for method sally\n",
      "12:31 madminer.ml          INFO    Training model\n",
      "12:32 madminer.utils.ml.sc INFO      Epoch 01: train loss 294.3410 (mse_score: 294.3410)\n",
      "12:32 madminer.utils.ml.sc INFO                val. loss  290.1176 (mse_score: 290.1176) (*)\n",
      "12:32 madminer.utils.ml.sc INFO      Epoch 02: train loss 278.7967 (mse_score: 278.7967)\n",
      "12:32 madminer.utils.ml.sc INFO                val. loss  283.5688 (mse_score: 283.5688) (*)\n",
      "12:33 madminer.utils.ml.sc INFO      Epoch 03: train loss 273.3383 (mse_score: 273.3383)\n",
      "12:33 madminer.utils.ml.sc INFO                val. loss  278.9233 (mse_score: 278.9233) (*)\n",
      "12:33 madminer.utils.ml.sc INFO      Epoch 04: train loss 269.7601 (mse_score: 269.7601)\n",
      "12:33 madminer.utils.ml.sc INFO                val. loss  275.9579 (mse_score: 275.9579) (*)\n",
      "12:34 madminer.utils.ml.sc INFO      Epoch 05: train loss 267.7586 (mse_score: 267.7586)\n",
      "12:34 madminer.utils.ml.sc INFO                val. loss  274.5538 (mse_score: 274.5538) (*)\n",
      "12:34 madminer.utils.ml.sc INFO      Epoch 06: train loss 266.3169 (mse_score: 266.3169)\n",
      "12:34 madminer.utils.ml.sc INFO                val. loss  273.8730 (mse_score: 273.8730) (*)\n",
      "12:35 madminer.utils.ml.sc INFO      Epoch 07: train loss 265.5526 (mse_score: 265.5526)\n",
      "12:35 madminer.utils.ml.sc INFO                val. loss  272.9523 (mse_score: 272.9523) (*)\n",
      "12:35 madminer.utils.ml.sc INFO      Epoch 08: train loss 264.7607 (mse_score: 264.7607)\n",
      "12:35 madminer.utils.ml.sc INFO                val. loss  272.4550 (mse_score: 272.4550) (*)\n",
      "12:36 madminer.utils.ml.sc INFO      Epoch 09: train loss 264.1050 (mse_score: 264.1050)\n",
      "12:36 madminer.utils.ml.sc INFO                val. loss  272.0546 (mse_score: 272.0546) (*)\n",
      "12:37 madminer.utils.ml.sc INFO      Epoch 10: train loss 263.6098 (mse_score: 263.6098)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37 madminer.utils.ml.sc INFO                val. loss  271.6597 (mse_score: 271.6597) (*)\n",
      "12:37 madminer.utils.ml.sc INFO      Epoch 11: train loss 263.0197 (mse_score: 263.0197)\n",
      "12:37 madminer.utils.ml.sc INFO                val. loss  271.1023 (mse_score: 271.1023) (*)\n",
      "12:38 madminer.utils.ml.sc INFO      Epoch 12: train loss 262.3673 (mse_score: 262.3673)\n",
      "12:38 madminer.utils.ml.sc INFO                val. loss  270.6781 (mse_score: 270.6781) (*)\n",
      "12:38 madminer.utils.ml.sc INFO      Epoch 13: train loss 261.8813 (mse_score: 261.8813)\n",
      "12:38 madminer.utils.ml.sc INFO                val. loss  270.8273 (mse_score: 270.8273)\n",
      "12:39 madminer.utils.ml.sc INFO      Epoch 14: train loss 261.3288 (mse_score: 261.3288)\n",
      "12:39 madminer.utils.ml.sc INFO                val. loss  269.6891 (mse_score: 269.6891) (*)\n",
      "12:40 madminer.utils.ml.sc INFO      Epoch 15: train loss 260.7404 (mse_score: 260.7404)\n",
      "12:40 madminer.utils.ml.sc INFO                val. loss  269.4254 (mse_score: 269.4254) (*)\n",
      "12:40 madminer.utils.ml.sc INFO      Epoch 16: train loss 260.3321 (mse_score: 260.3321)\n",
      "12:40 madminer.utils.ml.sc INFO                val. loss  269.0913 (mse_score: 269.0913) (*)\n",
      "12:41 madminer.utils.ml.sc INFO      Epoch 17: train loss 259.9280 (mse_score: 259.9280)\n",
      "12:41 madminer.utils.ml.sc INFO                val. loss  269.0091 (mse_score: 269.0091) (*)\n",
      "12:41 madminer.utils.ml.sc INFO      Epoch 18: train loss 259.6316 (mse_score: 259.6316)\n",
      "12:41 madminer.utils.ml.sc INFO                val. loss  268.7161 (mse_score: 268.7161) (*)\n",
      "12:42 madminer.utils.ml.sc INFO      Epoch 19: train loss 259.2393 (mse_score: 259.2393)\n",
      "12:42 madminer.utils.ml.sc INFO                val. loss  268.5354 (mse_score: 268.5354) (*)\n",
      "12:42 madminer.utils.ml.sc INFO      Epoch 20: train loss 259.0198 (mse_score: 259.0198)\n",
      "12:42 madminer.utils.ml.sc INFO                val. loss  268.1618 (mse_score: 268.1618) (*)\n",
      "12:43 madminer.utils.ml.sc INFO      Epoch 21: train loss 258.7695 (mse_score: 258.7695)\n",
      "12:43 madminer.utils.ml.sc INFO                val. loss  268.1676 (mse_score: 268.1676)\n",
      "12:44 madminer.utils.ml.sc INFO      Epoch 22: train loss 258.4309 (mse_score: 258.4309)\n",
      "12:44 madminer.utils.ml.sc INFO                val. loss  267.7419 (mse_score: 267.7419) (*)\n",
      "12:44 madminer.utils.ml.sc INFO      Epoch 23: train loss 258.2497 (mse_score: 258.2497)\n",
      "12:44 madminer.utils.ml.sc INFO                val. loss  267.4867 (mse_score: 267.4867) (*)\n",
      "12:45 madminer.utils.ml.sc INFO      Epoch 24: train loss 258.0042 (mse_score: 258.0042)\n",
      "12:45 madminer.utils.ml.sc INFO                val. loss  267.5038 (mse_score: 267.5038)\n",
      "12:45 madminer.utils.ml.sc INFO      Epoch 25: train loss 257.7112 (mse_score: 257.7112)\n",
      "12:45 madminer.utils.ml.sc INFO                val. loss  267.4122 (mse_score: 267.4122) (*)\n",
      "12:46 madminer.utils.ml.sc INFO      Epoch 26: train loss 257.5840 (mse_score: 257.5840)\n",
      "12:46 madminer.utils.ml.sc INFO                val. loss  267.3356 (mse_score: 267.3356) (*)\n",
      "12:46 madminer.utils.ml.sc INFO      Epoch 27: train loss 257.3224 (mse_score: 257.3224)\n",
      "12:46 madminer.utils.ml.sc INFO                val. loss  267.2200 (mse_score: 267.2200) (*)\n",
      "12:47 madminer.utils.ml.sc INFO      Epoch 28: train loss 257.1628 (mse_score: 257.1628)\n",
      "12:47 madminer.utils.ml.sc INFO                val. loss  266.9587 (mse_score: 266.9587) (*)\n",
      "12:47 madminer.utils.ml.sc INFO      Epoch 29: train loss 256.9023 (mse_score: 256.9023)\n",
      "12:47 madminer.utils.ml.sc INFO                val. loss  267.0296 (mse_score: 267.0296)\n",
      "12:48 madminer.utils.ml.sc INFO      Epoch 30: train loss 256.6330 (mse_score: 256.6330)\n",
      "12:48 madminer.utils.ml.sc INFO                val. loss  266.9005 (mse_score: 266.9005) (*)\n",
      "12:49 madminer.utils.ml.sc INFO      Epoch 31: train loss 256.6342 (mse_score: 256.6342)\n",
      "12:49 madminer.utils.ml.sc INFO                val. loss  266.6320 (mse_score: 266.6320) (*)\n",
      "12:49 madminer.utils.ml.sc INFO      Epoch 32: train loss 256.4152 (mse_score: 256.4152)\n",
      "12:49 madminer.utils.ml.sc INFO                val. loss  266.8091 (mse_score: 266.8091)\n",
      "12:50 madminer.utils.ml.sc INFO      Epoch 33: train loss 256.3298 (mse_score: 256.3298)\n",
      "12:50 madminer.utils.ml.sc INFO                val. loss  266.8141 (mse_score: 266.8141)\n",
      "12:50 madminer.utils.ml.sc INFO      Epoch 34: train loss 256.1792 (mse_score: 256.1792)\n",
      "12:50 madminer.utils.ml.sc INFO                val. loss  266.5435 (mse_score: 266.5435) (*)\n",
      "12:51 madminer.utils.ml.sc INFO      Epoch 35: train loss 256.0610 (mse_score: 256.0610)\n",
      "12:51 madminer.utils.ml.sc INFO                val. loss  266.4840 (mse_score: 266.4840) (*)\n",
      "12:51 madminer.utils.ml.sc INFO      Epoch 36: train loss 255.9054 (mse_score: 255.9054)\n",
      "12:51 madminer.utils.ml.sc INFO                val. loss  266.3308 (mse_score: 266.3308) (*)\n",
      "12:52 madminer.utils.ml.sc INFO      Epoch 37: train loss 255.7605 (mse_score: 255.7605)\n",
      "12:52 madminer.utils.ml.sc INFO                val. loss  266.5276 (mse_score: 266.5276)\n",
      "12:52 madminer.utils.ml.sc INFO      Epoch 38: train loss 255.6800 (mse_score: 255.6800)\n",
      "12:52 madminer.utils.ml.sc INFO                val. loss  266.2251 (mse_score: 266.2251) (*)\n",
      "12:53 madminer.utils.ml.sc INFO      Epoch 39: train loss 255.5528 (mse_score: 255.5528)\n",
      "12:53 madminer.utils.ml.sc INFO                val. loss  266.1471 (mse_score: 266.1471) (*)\n",
      "12:53 madminer.utils.ml.sc INFO      Epoch 40: train loss 255.4767 (mse_score: 255.4767)\n",
      "12:53 madminer.utils.ml.sc INFO                val. loss  266.1830 (mse_score: 266.1830)\n",
      "12:54 madminer.utils.ml.sc INFO      Epoch 41: train loss 255.3166 (mse_score: 255.3166)\n",
      "12:54 madminer.utils.ml.sc INFO                val. loss  266.0119 (mse_score: 266.0119) (*)\n",
      "12:55 madminer.utils.ml.sc INFO      Epoch 42: train loss 255.3267 (mse_score: 255.3267)\n",
      "12:55 madminer.utils.ml.sc INFO                val. loss  265.9702 (mse_score: 265.9702) (*)\n",
      "12:55 madminer.utils.ml.sc INFO      Epoch 43: train loss 255.1812 (mse_score: 255.1812)\n",
      "12:55 madminer.utils.ml.sc INFO                val. loss  265.8887 (mse_score: 265.8887) (*)\n",
      "12:56 madminer.utils.ml.sc INFO      Epoch 44: train loss 255.1248 (mse_score: 255.1248)\n",
      "12:56 madminer.utils.ml.sc INFO                val. loss  265.8395 (mse_score: 265.8395) (*)\n",
      "12:56 madminer.utils.ml.sc INFO      Epoch 45: train loss 254.9643 (mse_score: 254.9643)\n",
      "12:56 madminer.utils.ml.sc INFO                val. loss  265.9198 (mse_score: 265.9198)\n",
      "12:57 madminer.utils.ml.sc INFO      Epoch 46: train loss 254.9762 (mse_score: 254.9762)\n",
      "12:57 madminer.utils.ml.sc INFO                val. loss  265.8315 (mse_score: 265.8315) (*)\n",
      "12:57 madminer.utils.ml.sc INFO      Epoch 47: train loss 254.8910 (mse_score: 254.8910)\n",
      "12:57 madminer.utils.ml.sc INFO                val. loss  265.7735 (mse_score: 265.7735) (*)\n",
      "12:58 madminer.utils.ml.sc INFO      Epoch 48: train loss 254.8223 (mse_score: 254.8223)\n",
      "12:58 madminer.utils.ml.sc INFO                val. loss  265.6982 (mse_score: 265.6982) (*)\n",
      "12:58 madminer.utils.ml.sc INFO      Epoch 49: train loss 254.7303 (mse_score: 254.7303)\n",
      "12:58 madminer.utils.ml.sc INFO                val. loss  265.7231 (mse_score: 265.7231)\n",
      "12:59 madminer.utils.ml.sc INFO      Epoch 50: train loss 254.6832 (mse_score: 254.6832)\n",
      "12:59 madminer.utils.ml.sc INFO                val. loss  265.7865 (mse_score: 265.7865)\n",
      "12:59 madminer.utils.ml.sc INFO    Early stopping after epoch 48, with loss 265.70 compared to final loss 265.79\n",
      "12:59 madminer.utils.ml.sc INFO    Finished training\n",
      "12:59 madminer.ml          INFO    Training estimator 9 / 10 in ensemble\n",
      "12:59 madminer.ml          INFO    Starting training\n",
      "12:59 madminer.ml          INFO      Method:                 sally\n",
      "12:59 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_8.npy\n",
      "12:59 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_8.npy\n",
      "12:59 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59 madminer.ml          INFO      Method:                 sally\n",
      "12:59 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "12:59 madminer.ml          INFO      Activation function:    tanh\n",
      "12:59 madminer.ml          INFO      Batch size:             128\n",
      "12:59 madminer.ml          INFO      Trainer:                amsgrad\n",
      "12:59 madminer.ml          INFO      Epochs:                 50\n",
      "12:59 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "12:59 madminer.ml          INFO      Validation split:       0.5\n",
      "12:59 madminer.ml          INFO      Early stopping:         True\n",
      "12:59 madminer.ml          INFO      Scale inputs:           True\n",
      "12:59 madminer.ml          INFO      Shuffle labels          False\n",
      "12:59 madminer.ml          INFO      Regularization:         None\n",
      "12:59 madminer.ml          INFO      Samples:                all\n",
      "12:59 madminer.ml          INFO    Loading training data\n",
      "12:59 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "12:59 madminer.ml          INFO    Rescaling inputs\n",
      "12:59 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "12:59 madminer.ml          INFO    Creating model for method sally\n",
      "12:59 madminer.ml          INFO    Training model\n",
      "12:59 madminer.utils.ml.sc INFO      Epoch 01: train loss 291.4897 (mse_score: 291.4897)\n",
      "12:59 madminer.utils.ml.sc INFO                val. loss  279.1923 (mse_score: 279.1923) (*)\n",
      "13:00 madminer.utils.ml.sc INFO      Epoch 02: train loss 275.9714 (mse_score: 275.9714)\n",
      "13:00 madminer.utils.ml.sc INFO                val. loss  271.4932 (mse_score: 271.4932) (*)\n",
      "13:00 madminer.utils.ml.sc INFO      Epoch 03: train loss 270.4462 (mse_score: 270.4462)\n",
      "13:00 madminer.utils.ml.sc INFO                val. loss  266.7173 (mse_score: 266.7173) (*)\n",
      "13:01 madminer.utils.ml.sc INFO      Epoch 04: train loss 266.9671 (mse_score: 266.9671)\n",
      "13:01 madminer.utils.ml.sc INFO                val. loss  265.1656 (mse_score: 265.1656) (*)\n",
      "13:01 madminer.utils.ml.sc INFO      Epoch 05: train loss 264.9479 (mse_score: 264.9479)\n",
      "13:01 madminer.utils.ml.sc INFO                val. loss  263.1879 (mse_score: 263.1879) (*)\n",
      "13:01 madminer.utils.ml.sc INFO      Epoch 06: train loss 263.8072 (mse_score: 263.8072)\n",
      "13:01 madminer.utils.ml.sc INFO                val. loss  262.1443 (mse_score: 262.1443) (*)\n",
      "13:02 madminer.utils.ml.sc INFO      Epoch 07: train loss 262.8038 (mse_score: 262.8038)\n",
      "13:02 madminer.utils.ml.sc INFO                val. loss  261.4801 (mse_score: 261.4801) (*)\n",
      "13:02 madminer.utils.ml.sc INFO      Epoch 08: train loss 261.9522 (mse_score: 261.9522)\n",
      "13:02 madminer.utils.ml.sc INFO                val. loss  261.2732 (mse_score: 261.2732) (*)\n",
      "13:03 madminer.utils.ml.sc INFO      Epoch 09: train loss 261.2835 (mse_score: 261.2835)\n",
      "13:03 madminer.utils.ml.sc INFO                val. loss  260.6662 (mse_score: 260.6662) (*)\n",
      "13:03 madminer.utils.ml.sc INFO      Epoch 10: train loss 260.7945 (mse_score: 260.7945)\n",
      "13:03 madminer.utils.ml.sc INFO                val. loss  260.4274 (mse_score: 260.4274) (*)\n",
      "13:04 madminer.utils.ml.sc INFO      Epoch 11: train loss 260.2538 (mse_score: 260.2538)\n",
      "13:04 madminer.utils.ml.sc INFO                val. loss  259.8832 (mse_score: 259.8832) (*)\n",
      "13:04 madminer.utils.ml.sc INFO      Epoch 12: train loss 259.7371 (mse_score: 259.7371)\n",
      "13:04 madminer.utils.ml.sc INFO                val. loss  259.3074 (mse_score: 259.3074) (*)\n",
      "13:05 madminer.utils.ml.sc INFO      Epoch 13: train loss 259.3221 (mse_score: 259.3221)\n",
      "13:05 madminer.utils.ml.sc INFO                val. loss  259.7550 (mse_score: 259.7550)\n",
      "13:05 madminer.utils.ml.sc INFO      Epoch 14: train loss 258.8956 (mse_score: 258.8956)\n",
      "13:05 madminer.utils.ml.sc INFO                val. loss  259.0698 (mse_score: 259.0698) (*)\n",
      "13:05 madminer.utils.ml.sc INFO      Epoch 15: train loss 258.3920 (mse_score: 258.3920)\n",
      "13:05 madminer.utils.ml.sc INFO                val. loss  258.3660 (mse_score: 258.3660) (*)\n",
      "13:06 madminer.utils.ml.sc INFO      Epoch 16: train loss 257.9722 (mse_score: 257.9722)\n",
      "13:06 madminer.utils.ml.sc INFO                val. loss  258.2301 (mse_score: 258.2301) (*)\n",
      "13:06 madminer.utils.ml.sc INFO      Epoch 17: train loss 257.6926 (mse_score: 257.6926)\n",
      "13:06 madminer.utils.ml.sc INFO                val. loss  257.8581 (mse_score: 257.8581) (*)\n",
      "13:07 madminer.utils.ml.sc INFO      Epoch 18: train loss 257.2667 (mse_score: 257.2667)\n",
      "13:07 madminer.utils.ml.sc INFO                val. loss  257.7390 (mse_score: 257.7390) (*)\n",
      "13:07 madminer.utils.ml.sc INFO      Epoch 19: train loss 257.0695 (mse_score: 257.0695)\n",
      "13:07 madminer.utils.ml.sc INFO                val. loss  257.7274 (mse_score: 257.7274) (*)\n",
      "13:07 madminer.utils.ml.sc INFO      Epoch 20: train loss 256.5971 (mse_score: 256.5971)\n",
      "13:07 madminer.utils.ml.sc INFO                val. loss  257.4716 (mse_score: 257.4716) (*)\n",
      "13:08 madminer.utils.ml.sc INFO      Epoch 21: train loss 256.3812 (mse_score: 256.3812)\n",
      "13:08 madminer.utils.ml.sc INFO                val. loss  256.9763 (mse_score: 256.9763) (*)\n",
      "13:08 madminer.utils.ml.sc INFO      Epoch 22: train loss 256.0411 (mse_score: 256.0411)\n",
      "13:08 madminer.utils.ml.sc INFO                val. loss  256.9670 (mse_score: 256.9670) (*)\n",
      "13:09 madminer.utils.ml.sc INFO      Epoch 23: train loss 255.7359 (mse_score: 255.7359)\n",
      "13:09 madminer.utils.ml.sc INFO                val. loss  256.8765 (mse_score: 256.8765) (*)\n",
      "13:09 madminer.utils.ml.sc INFO      Epoch 24: train loss 255.5545 (mse_score: 255.5545)\n",
      "13:09 madminer.utils.ml.sc INFO                val. loss  256.7620 (mse_score: 256.7620) (*)\n",
      "13:09 madminer.utils.ml.sc INFO      Epoch 25: train loss 255.2955 (mse_score: 255.2955)\n",
      "13:09 madminer.utils.ml.sc INFO                val. loss  256.4125 (mse_score: 256.4125) (*)\n",
      "13:10 madminer.utils.ml.sc INFO      Epoch 26: train loss 255.0536 (mse_score: 255.0536)\n",
      "13:10 madminer.utils.ml.sc INFO                val. loss  256.4520 (mse_score: 256.4520)\n",
      "13:10 madminer.utils.ml.sc INFO      Epoch 27: train loss 254.8821 (mse_score: 254.8821)\n",
      "13:10 madminer.utils.ml.sc INFO                val. loss  256.2669 (mse_score: 256.2669) (*)\n",
      "13:11 madminer.utils.ml.sc INFO      Epoch 28: train loss 254.6462 (mse_score: 254.6462)\n",
      "13:11 madminer.utils.ml.sc INFO                val. loss  256.2123 (mse_score: 256.2123) (*)\n",
      "13:11 madminer.utils.ml.sc INFO      Epoch 29: train loss 254.5306 (mse_score: 254.5306)\n",
      "13:11 madminer.utils.ml.sc INFO                val. loss  256.0554 (mse_score: 256.0554) (*)\n",
      "13:12 madminer.utils.ml.sc INFO      Epoch 30: train loss 254.4404 (mse_score: 254.4404)\n",
      "13:12 madminer.utils.ml.sc INFO                val. loss  255.8880 (mse_score: 255.8880) (*)\n",
      "13:12 madminer.utils.ml.sc INFO      Epoch 31: train loss 254.1720 (mse_score: 254.1720)\n",
      "13:12 madminer.utils.ml.sc INFO                val. loss  255.9202 (mse_score: 255.9202)\n",
      "13:12 madminer.utils.ml.sc INFO      Epoch 32: train loss 254.0149 (mse_score: 254.0149)\n",
      "13:12 madminer.utils.ml.sc INFO                val. loss  255.7879 (mse_score: 255.7879) (*)\n",
      "13:13 madminer.utils.ml.sc INFO      Epoch 33: train loss 253.9705 (mse_score: 253.9705)\n",
      "13:13 madminer.utils.ml.sc INFO                val. loss  255.6737 (mse_score: 255.6737) (*)\n",
      "13:13 madminer.utils.ml.sc INFO      Epoch 34: train loss 253.8837 (mse_score: 253.8837)\n",
      "13:13 madminer.utils.ml.sc INFO                val. loss  255.5690 (mse_score: 255.5690) (*)\n",
      "13:14 madminer.utils.ml.sc INFO      Epoch 35: train loss 253.6729 (mse_score: 253.6729)\n",
      "13:14 madminer.utils.ml.sc INFO                val. loss  255.6470 (mse_score: 255.6470)\n",
      "13:14 madminer.utils.ml.sc INFO      Epoch 36: train loss 253.5924 (mse_score: 253.5924)\n",
      "13:14 madminer.utils.ml.sc INFO                val. loss  255.4767 (mse_score: 255.4767) (*)\n",
      "13:15 madminer.utils.ml.sc INFO      Epoch 37: train loss 253.4696 (mse_score: 253.4696)\n",
      "13:15 madminer.utils.ml.sc INFO                val. loss  255.5624 (mse_score: 255.5624)\n",
      "13:15 madminer.utils.ml.sc INFO      Epoch 38: train loss 253.3514 (mse_score: 253.3514)\n",
      "13:15 madminer.utils.ml.sc INFO                val. loss  255.4148 (mse_score: 255.4148) (*)\n",
      "13:15 madminer.utils.ml.sc INFO      Epoch 39: train loss 253.2536 (mse_score: 253.2536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:15 madminer.utils.ml.sc INFO                val. loss  255.3386 (mse_score: 255.3386) (*)\n",
      "13:16 madminer.utils.ml.sc INFO      Epoch 40: train loss 253.1028 (mse_score: 253.1028)\n",
      "13:16 madminer.utils.ml.sc INFO                val. loss  255.2840 (mse_score: 255.2840) (*)\n",
      "13:16 madminer.utils.ml.sc INFO      Epoch 41: train loss 253.0280 (mse_score: 253.0280)\n",
      "13:16 madminer.utils.ml.sc INFO                val. loss  255.2253 (mse_score: 255.2253) (*)\n",
      "13:17 madminer.utils.ml.sc INFO      Epoch 42: train loss 252.9610 (mse_score: 252.9610)\n",
      "13:17 madminer.utils.ml.sc INFO                val. loss  255.3281 (mse_score: 255.3281)\n",
      "13:17 madminer.utils.ml.sc INFO      Epoch 43: train loss 252.8778 (mse_score: 252.8778)\n",
      "13:17 madminer.utils.ml.sc INFO                val. loss  255.2681 (mse_score: 255.2681)\n",
      "13:18 madminer.utils.ml.sc INFO      Epoch 44: train loss 252.8465 (mse_score: 252.8465)\n",
      "13:18 madminer.utils.ml.sc INFO                val. loss  255.2063 (mse_score: 255.2063) (*)\n",
      "13:18 madminer.utils.ml.sc INFO      Epoch 45: train loss 252.7569 (mse_score: 252.7569)\n",
      "13:18 madminer.utils.ml.sc INFO                val. loss  255.1353 (mse_score: 255.1353) (*)\n",
      "13:19 madminer.utils.ml.sc INFO      Epoch 46: train loss 252.6896 (mse_score: 252.6896)\n",
      "13:19 madminer.utils.ml.sc INFO                val. loss  255.1157 (mse_score: 255.1157) (*)\n",
      "13:19 madminer.utils.ml.sc INFO      Epoch 47: train loss 252.5743 (mse_score: 252.5743)\n",
      "13:19 madminer.utils.ml.sc INFO                val. loss  255.0663 (mse_score: 255.0663) (*)\n",
      "13:20 madminer.utils.ml.sc INFO      Epoch 48: train loss 253.0876 (mse_score: 253.0876)\n",
      "13:20 madminer.utils.ml.sc INFO                val. loss  255.1523 (mse_score: 255.1523)\n",
      "13:20 madminer.utils.ml.sc INFO      Epoch 49: train loss 252.5966 (mse_score: 252.5966)\n",
      "13:20 madminer.utils.ml.sc INFO                val. loss  255.0299 (mse_score: 255.0299) (*)\n",
      "13:20 madminer.utils.ml.sc INFO      Epoch 50: train loss 252.4392 (mse_score: 252.4392)\n",
      "13:20 madminer.utils.ml.sc INFO                val. loss  255.0734 (mse_score: 255.0734)\n",
      "13:20 madminer.utils.ml.sc INFO    Early stopping after epoch 49, with loss 255.03 compared to final loss 255.07\n",
      "13:20 madminer.utils.ml.sc INFO    Finished training\n",
      "13:20 madminer.ml          INFO    Training estimator 10 / 10 in ensemble\n",
      "13:20 madminer.ml          INFO    Starting training\n",
      "13:20 madminer.ml          INFO      Method:                 sally\n",
      "13:20 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_9.npy\n",
      "13:20 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_9.npy\n",
      "13:20 madminer.ml          INFO      Features:               [0, 1, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "13:20 madminer.ml          INFO      Method:                 sally\n",
      "13:20 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "13:20 madminer.ml          INFO      Activation function:    tanh\n",
      "13:20 madminer.ml          INFO      Batch size:             128\n",
      "13:20 madminer.ml          INFO      Trainer:                amsgrad\n",
      "13:20 madminer.ml          INFO      Epochs:                 50\n",
      "13:20 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "13:20 madminer.ml          INFO      Validation split:       0.5\n",
      "13:20 madminer.ml          INFO      Early stopping:         True\n",
      "13:20 madminer.ml          INFO      Scale inputs:           True\n",
      "13:20 madminer.ml          INFO      Shuffle labels          False\n",
      "13:20 madminer.ml          INFO      Regularization:         None\n",
      "13:20 madminer.ml          INFO      Samples:                all\n",
      "13:20 madminer.ml          INFO    Loading training data\n",
      "13:21 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "13:21 madminer.ml          INFO    Rescaling inputs\n",
      "13:21 madminer.ml          INFO    Only using 27 of 33 observables\n",
      "13:21 madminer.ml          INFO    Creating model for method sally\n",
      "13:21 madminer.ml          INFO    Training model\n",
      "13:21 madminer.utils.ml.sc INFO      Epoch 01: train loss 296.1595 (mse_score: 296.1595)\n",
      "13:21 madminer.utils.ml.sc INFO                val. loss  281.3675 (mse_score: 281.3675) (*)\n",
      "13:21 madminer.utils.ml.sc INFO      Epoch 02: train loss 281.0223 (mse_score: 281.0223)\n",
      "13:21 madminer.utils.ml.sc INFO                val. loss  274.7593 (mse_score: 274.7593) (*)\n",
      "13:22 madminer.utils.ml.sc INFO      Epoch 03: train loss 275.9903 (mse_score: 275.9903)\n",
      "13:22 madminer.utils.ml.sc INFO                val. loss  270.6202 (mse_score: 270.6202) (*)\n",
      "13:22 madminer.utils.ml.sc INFO      Epoch 04: train loss 272.7029 (mse_score: 272.7029)\n",
      "13:22 madminer.utils.ml.sc INFO                val. loss  268.1394 (mse_score: 268.1394) (*)\n",
      "13:23 madminer.utils.ml.sc INFO      Epoch 05: train loss 270.7050 (mse_score: 270.7050)\n",
      "13:23 madminer.utils.ml.sc INFO                val. loss  266.5384 (mse_score: 266.5384) (*)\n",
      "13:23 madminer.utils.ml.sc INFO      Epoch 06: train loss 269.2501 (mse_score: 269.2501)\n",
      "13:23 madminer.utils.ml.sc INFO                val. loss  265.7677 (mse_score: 265.7677) (*)\n",
      "13:24 madminer.utils.ml.sc INFO      Epoch 07: train loss 268.1585 (mse_score: 268.1585)\n",
      "13:24 madminer.utils.ml.sc INFO                val. loss  264.9247 (mse_score: 264.9247) (*)\n",
      "13:24 madminer.utils.ml.sc INFO      Epoch 08: train loss 267.1990 (mse_score: 267.1990)\n",
      "13:24 madminer.utils.ml.sc INFO                val. loss  263.9651 (mse_score: 263.9651) (*)\n",
      "13:25 madminer.utils.ml.sc INFO      Epoch 09: train loss 266.5179 (mse_score: 266.5179)\n",
      "13:25 madminer.utils.ml.sc INFO                val. loss  263.5126 (mse_score: 263.5126) (*)\n",
      "13:25 madminer.utils.ml.sc INFO      Epoch 10: train loss 265.7649 (mse_score: 265.7649)\n",
      "13:25 madminer.utils.ml.sc INFO                val. loss  262.9870 (mse_score: 262.9870) (*)\n",
      "13:25 madminer.utils.ml.sc INFO      Epoch 11: train loss 265.1654 (mse_score: 265.1654)\n",
      "13:25 madminer.utils.ml.sc INFO                val. loss  262.1778 (mse_score: 262.1778) (*)\n",
      "13:26 madminer.utils.ml.sc INFO      Epoch 12: train loss 264.5995 (mse_score: 264.5995)\n",
      "13:26 madminer.utils.ml.sc INFO                val. loss  262.0051 (mse_score: 262.0051) (*)\n",
      "13:26 madminer.utils.ml.sc INFO      Epoch 13: train loss 264.0602 (mse_score: 264.0602)\n",
      "13:26 madminer.utils.ml.sc INFO                val. loss  261.9886 (mse_score: 261.9886) (*)\n",
      "13:27 madminer.utils.ml.sc INFO      Epoch 14: train loss 263.4407 (mse_score: 263.4407)\n",
      "13:27 madminer.utils.ml.sc INFO                val. loss  261.1368 (mse_score: 261.1368) (*)\n",
      "13:27 madminer.utils.ml.sc INFO      Epoch 15: train loss 263.0686 (mse_score: 263.0686)\n",
      "13:27 madminer.utils.ml.sc INFO                val. loss  260.9271 (mse_score: 260.9271) (*)\n",
      "13:28 madminer.utils.ml.sc INFO      Epoch 16: train loss 262.5499 (mse_score: 262.5499)\n",
      "13:28 madminer.utils.ml.sc INFO                val. loss  260.5131 (mse_score: 260.5131) (*)\n",
      "13:28 madminer.utils.ml.sc INFO      Epoch 17: train loss 262.1286 (mse_score: 262.1286)\n",
      "13:28 madminer.utils.ml.sc INFO                val. loss  260.2382 (mse_score: 260.2382) (*)\n",
      "13:29 madminer.utils.ml.sc INFO      Epoch 18: train loss 261.8371 (mse_score: 261.8371)\n",
      "13:29 madminer.utils.ml.sc INFO                val. loss  259.9795 (mse_score: 259.9795) (*)\n",
      "13:29 madminer.utils.ml.sc INFO      Epoch 19: train loss 261.3217 (mse_score: 261.3217)\n",
      "13:29 madminer.utils.ml.sc INFO                val. loss  259.9740 (mse_score: 259.9740) (*)\n",
      "13:29 madminer.utils.ml.sc INFO      Epoch 20: train loss 261.0210 (mse_score: 261.0210)\n",
      "13:29 madminer.utils.ml.sc INFO                val. loss  259.7246 (mse_score: 259.7246) (*)\n",
      "13:30 madminer.utils.ml.sc INFO      Epoch 21: train loss 260.7176 (mse_score: 260.7176)\n",
      "13:30 madminer.utils.ml.sc INFO                val. loss  259.3263 (mse_score: 259.3263) (*)\n",
      "13:30 madminer.utils.ml.sc INFO      Epoch 22: train loss 260.4150 (mse_score: 260.4150)\n",
      "13:30 madminer.utils.ml.sc INFO                val. loss  259.3785 (mse_score: 259.3785)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31 madminer.utils.ml.sc INFO      Epoch 23: train loss 260.2270 (mse_score: 260.2270)\n",
      "13:31 madminer.utils.ml.sc INFO                val. loss  259.0198 (mse_score: 259.0198) (*)\n",
      "13:31 madminer.utils.ml.sc INFO      Epoch 24: train loss 260.8583 (mse_score: 260.8583)\n",
      "13:31 madminer.utils.ml.sc INFO                val. loss  259.1837 (mse_score: 259.1837)\n",
      "13:32 madminer.utils.ml.sc INFO      Epoch 25: train loss 259.7118 (mse_score: 259.7118)\n",
      "13:32 madminer.utils.ml.sc INFO                val. loss  258.7800 (mse_score: 258.7800) (*)\n",
      "13:32 madminer.utils.ml.sc INFO      Epoch 26: train loss 259.5505 (mse_score: 259.5505)\n",
      "13:32 madminer.utils.ml.sc INFO                val. loss  258.7725 (mse_score: 258.7725) (*)\n",
      "13:32 madminer.utils.ml.sc INFO      Epoch 27: train loss 259.2410 (mse_score: 259.2410)\n",
      "13:32 madminer.utils.ml.sc INFO                val. loss  258.7190 (mse_score: 258.7190) (*)\n",
      "13:33 madminer.utils.ml.sc INFO      Epoch 28: train loss 259.0281 (mse_score: 259.0281)\n",
      "13:33 madminer.utils.ml.sc INFO                val. loss  258.6399 (mse_score: 258.6399) (*)\n",
      "13:33 madminer.utils.ml.sc INFO      Epoch 29: train loss 258.9491 (mse_score: 258.9491)\n",
      "13:33 madminer.utils.ml.sc INFO                val. loss  258.7067 (mse_score: 258.7067)\n",
      "13:34 madminer.utils.ml.sc INFO      Epoch 30: train loss 258.6990 (mse_score: 258.6990)\n",
      "13:34 madminer.utils.ml.sc INFO                val. loss  258.5381 (mse_score: 258.5381) (*)\n",
      "13:35 madminer.utils.ml.sc INFO      Epoch 31: train loss 258.5695 (mse_score: 258.5695)\n",
      "13:35 madminer.utils.ml.sc INFO                val. loss  258.4902 (mse_score: 258.4902) (*)\n",
      "13:35 madminer.utils.ml.sc INFO      Epoch 32: train loss 258.3761 (mse_score: 258.3761)\n",
      "13:35 madminer.utils.ml.sc INFO                val. loss  258.3778 (mse_score: 258.3778) (*)\n",
      "13:36 madminer.utils.ml.sc INFO      Epoch 33: train loss 258.2201 (mse_score: 258.2201)\n",
      "13:36 madminer.utils.ml.sc INFO                val. loss  258.3348 (mse_score: 258.3348) (*)\n",
      "13:37 madminer.utils.ml.sc INFO      Epoch 34: train loss 258.1080 (mse_score: 258.1080)\n",
      "13:37 madminer.utils.ml.sc INFO                val. loss  258.1954 (mse_score: 258.1954) (*)\n",
      "13:37 madminer.utils.ml.sc INFO      Epoch 35: train loss 257.9712 (mse_score: 257.9712)\n",
      "13:37 madminer.utils.ml.sc INFO                val. loss  258.0827 (mse_score: 258.0827) (*)\n",
      "13:38 madminer.utils.ml.sc INFO      Epoch 36: train loss 257.8590 (mse_score: 257.8590)\n",
      "13:38 madminer.utils.ml.sc INFO                val. loss  258.1365 (mse_score: 258.1365)\n",
      "13:39 madminer.utils.ml.sc INFO      Epoch 37: train loss 257.7223 (mse_score: 257.7223)\n",
      "13:39 madminer.utils.ml.sc INFO                val. loss  258.0106 (mse_score: 258.0106) (*)\n",
      "13:39 madminer.utils.ml.sc INFO      Epoch 38: train loss 257.5747 (mse_score: 257.5747)\n",
      "13:39 madminer.utils.ml.sc INFO                val. loss  257.9487 (mse_score: 257.9487) (*)\n",
      "13:40 madminer.utils.ml.sc INFO      Epoch 39: train loss 257.5484 (mse_score: 257.5484)\n",
      "13:40 madminer.utils.ml.sc INFO                val. loss  257.9524 (mse_score: 257.9524)\n",
      "13:41 madminer.utils.ml.sc INFO      Epoch 40: train loss 257.4515 (mse_score: 257.4515)\n",
      "13:41 madminer.utils.ml.sc INFO                val. loss  257.8881 (mse_score: 257.8881) (*)\n",
      "13:41 madminer.utils.ml.sc INFO      Epoch 41: train loss 257.2989 (mse_score: 257.2989)\n",
      "13:41 madminer.utils.ml.sc INFO                val. loss  258.0701 (mse_score: 258.0701)\n",
      "13:42 madminer.utils.ml.sc INFO      Epoch 42: train loss 257.1572 (mse_score: 257.1572)\n",
      "13:42 madminer.utils.ml.sc INFO                val. loss  258.0008 (mse_score: 258.0008)\n",
      "13:43 madminer.utils.ml.sc INFO      Epoch 43: train loss 257.5673 (mse_score: 257.5673)\n",
      "13:43 madminer.utils.ml.sc INFO                val. loss  258.5943 (mse_score: 258.5943)\n",
      "13:44 madminer.utils.ml.sc INFO      Epoch 44: train loss 257.0227 (mse_score: 257.0227)\n",
      "13:44 madminer.utils.ml.sc INFO                val. loss  261.4883 (mse_score: 261.4883)\n",
      "13:44 madminer.utils.ml.sc INFO      Epoch 45: train loss 256.9149 (mse_score: 256.9149)\n",
      "13:44 madminer.utils.ml.sc INFO                val. loss  257.7872 (mse_score: 257.7872) (*)\n",
      "13:45 madminer.utils.ml.sc INFO      Epoch 46: train loss 256.8619 (mse_score: 256.8619)\n",
      "13:45 madminer.utils.ml.sc INFO                val. loss  257.7566 (mse_score: 257.7566) (*)\n",
      "13:45 madminer.utils.ml.sc INFO      Epoch 47: train loss 256.7817 (mse_score: 256.7817)\n",
      "13:45 madminer.utils.ml.sc INFO                val. loss  257.6026 (mse_score: 257.6026) (*)\n",
      "13:46 madminer.utils.ml.sc INFO      Epoch 48: train loss 256.7070 (mse_score: 256.7070)\n",
      "13:46 madminer.utils.ml.sc INFO                val. loss  257.5762 (mse_score: 257.5762) (*)\n",
      "13:47 madminer.utils.ml.sc INFO      Epoch 49: train loss 256.6845 (mse_score: 256.6845)\n",
      "13:47 madminer.utils.ml.sc INFO                val. loss  257.6274 (mse_score: 257.6274)\n",
      "13:47 madminer.utils.ml.sc INFO      Epoch 50: train loss 256.5874 (mse_score: 256.5874)\n",
      "13:47 madminer.utils.ml.sc INFO                val. loss  257.5575 (mse_score: 257.5575) (*)\n",
      "13:47 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "13:47 madminer.utils.ml.sc INFO    Finished training\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'minimal_tight',\n",
    "    use_tight_cuts=True,\n",
    "    features=[min_obs for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just resurrection phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:47 madminer.ml          INFO    Training 10 estimators in ensemble\n",
      "13:47 madminer.ml          INFO    Training estimator 1 / 10 in ensemble\n",
      "13:47 madminer.ml          INFO    Starting training\n",
      "13:47 madminer.ml          INFO      Method:                 sally\n",
      "13:47 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_0.npy\n",
      "13:47 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_0.npy\n",
      "13:47 madminer.ml          INFO      Features:               [32]\n",
      "13:47 madminer.ml          INFO      Method:                 sally\n",
      "13:47 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "13:47 madminer.ml          INFO      Activation function:    tanh\n",
      "13:47 madminer.ml          INFO      Batch size:             128\n",
      "13:47 madminer.ml          INFO      Trainer:                amsgrad\n",
      "13:47 madminer.ml          INFO      Epochs:                 50\n",
      "13:47 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "13:47 madminer.ml          INFO      Validation split:       0.5\n",
      "13:47 madminer.ml          INFO      Early stopping:         True\n",
      "13:47 madminer.ml          INFO      Scale inputs:           True\n",
      "13:47 madminer.ml          INFO      Shuffle labels          False\n",
      "13:47 madminer.ml          INFO      Regularization:         None\n",
      "13:47 madminer.ml          INFO      Samples:                all\n",
      "13:47 madminer.ml          INFO    Loading training data\n",
      "13:47 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "13:47 madminer.ml          INFO    Rescaling inputs\n",
      "13:47 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "13:47 madminer.ml          INFO    Creating model for method sally\n",
      "13:47 madminer.ml          INFO    Training model\n",
      "13:48 madminer.utils.ml.sc INFO      Epoch 01: train loss 321.6840 (mse_score: 321.6840)\n",
      "13:48 madminer.utils.ml.sc INFO                val. loss  314.3590 (mse_score: 314.3590) (*)\n",
      "13:48 madminer.utils.ml.sc INFO      Epoch 02: train loss 312.6737 (mse_score: 312.6737)\n",
      "13:48 madminer.utils.ml.sc INFO                val. loss  314.3476 (mse_score: 314.3476) (*)\n",
      "13:49 madminer.utils.ml.sc INFO      Epoch 03: train loss 312.6450 (mse_score: 312.6450)\n",
      "13:49 madminer.utils.ml.sc INFO                val. loss  314.1914 (mse_score: 314.1914) (*)\n",
      "13:49 madminer.utils.ml.sc INFO      Epoch 04: train loss 312.6257 (mse_score: 312.6257)\n",
      "13:49 madminer.utils.ml.sc INFO                val. loss  314.4173 (mse_score: 314.4173)\n",
      "13:50 madminer.utils.ml.sc INFO      Epoch 05: train loss 312.5739 (mse_score: 312.5739)\n",
      "13:50 madminer.utils.ml.sc INFO                val. loss  314.2845 (mse_score: 314.2845)\n",
      "13:50 madminer.utils.ml.sc INFO      Epoch 06: train loss 312.5631 (mse_score: 312.5631)\n",
      "13:50 madminer.utils.ml.sc INFO                val. loss  314.1689 (mse_score: 314.1689) (*)\n",
      "13:50 madminer.utils.ml.sc INFO      Epoch 07: train loss 312.5792 (mse_score: 312.5792)\n",
      "13:50 madminer.utils.ml.sc INFO                val. loss  314.3525 (mse_score: 314.3525)\n",
      "13:51 madminer.utils.ml.sc INFO      Epoch 08: train loss 312.5544 (mse_score: 312.5544)\n",
      "13:51 madminer.utils.ml.sc INFO                val. loss  314.1655 (mse_score: 314.1655) (*)\n",
      "13:51 madminer.utils.ml.sc INFO      Epoch 09: train loss 312.5317 (mse_score: 312.5317)\n",
      "13:51 madminer.utils.ml.sc INFO                val. loss  314.1890 (mse_score: 314.1890)\n",
      "13:52 madminer.utils.ml.sc INFO      Epoch 10: train loss 312.5598 (mse_score: 312.5598)\n",
      "13:52 madminer.utils.ml.sc INFO                val. loss  314.2293 (mse_score: 314.2293)\n",
      "13:52 madminer.utils.ml.sc INFO      Epoch 11: train loss 312.5294 (mse_score: 312.5294)\n",
      "13:52 madminer.utils.ml.sc INFO                val. loss  314.1203 (mse_score: 314.1203) (*)\n",
      "13:53 madminer.utils.ml.sc INFO      Epoch 12: train loss 312.5042 (mse_score: 312.5042)\n",
      "13:53 madminer.utils.ml.sc INFO                val. loss  314.1293 (mse_score: 314.1293)\n",
      "13:53 madminer.utils.ml.sc INFO      Epoch 13: train loss 312.4954 (mse_score: 312.4954)\n",
      "13:53 madminer.utils.ml.sc INFO                val. loss  314.3039 (mse_score: 314.3039)\n",
      "13:53 madminer.utils.ml.sc INFO      Epoch 14: train loss 312.4939 (mse_score: 312.4939)\n",
      "13:53 madminer.utils.ml.sc INFO                val. loss  314.1856 (mse_score: 314.1856)\n",
      "13:54 madminer.utils.ml.sc INFO      Epoch 15: train loss 312.4625 (mse_score: 312.4625)\n",
      "13:54 madminer.utils.ml.sc INFO                val. loss  314.1673 (mse_score: 314.1673)\n",
      "13:54 madminer.utils.ml.sc INFO      Epoch 16: train loss 312.4882 (mse_score: 312.4882)\n",
      "13:54 madminer.utils.ml.sc INFO                val. loss  314.0920 (mse_score: 314.0920) (*)\n",
      "13:55 madminer.utils.ml.sc INFO      Epoch 17: train loss 312.4710 (mse_score: 312.4710)\n",
      "13:55 madminer.utils.ml.sc INFO                val. loss  314.2255 (mse_score: 314.2255)\n",
      "13:55 madminer.utils.ml.sc INFO      Epoch 18: train loss 312.4673 (mse_score: 312.4673)\n",
      "13:55 madminer.utils.ml.sc INFO                val. loss  314.1050 (mse_score: 314.1050)\n",
      "13:55 madminer.utils.ml.sc INFO      Epoch 19: train loss 312.4614 (mse_score: 312.4614)\n",
      "13:55 madminer.utils.ml.sc INFO                val. loss  314.2234 (mse_score: 314.2234)\n",
      "13:56 madminer.utils.ml.sc INFO      Epoch 20: train loss 312.4716 (mse_score: 312.4716)\n",
      "13:56 madminer.utils.ml.sc INFO                val. loss  314.2364 (mse_score: 314.2364)\n",
      "13:56 madminer.utils.ml.sc INFO      Epoch 21: train loss 312.4317 (mse_score: 312.4317)\n",
      "13:56 madminer.utils.ml.sc INFO                val. loss  314.1331 (mse_score: 314.1331)\n",
      "13:57 madminer.utils.ml.sc INFO      Epoch 22: train loss 312.4610 (mse_score: 312.4610)\n",
      "13:57 madminer.utils.ml.sc INFO                val. loss  314.0495 (mse_score: 314.0495) (*)\n",
      "13:57 madminer.utils.ml.sc INFO      Epoch 23: train loss 312.4441 (mse_score: 312.4441)\n",
      "13:57 madminer.utils.ml.sc INFO                val. loss  314.1249 (mse_score: 314.1249)\n",
      "13:58 madminer.utils.ml.sc INFO      Epoch 24: train loss 312.5137 (mse_score: 312.5137)\n",
      "13:58 madminer.utils.ml.sc INFO                val. loss  314.0860 (mse_score: 314.0860)\n",
      "13:58 madminer.utils.ml.sc INFO      Epoch 25: train loss 312.4233 (mse_score: 312.4233)\n",
      "13:58 madminer.utils.ml.sc INFO                val. loss  314.2627 (mse_score: 314.2627)\n",
      "13:58 madminer.utils.ml.sc INFO      Epoch 26: train loss 312.4245 (mse_score: 312.4245)\n",
      "13:58 madminer.utils.ml.sc INFO                val. loss  314.0393 (mse_score: 314.0393) (*)\n",
      "13:59 madminer.utils.ml.sc INFO      Epoch 27: train loss 312.4099 (mse_score: 312.4099)\n",
      "13:59 madminer.utils.ml.sc INFO                val. loss  314.0416 (mse_score: 314.0416)\n",
      "13:59 madminer.utils.ml.sc INFO      Epoch 28: train loss 312.4192 (mse_score: 312.4192)\n",
      "13:59 madminer.utils.ml.sc INFO                val. loss  314.0527 (mse_score: 314.0527)\n",
      "14:00 madminer.utils.ml.sc INFO      Epoch 29: train loss 312.4622 (mse_score: 312.4622)\n",
      "14:00 madminer.utils.ml.sc INFO                val. loss  314.0650 (mse_score: 314.0650)\n",
      "14:00 madminer.utils.ml.sc INFO      Epoch 30: train loss 312.3973 (mse_score: 312.3973)\n",
      "14:00 madminer.utils.ml.sc INFO                val. loss  314.1597 (mse_score: 314.1597)\n",
      "14:01 madminer.utils.ml.sc INFO      Epoch 31: train loss 312.4995 (mse_score: 312.4995)\n",
      "14:01 madminer.utils.ml.sc INFO                val. loss  314.0832 (mse_score: 314.0832)\n",
      "14:01 madminer.utils.ml.sc INFO      Epoch 32: train loss 312.4045 (mse_score: 312.4045)\n",
      "14:01 madminer.utils.ml.sc INFO                val. loss  314.0507 (mse_score: 314.0507)\n",
      "14:01 madminer.utils.ml.sc INFO      Epoch 33: train loss 312.3803 (mse_score: 312.3803)\n",
      "14:01 madminer.utils.ml.sc INFO                val. loss  314.1427 (mse_score: 314.1427)\n",
      "14:02 madminer.utils.ml.sc INFO      Epoch 34: train loss 312.3872 (mse_score: 312.3872)\n",
      "14:02 madminer.utils.ml.sc INFO                val. loss  314.0476 (mse_score: 314.0476)\n",
      "14:02 madminer.utils.ml.sc INFO      Epoch 35: train loss 312.4046 (mse_score: 312.4046)\n",
      "14:02 madminer.utils.ml.sc INFO                val. loss  314.1694 (mse_score: 314.1694)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:03 madminer.utils.ml.sc INFO      Epoch 36: train loss 312.3773 (mse_score: 312.3773)\n",
      "14:03 madminer.utils.ml.sc INFO                val. loss  314.0293 (mse_score: 314.0293) (*)\n",
      "14:03 madminer.utils.ml.sc INFO      Epoch 37: train loss 312.3811 (mse_score: 312.3811)\n",
      "14:03 madminer.utils.ml.sc INFO                val. loss  314.0607 (mse_score: 314.0607)\n",
      "14:04 madminer.utils.ml.sc INFO      Epoch 38: train loss 312.3723 (mse_score: 312.3723)\n",
      "14:04 madminer.utils.ml.sc INFO                val. loss  314.0312 (mse_score: 314.0312)\n",
      "14:04 madminer.utils.ml.sc INFO      Epoch 39: train loss 312.3838 (mse_score: 312.3838)\n",
      "14:04 madminer.utils.ml.sc INFO                val. loss  314.0273 (mse_score: 314.0273) (*)\n",
      "14:04 madminer.utils.ml.sc INFO      Epoch 40: train loss 312.4221 (mse_score: 312.4221)\n",
      "14:04 madminer.utils.ml.sc INFO                val. loss  314.0547 (mse_score: 314.0547)\n",
      "14:05 madminer.utils.ml.sc INFO      Epoch 41: train loss 312.3852 (mse_score: 312.3852)\n",
      "14:05 madminer.utils.ml.sc INFO                val. loss  314.0523 (mse_score: 314.0523)\n",
      "14:05 madminer.utils.ml.sc INFO      Epoch 42: train loss 312.3674 (mse_score: 312.3674)\n",
      "14:05 madminer.utils.ml.sc INFO                val. loss  314.0173 (mse_score: 314.0173) (*)\n",
      "14:06 madminer.utils.ml.sc INFO      Epoch 43: train loss 312.3937 (mse_score: 312.3937)\n",
      "14:06 madminer.utils.ml.sc INFO                val. loss  314.0487 (mse_score: 314.0487)\n",
      "14:06 madminer.utils.ml.sc INFO      Epoch 44: train loss 312.3902 (mse_score: 312.3902)\n",
      "14:06 madminer.utils.ml.sc INFO                val. loss  314.0785 (mse_score: 314.0785)\n",
      "14:06 madminer.utils.ml.sc INFO      Epoch 45: train loss 312.4084 (mse_score: 312.4084)\n",
      "14:06 madminer.utils.ml.sc INFO                val. loss  314.0399 (mse_score: 314.0399)\n",
      "14:07 madminer.utils.ml.sc INFO      Epoch 46: train loss 312.3876 (mse_score: 312.3876)\n",
      "14:07 madminer.utils.ml.sc INFO                val. loss  314.0442 (mse_score: 314.0442)\n",
      "14:07 madminer.utils.ml.sc INFO      Epoch 47: train loss 312.3758 (mse_score: 312.3758)\n",
      "14:07 madminer.utils.ml.sc INFO                val. loss  314.0489 (mse_score: 314.0489)\n",
      "14:08 madminer.utils.ml.sc INFO      Epoch 48: train loss 312.3664 (mse_score: 312.3664)\n",
      "14:08 madminer.utils.ml.sc INFO                val. loss  314.0696 (mse_score: 314.0696)\n",
      "14:08 madminer.utils.ml.sc INFO      Epoch 49: train loss 312.3440 (mse_score: 312.3440)\n",
      "14:08 madminer.utils.ml.sc INFO                val. loss  314.0174 (mse_score: 314.0174)\n",
      "14:08 madminer.utils.ml.sc INFO      Epoch 50: train loss 312.3452 (mse_score: 312.3452)\n",
      "14:08 madminer.utils.ml.sc INFO                val. loss  314.1484 (mse_score: 314.1484)\n",
      "14:08 madminer.utils.ml.sc INFO    Early stopping after epoch 42, with loss 314.02 compared to final loss 314.15\n",
      "14:08 madminer.utils.ml.sc INFO    Finished training\n",
      "14:08 madminer.ml          INFO    Training estimator 2 / 10 in ensemble\n",
      "14:08 madminer.ml          INFO    Starting training\n",
      "14:08 madminer.ml          INFO      Method:                 sally\n",
      "14:08 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_1.npy\n",
      "14:08 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_1.npy\n",
      "14:08 madminer.ml          INFO      Features:               [32]\n",
      "14:08 madminer.ml          INFO      Method:                 sally\n",
      "14:08 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "14:08 madminer.ml          INFO      Activation function:    tanh\n",
      "14:08 madminer.ml          INFO      Batch size:             128\n",
      "14:08 madminer.ml          INFO      Trainer:                amsgrad\n",
      "14:08 madminer.ml          INFO      Epochs:                 50\n",
      "14:08 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "14:08 madminer.ml          INFO      Validation split:       0.5\n",
      "14:08 madminer.ml          INFO      Early stopping:         True\n",
      "14:08 madminer.ml          INFO      Scale inputs:           True\n",
      "14:08 madminer.ml          INFO      Shuffle labels          False\n",
      "14:08 madminer.ml          INFO      Regularization:         None\n",
      "14:08 madminer.ml          INFO      Samples:                all\n",
      "14:08 madminer.ml          INFO    Loading training data\n",
      "14:08 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "14:08 madminer.ml          INFO    Rescaling inputs\n",
      "14:08 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "14:08 madminer.ml          INFO    Creating model for method sally\n",
      "14:08 madminer.ml          INFO    Training model\n",
      "14:09 madminer.utils.ml.sc INFO      Epoch 01: train loss 311.7422 (mse_score: 311.7422)\n",
      "14:09 madminer.utils.ml.sc INFO                val. loss  304.9215 (mse_score: 304.9215) (*)\n",
      "14:09 madminer.utils.ml.sc INFO      Epoch 02: train loss 301.1306 (mse_score: 301.1306)\n",
      "14:09 madminer.utils.ml.sc INFO                val. loss  304.6566 (mse_score: 304.6566) (*)\n",
      "14:10 madminer.utils.ml.sc INFO      Epoch 03: train loss 300.9161 (mse_score: 300.9161)\n",
      "14:10 madminer.utils.ml.sc INFO                val. loss  305.3977 (mse_score: 305.3977)\n",
      "14:10 madminer.utils.ml.sc INFO      Epoch 04: train loss 301.2671 (mse_score: 301.2671)\n",
      "14:10 madminer.utils.ml.sc INFO                val. loss  304.3751 (mse_score: 304.3751) (*)\n",
      "14:10 madminer.utils.ml.sc INFO      Epoch 05: train loss 300.8342 (mse_score: 300.8342)\n",
      "14:10 madminer.utils.ml.sc INFO                val. loss  304.5693 (mse_score: 304.5693)\n",
      "14:11 madminer.utils.ml.sc INFO      Epoch 06: train loss 300.8943 (mse_score: 300.8943)\n",
      "14:11 madminer.utils.ml.sc INFO                val. loss  304.7386 (mse_score: 304.7386)\n",
      "14:12 madminer.utils.ml.sc INFO      Epoch 07: train loss 300.8053 (mse_score: 300.8053)\n",
      "14:12 madminer.utils.ml.sc INFO                val. loss  304.3272 (mse_score: 304.3272) (*)\n",
      "14:13 madminer.utils.ml.sc INFO      Epoch 08: train loss 300.8026 (mse_score: 300.8026)\n",
      "14:13 madminer.utils.ml.sc INFO                val. loss  304.6071 (mse_score: 304.6071)\n",
      "14:14 madminer.utils.ml.sc INFO      Epoch 09: train loss 300.7936 (mse_score: 300.7936)\n",
      "14:14 madminer.utils.ml.sc INFO                val. loss  304.4274 (mse_score: 304.4274)\n",
      "14:14 madminer.utils.ml.sc INFO      Epoch 10: train loss 300.8814 (mse_score: 300.8814)\n",
      "14:14 madminer.utils.ml.sc INFO                val. loss  304.4207 (mse_score: 304.4207)\n",
      "14:15 madminer.utils.ml.sc INFO      Epoch 11: train loss 300.7714 (mse_score: 300.7714)\n",
      "14:15 madminer.utils.ml.sc INFO                val. loss  304.3176 (mse_score: 304.3176) (*)\n",
      "14:16 madminer.utils.ml.sc INFO      Epoch 12: train loss 300.7432 (mse_score: 300.7432)\n",
      "14:16 madminer.utils.ml.sc INFO                val. loss  304.3507 (mse_score: 304.3507)\n",
      "14:16 madminer.utils.ml.sc INFO      Epoch 13: train loss 300.7391 (mse_score: 300.7391)\n",
      "14:16 madminer.utils.ml.sc INFO                val. loss  304.3465 (mse_score: 304.3465)\n",
      "14:17 madminer.utils.ml.sc INFO      Epoch 14: train loss 300.7682 (mse_score: 300.7682)\n",
      "14:17 madminer.utils.ml.sc INFO                val. loss  304.4215 (mse_score: 304.4215)\n",
      "14:18 madminer.utils.ml.sc INFO      Epoch 15: train loss 301.9759 (mse_score: 301.9759)\n",
      "14:18 madminer.utils.ml.sc INFO                val. loss  304.4652 (mse_score: 304.4652)\n",
      "14:18 madminer.utils.ml.sc INFO      Epoch 16: train loss 300.7092 (mse_score: 300.7092)\n",
      "14:18 madminer.utils.ml.sc INFO                val. loss  304.3302 (mse_score: 304.3302)\n",
      "14:19 madminer.utils.ml.sc INFO      Epoch 17: train loss 300.7127 (mse_score: 300.7127)\n",
      "14:19 madminer.utils.ml.sc INFO                val. loss  304.2733 (mse_score: 304.2733) (*)\n",
      "14:19 madminer.utils.ml.sc INFO      Epoch 18: train loss 300.7064 (mse_score: 300.7064)\n",
      "14:19 madminer.utils.ml.sc INFO                val. loss  304.2547 (mse_score: 304.2547) (*)\n",
      "14:19 madminer.utils.ml.sc INFO      Epoch 19: train loss 300.7946 (mse_score: 300.7946)\n",
      "14:19 madminer.utils.ml.sc INFO                val. loss  304.4769 (mse_score: 304.4769)\n",
      "14:20 madminer.utils.ml.sc INFO      Epoch 20: train loss 300.7005 (mse_score: 300.7005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:20 madminer.utils.ml.sc INFO                val. loss  304.3372 (mse_score: 304.3372)\n",
      "14:20 madminer.utils.ml.sc INFO      Epoch 21: train loss 300.7072 (mse_score: 300.7072)\n",
      "14:20 madminer.utils.ml.sc INFO                val. loss  304.3528 (mse_score: 304.3528)\n",
      "14:21 madminer.utils.ml.sc INFO      Epoch 22: train loss 300.6679 (mse_score: 300.6679)\n",
      "14:21 madminer.utils.ml.sc INFO                val. loss  304.2360 (mse_score: 304.2360) (*)\n",
      "14:21 madminer.utils.ml.sc INFO      Epoch 23: train loss 300.7255 (mse_score: 300.7255)\n",
      "14:21 madminer.utils.ml.sc INFO                val. loss  304.2576 (mse_score: 304.2576)\n",
      "14:21 madminer.utils.ml.sc INFO      Epoch 24: train loss 300.6866 (mse_score: 300.6866)\n",
      "14:21 madminer.utils.ml.sc INFO                val. loss  304.2303 (mse_score: 304.2303) (*)\n",
      "14:22 madminer.utils.ml.sc INFO      Epoch 25: train loss 301.1292 (mse_score: 301.1292)\n",
      "14:22 madminer.utils.ml.sc INFO                val. loss  304.2608 (mse_score: 304.2608)\n",
      "14:22 madminer.utils.ml.sc INFO      Epoch 26: train loss 300.6712 (mse_score: 300.6712)\n",
      "14:22 madminer.utils.ml.sc INFO                val. loss  304.3250 (mse_score: 304.3250)\n",
      "14:23 madminer.utils.ml.sc INFO      Epoch 27: train loss 300.7100 (mse_score: 300.7100)\n",
      "14:23 madminer.utils.ml.sc INFO                val. loss  304.2542 (mse_score: 304.2542)\n",
      "14:23 madminer.utils.ml.sc INFO      Epoch 28: train loss 300.7492 (mse_score: 300.7492)\n",
      "14:23 madminer.utils.ml.sc INFO                val. loss  304.2569 (mse_score: 304.2569)\n",
      "14:23 madminer.utils.ml.sc INFO      Epoch 29: train loss 300.6691 (mse_score: 300.6691)\n",
      "14:23 madminer.utils.ml.sc INFO                val. loss  304.2776 (mse_score: 304.2776)\n",
      "14:24 madminer.utils.ml.sc INFO      Epoch 30: train loss 300.6440 (mse_score: 300.6440)\n",
      "14:24 madminer.utils.ml.sc INFO                val. loss  304.2679 (mse_score: 304.2679)\n",
      "14:24 madminer.utils.ml.sc INFO      Epoch 31: train loss 300.6443 (mse_score: 300.6443)\n",
      "14:24 madminer.utils.ml.sc INFO                val. loss  304.4360 (mse_score: 304.4360)\n",
      "14:25 madminer.utils.ml.sc INFO      Epoch 32: train loss 300.7388 (mse_score: 300.7388)\n",
      "14:25 madminer.utils.ml.sc INFO                val. loss  304.2318 (mse_score: 304.2318)\n",
      "14:25 madminer.utils.ml.sc INFO      Epoch 33: train loss 300.7167 (mse_score: 300.7167)\n",
      "14:25 madminer.utils.ml.sc INFO                val. loss  304.3225 (mse_score: 304.3225)\n",
      "14:25 madminer.utils.ml.sc INFO      Epoch 34: train loss 300.7157 (mse_score: 300.7157)\n",
      "14:25 madminer.utils.ml.sc INFO                val. loss  304.2362 (mse_score: 304.2362)\n",
      "14:26 madminer.utils.ml.sc INFO      Epoch 35: train loss 300.6407 (mse_score: 300.6407)\n",
      "14:26 madminer.utils.ml.sc INFO                val. loss  304.2117 (mse_score: 304.2117) (*)\n",
      "14:26 madminer.utils.ml.sc INFO      Epoch 36: train loss 300.6786 (mse_score: 300.6786)\n",
      "14:26 madminer.utils.ml.sc INFO                val. loss  304.2812 (mse_score: 304.2812)\n",
      "14:27 madminer.utils.ml.sc INFO      Epoch 37: train loss 300.6309 (mse_score: 300.6309)\n",
      "14:27 madminer.utils.ml.sc INFO                val. loss  304.2171 (mse_score: 304.2171)\n",
      "14:27 madminer.utils.ml.sc INFO      Epoch 38: train loss 300.6350 (mse_score: 300.6350)\n",
      "14:27 madminer.utils.ml.sc INFO                val. loss  304.3208 (mse_score: 304.3208)\n",
      "14:27 madminer.utils.ml.sc INFO      Epoch 39: train loss 300.6341 (mse_score: 300.6341)\n",
      "14:27 madminer.utils.ml.sc INFO                val. loss  304.2422 (mse_score: 304.2422)\n",
      "14:28 madminer.utils.ml.sc INFO      Epoch 40: train loss 300.6177 (mse_score: 300.6177)\n",
      "14:28 madminer.utils.ml.sc INFO                val. loss  304.2491 (mse_score: 304.2491)\n",
      "14:28 madminer.utils.ml.sc INFO      Epoch 41: train loss 300.6743 (mse_score: 300.6743)\n",
      "14:28 madminer.utils.ml.sc INFO                val. loss  304.1912 (mse_score: 304.1912) (*)\n",
      "14:29 madminer.utils.ml.sc INFO      Epoch 42: train loss 300.6175 (mse_score: 300.6175)\n",
      "14:29 madminer.utils.ml.sc INFO                val. loss  304.2408 (mse_score: 304.2408)\n",
      "14:29 madminer.utils.ml.sc INFO      Epoch 43: train loss 300.6217 (mse_score: 300.6217)\n",
      "14:29 madminer.utils.ml.sc INFO                val. loss  304.2351 (mse_score: 304.2351)\n",
      "14:29 madminer.utils.ml.sc INFO      Epoch 44: train loss 300.6290 (mse_score: 300.6290)\n",
      "14:29 madminer.utils.ml.sc INFO                val. loss  304.1990 (mse_score: 304.1990)\n",
      "14:30 madminer.utils.ml.sc INFO      Epoch 45: train loss 300.6163 (mse_score: 300.6163)\n",
      "14:30 madminer.utils.ml.sc INFO                val. loss  304.2397 (mse_score: 304.2397)\n",
      "14:30 madminer.utils.ml.sc INFO      Epoch 46: train loss 300.6774 (mse_score: 300.6774)\n",
      "14:30 madminer.utils.ml.sc INFO                val. loss  304.2058 (mse_score: 304.2058)\n",
      "14:31 madminer.utils.ml.sc INFO      Epoch 47: train loss 300.6327 (mse_score: 300.6327)\n",
      "14:31 madminer.utils.ml.sc INFO                val. loss  304.2097 (mse_score: 304.2097)\n",
      "14:31 madminer.utils.ml.sc INFO      Epoch 48: train loss 300.6260 (mse_score: 300.6260)\n",
      "14:31 madminer.utils.ml.sc INFO                val. loss  304.5697 (mse_score: 304.5697)\n",
      "14:32 madminer.utils.ml.sc INFO      Epoch 49: train loss 300.6023 (mse_score: 300.6023)\n",
      "14:32 madminer.utils.ml.sc INFO                val. loss  304.2208 (mse_score: 304.2208)\n",
      "14:32 madminer.utils.ml.sc INFO      Epoch 50: train loss 300.6054 (mse_score: 300.6054)\n",
      "14:32 madminer.utils.ml.sc INFO                val. loss  304.3108 (mse_score: 304.3108)\n",
      "14:32 madminer.utils.ml.sc INFO    Early stopping after epoch 41, with loss 304.19 compared to final loss 304.31\n",
      "14:32 madminer.utils.ml.sc INFO    Finished training\n",
      "14:32 madminer.ml          INFO    Training estimator 3 / 10 in ensemble\n",
      "14:32 madminer.ml          INFO    Starting training\n",
      "14:32 madminer.ml          INFO      Method:                 sally\n",
      "14:32 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_2.npy\n",
      "14:32 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_2.npy\n",
      "14:32 madminer.ml          INFO      Features:               [32]\n",
      "14:32 madminer.ml          INFO      Method:                 sally\n",
      "14:32 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "14:32 madminer.ml          INFO      Activation function:    tanh\n",
      "14:32 madminer.ml          INFO      Batch size:             128\n",
      "14:32 madminer.ml          INFO      Trainer:                amsgrad\n",
      "14:32 madminer.ml          INFO      Epochs:                 50\n",
      "14:32 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "14:32 madminer.ml          INFO      Validation split:       0.5\n",
      "14:32 madminer.ml          INFO      Early stopping:         True\n",
      "14:32 madminer.ml          INFO      Scale inputs:           True\n",
      "14:32 madminer.ml          INFO      Shuffle labels          False\n",
      "14:32 madminer.ml          INFO      Regularization:         None\n",
      "14:32 madminer.ml          INFO      Samples:                all\n",
      "14:32 madminer.ml          INFO    Loading training data\n",
      "14:32 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "14:32 madminer.ml          INFO    Rescaling inputs\n",
      "14:32 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "14:32 madminer.ml          INFO    Creating model for method sally\n",
      "14:32 madminer.ml          INFO    Training model\n",
      "14:32 madminer.utils.ml.sc INFO      Epoch 01: train loss 334.6185 (mse_score: 334.6185)\n",
      "14:32 madminer.utils.ml.sc INFO                val. loss  314.3638 (mse_score: 314.3638) (*)\n",
      "14:33 madminer.utils.ml.sc INFO      Epoch 02: train loss 325.1969 (mse_score: 325.1969)\n",
      "14:33 madminer.utils.ml.sc INFO                val. loss  314.1231 (mse_score: 314.1231) (*)\n",
      "14:33 madminer.utils.ml.sc INFO      Epoch 03: train loss 325.1058 (mse_score: 325.1058)\n",
      "14:33 madminer.utils.ml.sc INFO                val. loss  314.0967 (mse_score: 314.0967) (*)\n",
      "14:33 madminer.utils.ml.sc INFO      Epoch 04: train loss 325.0627 (mse_score: 325.0627)\n",
      "14:33 madminer.utils.ml.sc INFO                val. loss  314.7048 (mse_score: 314.7048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:34 madminer.utils.ml.sc INFO      Epoch 05: train loss 325.0705 (mse_score: 325.0705)\n",
      "14:34 madminer.utils.ml.sc INFO                val. loss  314.1480 (mse_score: 314.1480)\n",
      "14:34 madminer.utils.ml.sc INFO      Epoch 06: train loss 325.0205 (mse_score: 325.0205)\n",
      "14:34 madminer.utils.ml.sc INFO                val. loss  314.2208 (mse_score: 314.2208)\n",
      "14:34 madminer.utils.ml.sc INFO      Epoch 07: train loss 325.0610 (mse_score: 325.0610)\n",
      "14:34 madminer.utils.ml.sc INFO                val. loss  313.9515 (mse_score: 313.9515) (*)\n",
      "14:35 madminer.utils.ml.sc INFO      Epoch 08: train loss 324.9961 (mse_score: 324.9961)\n",
      "14:35 madminer.utils.ml.sc INFO                val. loss  314.2362 (mse_score: 314.2362)\n",
      "14:35 madminer.utils.ml.sc INFO      Epoch 09: train loss 324.9969 (mse_score: 324.9969)\n",
      "14:35 madminer.utils.ml.sc INFO                val. loss  313.9442 (mse_score: 313.9442) (*)\n",
      "14:35 madminer.utils.ml.sc INFO      Epoch 10: train loss 324.9853 (mse_score: 324.9853)\n",
      "14:35 madminer.utils.ml.sc INFO                val. loss  314.0966 (mse_score: 314.0966)\n",
      "14:36 madminer.utils.ml.sc INFO      Epoch 11: train loss 325.0250 (mse_score: 325.0250)\n",
      "14:36 madminer.utils.ml.sc INFO                val. loss  313.8984 (mse_score: 313.8984) (*)\n",
      "14:36 madminer.utils.ml.sc INFO      Epoch 12: train loss 324.9535 (mse_score: 324.9535)\n",
      "14:36 madminer.utils.ml.sc INFO                val. loss  314.1072 (mse_score: 314.1072)\n",
      "14:36 madminer.utils.ml.sc INFO      Epoch 13: train loss 324.9621 (mse_score: 324.9621)\n",
      "14:36 madminer.utils.ml.sc INFO                val. loss  314.0147 (mse_score: 314.0147)\n",
      "14:37 madminer.utils.ml.sc INFO      Epoch 14: train loss 324.9317 (mse_score: 324.9317)\n",
      "14:37 madminer.utils.ml.sc INFO                val. loss  314.1471 (mse_score: 314.1471)\n",
      "14:37 madminer.utils.ml.sc INFO      Epoch 15: train loss 324.9550 (mse_score: 324.9550)\n",
      "14:37 madminer.utils.ml.sc INFO                val. loss  313.9250 (mse_score: 313.9250)\n",
      "14:37 madminer.utils.ml.sc INFO      Epoch 16: train loss 324.9287 (mse_score: 324.9287)\n",
      "14:37 madminer.utils.ml.sc INFO                val. loss  314.0262 (mse_score: 314.0262)\n",
      "14:38 madminer.utils.ml.sc INFO      Epoch 17: train loss 324.9273 (mse_score: 324.9273)\n",
      "14:38 madminer.utils.ml.sc INFO                val. loss  313.9464 (mse_score: 313.9464)\n",
      "14:38 madminer.utils.ml.sc INFO      Epoch 18: train loss 324.9688 (mse_score: 324.9688)\n",
      "14:38 madminer.utils.ml.sc INFO                val. loss  313.9714 (mse_score: 313.9714)\n",
      "14:38 madminer.utils.ml.sc INFO      Epoch 19: train loss 324.9056 (mse_score: 324.9056)\n",
      "14:38 madminer.utils.ml.sc INFO                val. loss  313.9031 (mse_score: 313.9031)\n",
      "14:39 madminer.utils.ml.sc INFO      Epoch 20: train loss 324.9019 (mse_score: 324.9019)\n",
      "14:39 madminer.utils.ml.sc INFO                val. loss  314.2600 (mse_score: 314.2600)\n",
      "14:39 madminer.utils.ml.sc INFO      Epoch 21: train loss 325.2476 (mse_score: 325.2476)\n",
      "14:39 madminer.utils.ml.sc INFO                val. loss  313.9302 (mse_score: 313.9302)\n",
      "14:39 madminer.utils.ml.sc INFO      Epoch 22: train loss 324.9174 (mse_score: 324.9174)\n",
      "14:39 madminer.utils.ml.sc INFO                val. loss  313.8898 (mse_score: 313.8898) (*)\n",
      "14:40 madminer.utils.ml.sc INFO      Epoch 23: train loss 324.9369 (mse_score: 324.9369)\n",
      "14:40 madminer.utils.ml.sc INFO                val. loss  314.1070 (mse_score: 314.1070)\n",
      "14:40 madminer.utils.ml.sc INFO      Epoch 24: train loss 324.9092 (mse_score: 324.9092)\n",
      "14:40 madminer.utils.ml.sc INFO                val. loss  313.9041 (mse_score: 313.9041)\n",
      "14:40 madminer.utils.ml.sc INFO      Epoch 25: train loss 324.9024 (mse_score: 324.9024)\n",
      "14:40 madminer.utils.ml.sc INFO                val. loss  313.9001 (mse_score: 313.9001)\n",
      "14:41 madminer.utils.ml.sc INFO      Epoch 26: train loss 325.1707 (mse_score: 325.1707)\n",
      "14:41 madminer.utils.ml.sc INFO                val. loss  313.8962 (mse_score: 313.8962)\n",
      "14:41 madminer.utils.ml.sc INFO      Epoch 27: train loss 324.8776 (mse_score: 324.8776)\n",
      "14:41 madminer.utils.ml.sc INFO                val. loss  313.9691 (mse_score: 313.9691)\n",
      "14:41 madminer.utils.ml.sc INFO      Epoch 28: train loss 324.8686 (mse_score: 324.8686)\n",
      "14:41 madminer.utils.ml.sc INFO                val. loss  314.5316 (mse_score: 314.5316)\n",
      "14:42 madminer.utils.ml.sc INFO      Epoch 29: train loss 324.8727 (mse_score: 324.8727)\n",
      "14:42 madminer.utils.ml.sc INFO                val. loss  313.8618 (mse_score: 313.8618) (*)\n",
      "14:42 madminer.utils.ml.sc INFO      Epoch 30: train loss 324.8684 (mse_score: 324.8684)\n",
      "14:42 madminer.utils.ml.sc INFO                val. loss  314.1501 (mse_score: 314.1501)\n",
      "14:42 madminer.utils.ml.sc INFO      Epoch 31: train loss 324.8773 (mse_score: 324.8773)\n",
      "14:42 madminer.utils.ml.sc INFO                val. loss  313.9605 (mse_score: 313.9605)\n",
      "14:43 madminer.utils.ml.sc INFO      Epoch 32: train loss 324.8540 (mse_score: 324.8540)\n",
      "14:43 madminer.utils.ml.sc INFO                val. loss  313.9276 (mse_score: 313.9276)\n",
      "14:43 madminer.utils.ml.sc INFO      Epoch 33: train loss 324.8637 (mse_score: 324.8637)\n",
      "14:43 madminer.utils.ml.sc INFO                val. loss  313.8923 (mse_score: 313.8923)\n",
      "14:44 madminer.utils.ml.sc INFO      Epoch 34: train loss 324.8564 (mse_score: 324.8564)\n",
      "14:44 madminer.utils.ml.sc INFO                val. loss  314.1221 (mse_score: 314.1221)\n",
      "14:44 madminer.utils.ml.sc INFO      Epoch 35: train loss 324.8345 (mse_score: 324.8345)\n",
      "14:44 madminer.utils.ml.sc INFO                val. loss  313.9021 (mse_score: 313.9021)\n",
      "14:44 madminer.utils.ml.sc INFO      Epoch 36: train loss 324.8484 (mse_score: 324.8484)\n",
      "14:44 madminer.utils.ml.sc INFO                val. loss  313.9264 (mse_score: 313.9264)\n",
      "14:45 madminer.utils.ml.sc INFO      Epoch 37: train loss 324.8319 (mse_score: 324.8319)\n",
      "14:45 madminer.utils.ml.sc INFO                val. loss  313.8878 (mse_score: 313.8878)\n",
      "14:45 madminer.utils.ml.sc INFO      Epoch 38: train loss 324.8408 (mse_score: 324.8408)\n",
      "14:45 madminer.utils.ml.sc INFO                val. loss  313.9191 (mse_score: 313.9191)\n",
      "14:45 madminer.utils.ml.sc INFO      Epoch 39: train loss 324.8408 (mse_score: 324.8408)\n",
      "14:45 madminer.utils.ml.sc INFO                val. loss  314.7241 (mse_score: 314.7241)\n",
      "14:46 madminer.utils.ml.sc INFO      Epoch 40: train loss 324.8705 (mse_score: 324.8705)\n",
      "14:46 madminer.utils.ml.sc INFO                val. loss  313.8839 (mse_score: 313.8839)\n",
      "14:46 madminer.utils.ml.sc INFO      Epoch 41: train loss 324.8399 (mse_score: 324.8399)\n",
      "14:46 madminer.utils.ml.sc INFO                val. loss  313.8825 (mse_score: 313.8825)\n",
      "14:47 madminer.utils.ml.sc INFO      Epoch 42: train loss 324.8332 (mse_score: 324.8332)\n",
      "14:47 madminer.utils.ml.sc INFO                val. loss  313.8808 (mse_score: 313.8808)\n",
      "14:47 madminer.utils.ml.sc INFO      Epoch 43: train loss 324.8823 (mse_score: 324.8823)\n",
      "14:47 madminer.utils.ml.sc INFO                val. loss  313.8813 (mse_score: 313.8813)\n",
      "14:47 madminer.utils.ml.sc INFO      Epoch 44: train loss 324.8261 (mse_score: 324.8261)\n",
      "14:47 madminer.utils.ml.sc INFO                val. loss  313.8531 (mse_score: 313.8531) (*)\n",
      "14:48 madminer.utils.ml.sc INFO      Epoch 45: train loss 324.8502 (mse_score: 324.8502)\n",
      "14:48 madminer.utils.ml.sc INFO                val. loss  313.8612 (mse_score: 313.8612)\n",
      "14:48 madminer.utils.ml.sc INFO      Epoch 46: train loss 324.8243 (mse_score: 324.8243)\n",
      "14:48 madminer.utils.ml.sc INFO                val. loss  313.9550 (mse_score: 313.9550)\n",
      "14:49 madminer.utils.ml.sc INFO      Epoch 47: train loss 324.8301 (mse_score: 324.8301)\n",
      "14:49 madminer.utils.ml.sc INFO                val. loss  313.8711 (mse_score: 313.8711)\n",
      "14:49 madminer.utils.ml.sc INFO      Epoch 48: train loss 324.8639 (mse_score: 324.8639)\n",
      "14:49 madminer.utils.ml.sc INFO                val. loss  313.8487 (mse_score: 313.8487) (*)\n",
      "14:49 madminer.utils.ml.sc INFO      Epoch 49: train loss 324.8959 (mse_score: 324.8959)\n",
      "14:49 madminer.utils.ml.sc INFO                val. loss  313.8586 (mse_score: 313.8586)\n",
      "14:50 madminer.utils.ml.sc INFO      Epoch 50: train loss 324.8509 (mse_score: 324.8509)\n",
      "14:50 madminer.utils.ml.sc INFO                val. loss  313.8441 (mse_score: 313.8441) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:50 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "14:50 madminer.utils.ml.sc INFO    Finished training\n",
      "14:50 madminer.ml          INFO    Training estimator 4 / 10 in ensemble\n",
      "14:50 madminer.ml          INFO    Starting training\n",
      "14:50 madminer.ml          INFO      Method:                 sally\n",
      "14:50 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_3.npy\n",
      "14:50 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_3.npy\n",
      "14:50 madminer.ml          INFO      Features:               [32]\n",
      "14:50 madminer.ml          INFO      Method:                 sally\n",
      "14:50 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "14:50 madminer.ml          INFO      Activation function:    tanh\n",
      "14:50 madminer.ml          INFO      Batch size:             128\n",
      "14:50 madminer.ml          INFO      Trainer:                amsgrad\n",
      "14:50 madminer.ml          INFO      Epochs:                 50\n",
      "14:50 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "14:50 madminer.ml          INFO      Validation split:       0.5\n",
      "14:50 madminer.ml          INFO      Early stopping:         True\n",
      "14:50 madminer.ml          INFO      Scale inputs:           True\n",
      "14:50 madminer.ml          INFO      Shuffle labels          False\n",
      "14:50 madminer.ml          INFO      Regularization:         None\n",
      "14:50 madminer.ml          INFO      Samples:                all\n",
      "14:50 madminer.ml          INFO    Loading training data\n",
      "14:50 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "14:50 madminer.ml          INFO    Rescaling inputs\n",
      "14:50 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "14:50 madminer.ml          INFO    Creating model for method sally\n",
      "14:50 madminer.ml          INFO    Training model\n",
      "14:50 madminer.utils.ml.sc INFO      Epoch 01: train loss 309.5816 (mse_score: 309.5816)\n",
      "14:50 madminer.utils.ml.sc INFO                val. loss  301.4282 (mse_score: 301.4282) (*)\n",
      "14:50 madminer.utils.ml.sc INFO      Epoch 02: train loss 300.3410 (mse_score: 300.3410)\n",
      "14:50 madminer.utils.ml.sc INFO                val. loss  301.3002 (mse_score: 301.3002) (*)\n",
      "14:51 madminer.utils.ml.sc INFO      Epoch 03: train loss 300.3385 (mse_score: 300.3385)\n",
      "14:51 madminer.utils.ml.sc INFO                val. loss  301.3191 (mse_score: 301.3191)\n",
      "14:51 madminer.utils.ml.sc INFO      Epoch 04: train loss 300.1980 (mse_score: 300.1980)\n",
      "14:51 madminer.utils.ml.sc INFO                val. loss  301.2161 (mse_score: 301.2161) (*)\n",
      "14:52 madminer.utils.ml.sc INFO      Epoch 05: train loss 300.1577 (mse_score: 300.1577)\n",
      "14:52 madminer.utils.ml.sc INFO                val. loss  301.1586 (mse_score: 301.1586) (*)\n",
      "14:52 madminer.utils.ml.sc INFO      Epoch 06: train loss 300.1777 (mse_score: 300.1777)\n",
      "14:52 madminer.utils.ml.sc INFO                val. loss  301.2192 (mse_score: 301.2192)\n",
      "14:52 madminer.utils.ml.sc INFO      Epoch 07: train loss 300.1837 (mse_score: 300.1837)\n",
      "14:52 madminer.utils.ml.sc INFO                val. loss  301.2319 (mse_score: 301.2319)\n",
      "14:53 madminer.utils.ml.sc INFO      Epoch 08: train loss 300.5138 (mse_score: 300.5138)\n",
      "14:53 madminer.utils.ml.sc INFO                val. loss  301.1333 (mse_score: 301.1333) (*)\n",
      "14:53 madminer.utils.ml.sc INFO      Epoch 09: train loss 300.3038 (mse_score: 300.3038)\n",
      "14:53 madminer.utils.ml.sc INFO                val. loss  301.1514 (mse_score: 301.1514)\n",
      "14:54 madminer.utils.ml.sc INFO      Epoch 10: train loss 300.1155 (mse_score: 300.1155)\n",
      "14:54 madminer.utils.ml.sc INFO                val. loss  301.1045 (mse_score: 301.1045) (*)\n",
      "14:54 madminer.utils.ml.sc INFO      Epoch 11: train loss 300.3092 (mse_score: 300.3092)\n",
      "14:54 madminer.utils.ml.sc INFO                val. loss  301.1216 (mse_score: 301.1216)\n",
      "14:54 madminer.utils.ml.sc INFO      Epoch 12: train loss 300.1801 (mse_score: 300.1801)\n",
      "14:54 madminer.utils.ml.sc INFO                val. loss  301.1342 (mse_score: 301.1342)\n",
      "14:55 madminer.utils.ml.sc INFO      Epoch 13: train loss 300.0783 (mse_score: 300.0783)\n",
      "14:55 madminer.utils.ml.sc INFO                val. loss  301.1504 (mse_score: 301.1504)\n",
      "14:55 madminer.utils.ml.sc INFO      Epoch 14: train loss 300.2661 (mse_score: 300.2661)\n",
      "14:55 madminer.utils.ml.sc INFO                val. loss  301.1097 (mse_score: 301.1097)\n",
      "14:56 madminer.utils.ml.sc INFO      Epoch 15: train loss 300.2523 (mse_score: 300.2523)\n",
      "14:56 madminer.utils.ml.sc INFO                val. loss  301.1152 (mse_score: 301.1152)\n",
      "14:56 madminer.utils.ml.sc INFO      Epoch 16: train loss 300.0721 (mse_score: 300.0721)\n",
      "14:56 madminer.utils.ml.sc INFO                val. loss  301.1108 (mse_score: 301.1108)\n",
      "14:56 madminer.utils.ml.sc INFO      Epoch 17: train loss 300.1404 (mse_score: 300.1404)\n",
      "14:56 madminer.utils.ml.sc INFO                val. loss  301.0503 (mse_score: 301.0503) (*)\n",
      "14:57 madminer.utils.ml.sc INFO      Epoch 18: train loss 300.0637 (mse_score: 300.0637)\n",
      "14:57 madminer.utils.ml.sc INFO                val. loss  301.1457 (mse_score: 301.1457)\n",
      "14:57 madminer.utils.ml.sc INFO      Epoch 19: train loss 300.0349 (mse_score: 300.0349)\n",
      "14:57 madminer.utils.ml.sc INFO                val. loss  301.0574 (mse_score: 301.0574)\n",
      "14:57 madminer.utils.ml.sc INFO      Epoch 20: train loss 300.0328 (mse_score: 300.0328)\n",
      "14:57 madminer.utils.ml.sc INFO                val. loss  301.1075 (mse_score: 301.1075)\n",
      "14:58 madminer.utils.ml.sc INFO      Epoch 21: train loss 300.0110 (mse_score: 300.0110)\n",
      "14:58 madminer.utils.ml.sc INFO                val. loss  301.1062 (mse_score: 301.1062)\n",
      "14:58 madminer.utils.ml.sc INFO      Epoch 22: train loss 300.0177 (mse_score: 300.0177)\n",
      "14:58 madminer.utils.ml.sc INFO                val. loss  301.0820 (mse_score: 301.0820)\n",
      "14:59 madminer.utils.ml.sc INFO      Epoch 23: train loss 300.0259 (mse_score: 300.0259)\n",
      "14:59 madminer.utils.ml.sc INFO                val. loss  301.0493 (mse_score: 301.0493) (*)\n",
      "14:59 madminer.utils.ml.sc INFO      Epoch 24: train loss 299.9904 (mse_score: 299.9904)\n",
      "14:59 madminer.utils.ml.sc INFO                val. loss  301.0266 (mse_score: 301.0266) (*)\n",
      "14:59 madminer.utils.ml.sc INFO      Epoch 25: train loss 300.0097 (mse_score: 300.0097)\n",
      "14:59 madminer.utils.ml.sc INFO                val. loss  301.0391 (mse_score: 301.0391)\n",
      "15:00 madminer.utils.ml.sc INFO      Epoch 26: train loss 299.9900 (mse_score: 299.9900)\n",
      "15:00 madminer.utils.ml.sc INFO                val. loss  301.1131 (mse_score: 301.1131)\n",
      "15:00 madminer.utils.ml.sc INFO      Epoch 27: train loss 300.0088 (mse_score: 300.0088)\n",
      "15:00 madminer.utils.ml.sc INFO                val. loss  301.0591 (mse_score: 301.0591)\n",
      "15:01 madminer.utils.ml.sc INFO      Epoch 28: train loss 300.0082 (mse_score: 300.0082)\n",
      "15:01 madminer.utils.ml.sc INFO                val. loss  301.0108 (mse_score: 301.0108) (*)\n",
      "15:01 madminer.utils.ml.sc INFO      Epoch 29: train loss 299.9739 (mse_score: 299.9739)\n",
      "15:01 madminer.utils.ml.sc INFO                val. loss  301.0850 (mse_score: 301.0850)\n",
      "15:02 madminer.utils.ml.sc INFO      Epoch 30: train loss 299.9723 (mse_score: 299.9723)\n",
      "15:02 madminer.utils.ml.sc INFO                val. loss  301.0734 (mse_score: 301.0734)\n",
      "15:02 madminer.utils.ml.sc INFO      Epoch 31: train loss 299.9880 (mse_score: 299.9880)\n",
      "15:02 madminer.utils.ml.sc INFO                val. loss  301.0673 (mse_score: 301.0673)\n",
      "15:02 madminer.utils.ml.sc INFO      Epoch 32: train loss 300.1042 (mse_score: 300.1042)\n",
      "15:02 madminer.utils.ml.sc INFO                val. loss  301.0138 (mse_score: 301.0138)\n",
      "15:03 madminer.utils.ml.sc INFO      Epoch 33: train loss 299.9639 (mse_score: 299.9639)\n",
      "15:03 madminer.utils.ml.sc INFO                val. loss  301.0600 (mse_score: 301.0600)\n",
      "15:03 madminer.utils.ml.sc INFO      Epoch 34: train loss 299.9592 (mse_score: 299.9592)\n",
      "15:03 madminer.utils.ml.sc INFO                val. loss  301.0703 (mse_score: 301.0703)\n",
      "15:04 madminer.utils.ml.sc INFO      Epoch 35: train loss 299.9631 (mse_score: 299.9631)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:04 madminer.utils.ml.sc INFO                val. loss  301.0743 (mse_score: 301.0743)\n",
      "15:04 madminer.utils.ml.sc INFO      Epoch 36: train loss 299.9621 (mse_score: 299.9621)\n",
      "15:04 madminer.utils.ml.sc INFO                val. loss  301.1202 (mse_score: 301.1202)\n",
      "15:04 madminer.utils.ml.sc INFO      Epoch 37: train loss 299.9723 (mse_score: 299.9723)\n",
      "15:04 madminer.utils.ml.sc INFO                val. loss  301.0098 (mse_score: 301.0098) (*)\n",
      "15:05 madminer.utils.ml.sc INFO      Epoch 38: train loss 299.9525 (mse_score: 299.9525)\n",
      "15:05 madminer.utils.ml.sc INFO                val. loss  301.0104 (mse_score: 301.0104)\n",
      "15:05 madminer.utils.ml.sc INFO      Epoch 39: train loss 299.9938 (mse_score: 299.9938)\n",
      "15:05 madminer.utils.ml.sc INFO                val. loss  301.1420 (mse_score: 301.1420)\n",
      "15:06 madminer.utils.ml.sc INFO      Epoch 40: train loss 299.9450 (mse_score: 299.9450)\n",
      "15:06 madminer.utils.ml.sc INFO                val. loss  301.0264 (mse_score: 301.0264)\n",
      "15:06 madminer.utils.ml.sc INFO      Epoch 41: train loss 299.9576 (mse_score: 299.9576)\n",
      "15:06 madminer.utils.ml.sc INFO                val. loss  301.0380 (mse_score: 301.0380)\n",
      "15:06 madminer.utils.ml.sc INFO      Epoch 42: train loss 299.9611 (mse_score: 299.9611)\n",
      "15:06 madminer.utils.ml.sc INFO                val. loss  301.0259 (mse_score: 301.0259)\n",
      "15:07 madminer.utils.ml.sc INFO      Epoch 43: train loss 299.9389 (mse_score: 299.9389)\n",
      "15:07 madminer.utils.ml.sc INFO                val. loss  301.0016 (mse_score: 301.0016) (*)\n",
      "15:07 madminer.utils.ml.sc INFO      Epoch 44: train loss 299.9859 (mse_score: 299.9859)\n",
      "15:07 madminer.utils.ml.sc INFO                val. loss  301.0227 (mse_score: 301.0227)\n",
      "15:07 madminer.utils.ml.sc INFO      Epoch 45: train loss 299.9600 (mse_score: 299.9600)\n",
      "15:07 madminer.utils.ml.sc INFO                val. loss  301.0114 (mse_score: 301.0114)\n",
      "15:08 madminer.utils.ml.sc INFO      Epoch 46: train loss 299.9675 (mse_score: 299.9675)\n",
      "15:08 madminer.utils.ml.sc INFO                val. loss  301.0184 (mse_score: 301.0184)\n",
      "15:08 madminer.utils.ml.sc INFO      Epoch 47: train loss 299.9382 (mse_score: 299.9382)\n",
      "15:08 madminer.utils.ml.sc INFO                val. loss  301.0336 (mse_score: 301.0336)\n",
      "15:09 madminer.utils.ml.sc INFO      Epoch 48: train loss 300.0482 (mse_score: 300.0482)\n",
      "15:09 madminer.utils.ml.sc INFO                val. loss  301.0177 (mse_score: 301.0177)\n",
      "15:09 madminer.utils.ml.sc INFO      Epoch 49: train loss 299.9536 (mse_score: 299.9536)\n",
      "15:09 madminer.utils.ml.sc INFO                val. loss  301.0261 (mse_score: 301.0261)\n",
      "15:09 madminer.utils.ml.sc INFO      Epoch 50: train loss 299.9338 (mse_score: 299.9338)\n",
      "15:09 madminer.utils.ml.sc INFO                val. loss  301.0719 (mse_score: 301.0719)\n",
      "15:09 madminer.utils.ml.sc INFO    Early stopping after epoch 43, with loss 301.00 compared to final loss 301.07\n",
      "15:09 madminer.utils.ml.sc INFO    Finished training\n",
      "15:09 madminer.ml          INFO    Training estimator 5 / 10 in ensemble\n",
      "15:09 madminer.ml          INFO    Starting training\n",
      "15:09 madminer.ml          INFO      Method:                 sally\n",
      "15:09 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_4.npy\n",
      "15:09 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_4.npy\n",
      "15:09 madminer.ml          INFO      Features:               [32]\n",
      "15:09 madminer.ml          INFO      Method:                 sally\n",
      "15:09 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "15:09 madminer.ml          INFO      Activation function:    tanh\n",
      "15:09 madminer.ml          INFO      Batch size:             128\n",
      "15:09 madminer.ml          INFO      Trainer:                amsgrad\n",
      "15:09 madminer.ml          INFO      Epochs:                 50\n",
      "15:09 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "15:09 madminer.ml          INFO      Validation split:       0.5\n",
      "15:09 madminer.ml          INFO      Early stopping:         True\n",
      "15:09 madminer.ml          INFO      Scale inputs:           True\n",
      "15:09 madminer.ml          INFO      Shuffle labels          False\n",
      "15:09 madminer.ml          INFO      Regularization:         None\n",
      "15:09 madminer.ml          INFO      Samples:                all\n",
      "15:09 madminer.ml          INFO    Loading training data\n",
      "15:09 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "15:09 madminer.ml          INFO    Rescaling inputs\n",
      "15:09 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "15:09 madminer.ml          INFO    Creating model for method sally\n",
      "15:09 madminer.ml          INFO    Training model\n",
      "15:10 madminer.utils.ml.sc INFO      Epoch 01: train loss 321.6989 (mse_score: 321.6989)\n",
      "15:10 madminer.utils.ml.sc INFO                val. loss  323.8893 (mse_score: 323.8893) (*)\n",
      "15:10 madminer.utils.ml.sc INFO      Epoch 02: train loss 311.6587 (mse_score: 311.6587)\n",
      "15:10 madminer.utils.ml.sc INFO                val. loss  323.4942 (mse_score: 323.4942) (*)\n",
      "15:11 madminer.utils.ml.sc INFO      Epoch 03: train loss 311.5454 (mse_score: 311.5454)\n",
      "15:11 madminer.utils.ml.sc INFO                val. loss  323.4752 (mse_score: 323.4752) (*)\n",
      "15:11 madminer.utils.ml.sc INFO      Epoch 04: train loss 311.5573 (mse_score: 311.5573)\n",
      "15:11 madminer.utils.ml.sc INFO                val. loss  323.5601 (mse_score: 323.5601)\n",
      "15:11 madminer.utils.ml.sc INFO      Epoch 05: train loss 311.5666 (mse_score: 311.5666)\n",
      "15:11 madminer.utils.ml.sc INFO                val. loss  323.3785 (mse_score: 323.3785) (*)\n",
      "15:12 madminer.utils.ml.sc INFO      Epoch 06: train loss 311.4801 (mse_score: 311.4801)\n",
      "15:12 madminer.utils.ml.sc INFO                val. loss  323.5577 (mse_score: 323.5577)\n",
      "15:12 madminer.utils.ml.sc INFO      Epoch 07: train loss 311.4713 (mse_score: 311.4713)\n",
      "15:12 madminer.utils.ml.sc INFO                val. loss  323.4750 (mse_score: 323.4750)\n",
      "15:12 madminer.utils.ml.sc INFO      Epoch 08: train loss 311.4951 (mse_score: 311.4951)\n",
      "15:12 madminer.utils.ml.sc INFO                val. loss  323.4648 (mse_score: 323.4648)\n",
      "15:13 madminer.utils.ml.sc INFO      Epoch 09: train loss 311.4567 (mse_score: 311.4567)\n",
      "15:13 madminer.utils.ml.sc INFO                val. loss  323.4449 (mse_score: 323.4449)\n",
      "15:13 madminer.utils.ml.sc INFO      Epoch 10: train loss 312.4261 (mse_score: 312.4261)\n",
      "15:13 madminer.utils.ml.sc INFO                val. loss  323.5923 (mse_score: 323.5923)\n",
      "15:14 madminer.utils.ml.sc INFO      Epoch 11: train loss 311.4359 (mse_score: 311.4359)\n",
      "15:14 madminer.utils.ml.sc INFO                val. loss  323.3860 (mse_score: 323.3860)\n",
      "15:14 madminer.utils.ml.sc INFO      Epoch 12: train loss 311.4131 (mse_score: 311.4131)\n",
      "15:14 madminer.utils.ml.sc INFO                val. loss  323.4350 (mse_score: 323.4350)\n",
      "15:14 madminer.utils.ml.sc INFO      Epoch 13: train loss 311.4628 (mse_score: 311.4628)\n",
      "15:14 madminer.utils.ml.sc INFO                val. loss  323.3964 (mse_score: 323.3964)\n",
      "15:15 madminer.utils.ml.sc INFO      Epoch 14: train loss 311.3960 (mse_score: 311.3960)\n",
      "15:15 madminer.utils.ml.sc INFO                val. loss  323.4075 (mse_score: 323.4075)\n",
      "15:15 madminer.utils.ml.sc INFO      Epoch 15: train loss 311.4992 (mse_score: 311.4992)\n",
      "15:15 madminer.utils.ml.sc INFO                val. loss  323.3262 (mse_score: 323.3262) (*)\n",
      "15:15 madminer.utils.ml.sc INFO      Epoch 16: train loss 311.4134 (mse_score: 311.4134)\n",
      "15:15 madminer.utils.ml.sc INFO                val. loss  323.3222 (mse_score: 323.3222) (*)\n",
      "15:16 madminer.utils.ml.sc INFO      Epoch 17: train loss 311.3787 (mse_score: 311.3787)\n",
      "15:16 madminer.utils.ml.sc INFO                val. loss  323.3417 (mse_score: 323.3417)\n",
      "15:16 madminer.utils.ml.sc INFO      Epoch 18: train loss 311.4266 (mse_score: 311.4266)\n",
      "15:16 madminer.utils.ml.sc INFO                val. loss  323.3021 (mse_score: 323.3021) (*)\n",
      "15:17 madminer.utils.ml.sc INFO      Epoch 19: train loss 311.6374 (mse_score: 311.6374)\n",
      "15:17 madminer.utils.ml.sc INFO                val. loss  323.4304 (mse_score: 323.4304)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:17 madminer.utils.ml.sc INFO      Epoch 20: train loss 311.4227 (mse_score: 311.4227)\n",
      "15:17 madminer.utils.ml.sc INFO                val. loss  323.3740 (mse_score: 323.3740)\n",
      "15:17 madminer.utils.ml.sc INFO      Epoch 21: train loss 311.3606 (mse_score: 311.3606)\n",
      "15:17 madminer.utils.ml.sc INFO                val. loss  323.4707 (mse_score: 323.4707)\n",
      "15:18 madminer.utils.ml.sc INFO      Epoch 22: train loss 311.3532 (mse_score: 311.3532)\n",
      "15:18 madminer.utils.ml.sc INFO                val. loss  323.3089 (mse_score: 323.3089)\n",
      "15:18 madminer.utils.ml.sc INFO      Epoch 23: train loss 311.4058 (mse_score: 311.4058)\n",
      "15:18 madminer.utils.ml.sc INFO                val. loss  323.3546 (mse_score: 323.3546)\n",
      "15:19 madminer.utils.ml.sc INFO      Epoch 24: train loss 311.3390 (mse_score: 311.3390)\n",
      "15:19 madminer.utils.ml.sc INFO                val. loss  323.3130 (mse_score: 323.3130)\n",
      "15:19 madminer.utils.ml.sc INFO      Epoch 25: train loss 311.3458 (mse_score: 311.3458)\n",
      "15:19 madminer.utils.ml.sc INFO                val. loss  323.2804 (mse_score: 323.2804) (*)\n",
      "15:19 madminer.utils.ml.sc INFO      Epoch 26: train loss 311.3664 (mse_score: 311.3664)\n",
      "15:19 madminer.utils.ml.sc INFO                val. loss  323.3140 (mse_score: 323.3140)\n",
      "15:20 madminer.utils.ml.sc INFO      Epoch 27: train loss 311.3619 (mse_score: 311.3619)\n",
      "15:20 madminer.utils.ml.sc INFO                val. loss  323.2936 (mse_score: 323.2936)\n",
      "15:20 madminer.utils.ml.sc INFO      Epoch 28: train loss 311.3295 (mse_score: 311.3295)\n",
      "15:20 madminer.utils.ml.sc INFO                val. loss  323.3100 (mse_score: 323.3100)\n",
      "15:20 madminer.utils.ml.sc INFO      Epoch 29: train loss 311.3540 (mse_score: 311.3540)\n",
      "15:20 madminer.utils.ml.sc INFO                val. loss  323.2632 (mse_score: 323.2632) (*)\n",
      "15:21 madminer.utils.ml.sc INFO      Epoch 30: train loss 311.3795 (mse_score: 311.3795)\n",
      "15:21 madminer.utils.ml.sc INFO                val. loss  323.2889 (mse_score: 323.2889)\n",
      "15:21 madminer.utils.ml.sc INFO      Epoch 31: train loss 311.3553 (mse_score: 311.3553)\n",
      "15:21 madminer.utils.ml.sc INFO                val. loss  323.2737 (mse_score: 323.2737)\n",
      "15:21 madminer.utils.ml.sc INFO      Epoch 32: train loss 311.3176 (mse_score: 311.3176)\n",
      "15:21 madminer.utils.ml.sc INFO                val. loss  323.2824 (mse_score: 323.2824)\n",
      "15:22 madminer.utils.ml.sc INFO      Epoch 33: train loss 311.3029 (mse_score: 311.3029)\n",
      "15:22 madminer.utils.ml.sc INFO                val. loss  323.2863 (mse_score: 323.2863)\n",
      "15:22 madminer.utils.ml.sc INFO      Epoch 34: train loss 311.3215 (mse_score: 311.3215)\n",
      "15:22 madminer.utils.ml.sc INFO                val. loss  323.2784 (mse_score: 323.2784)\n",
      "15:23 madminer.utils.ml.sc INFO      Epoch 35: train loss 311.3229 (mse_score: 311.3229)\n",
      "15:23 madminer.utils.ml.sc INFO                val. loss  323.2734 (mse_score: 323.2734)\n",
      "15:23 madminer.utils.ml.sc INFO      Epoch 36: train loss 311.3085 (mse_score: 311.3085)\n",
      "15:23 madminer.utils.ml.sc INFO                val. loss  323.2780 (mse_score: 323.2780)\n",
      "15:23 madminer.utils.ml.sc INFO      Epoch 37: train loss 311.3190 (mse_score: 311.3190)\n",
      "15:23 madminer.utils.ml.sc INFO                val. loss  323.2921 (mse_score: 323.2921)\n",
      "15:24 madminer.utils.ml.sc INFO      Epoch 38: train loss 311.3066 (mse_score: 311.3066)\n",
      "15:24 madminer.utils.ml.sc INFO                val. loss  323.2723 (mse_score: 323.2723)\n",
      "15:24 madminer.utils.ml.sc INFO      Epoch 39: train loss 311.3142 (mse_score: 311.3142)\n",
      "15:24 madminer.utils.ml.sc INFO                val. loss  323.2813 (mse_score: 323.2813)\n",
      "15:24 madminer.utils.ml.sc INFO      Epoch 40: train loss 311.4334 (mse_score: 311.4334)\n",
      "15:24 madminer.utils.ml.sc INFO                val. loss  323.2694 (mse_score: 323.2694)\n",
      "15:25 madminer.utils.ml.sc INFO      Epoch 41: train loss 311.3450 (mse_score: 311.3450)\n",
      "15:25 madminer.utils.ml.sc INFO                val. loss  323.2780 (mse_score: 323.2780)\n",
      "15:25 madminer.utils.ml.sc INFO      Epoch 42: train loss 311.2863 (mse_score: 311.2863)\n",
      "15:25 madminer.utils.ml.sc INFO                val. loss  323.2685 (mse_score: 323.2685)\n",
      "15:25 madminer.utils.ml.sc INFO      Epoch 43: train loss 311.4159 (mse_score: 311.4159)\n",
      "15:25 madminer.utils.ml.sc INFO                val. loss  323.2643 (mse_score: 323.2643)\n",
      "15:26 madminer.utils.ml.sc INFO      Epoch 44: train loss 311.3238 (mse_score: 311.3238)\n",
      "15:26 madminer.utils.ml.sc INFO                val. loss  323.2698 (mse_score: 323.2698)\n",
      "15:26 madminer.utils.ml.sc INFO      Epoch 45: train loss 311.2866 (mse_score: 311.2866)\n",
      "15:26 madminer.utils.ml.sc INFO                val. loss  323.2573 (mse_score: 323.2573) (*)\n",
      "15:26 madminer.utils.ml.sc INFO      Epoch 46: train loss 311.3343 (mse_score: 311.3343)\n",
      "15:26 madminer.utils.ml.sc INFO                val. loss  323.3675 (mse_score: 323.3675)\n",
      "15:27 madminer.utils.ml.sc INFO      Epoch 47: train loss 311.2975 (mse_score: 311.2975)\n",
      "15:27 madminer.utils.ml.sc INFO                val. loss  323.2685 (mse_score: 323.2685)\n",
      "15:27 madminer.utils.ml.sc INFO      Epoch 48: train loss 311.2842 (mse_score: 311.2842)\n",
      "15:27 madminer.utils.ml.sc INFO                val. loss  323.2847 (mse_score: 323.2847)\n",
      "15:27 madminer.utils.ml.sc INFO      Epoch 49: train loss 311.2975 (mse_score: 311.2975)\n",
      "15:27 madminer.utils.ml.sc INFO                val. loss  323.2613 (mse_score: 323.2613)\n",
      "15:28 madminer.utils.ml.sc INFO      Epoch 50: train loss 311.3016 (mse_score: 311.3016)\n",
      "15:28 madminer.utils.ml.sc INFO                val. loss  323.2688 (mse_score: 323.2688)\n",
      "15:28 madminer.utils.ml.sc INFO    Early stopping after epoch 45, with loss 323.26 compared to final loss 323.27\n",
      "15:28 madminer.utils.ml.sc INFO    Finished training\n",
      "15:28 madminer.ml          INFO    Training estimator 6 / 10 in ensemble\n",
      "15:28 madminer.ml          INFO    Starting training\n",
      "15:28 madminer.ml          INFO      Method:                 sally\n",
      "15:28 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_5.npy\n",
      "15:28 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_5.npy\n",
      "15:28 madminer.ml          INFO      Features:               [32]\n",
      "15:28 madminer.ml          INFO      Method:                 sally\n",
      "15:28 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "15:28 madminer.ml          INFO      Activation function:    tanh\n",
      "15:28 madminer.ml          INFO      Batch size:             128\n",
      "15:28 madminer.ml          INFO      Trainer:                amsgrad\n",
      "15:28 madminer.ml          INFO      Epochs:                 50\n",
      "15:28 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "15:28 madminer.ml          INFO      Validation split:       0.5\n",
      "15:28 madminer.ml          INFO      Early stopping:         True\n",
      "15:28 madminer.ml          INFO      Scale inputs:           True\n",
      "15:28 madminer.ml          INFO      Shuffle labels          False\n",
      "15:28 madminer.ml          INFO      Regularization:         None\n",
      "15:28 madminer.ml          INFO      Samples:                all\n",
      "15:28 madminer.ml          INFO    Loading training data\n",
      "15:28 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "15:28 madminer.ml          INFO    Rescaling inputs\n",
      "15:28 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "15:28 madminer.ml          INFO    Creating model for method sally\n",
      "15:28 madminer.ml          INFO    Training model\n",
      "15:28 madminer.utils.ml.sc INFO      Epoch 01: train loss 329.1437 (mse_score: 329.1437)\n",
      "15:28 madminer.utils.ml.sc INFO                val. loss  313.8931 (mse_score: 313.8931) (*)\n",
      "15:28 madminer.utils.ml.sc INFO      Epoch 02: train loss 319.4140 (mse_score: 319.4140)\n",
      "15:28 madminer.utils.ml.sc INFO                val. loss  313.6773 (mse_score: 313.6773) (*)\n",
      "15:29 madminer.utils.ml.sc INFO      Epoch 03: train loss 319.3462 (mse_score: 319.3462)\n",
      "15:29 madminer.utils.ml.sc INFO                val. loss  313.6720 (mse_score: 313.6720) (*)\n",
      "15:29 madminer.utils.ml.sc INFO      Epoch 04: train loss 319.2534 (mse_score: 319.2534)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:29 madminer.utils.ml.sc INFO                val. loss  313.6721 (mse_score: 313.6721)\n",
      "15:30 madminer.utils.ml.sc INFO      Epoch 05: train loss 319.2832 (mse_score: 319.2832)\n",
      "15:30 madminer.utils.ml.sc INFO                val. loss  313.6837 (mse_score: 313.6837)\n",
      "15:30 madminer.utils.ml.sc INFO      Epoch 06: train loss 319.2454 (mse_score: 319.2454)\n",
      "15:30 madminer.utils.ml.sc INFO                val. loss  313.5759 (mse_score: 313.5759) (*)\n",
      "15:30 madminer.utils.ml.sc INFO      Epoch 07: train loss 319.2261 (mse_score: 319.2261)\n",
      "15:30 madminer.utils.ml.sc INFO                val. loss  313.6351 (mse_score: 313.6351)\n",
      "15:31 madminer.utils.ml.sc INFO      Epoch 08: train loss 319.2095 (mse_score: 319.2095)\n",
      "15:31 madminer.utils.ml.sc INFO                val. loss  313.5354 (mse_score: 313.5354) (*)\n",
      "15:31 madminer.utils.ml.sc INFO      Epoch 09: train loss 319.2328 (mse_score: 319.2328)\n",
      "15:31 madminer.utils.ml.sc INFO                val. loss  313.5687 (mse_score: 313.5687)\n",
      "15:31 madminer.utils.ml.sc INFO      Epoch 10: train loss 319.1717 (mse_score: 319.1717)\n",
      "15:31 madminer.utils.ml.sc INFO                val. loss  313.8579 (mse_score: 313.8579)\n",
      "15:32 madminer.utils.ml.sc INFO      Epoch 11: train loss 319.2819 (mse_score: 319.2819)\n",
      "15:32 madminer.utils.ml.sc INFO                val. loss  313.4877 (mse_score: 313.4877) (*)\n",
      "15:32 madminer.utils.ml.sc INFO      Epoch 12: train loss 319.1597 (mse_score: 319.1597)\n",
      "15:32 madminer.utils.ml.sc INFO                val. loss  313.4817 (mse_score: 313.4817) (*)\n",
      "15:33 madminer.utils.ml.sc INFO      Epoch 13: train loss 319.1719 (mse_score: 319.1719)\n",
      "15:33 madminer.utils.ml.sc INFO                val. loss  313.5552 (mse_score: 313.5552)\n",
      "15:33 madminer.utils.ml.sc INFO      Epoch 14: train loss 319.1579 (mse_score: 319.1579)\n",
      "15:33 madminer.utils.ml.sc INFO                val. loss  313.5748 (mse_score: 313.5748)\n",
      "15:33 madminer.utils.ml.sc INFO      Epoch 15: train loss 319.2695 (mse_score: 319.2695)\n",
      "15:33 madminer.utils.ml.sc INFO                val. loss  313.7662 (mse_score: 313.7662)\n",
      "15:34 madminer.utils.ml.sc INFO      Epoch 16: train loss 319.1868 (mse_score: 319.1868)\n",
      "15:34 madminer.utils.ml.sc INFO                val. loss  313.5838 (mse_score: 313.5838)\n",
      "15:34 madminer.utils.ml.sc INFO      Epoch 17: train loss 319.1349 (mse_score: 319.1349)\n",
      "15:34 madminer.utils.ml.sc INFO                val. loss  313.5312 (mse_score: 313.5312)\n",
      "15:35 madminer.utils.ml.sc INFO      Epoch 18: train loss 319.1145 (mse_score: 319.1145)\n",
      "15:35 madminer.utils.ml.sc INFO                val. loss  313.5782 (mse_score: 313.5782)\n",
      "15:35 madminer.utils.ml.sc INFO      Epoch 19: train loss 319.1188 (mse_score: 319.1188)\n",
      "15:35 madminer.utils.ml.sc INFO                val. loss  313.4730 (mse_score: 313.4730) (*)\n",
      "15:35 madminer.utils.ml.sc INFO      Epoch 20: train loss 319.1056 (mse_score: 319.1056)\n",
      "15:35 madminer.utils.ml.sc INFO                val. loss  313.5096 (mse_score: 313.5096)\n",
      "15:36 madminer.utils.ml.sc INFO      Epoch 21: train loss 319.1340 (mse_score: 319.1340)\n",
      "15:36 madminer.utils.ml.sc INFO                val. loss  313.4852 (mse_score: 313.4852)\n",
      "15:37 madminer.utils.ml.sc INFO      Epoch 22: train loss 319.1076 (mse_score: 319.1076)\n",
      "15:37 madminer.utils.ml.sc INFO                val. loss  313.5237 (mse_score: 313.5237)\n",
      "15:38 madminer.utils.ml.sc INFO      Epoch 23: train loss 319.3574 (mse_score: 319.3574)\n",
      "15:38 madminer.utils.ml.sc INFO                val. loss  313.8244 (mse_score: 313.8244)\n",
      "15:38 madminer.utils.ml.sc INFO      Epoch 24: train loss 319.0746 (mse_score: 319.0746)\n",
      "15:38 madminer.utils.ml.sc INFO                val. loss  313.4478 (mse_score: 313.4478) (*)\n",
      "15:39 madminer.utils.ml.sc INFO      Epoch 25: train loss 319.1791 (mse_score: 319.1791)\n",
      "15:39 madminer.utils.ml.sc INFO                val. loss  313.4777 (mse_score: 313.4777)\n",
      "15:39 madminer.utils.ml.sc INFO      Epoch 26: train loss 319.1244 (mse_score: 319.1244)\n",
      "15:39 madminer.utils.ml.sc INFO                val. loss  313.4312 (mse_score: 313.4312) (*)\n",
      "15:40 madminer.utils.ml.sc INFO      Epoch 27: train loss 319.0502 (mse_score: 319.0502)\n",
      "15:40 madminer.utils.ml.sc INFO                val. loss  313.4682 (mse_score: 313.4682)\n",
      "15:40 madminer.utils.ml.sc INFO      Epoch 28: train loss 319.0587 (mse_score: 319.0587)\n",
      "15:40 madminer.utils.ml.sc INFO                val. loss  313.4637 (mse_score: 313.4637)\n",
      "15:41 madminer.utils.ml.sc INFO      Epoch 29: train loss 319.1470 (mse_score: 319.1470)\n",
      "15:41 madminer.utils.ml.sc INFO                val. loss  313.4793 (mse_score: 313.4793)\n",
      "15:41 madminer.utils.ml.sc INFO      Epoch 30: train loss 319.1321 (mse_score: 319.1321)\n",
      "15:41 madminer.utils.ml.sc INFO                val. loss  313.4767 (mse_score: 313.4767)\n",
      "15:42 madminer.utils.ml.sc INFO      Epoch 31: train loss 319.0545 (mse_score: 319.0545)\n",
      "15:42 madminer.utils.ml.sc INFO                val. loss  313.4058 (mse_score: 313.4058) (*)\n",
      "15:42 madminer.utils.ml.sc INFO      Epoch 32: train loss 319.0850 (mse_score: 319.0850)\n",
      "15:42 madminer.utils.ml.sc INFO                val. loss  313.5204 (mse_score: 313.5204)\n",
      "15:43 madminer.utils.ml.sc INFO      Epoch 33: train loss 319.0512 (mse_score: 319.0512)\n",
      "15:43 madminer.utils.ml.sc INFO                val. loss  313.4351 (mse_score: 313.4351)\n",
      "15:43 madminer.utils.ml.sc INFO      Epoch 34: train loss 319.0683 (mse_score: 319.0683)\n",
      "15:43 madminer.utils.ml.sc INFO                val. loss  313.4635 (mse_score: 313.4635)\n",
      "15:44 madminer.utils.ml.sc INFO      Epoch 35: train loss 319.0502 (mse_score: 319.0502)\n",
      "15:44 madminer.utils.ml.sc INFO                val. loss  313.4267 (mse_score: 313.4267)\n",
      "15:44 madminer.utils.ml.sc INFO      Epoch 36: train loss 319.0432 (mse_score: 319.0432)\n",
      "15:44 madminer.utils.ml.sc INFO                val. loss  313.4265 (mse_score: 313.4265)\n",
      "15:45 madminer.utils.ml.sc INFO      Epoch 37: train loss 319.0862 (mse_score: 319.0862)\n",
      "15:45 madminer.utils.ml.sc INFO                val. loss  313.4501 (mse_score: 313.4501)\n",
      "15:45 madminer.utils.ml.sc INFO      Epoch 38: train loss 319.0242 (mse_score: 319.0242)\n",
      "15:45 madminer.utils.ml.sc INFO                val. loss  313.4276 (mse_score: 313.4276)\n",
      "15:46 madminer.utils.ml.sc INFO      Epoch 39: train loss 319.0532 (mse_score: 319.0532)\n",
      "15:46 madminer.utils.ml.sc INFO                val. loss  313.6999 (mse_score: 313.6999)\n",
      "15:46 madminer.utils.ml.sc INFO      Epoch 40: train loss 319.0404 (mse_score: 319.0404)\n",
      "15:46 madminer.utils.ml.sc INFO                val. loss  313.4147 (mse_score: 313.4147)\n",
      "15:47 madminer.utils.ml.sc INFO      Epoch 41: train loss 319.0389 (mse_score: 319.0389)\n",
      "15:47 madminer.utils.ml.sc INFO                val. loss  313.4362 (mse_score: 313.4362)\n",
      "15:47 madminer.utils.ml.sc INFO      Epoch 42: train loss 319.0296 (mse_score: 319.0296)\n",
      "15:47 madminer.utils.ml.sc INFO                val. loss  313.4281 (mse_score: 313.4281)\n",
      "15:48 madminer.utils.ml.sc INFO      Epoch 43: train loss 319.0169 (mse_score: 319.0169)\n",
      "15:48 madminer.utils.ml.sc INFO                val. loss  313.4043 (mse_score: 313.4043) (*)\n",
      "15:48 madminer.utils.ml.sc INFO      Epoch 44: train loss 319.0595 (mse_score: 319.0595)\n",
      "15:48 madminer.utils.ml.sc INFO                val. loss  313.4352 (mse_score: 313.4352)\n",
      "15:49 madminer.utils.ml.sc INFO      Epoch 45: train loss 319.0494 (mse_score: 319.0494)\n",
      "15:49 madminer.utils.ml.sc INFO                val. loss  313.4392 (mse_score: 313.4392)\n",
      "15:49 madminer.utils.ml.sc INFO      Epoch 46: train loss 319.0221 (mse_score: 319.0221)\n",
      "15:49 madminer.utils.ml.sc INFO                val. loss  313.4084 (mse_score: 313.4084)\n",
      "15:50 madminer.utils.ml.sc INFO      Epoch 47: train loss 319.0194 (mse_score: 319.0194)\n",
      "15:50 madminer.utils.ml.sc INFO                val. loss  313.6087 (mse_score: 313.6087)\n",
      "15:50 madminer.utils.ml.sc INFO      Epoch 48: train loss 319.1509 (mse_score: 319.1509)\n",
      "15:50 madminer.utils.ml.sc INFO                val. loss  313.4360 (mse_score: 313.4360)\n",
      "15:51 madminer.utils.ml.sc INFO      Epoch 49: train loss 319.0903 (mse_score: 319.0903)\n",
      "15:51 madminer.utils.ml.sc INFO                val. loss  313.4126 (mse_score: 313.4126)\n",
      "15:51 madminer.utils.ml.sc INFO      Epoch 50: train loss 319.0072 (mse_score: 319.0072)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:51 madminer.utils.ml.sc INFO                val. loss  313.4094 (mse_score: 313.4094)\n",
      "15:51 madminer.utils.ml.sc INFO    Early stopping after epoch 43, with loss 313.40 compared to final loss 313.41\n",
      "15:51 madminer.utils.ml.sc INFO    Finished training\n",
      "15:51 madminer.ml          INFO    Training estimator 7 / 10 in ensemble\n",
      "15:51 madminer.ml          INFO    Starting training\n",
      "15:51 madminer.ml          INFO      Method:                 sally\n",
      "15:51 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_6.npy\n",
      "15:51 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_6.npy\n",
      "15:51 madminer.ml          INFO      Features:               [32]\n",
      "15:51 madminer.ml          INFO      Method:                 sally\n",
      "15:51 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "15:51 madminer.ml          INFO      Activation function:    tanh\n",
      "15:51 madminer.ml          INFO      Batch size:             128\n",
      "15:51 madminer.ml          INFO      Trainer:                amsgrad\n",
      "15:51 madminer.ml          INFO      Epochs:                 50\n",
      "15:51 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "15:51 madminer.ml          INFO      Validation split:       0.5\n",
      "15:51 madminer.ml          INFO      Early stopping:         True\n",
      "15:51 madminer.ml          INFO      Scale inputs:           True\n",
      "15:51 madminer.ml          INFO      Shuffle labels          False\n",
      "15:51 madminer.ml          INFO      Regularization:         None\n",
      "15:51 madminer.ml          INFO      Samples:                all\n",
      "15:51 madminer.ml          INFO    Loading training data\n",
      "15:51 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "15:51 madminer.ml          INFO    Rescaling inputs\n",
      "15:51 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "15:51 madminer.ml          INFO    Creating model for method sally\n",
      "15:51 madminer.ml          INFO    Training model\n",
      "15:52 madminer.utils.ml.sc INFO      Epoch 01: train loss 312.0329 (mse_score: 312.0329)\n",
      "15:52 madminer.utils.ml.sc INFO                val. loss  305.3425 (mse_score: 305.3425) (*)\n",
      "15:52 madminer.utils.ml.sc INFO      Epoch 02: train loss 302.7168 (mse_score: 302.7168)\n",
      "15:52 madminer.utils.ml.sc INFO                val. loss  305.3646 (mse_score: 305.3646)\n",
      "15:52 madminer.utils.ml.sc INFO      Epoch 03: train loss 302.5936 (mse_score: 302.5936)\n",
      "15:52 madminer.utils.ml.sc INFO                val. loss  305.0914 (mse_score: 305.0914) (*)\n",
      "15:53 madminer.utils.ml.sc INFO      Epoch 04: train loss 302.7566 (mse_score: 302.7566)\n",
      "15:53 madminer.utils.ml.sc INFO                val. loss  305.0218 (mse_score: 305.0218) (*)\n",
      "15:53 madminer.utils.ml.sc INFO      Epoch 05: train loss 302.6490 (mse_score: 302.6490)\n",
      "15:53 madminer.utils.ml.sc INFO                val. loss  305.3054 (mse_score: 305.3054)\n",
      "15:54 madminer.utils.ml.sc INFO      Epoch 06: train loss 302.5355 (mse_score: 302.5355)\n",
      "15:54 madminer.utils.ml.sc INFO                val. loss  305.4026 (mse_score: 305.4026)\n",
      "15:54 madminer.utils.ml.sc INFO      Epoch 07: train loss 303.5217 (mse_score: 303.5217)\n",
      "15:54 madminer.utils.ml.sc INFO                val. loss  305.3102 (mse_score: 305.3102)\n",
      "15:54 madminer.utils.ml.sc INFO      Epoch 08: train loss 302.5092 (mse_score: 302.5092)\n",
      "15:54 madminer.utils.ml.sc INFO                val. loss  305.2158 (mse_score: 305.2158)\n",
      "15:55 madminer.utils.ml.sc INFO      Epoch 09: train loss 302.4923 (mse_score: 302.4923)\n",
      "15:55 madminer.utils.ml.sc INFO                val. loss  305.2306 (mse_score: 305.2306)\n",
      "15:55 madminer.utils.ml.sc INFO      Epoch 10: train loss 302.4872 (mse_score: 302.4872)\n",
      "15:55 madminer.utils.ml.sc INFO                val. loss  305.5696 (mse_score: 305.5696)\n",
      "15:56 madminer.utils.ml.sc INFO      Epoch 11: train loss 302.4594 (mse_score: 302.4594)\n",
      "15:56 madminer.utils.ml.sc INFO                val. loss  305.0793 (mse_score: 305.0793)\n",
      "15:56 madminer.utils.ml.sc INFO      Epoch 12: train loss 302.4798 (mse_score: 302.4798)\n",
      "15:56 madminer.utils.ml.sc INFO                val. loss  305.1384 (mse_score: 305.1384)\n",
      "15:57 madminer.utils.ml.sc INFO      Epoch 13: train loss 302.4431 (mse_score: 302.4431)\n",
      "15:57 madminer.utils.ml.sc INFO                val. loss  305.0039 (mse_score: 305.0039) (*)\n",
      "15:57 madminer.utils.ml.sc INFO      Epoch 14: train loss 302.5460 (mse_score: 302.5460)\n",
      "15:57 madminer.utils.ml.sc INFO                val. loss  305.0257 (mse_score: 305.0257)\n",
      "15:57 madminer.utils.ml.sc INFO      Epoch 15: train loss 302.4168 (mse_score: 302.4168)\n",
      "15:57 madminer.utils.ml.sc INFO                val. loss  305.1024 (mse_score: 305.1024)\n",
      "15:58 madminer.utils.ml.sc INFO      Epoch 16: train loss 302.4261 (mse_score: 302.4261)\n",
      "15:58 madminer.utils.ml.sc INFO                val. loss  305.0083 (mse_score: 305.0083)\n",
      "15:58 madminer.utils.ml.sc INFO      Epoch 17: train loss 302.4627 (mse_score: 302.4627)\n",
      "15:58 madminer.utils.ml.sc INFO                val. loss  305.2854 (mse_score: 305.2854)\n",
      "15:59 madminer.utils.ml.sc INFO      Epoch 18: train loss 302.4139 (mse_score: 302.4139)\n",
      "15:59 madminer.utils.ml.sc INFO                val. loss  305.0926 (mse_score: 305.0926)\n",
      "15:59 madminer.utils.ml.sc INFO      Epoch 19: train loss 302.4098 (mse_score: 302.4098)\n",
      "15:59 madminer.utils.ml.sc INFO                val. loss  305.0029 (mse_score: 305.0029) (*)\n",
      "16:00 madminer.utils.ml.sc INFO      Epoch 20: train loss 302.3883 (mse_score: 302.3883)\n",
      "16:00 madminer.utils.ml.sc INFO                val. loss  304.9439 (mse_score: 304.9439) (*)\n",
      "16:00 madminer.utils.ml.sc INFO      Epoch 21: train loss 302.3768 (mse_score: 302.3768)\n",
      "16:00 madminer.utils.ml.sc INFO                val. loss  305.0240 (mse_score: 305.0240)\n",
      "16:01 madminer.utils.ml.sc INFO      Epoch 22: train loss 302.3859 (mse_score: 302.3859)\n",
      "16:01 madminer.utils.ml.sc INFO                val. loss  304.9763 (mse_score: 304.9763)\n",
      "16:01 madminer.utils.ml.sc INFO      Epoch 23: train loss 302.3839 (mse_score: 302.3839)\n",
      "16:01 madminer.utils.ml.sc INFO                val. loss  305.0091 (mse_score: 305.0091)\n",
      "16:02 madminer.utils.ml.sc INFO      Epoch 24: train loss 302.4742 (mse_score: 302.4742)\n",
      "16:02 madminer.utils.ml.sc INFO                val. loss  304.9970 (mse_score: 304.9970)\n",
      "16:02 madminer.utils.ml.sc INFO      Epoch 25: train loss 302.9093 (mse_score: 302.9093)\n",
      "16:02 madminer.utils.ml.sc INFO                val. loss  304.9167 (mse_score: 304.9167) (*)\n",
      "16:03 madminer.utils.ml.sc INFO      Epoch 26: train loss 302.4292 (mse_score: 302.4292)\n",
      "16:03 madminer.utils.ml.sc INFO                val. loss  304.9733 (mse_score: 304.9733)\n",
      "16:03 madminer.utils.ml.sc INFO      Epoch 27: train loss 302.3604 (mse_score: 302.3604)\n",
      "16:03 madminer.utils.ml.sc INFO                val. loss  304.9462 (mse_score: 304.9462)\n",
      "16:03 madminer.utils.ml.sc INFO      Epoch 28: train loss 302.3657 (mse_score: 302.3657)\n",
      "16:03 madminer.utils.ml.sc INFO                val. loss  304.9459 (mse_score: 304.9459)\n",
      "16:04 madminer.utils.ml.sc INFO      Epoch 29: train loss 302.3511 (mse_score: 302.3511)\n",
      "16:04 madminer.utils.ml.sc INFO                val. loss  305.0796 (mse_score: 305.0796)\n",
      "16:04 madminer.utils.ml.sc INFO      Epoch 30: train loss 302.3451 (mse_score: 302.3451)\n",
      "16:04 madminer.utils.ml.sc INFO                val. loss  304.9402 (mse_score: 304.9402)\n",
      "16:05 madminer.utils.ml.sc INFO      Epoch 31: train loss 302.3392 (mse_score: 302.3392)\n",
      "16:05 madminer.utils.ml.sc INFO                val. loss  304.9287 (mse_score: 304.9287)\n",
      "16:05 madminer.utils.ml.sc INFO      Epoch 32: train loss 302.3545 (mse_score: 302.3545)\n",
      "16:05 madminer.utils.ml.sc INFO                val. loss  304.9179 (mse_score: 304.9179)\n",
      "16:06 madminer.utils.ml.sc INFO      Epoch 33: train loss 302.3686 (mse_score: 302.3686)\n",
      "16:06 madminer.utils.ml.sc INFO                val. loss  304.9133 (mse_score: 304.9133) (*)\n",
      "16:06 madminer.utils.ml.sc INFO      Epoch 34: train loss 302.3474 (mse_score: 302.3474)\n",
      "16:06 madminer.utils.ml.sc INFO                val. loss  304.9008 (mse_score: 304.9008) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:06 madminer.utils.ml.sc INFO      Epoch 35: train loss 302.3612 (mse_score: 302.3612)\n",
      "16:06 madminer.utils.ml.sc INFO                val. loss  304.9158 (mse_score: 304.9158)\n",
      "16:07 madminer.utils.ml.sc INFO      Epoch 36: train loss 302.3838 (mse_score: 302.3838)\n",
      "16:07 madminer.utils.ml.sc INFO                val. loss  304.9188 (mse_score: 304.9188)\n",
      "16:07 madminer.utils.ml.sc INFO      Epoch 37: train loss 302.3288 (mse_score: 302.3288)\n",
      "16:07 madminer.utils.ml.sc INFO                val. loss  304.9362 (mse_score: 304.9362)\n",
      "16:08 madminer.utils.ml.sc INFO      Epoch 38: train loss 302.4041 (mse_score: 302.4041)\n",
      "16:08 madminer.utils.ml.sc INFO                val. loss  304.9079 (mse_score: 304.9079)\n",
      "16:08 madminer.utils.ml.sc INFO      Epoch 39: train loss 302.3305 (mse_score: 302.3305)\n",
      "16:08 madminer.utils.ml.sc INFO                val. loss  304.9026 (mse_score: 304.9026)\n",
      "16:09 madminer.utils.ml.sc INFO      Epoch 40: train loss 302.3364 (mse_score: 302.3364)\n",
      "16:09 madminer.utils.ml.sc INFO                val. loss  304.9453 (mse_score: 304.9453)\n",
      "16:09 madminer.utils.ml.sc INFO      Epoch 41: train loss 302.3378 (mse_score: 302.3378)\n",
      "16:09 madminer.utils.ml.sc INFO                val. loss  305.0560 (mse_score: 305.0560)\n",
      "16:10 madminer.utils.ml.sc INFO      Epoch 42: train loss 302.3180 (mse_score: 302.3180)\n",
      "16:10 madminer.utils.ml.sc INFO                val. loss  304.9094 (mse_score: 304.9094)\n",
      "16:10 madminer.utils.ml.sc INFO      Epoch 43: train loss 302.3214 (mse_score: 302.3214)\n",
      "16:10 madminer.utils.ml.sc INFO                val. loss  304.9624 (mse_score: 304.9624)\n",
      "16:11 madminer.utils.ml.sc INFO      Epoch 44: train loss 302.3628 (mse_score: 302.3628)\n",
      "16:11 madminer.utils.ml.sc INFO                val. loss  304.9291 (mse_score: 304.9291)\n",
      "16:11 madminer.utils.ml.sc INFO      Epoch 45: train loss 302.3628 (mse_score: 302.3628)\n",
      "16:11 madminer.utils.ml.sc INFO                val. loss  304.9307 (mse_score: 304.9307)\n",
      "16:12 madminer.utils.ml.sc INFO      Epoch 46: train loss 302.3165 (mse_score: 302.3165)\n",
      "16:12 madminer.utils.ml.sc INFO                val. loss  304.9176 (mse_score: 304.9176)\n",
      "16:12 madminer.utils.ml.sc INFO      Epoch 47: train loss 302.3120 (mse_score: 302.3120)\n",
      "16:12 madminer.utils.ml.sc INFO                val. loss  304.9566 (mse_score: 304.9566)\n",
      "16:13 madminer.utils.ml.sc INFO      Epoch 48: train loss 302.3367 (mse_score: 302.3367)\n",
      "16:13 madminer.utils.ml.sc INFO                val. loss  305.0002 (mse_score: 305.0002)\n",
      "16:13 madminer.utils.ml.sc INFO      Epoch 49: train loss 302.3128 (mse_score: 302.3128)\n",
      "16:13 madminer.utils.ml.sc INFO                val. loss  305.0869 (mse_score: 305.0869)\n",
      "16:14 madminer.utils.ml.sc INFO      Epoch 50: train loss 302.3490 (mse_score: 302.3490)\n",
      "16:14 madminer.utils.ml.sc INFO                val. loss  304.9761 (mse_score: 304.9761)\n",
      "16:14 madminer.utils.ml.sc INFO    Early stopping after epoch 34, with loss 304.90 compared to final loss 304.98\n",
      "16:14 madminer.utils.ml.sc INFO    Finished training\n",
      "16:14 madminer.ml          INFO    Training estimator 8 / 10 in ensemble\n",
      "16:14 madminer.ml          INFO    Starting training\n",
      "16:14 madminer.ml          INFO      Method:                 sally\n",
      "16:14 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_7.npy\n",
      "16:14 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_7.npy\n",
      "16:14 madminer.ml          INFO      Features:               [32]\n",
      "16:14 madminer.ml          INFO      Method:                 sally\n",
      "16:14 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "16:14 madminer.ml          INFO      Activation function:    tanh\n",
      "16:14 madminer.ml          INFO      Batch size:             128\n",
      "16:14 madminer.ml          INFO      Trainer:                amsgrad\n",
      "16:14 madminer.ml          INFO      Epochs:                 50\n",
      "16:14 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:14 madminer.ml          INFO      Validation split:       0.5\n",
      "16:14 madminer.ml          INFO      Early stopping:         True\n",
      "16:14 madminer.ml          INFO      Scale inputs:           True\n",
      "16:14 madminer.ml          INFO      Shuffle labels          False\n",
      "16:14 madminer.ml          INFO      Regularization:         None\n",
      "16:14 madminer.ml          INFO      Samples:                all\n",
      "16:14 madminer.ml          INFO    Loading training data\n",
      "16:14 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "16:14 madminer.ml          INFO    Rescaling inputs\n",
      "16:14 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "16:14 madminer.ml          INFO    Creating model for method sally\n",
      "16:14 madminer.ml          INFO    Training model\n",
      "16:14 madminer.utils.ml.sc INFO      Epoch 01: train loss 329.1320 (mse_score: 329.1320)\n",
      "16:14 madminer.utils.ml.sc INFO                val. loss  311.9297 (mse_score: 311.9297) (*)\n",
      "16:15 madminer.utils.ml.sc INFO      Epoch 02: train loss 318.8930 (mse_score: 318.8930)\n",
      "16:15 madminer.utils.ml.sc INFO                val. loss  311.7100 (mse_score: 311.7100) (*)\n",
      "16:15 madminer.utils.ml.sc INFO      Epoch 03: train loss 318.7065 (mse_score: 318.7065)\n",
      "16:15 madminer.utils.ml.sc INFO                val. loss  311.4280 (mse_score: 311.4280) (*)\n",
      "16:15 madminer.utils.ml.sc INFO      Epoch 04: train loss 318.6390 (mse_score: 318.6390)\n",
      "16:15 madminer.utils.ml.sc INFO                val. loss  311.4974 (mse_score: 311.4974)\n",
      "16:16 madminer.utils.ml.sc INFO      Epoch 05: train loss 318.5969 (mse_score: 318.5969)\n",
      "16:16 madminer.utils.ml.sc INFO                val. loss  311.3922 (mse_score: 311.3922) (*)\n",
      "16:16 madminer.utils.ml.sc INFO      Epoch 06: train loss 318.6053 (mse_score: 318.6053)\n",
      "16:16 madminer.utils.ml.sc INFO                val. loss  311.2991 (mse_score: 311.2991) (*)\n",
      "16:17 madminer.utils.ml.sc INFO      Epoch 07: train loss 318.6003 (mse_score: 318.6003)\n",
      "16:17 madminer.utils.ml.sc INFO                val. loss  311.3689 (mse_score: 311.3689)\n",
      "16:18 madminer.utils.ml.sc INFO      Epoch 08: train loss 318.5929 (mse_score: 318.5929)\n",
      "16:18 madminer.utils.ml.sc INFO                val. loss  311.4564 (mse_score: 311.4564)\n",
      "16:18 madminer.utils.ml.sc INFO      Epoch 09: train loss 318.5401 (mse_score: 318.5401)\n",
      "16:18 madminer.utils.ml.sc INFO                val. loss  311.3174 (mse_score: 311.3174)\n",
      "16:19 madminer.utils.ml.sc INFO      Epoch 10: train loss 318.5382 (mse_score: 318.5382)\n",
      "16:19 madminer.utils.ml.sc INFO                val. loss  311.3525 (mse_score: 311.3525)\n",
      "16:19 madminer.utils.ml.sc INFO      Epoch 11: train loss 318.5516 (mse_score: 318.5516)\n",
      "16:19 madminer.utils.ml.sc INFO                val. loss  311.3164 (mse_score: 311.3164)\n",
      "16:20 madminer.utils.ml.sc INFO      Epoch 12: train loss 318.5209 (mse_score: 318.5209)\n",
      "16:20 madminer.utils.ml.sc INFO                val. loss  311.2540 (mse_score: 311.2540) (*)\n",
      "16:20 madminer.utils.ml.sc INFO      Epoch 13: train loss 318.5449 (mse_score: 318.5449)\n",
      "16:20 madminer.utils.ml.sc INFO                val. loss  311.3553 (mse_score: 311.3553)\n",
      "16:21 madminer.utils.ml.sc INFO      Epoch 14: train loss 318.5659 (mse_score: 318.5659)\n",
      "16:21 madminer.utils.ml.sc INFO                val. loss  311.2826 (mse_score: 311.2826)\n",
      "16:21 madminer.utils.ml.sc INFO      Epoch 15: train loss 318.4935 (mse_score: 318.4935)\n",
      "16:21 madminer.utils.ml.sc INFO                val. loss  311.2797 (mse_score: 311.2797)\n",
      "16:22 madminer.utils.ml.sc INFO      Epoch 16: train loss 318.4932 (mse_score: 318.4932)\n",
      "16:22 madminer.utils.ml.sc INFO                val. loss  311.2955 (mse_score: 311.2955)\n",
      "16:22 madminer.utils.ml.sc INFO      Epoch 17: train loss 318.5701 (mse_score: 318.5701)\n",
      "16:22 madminer.utils.ml.sc INFO                val. loss  311.2861 (mse_score: 311.2861)\n",
      "16:22 madminer.utils.ml.sc INFO      Epoch 18: train loss 318.4869 (mse_score: 318.4869)\n",
      "16:22 madminer.utils.ml.sc INFO                val. loss  311.2790 (mse_score: 311.2790)\n",
      "16:23 madminer.utils.ml.sc INFO      Epoch 19: train loss 318.4736 (mse_score: 318.4736)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:23 madminer.utils.ml.sc INFO                val. loss  311.2656 (mse_score: 311.2656)\n",
      "16:23 madminer.utils.ml.sc INFO      Epoch 20: train loss 318.4820 (mse_score: 318.4820)\n",
      "16:23 madminer.utils.ml.sc INFO                val. loss  311.4254 (mse_score: 311.4254)\n",
      "16:24 madminer.utils.ml.sc INFO      Epoch 21: train loss 318.4657 (mse_score: 318.4657)\n",
      "16:24 madminer.utils.ml.sc INFO                val. loss  311.3425 (mse_score: 311.3425)\n",
      "16:24 madminer.utils.ml.sc INFO      Epoch 22: train loss 318.5200 (mse_score: 318.5200)\n",
      "16:24 madminer.utils.ml.sc INFO                val. loss  311.2750 (mse_score: 311.2750)\n",
      "16:24 madminer.utils.ml.sc INFO      Epoch 23: train loss 318.4953 (mse_score: 318.4953)\n",
      "16:24 madminer.utils.ml.sc INFO                val. loss  311.2471 (mse_score: 311.2471) (*)\n",
      "16:25 madminer.utils.ml.sc INFO      Epoch 24: train loss 318.4629 (mse_score: 318.4629)\n",
      "16:25 madminer.utils.ml.sc INFO                val. loss  311.2659 (mse_score: 311.2659)\n",
      "16:25 madminer.utils.ml.sc INFO      Epoch 25: train loss 318.5284 (mse_score: 318.5284)\n",
      "16:25 madminer.utils.ml.sc INFO                val. loss  311.3109 (mse_score: 311.3109)\n",
      "16:26 madminer.utils.ml.sc INFO      Epoch 26: train loss 318.4434 (mse_score: 318.4434)\n",
      "16:26 madminer.utils.ml.sc INFO                val. loss  311.2398 (mse_score: 311.2398) (*)\n",
      "16:26 madminer.utils.ml.sc INFO      Epoch 27: train loss 318.4333 (mse_score: 318.4333)\n",
      "16:26 madminer.utils.ml.sc INFO                val. loss  311.3203 (mse_score: 311.3203)\n",
      "16:26 madminer.utils.ml.sc INFO      Epoch 28: train loss 318.4340 (mse_score: 318.4340)\n",
      "16:26 madminer.utils.ml.sc INFO                val. loss  311.2759 (mse_score: 311.2759)\n",
      "16:27 madminer.utils.ml.sc INFO      Epoch 29: train loss 318.4388 (mse_score: 318.4388)\n",
      "16:27 madminer.utils.ml.sc INFO                val. loss  311.2069 (mse_score: 311.2069) (*)\n",
      "16:27 madminer.utils.ml.sc INFO      Epoch 30: train loss 318.4266 (mse_score: 318.4266)\n",
      "16:27 madminer.utils.ml.sc INFO                val. loss  311.2434 (mse_score: 311.2434)\n",
      "16:28 madminer.utils.ml.sc INFO      Epoch 31: train loss 318.4319 (mse_score: 318.4319)\n",
      "16:28 madminer.utils.ml.sc INFO                val. loss  311.2586 (mse_score: 311.2586)\n",
      "16:28 madminer.utils.ml.sc INFO      Epoch 32: train loss 318.4471 (mse_score: 318.4471)\n",
      "16:28 madminer.utils.ml.sc INFO                val. loss  311.2142 (mse_score: 311.2142)\n",
      "16:28 madminer.utils.ml.sc INFO      Epoch 33: train loss 318.7441 (mse_score: 318.7441)\n",
      "16:28 madminer.utils.ml.sc INFO                val. loss  311.2477 (mse_score: 311.2477)\n",
      "16:29 madminer.utils.ml.sc INFO      Epoch 34: train loss 318.4879 (mse_score: 318.4879)\n",
      "16:29 madminer.utils.ml.sc INFO                val. loss  311.1890 (mse_score: 311.1890) (*)\n",
      "16:29 madminer.utils.ml.sc INFO      Epoch 35: train loss 318.4187 (mse_score: 318.4187)\n",
      "16:29 madminer.utils.ml.sc INFO                val. loss  311.1854 (mse_score: 311.1854) (*)\n",
      "16:30 madminer.utils.ml.sc INFO      Epoch 36: train loss 318.5465 (mse_score: 318.5465)\n",
      "16:30 madminer.utils.ml.sc INFO                val. loss  311.2056 (mse_score: 311.2056)\n",
      "16:30 madminer.utils.ml.sc INFO      Epoch 37: train loss 318.4336 (mse_score: 318.4336)\n",
      "16:30 madminer.utils.ml.sc INFO                val. loss  311.1895 (mse_score: 311.1895)\n",
      "16:30 madminer.utils.ml.sc INFO      Epoch 38: train loss 318.4093 (mse_score: 318.4093)\n",
      "16:30 madminer.utils.ml.sc INFO                val. loss  311.2437 (mse_score: 311.2437)\n",
      "16:31 madminer.utils.ml.sc INFO      Epoch 39: train loss 318.4050 (mse_score: 318.4050)\n",
      "16:31 madminer.utils.ml.sc INFO                val. loss  311.1852 (mse_score: 311.1852) (*)\n",
      "16:31 madminer.utils.ml.sc INFO      Epoch 40: train loss 318.3972 (mse_score: 318.3972)\n",
      "16:31 madminer.utils.ml.sc INFO                val. loss  311.2244 (mse_score: 311.2244)\n",
      "16:31 madminer.utils.ml.sc INFO      Epoch 41: train loss 318.4121 (mse_score: 318.4121)\n",
      "16:31 madminer.utils.ml.sc INFO                val. loss  311.1977 (mse_score: 311.1977)\n",
      "16:32 madminer.utils.ml.sc INFO      Epoch 42: train loss 318.4241 (mse_score: 318.4241)\n",
      "16:32 madminer.utils.ml.sc INFO                val. loss  311.1813 (mse_score: 311.1813) (*)\n",
      "16:32 madminer.utils.ml.sc INFO      Epoch 43: train loss 318.4138 (mse_score: 318.4138)\n",
      "16:32 madminer.utils.ml.sc INFO                val. loss  311.1815 (mse_score: 311.1815)\n",
      "16:33 madminer.utils.ml.sc INFO      Epoch 44: train loss 318.4415 (mse_score: 318.4415)\n",
      "16:33 madminer.utils.ml.sc INFO                val. loss  311.2097 (mse_score: 311.2097)\n",
      "16:33 madminer.utils.ml.sc INFO      Epoch 45: train loss 318.4029 (mse_score: 318.4029)\n",
      "16:33 madminer.utils.ml.sc INFO                val. loss  311.2007 (mse_score: 311.2007)\n",
      "16:33 madminer.utils.ml.sc INFO      Epoch 46: train loss 318.3985 (mse_score: 318.3985)\n",
      "16:33 madminer.utils.ml.sc INFO                val. loss  311.1999 (mse_score: 311.1999)\n",
      "16:34 madminer.utils.ml.sc INFO      Epoch 47: train loss 318.3886 (mse_score: 318.3886)\n",
      "16:34 madminer.utils.ml.sc INFO                val. loss  311.1708 (mse_score: 311.1708) (*)\n",
      "16:34 madminer.utils.ml.sc INFO      Epoch 48: train loss 318.4372 (mse_score: 318.4372)\n",
      "16:34 madminer.utils.ml.sc INFO                val. loss  311.1840 (mse_score: 311.1840)\n",
      "16:35 madminer.utils.ml.sc INFO      Epoch 49: train loss 318.3897 (mse_score: 318.3897)\n",
      "16:35 madminer.utils.ml.sc INFO                val. loss  312.5739 (mse_score: 312.5739)\n",
      "16:35 madminer.utils.ml.sc INFO      Epoch 50: train loss 326.5660 (mse_score: 326.5660)\n",
      "16:35 madminer.utils.ml.sc INFO                val. loss  311.1699 (mse_score: 311.1699) (*)\n",
      "16:35 madminer.utils.ml.sc INFO    Early stopping did not improve performance\n",
      "16:35 madminer.utils.ml.sc INFO    Finished training\n",
      "16:35 madminer.ml          INFO    Training estimator 9 / 10 in ensemble\n",
      "16:35 madminer.ml          INFO    Starting training\n",
      "16:35 madminer.ml          INFO      Method:                 sally\n",
      "16:35 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_8.npy\n",
      "16:35 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_8.npy\n",
      "16:35 madminer.ml          INFO      Features:               [32]\n",
      "16:35 madminer.ml          INFO      Method:                 sally\n",
      "16:35 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "16:35 madminer.ml          INFO      Activation function:    tanh\n",
      "16:35 madminer.ml          INFO      Batch size:             128\n",
      "16:35 madminer.ml          INFO      Trainer:                amsgrad\n",
      "16:35 madminer.ml          INFO      Epochs:                 50\n",
      "16:35 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:35 madminer.ml          INFO      Validation split:       0.5\n",
      "16:35 madminer.ml          INFO      Early stopping:         True\n",
      "16:35 madminer.ml          INFO      Scale inputs:           True\n",
      "16:35 madminer.ml          INFO      Shuffle labels          False\n",
      "16:35 madminer.ml          INFO      Regularization:         None\n",
      "16:35 madminer.ml          INFO      Samples:                all\n",
      "16:35 madminer.ml          INFO    Loading training data\n",
      "16:35 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "16:35 madminer.ml          INFO    Rescaling inputs\n",
      "16:35 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "16:35 madminer.ml          INFO    Creating model for method sally\n",
      "16:35 madminer.ml          INFO    Training model\n",
      "16:35 madminer.utils.ml.sc INFO      Epoch 01: train loss 323.0545 (mse_score: 323.0545)\n",
      "16:35 madminer.utils.ml.sc INFO                val. loss  304.8597 (mse_score: 304.8597) (*)\n",
      "16:36 madminer.utils.ml.sc INFO      Epoch 02: train loss 313.1288 (mse_score: 313.1288)\n",
      "16:36 madminer.utils.ml.sc INFO                val. loss  304.4607 (mse_score: 304.4607) (*)\n",
      "16:36 madminer.utils.ml.sc INFO      Epoch 03: train loss 313.0491 (mse_score: 313.0491)\n",
      "16:36 madminer.utils.ml.sc INFO                val. loss  304.4709 (mse_score: 304.4709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:36 madminer.utils.ml.sc INFO      Epoch 04: train loss 313.0008 (mse_score: 313.0008)\n",
      "16:36 madminer.utils.ml.sc INFO                val. loss  304.3478 (mse_score: 304.3478) (*)\n",
      "16:37 madminer.utils.ml.sc INFO      Epoch 05: train loss 312.8865 (mse_score: 312.8865)\n",
      "16:37 madminer.utils.ml.sc INFO                val. loss  304.3633 (mse_score: 304.3633)\n",
      "16:37 madminer.utils.ml.sc INFO      Epoch 06: train loss 312.8697 (mse_score: 312.8697)\n",
      "16:37 madminer.utils.ml.sc INFO                val. loss  304.4257 (mse_score: 304.4257)\n",
      "16:38 madminer.utils.ml.sc INFO      Epoch 07: train loss 312.8410 (mse_score: 312.8410)\n",
      "16:38 madminer.utils.ml.sc INFO                val. loss  304.5072 (mse_score: 304.5072)\n",
      "16:38 madminer.utils.ml.sc INFO      Epoch 08: train loss 312.8368 (mse_score: 312.8368)\n",
      "16:38 madminer.utils.ml.sc INFO                val. loss  304.6419 (mse_score: 304.6419)\n",
      "16:39 madminer.utils.ml.sc INFO      Epoch 09: train loss 312.8337 (mse_score: 312.8337)\n",
      "16:39 madminer.utils.ml.sc INFO                val. loss  304.3770 (mse_score: 304.3770)\n",
      "16:39 madminer.utils.ml.sc INFO      Epoch 10: train loss 312.8058 (mse_score: 312.8058)\n",
      "16:39 madminer.utils.ml.sc INFO                val. loss  304.3440 (mse_score: 304.3440) (*)\n",
      "16:39 madminer.utils.ml.sc INFO      Epoch 11: train loss 312.7905 (mse_score: 312.7905)\n",
      "16:39 madminer.utils.ml.sc INFO                val. loss  304.2775 (mse_score: 304.2775) (*)\n",
      "16:39 madminer.utils.ml.sc INFO      Epoch 12: train loss 312.7707 (mse_score: 312.7707)\n",
      "16:39 madminer.utils.ml.sc INFO                val. loss  304.5539 (mse_score: 304.5539)\n",
      "16:40 madminer.utils.ml.sc INFO      Epoch 13: train loss 312.8298 (mse_score: 312.8298)\n",
      "16:40 madminer.utils.ml.sc INFO                val. loss  304.2587 (mse_score: 304.2587) (*)\n",
      "16:40 madminer.utils.ml.sc INFO      Epoch 14: train loss 312.7702 (mse_score: 312.7702)\n",
      "16:40 madminer.utils.ml.sc INFO                val. loss  304.3814 (mse_score: 304.3814)\n",
      "16:40 madminer.utils.ml.sc INFO      Epoch 15: train loss 312.7497 (mse_score: 312.7497)\n",
      "16:40 madminer.utils.ml.sc INFO                val. loss  304.3494 (mse_score: 304.3494)\n",
      "16:41 madminer.utils.ml.sc INFO      Epoch 16: train loss 312.7466 (mse_score: 312.7466)\n",
      "16:41 madminer.utils.ml.sc INFO                val. loss  304.2923 (mse_score: 304.2923)\n",
      "16:41 madminer.utils.ml.sc INFO      Epoch 17: train loss 312.7534 (mse_score: 312.7534)\n",
      "16:41 madminer.utils.ml.sc INFO                val. loss  304.2737 (mse_score: 304.2737)\n",
      "16:41 madminer.utils.ml.sc INFO      Epoch 18: train loss 312.7202 (mse_score: 312.7202)\n",
      "16:41 madminer.utils.ml.sc INFO                val. loss  304.4015 (mse_score: 304.4015)\n",
      "16:42 madminer.utils.ml.sc INFO      Epoch 19: train loss 312.8386 (mse_score: 312.8386)\n",
      "16:42 madminer.utils.ml.sc INFO                val. loss  304.2865 (mse_score: 304.2865)\n",
      "16:42 madminer.utils.ml.sc INFO      Epoch 20: train loss 312.7183 (mse_score: 312.7183)\n",
      "16:42 madminer.utils.ml.sc INFO                val. loss  304.2147 (mse_score: 304.2147) (*)\n",
      "16:42 madminer.utils.ml.sc INFO      Epoch 21: train loss 312.7335 (mse_score: 312.7335)\n",
      "16:42 madminer.utils.ml.sc INFO                val. loss  304.3951 (mse_score: 304.3951)\n",
      "16:42 madminer.utils.ml.sc INFO      Epoch 22: train loss 312.6912 (mse_score: 312.6912)\n",
      "16:42 madminer.utils.ml.sc INFO                val. loss  304.2039 (mse_score: 304.2039) (*)\n",
      "16:43 madminer.utils.ml.sc INFO      Epoch 23: train loss 312.6929 (mse_score: 312.6929)\n",
      "16:43 madminer.utils.ml.sc INFO                val. loss  304.2842 (mse_score: 304.2842)\n",
      "16:43 madminer.utils.ml.sc INFO      Epoch 24: train loss 312.6960 (mse_score: 312.6960)\n",
      "16:43 madminer.utils.ml.sc INFO                val. loss  304.2532 (mse_score: 304.2532)\n",
      "16:43 madminer.utils.ml.sc INFO      Epoch 25: train loss 312.6855 (mse_score: 312.6855)\n",
      "16:43 madminer.utils.ml.sc INFO                val. loss  304.2722 (mse_score: 304.2722)\n",
      "16:44 madminer.utils.ml.sc INFO      Epoch 26: train loss 312.7030 (mse_score: 312.7030)\n",
      "16:44 madminer.utils.ml.sc INFO                val. loss  304.2465 (mse_score: 304.2465)\n",
      "16:44 madminer.utils.ml.sc INFO      Epoch 27: train loss 312.7664 (mse_score: 312.7664)\n",
      "16:44 madminer.utils.ml.sc INFO                val. loss  304.2790 (mse_score: 304.2790)\n",
      "16:44 madminer.utils.ml.sc INFO      Epoch 28: train loss 312.7313 (mse_score: 312.7313)\n",
      "16:44 madminer.utils.ml.sc INFO                val. loss  304.2588 (mse_score: 304.2588)\n",
      "16:45 madminer.utils.ml.sc INFO      Epoch 29: train loss 312.6729 (mse_score: 312.6729)\n",
      "16:45 madminer.utils.ml.sc INFO                val. loss  304.2939 (mse_score: 304.2939)\n",
      "16:45 madminer.utils.ml.sc INFO      Epoch 30: train loss 312.7750 (mse_score: 312.7750)\n",
      "16:45 madminer.utils.ml.sc INFO                val. loss  304.2176 (mse_score: 304.2176)\n",
      "16:45 madminer.utils.ml.sc INFO      Epoch 31: train loss 312.6707 (mse_score: 312.6707)\n",
      "16:45 madminer.utils.ml.sc INFO                val. loss  304.2387 (mse_score: 304.2387)\n",
      "16:45 madminer.utils.ml.sc INFO      Epoch 32: train loss 312.6474 (mse_score: 312.6474)\n",
      "16:45 madminer.utils.ml.sc INFO                val. loss  304.2352 (mse_score: 304.2352)\n",
      "16:46 madminer.utils.ml.sc INFO      Epoch 33: train loss 312.6546 (mse_score: 312.6546)\n",
      "16:46 madminer.utils.ml.sc INFO                val. loss  304.2158 (mse_score: 304.2158)\n",
      "16:46 madminer.utils.ml.sc INFO      Epoch 34: train loss 312.6669 (mse_score: 312.6669)\n",
      "16:46 madminer.utils.ml.sc INFO                val. loss  304.2296 (mse_score: 304.2296)\n",
      "16:46 madminer.utils.ml.sc INFO      Epoch 35: train loss 312.6547 (mse_score: 312.6547)\n",
      "16:46 madminer.utils.ml.sc INFO                val. loss  304.2302 (mse_score: 304.2302)\n",
      "16:47 madminer.utils.ml.sc INFO      Epoch 36: train loss 312.7131 (mse_score: 312.7131)\n",
      "16:47 madminer.utils.ml.sc INFO                val. loss  304.3479 (mse_score: 304.3479)\n",
      "16:47 madminer.utils.ml.sc INFO      Epoch 37: train loss 312.6584 (mse_score: 312.6584)\n",
      "16:47 madminer.utils.ml.sc INFO                val. loss  304.2048 (mse_score: 304.2048)\n",
      "16:47 madminer.utils.ml.sc INFO      Epoch 38: train loss 312.6442 (mse_score: 312.6442)\n",
      "16:47 madminer.utils.ml.sc INFO                val. loss  304.2365 (mse_score: 304.2365)\n",
      "16:48 madminer.utils.ml.sc INFO      Epoch 39: train loss 312.6502 (mse_score: 312.6502)\n",
      "16:48 madminer.utils.ml.sc INFO                val. loss  304.2492 (mse_score: 304.2492)\n",
      "16:48 madminer.utils.ml.sc INFO      Epoch 40: train loss 312.6335 (mse_score: 312.6335)\n",
      "16:48 madminer.utils.ml.sc INFO                val. loss  304.2289 (mse_score: 304.2289)\n",
      "16:48 madminer.utils.ml.sc INFO      Epoch 41: train loss 312.6442 (mse_score: 312.6442)\n",
      "16:48 madminer.utils.ml.sc INFO                val. loss  304.2201 (mse_score: 304.2201)\n",
      "16:48 madminer.utils.ml.sc INFO      Epoch 42: train loss 312.6610 (mse_score: 312.6610)\n",
      "16:48 madminer.utils.ml.sc INFO                val. loss  304.2060 (mse_score: 304.2060)\n",
      "16:49 madminer.utils.ml.sc INFO      Epoch 43: train loss 312.6609 (mse_score: 312.6609)\n",
      "16:49 madminer.utils.ml.sc INFO                val. loss  304.1889 (mse_score: 304.1889) (*)\n",
      "16:49 madminer.utils.ml.sc INFO      Epoch 44: train loss 312.6428 (mse_score: 312.6428)\n",
      "16:49 madminer.utils.ml.sc INFO                val. loss  304.2981 (mse_score: 304.2981)\n",
      "16:49 madminer.utils.ml.sc INFO      Epoch 45: train loss 312.6485 (mse_score: 312.6485)\n",
      "16:49 madminer.utils.ml.sc INFO                val. loss  304.1960 (mse_score: 304.1960)\n",
      "16:50 madminer.utils.ml.sc INFO      Epoch 46: train loss 312.6638 (mse_score: 312.6638)\n",
      "16:50 madminer.utils.ml.sc INFO                val. loss  304.1868 (mse_score: 304.1868) (*)\n",
      "16:50 madminer.utils.ml.sc INFO      Epoch 47: train loss 312.6268 (mse_score: 312.6268)\n",
      "16:50 madminer.utils.ml.sc INFO                val. loss  304.1967 (mse_score: 304.1967)\n",
      "16:50 madminer.utils.ml.sc INFO      Epoch 48: train loss 312.6472 (mse_score: 312.6472)\n",
      "16:50 madminer.utils.ml.sc INFO                val. loss  304.2313 (mse_score: 304.2313)\n",
      "16:51 madminer.utils.ml.sc INFO      Epoch 49: train loss 312.6364 (mse_score: 312.6364)\n",
      "16:51 madminer.utils.ml.sc INFO                val. loss  304.1966 (mse_score: 304.1966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:51 madminer.utils.ml.sc INFO      Epoch 50: train loss 313.2358 (mse_score: 313.2358)\n",
      "16:51 madminer.utils.ml.sc INFO                val. loss  304.2551 (mse_score: 304.2551)\n",
      "16:51 madminer.utils.ml.sc INFO    Early stopping after epoch 46, with loss 304.19 compared to final loss 304.26\n",
      "16:51 madminer.utils.ml.sc INFO    Finished training\n",
      "16:51 madminer.ml          INFO    Training estimator 10 / 10 in ensemble\n",
      "16:51 madminer.ml          INFO    Starting training\n",
      "16:51 madminer.ml          INFO      Method:                 sally\n",
      "16:51 madminer.ml          INFO      Training data:          x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/x_train_9.npy\n",
      "16:51 madminer.ml          INFO                              t_xz (theta0) at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma_sys/train_local_tight/t_xz_train_9.npy\n",
      "16:51 madminer.ml          INFO      Features:               [32]\n",
      "16:51 madminer.ml          INFO      Method:                 sally\n",
      "16:51 madminer.ml          INFO      Hidden layers:          (100, 100)\n",
      "16:51 madminer.ml          INFO      Activation function:    tanh\n",
      "16:51 madminer.ml          INFO      Batch size:             128\n",
      "16:51 madminer.ml          INFO      Trainer:                amsgrad\n",
      "16:51 madminer.ml          INFO      Epochs:                 50\n",
      "16:51 madminer.ml          INFO      Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:51 madminer.ml          INFO      Validation split:       0.5\n",
      "16:51 madminer.ml          INFO      Early stopping:         True\n",
      "16:51 madminer.ml          INFO      Scale inputs:           True\n",
      "16:51 madminer.ml          INFO      Shuffle labels          False\n",
      "16:51 madminer.ml          INFO      Regularization:         None\n",
      "16:51 madminer.ml          INFO      Samples:                all\n",
      "16:51 madminer.ml          INFO    Loading training data\n",
      "16:51 madminer.ml          INFO    Found 1000000 samples with 34 parameters and 33 observables\n",
      "16:51 madminer.ml          INFO    Rescaling inputs\n",
      "16:51 madminer.ml          INFO    Only using 1 of 33 observables\n",
      "16:51 madminer.ml          INFO    Creating model for method sally\n",
      "16:51 madminer.ml          INFO    Training model\n",
      "16:51 madminer.utils.ml.sc INFO      Epoch 01: train loss 322.9465 (mse_score: 322.9465)\n",
      "16:51 madminer.utils.ml.sc INFO                val. loss  313.5878 (mse_score: 313.5878) (*)\n",
      "16:51 madminer.utils.ml.sc INFO      Epoch 02: train loss 311.3408 (mse_score: 311.3408)\n",
      "16:51 madminer.utils.ml.sc INFO                val. loss  312.6643 (mse_score: 312.6643) (*)\n",
      "16:52 madminer.utils.ml.sc INFO      Epoch 03: train loss 310.9594 (mse_score: 310.9594)\n",
      "16:52 madminer.utils.ml.sc INFO                val. loss  312.6431 (mse_score: 312.6431) (*)\n",
      "16:52 madminer.utils.ml.sc INFO      Epoch 04: train loss 310.9922 (mse_score: 310.9922)\n",
      "16:52 madminer.utils.ml.sc INFO                val. loss  312.6089 (mse_score: 312.6089) (*)\n",
      "16:52 madminer.utils.ml.sc INFO      Epoch 05: train loss 310.8721 (mse_score: 310.8721)\n",
      "16:52 madminer.utils.ml.sc INFO                val. loss  312.5995 (mse_score: 312.5995) (*)\n",
      "16:53 madminer.utils.ml.sc INFO      Epoch 06: train loss 310.8698 (mse_score: 310.8698)\n",
      "16:53 madminer.utils.ml.sc INFO                val. loss  312.6728 (mse_score: 312.6728)\n",
      "16:53 madminer.utils.ml.sc INFO      Epoch 07: train loss 310.9053 (mse_score: 310.9053)\n",
      "16:53 madminer.utils.ml.sc INFO                val. loss  312.9308 (mse_score: 312.9308)\n",
      "16:53 madminer.utils.ml.sc INFO      Epoch 08: train loss 310.8395 (mse_score: 310.8395)\n",
      "16:53 madminer.utils.ml.sc INFO                val. loss  313.3255 (mse_score: 313.3255)\n",
      "16:54 madminer.utils.ml.sc INFO      Epoch 09: train loss 310.8152 (mse_score: 310.8152)\n",
      "16:54 madminer.utils.ml.sc INFO                val. loss  312.5477 (mse_score: 312.5477) (*)\n",
      "16:54 madminer.utils.ml.sc INFO      Epoch 10: train loss 310.8076 (mse_score: 310.8076)\n",
      "16:54 madminer.utils.ml.sc INFO                val. loss  312.5406 (mse_score: 312.5406) (*)\n",
      "16:54 madminer.utils.ml.sc INFO      Epoch 11: train loss 310.7908 (mse_score: 310.7908)\n",
      "16:54 madminer.utils.ml.sc INFO                val. loss  312.6389 (mse_score: 312.6389)\n",
      "16:55 madminer.utils.ml.sc INFO      Epoch 12: train loss 310.7803 (mse_score: 310.7803)\n",
      "16:55 madminer.utils.ml.sc INFO                val. loss  312.5589 (mse_score: 312.5589)\n",
      "16:55 madminer.utils.ml.sc INFO      Epoch 13: train loss 310.7767 (mse_score: 310.7767)\n",
      "16:55 madminer.utils.ml.sc INFO                val. loss  312.6443 (mse_score: 312.6443)\n",
      "16:55 madminer.utils.ml.sc INFO      Epoch 14: train loss 310.7704 (mse_score: 310.7704)\n",
      "16:55 madminer.utils.ml.sc INFO                val. loss  312.6163 (mse_score: 312.6163)\n",
      "16:56 madminer.utils.ml.sc INFO      Epoch 15: train loss 310.7606 (mse_score: 310.7606)\n",
      "16:56 madminer.utils.ml.sc INFO                val. loss  312.6333 (mse_score: 312.6333)\n",
      "16:56 madminer.utils.ml.sc INFO      Epoch 16: train loss 310.7676 (mse_score: 310.7676)\n",
      "16:56 madminer.utils.ml.sc INFO                val. loss  312.5382 (mse_score: 312.5382) (*)\n",
      "16:56 madminer.utils.ml.sc INFO      Epoch 17: train loss 310.8082 (mse_score: 310.8082)\n",
      "16:56 madminer.utils.ml.sc INFO                val. loss  312.5366 (mse_score: 312.5366) (*)\n",
      "16:57 madminer.utils.ml.sc INFO      Epoch 18: train loss 310.7588 (mse_score: 310.7588)\n",
      "16:57 madminer.utils.ml.sc INFO                val. loss  312.5471 (mse_score: 312.5471)\n",
      "16:57 madminer.utils.ml.sc INFO      Epoch 19: train loss 310.7891 (mse_score: 310.7891)\n",
      "16:57 madminer.utils.ml.sc INFO                val. loss  312.5443 (mse_score: 312.5443)\n",
      "16:57 madminer.utils.ml.sc INFO      Epoch 20: train loss 310.7279 (mse_score: 310.7279)\n",
      "16:57 madminer.utils.ml.sc INFO                val. loss  312.4850 (mse_score: 312.4850) (*)\n",
      "16:57 madminer.utils.ml.sc INFO      Epoch 21: train loss 310.7164 (mse_score: 310.7164)\n",
      "16:57 madminer.utils.ml.sc INFO                val. loss  312.5282 (mse_score: 312.5282)\n",
      "16:58 madminer.utils.ml.sc INFO      Epoch 22: train loss 310.7710 (mse_score: 310.7710)\n",
      "16:58 madminer.utils.ml.sc INFO                val. loss  312.4830 (mse_score: 312.4830) (*)\n",
      "16:58 madminer.utils.ml.sc INFO      Epoch 23: train loss 310.8408 (mse_score: 310.8408)\n",
      "16:58 madminer.utils.ml.sc INFO                val. loss  312.6635 (mse_score: 312.6635)\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'phi_tight',\n",
    "    use_tight_cuts=True,\n",
    "    features=[[32] for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'pta_phi_tight',\n",
    "    use_tight_cuts=True,\n",
    "    features=[[9, 32] for _ in range(n_estimators)],\n",
    "    validation_split=0.5,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (higgs_inference)",
   "language": "python",
   "name": "higgs_inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
