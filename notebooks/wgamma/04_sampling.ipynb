{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Delphes and extract observables\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (with tight cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:59  \n",
      "09:59  ------------------------------------------------------------\n",
      "09:59  |                                                          |\n",
      "09:59  |  MadMiner v2018.11.13                                    |\n",
      "09:59  |                                                          |\n",
      "09:59  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "09:59  |                                                          |\n",
      "09:59  ------------------------------------------------------------\n",
      "09:59  \n",
      "09:59  Loading data from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/samples_tight.h5\n",
      "09:59  Found 2 parameters:\n",
      "09:59     cWWW (LHA: dim6 1, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "09:59     cWWWtilde (LHA: dim6 2, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "09:59  Found 6 benchmarks:\n",
      "09:59     sm: cWWW = 0.00e+00, cWWWtilde = 0.00e+00\n",
      "09:59     morphing_basis_vector_1: cWWW = -6.07e-03, cWWWtilde = -1.84e-02\n",
      "09:59     morphing_basis_vector_2: cWWW = 1.00e-02, cWWWtilde = 1.70e-02\n",
      "09:59     morphing_basis_vector_3: cWWW = -1.99e-02, cWWWtilde = 1.87e-02\n",
      "09:59     morphing_basis_vector_4: cWWW = 1.97e-02, cWWWtilde = -1.53e-02\n",
      "09:59     morphing_basis_vector_5: cWWW = -1.65e-02, cWWWtilde = -6.33e-03\n",
      "09:59  Found 27 observables: et_miss, phi_miss, e_visible, eta_visible, e_l1, pt_l1, eta_l1, phi_l1, e_a1, pt_a1, eta_a1, phi_a1, e_j1, pt_j1, eta_j1, phi_j1, deltaphi_l1_met, deltaphi_a1_met, m_l1_met, pt_l1_met, m_l1_a1, deltaeta_l1_a1, deltaphi_l1_a1, m_a1_l1_met, pt_a1_l1_met, mt, phi_resurrection\n",
      "09:59  Found 1207773 events\n",
      "09:59  Found morphing setup with 6 components\n"
     ]
    }
   ],
   "source": [
    "sa = SampleAugmenter(sample_dir + 'samples_tight.h5', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SALLY training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    _, _, _ = sa.extract_samples_train_local(\n",
    "        theta=constant_morphing_theta([0.,0.]),\n",
    "        n_samples=1000000,\n",
    "        folder=sample_dir + 'train_local_tight',\n",
    "        filename='train_' + str(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RASCAL training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:58  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "16:06  Effective number of samples: mean 74.43564780032064, with individual thetas ranging from 21.63954540615782 to 2284.823339981527\n",
      "17:07  Effective number of samples: mean 75.92016292368486, with individual thetas ranging from 21.161377686203156 to 2281.875000642281\n",
      "17:07  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "17:07  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "17:17  Effective number of samples: mean 73.20635723117282, with individual thetas ranging from 21.314169415064793 to 2284.1798775026755\n",
      "17:26  Effective number of samples: mean 73.84520107083483, with individual thetas ranging from 21.381479553046063 to 2284.821459818786\n",
      "17:26  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "17:26  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "17:35  Effective number of samples: mean 75.26535433348769, with individual thetas ranging from 21.47481031871675 to 2283.0036814354444\n",
      "17:43  Effective number of samples: mean 75.39609491846014, with individual thetas ranging from 21.318796674323668 to 2283.0891571909137\n",
      "17:43  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "17:43  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "17:52  Effective number of samples: mean 77.22718893728916, with individual thetas ranging from 21.62154135985063 to 2283.4153421661113\n",
      "18:01  Effective number of samples: mean 74.41191182638389, with individual thetas ranging from 21.276366965192043 to 2284.001632474773\n",
      "18:01  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "18:01  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "18:10  Effective number of samples: mean 70.07759625043496, with individual thetas ranging from 21.71569109558737 to 2284.380669022022\n",
      "18:19  Effective number of samples: mean 73.34277654746195, with individual thetas ranging from 21.544805711556062 to 2282.837317544955\n",
      "18:19  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "18:19  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "18:29  Effective number of samples: mean 76.5072080824239, with individual thetas ranging from 21.647865355596643 to 2284.226511845527\n",
      "18:43  Effective number of samples: mean 71.63336015972519, with individual thetas ranging from 21.486306458202876 to 2284.4888243653395\n",
      "18:43  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "18:43  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "18:52  Effective number of samples: mean 73.7207360931378, with individual thetas ranging from 21.539493442606133 to 2282.123730243976\n",
      "19:00  Effective number of samples: mean 73.41462431203749, with individual thetas ranging from 21.59500545269459 to 2281.726555684166\n",
      "19:00  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "19:01  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "19:09  Effective number of samples: mean 76.12596741737795, with individual thetas ranging from 21.269329821722636 to 2285.94656947466\n",
      "19:18  Effective number of samples: mean 72.02445588181824, with individual thetas ranging from 21.281524586930882 to 2283.898253244887\n",
      "19:18  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "19:18  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "19:27  Effective number of samples: mean 73.0262569959806, with individual thetas ranging from 21.782200479764782 to 2278.7794305290086\n",
      "19:36  Effective number of samples: mean 72.75498792800661, with individual thetas ranging from 21.585223892652632 to 2286.9233220134875\n",
      "19:36  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "19:36  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "19:46  Effective number of samples: mean 69.56436368839344, with individual thetas ranging from 21.673583799185767 to 2282.629499986486\n",
      "19:56  Effective number of samples: mean 76.29845884334827, with individual thetas ranging from 21.351520447745106 to 2284.931517648395\n",
      "19:56  Oversampling: created 1000000 training samples from 500000 original unweighted events\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    _ = sa.extract_samples_train_more_ratios(\n",
    "        theta0=random_morphing_thetas(5000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)]),\n",
    "        theta1=random_morphing_thetas(5000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)]),\n",
    "        additional_thetas=[random_morphing_thetas(5000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)])\n",
    "                           for _ in range(1)],\n",
    "        n_samples=500000,\n",
    "        folder=sample_dir + 'train_ratios_tight',\n",
    "        filename='train_' + str(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCANDAL training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:56  Extracting training sample for non-local score-based methods. Sampling and score evaluation according to ('random', (10000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "20:14  Effective number of samples: mean 77.0283842526613, with individual thetas ranging from 21.386321260317445 to 2288.063823086091\n",
      "20:14  Extracting training sample for non-local score-based methods. Sampling and score evaluation according to ('random', (10000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bc7bd9be8fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_scandal_tight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     )\n",
      "\u001b[0;32m~/work/projects/madminer/madminer/madminer/sampling.py\u001b[0m in \u001b[0;36mextract_samples_train_global\u001b[0;34m(self, theta, n_samples, folder, filename, test_split, switch_train_test_events)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mtest_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mswitch_train_test_events\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswitch_train_test_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0mlog_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         )\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/madminer/madminer/madminer/sampling.py\u001b[0m in \u001b[0;36mextract_samples_train_local\u001b[0;34m(self, theta, n_samples, folder, filename, test_split, switch_train_test_events, log_message)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0maugmented_data_definitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmented_data_definitions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mstart_event\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_event\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mend_event\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_event\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         )\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/madminer/madminer/madminer/sampling.py\u001b[0m in \u001b[0;36m_extract_sample\u001b[0;34m(self, theta_sets_types, theta_sets_values, n_samples_per_theta, sampling_theta_index, augmented_data_definitions, start_event, end_event)\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 ):\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;31m# Evaluate p(x | sampling theta)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                     \u001b[0mweights_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampling_theta_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_benchmarks_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape (n_batch_size,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                     \u001b[0mp_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_theta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mxsec_sampling_theta\u001b[0m  \u001b[0;31m# Shape: (n_batch_size,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sa.extract_samples_train_global(\n",
    "        theta=random_morphing_thetas(10000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)]),\n",
    "        n_samples=1000000,\n",
    "        folder=sample_dir + 'train_scandal_tight',\n",
    "        filename='train_' + str(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = sa.extract_samples_train_plain(\n",
    "    theta=constant_morphing_theta([0.,0.]),\n",
    "    n_samples=1000000,\n",
    "    folder=sample_dir + 'validation_tight',\n",
    "    filename='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sm, _ = sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.]),\n",
    "    n_samples=1000000,\n",
    "    folder=sample_dir + 'test_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:34  Extracting evaluation sample. Sampling according to ('theta', array([0., 0.]))\n",
      "09:34  Effective number of samples: 2259.525446107569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.17253738e+02,  2.30557370e+00,  8.86337244e+02, ...,\n",
       "          1.52458694e+02,  3.22859440e+01, -3.47320220e-01],\n",
       "        [ 2.07721146e+02, -1.81286871e+00,  6.53493440e+02, ...,\n",
       "          2.81297518e+02,  6.74082272e+00,  2.98951358e+00],\n",
       "        [ 1.22945518e+02,  2.69437535e-03,  1.75161849e+02, ...,\n",
       "          2.54042924e+01,  7.66752857e+01, -1.36310169e+00],\n",
       "        ...,\n",
       "        [ 2.17523285e+02, -2.92998409e+00,  4.39063499e+02, ...,\n",
       "          1.88195239e+02,  1.16738988e+01,  3.04249414e+00],\n",
       "        [ 1.12007751e+02,  2.50395703e+00,  2.25418053e+02, ...,\n",
       "          1.05265545e+02,  5.12473658e+00, -6.17783841e-02],\n",
       "        [ 4.04335083e+02, -1.15071929e+00,  7.07115430e+02, ...,\n",
       "          2.60991267e+02,  4.28514999e+01, -4.31850324e-01]]), array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_sm_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:59  Extracting evaluation sample. Sampling according to ('theta', array([0.02, 0.  ]))\n",
      "09:59  Effective number of samples: 120.6630101056156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 2.09159668e+02,  8.27919394e-02,  9.22145328e+02, ...,\n",
       "          3.31864907e+01,  2.66064620e+01, -2.82906483e+00],\n",
       "        [ 4.83811859e+02, -1.65001988e+00,  1.02652408e+03, ...,\n",
       "          4.56574134e+02,  1.25176430e+01, -2.51325130e-01],\n",
       "        [ 4.59729767e+02, -1.43100786e+00,  2.18332224e+02, ...,\n",
       "          1.06060541e+02,  3.20591797e+01,  2.69200809e+00],\n",
       "        ...,\n",
       "        [ 6.77438293e+02, -1.23415582e-01,  1.10320346e+03, ...,\n",
       "          1.87576904e+01,  2.82283475e+01,  4.44017913e-01],\n",
       "        [ 2.43731308e+02, -1.18725456e-01,  7.89251520e+02, ...,\n",
       "          1.74396358e+02,  4.50046341e+01, -4.72359308e-01],\n",
       "        [ 1.50232285e+02,  3.08450913e+00,  2.02594379e+03, ...,\n",
       "          1.50916563e+02,  1.25974775e+01, -2.04640929e-01]]),\n",
       " array([[0.02, 0.  ],\n",
       "        [0.02, 0.  ],\n",
       "        [0.02, 0.  ],\n",
       "        ...,\n",
       "        [0.02, 0.  ],\n",
       "        [0.02, 0.  ],\n",
       "        [0.02, 0.  ]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.02,0.]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_www_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:31  Extracting evaluation sample. Sampling according to ('theta', array([0.005, 0.   ]))\n",
      "10:31  Effective number of samples: 986.9461974974071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.22683754e+02,  1.14082825e+00,  3.34105859e+02, ...,\n",
       "          1.35082948e+02,  2.11441009e+00, -1.85818514e-02],\n",
       "        [ 9.19899368e+01,  1.06257617e+00,  4.14038487e+02, ...,\n",
       "          1.09658210e+02,  9.59090649e+00,  2.95605195e+00],\n",
       "        [ 8.31525650e+01, -1.93947387e+00,  1.88542282e+02, ...,\n",
       "          9.20281837e+01,  1.69210312e+01,  2.72308010e-01],\n",
       "        ...,\n",
       "        [ 9.94973145e+01, -8.27758610e-01,  1.53625769e+03, ...,\n",
       "          5.25824096e+01,  1.23876439e+01, -9.19388928e-02],\n",
       "        [ 1.24059525e+02, -7.23481655e-01,  1.77488305e+02, ...,\n",
       "          7.05015473e+01,  3.98950083e+01,  2.58415419e+00],\n",
       "        [ 9.71189270e+01, -2.72597218e+00,  1.64953684e+02, ...,\n",
       "          3.84217464e+00,  3.63747485e+01, -2.68695069e+00]]),\n",
       " array([[0.005, 0.   ],\n",
       "        [0.005, 0.   ],\n",
       "        [0.005, 0.   ],\n",
       "        ...,\n",
       "        [0.005, 0.   ],\n",
       "        [0.005, 0.   ],\n",
       "        [0.005, 0.   ]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.005,0.]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_www_small_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:38  Extracting evaluation sample. Sampling according to ('theta', array([-0.005,  0.   ]))\n",
      "10:38  Effective number of samples: 989.1505252107842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.23298172e+02,  2.58348513e+00,  2.04053212e+02, ...,\n",
       "          9.44341574e+01,  1.12610386e+01,  4.90115225e-02],\n",
       "        [ 8.79270554e+01,  2.30236316e+00,  9.13900053e+02, ...,\n",
       "          1.36758643e+00,  6.49419596e+01,  1.53461231e+00],\n",
       "        [ 1.34921570e+02,  4.59023088e-01,  2.11196001e+02, ...,\n",
       "          7.72217691e+01,  7.13919538e+01,  2.07502526e+00],\n",
       "        ...,\n",
       "        [ 9.45649948e+01,  2.08066726e+00,  2.05641363e+02, ...,\n",
       "          4.57456851e+01,  2.56162039e+01,  2.71131416e+00],\n",
       "        [ 1.67094864e+02,  1.62404323e+00,  3.45389553e+02, ...,\n",
       "          1.43207620e+02,  2.82108137e+01, -3.37517767e-01],\n",
       "        [ 2.34366486e+02, -7.45173275e-01,  9.98064050e+02, ...,\n",
       "          1.63433531e+02,  3.60964327e+00,  2.38521008e-02]]),\n",
       " array([[-0.005,  0.   ],\n",
       "        [-0.005,  0.   ],\n",
       "        [-0.005,  0.   ],\n",
       "        ...,\n",
       "        [-0.005,  0.   ],\n",
       "        [-0.005,  0.   ],\n",
       "        [-0.005,  0.   ]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([-0.005,0.]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_www_smallnegative_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:59  Extracting evaluation sample. Sampling according to ('theta', array([0.  , 0.02]))\n",
      "09:59  Effective number of samples: 121.0377803284034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.37806488e+02,  1.35081220e+00,  3.12915131e+02, ...,\n",
       "          1.30661486e+02,  1.89120114e+01, -2.24675448e-01],\n",
       "        [ 1.79046814e+02,  1.65292239e+00,  3.45149229e+02, ...,\n",
       "          1.62311555e+02,  1.89325979e+01,  2.88270186e+00],\n",
       "        [ 1.09205765e+02,  2.07176781e+00,  4.63694880e+02, ...,\n",
       "          6.92713904e+01,  1.60210299e+00, -1.85390817e-02],\n",
       "        ...,\n",
       "        [ 3.24035828e+02, -2.45303774e+00,  4.85000356e+02, ...,\n",
       "          2.32594055e+02,  1.81344728e+01,  2.89999621e+00],\n",
       "        [ 1.10621330e+02, -2.04121423e+00,  4.82436452e+03, ...,\n",
       "          6.99785850e+01,  4.12134563e+01,  4.93750332e-01],\n",
       "        [ 1.30596710e+02,  4.55058545e-01,  4.61122608e+02, ...,\n",
       "          9.18030577e+01,  5.71031895e+01, -7.59526792e-01]]),\n",
       " array([[0.  , 0.02],\n",
       "        [0.  , 0.02],\n",
       "        [0.  , 0.02],\n",
       "        ...,\n",
       "        [0.  , 0.02],\n",
       "        [0.  , 0.02],\n",
       "        [0.  , 0.02]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.02]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_wwwtilde_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:31  Extracting evaluation sample. Sampling according to ('theta', array([0.   , 0.005]))\n",
      "10:31  Effective number of samples: 988.5259861919268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 9.35546631e+02, -2.98013747e-01,  1.69015191e+03, ...,\n",
       "          8.08507741e+02,  2.74514074e+00,  6.96583958e-02],\n",
       "        [ 3.19759857e+02, -1.58291769e+00,  8.42416084e+02, ...,\n",
       "          3.74892321e+02,  6.97266550e+00,  3.12757228e+00],\n",
       "        [ 1.76742737e+02, -2.83967900e+00,  3.60888451e+02, ...,\n",
       "          1.19213867e+02,  3.13900352e+00,  6.06286622e-02],\n",
       "        ...,\n",
       "        [ 1.06591537e+02, -1.71821427e+00,  2.78371766e+02, ...,\n",
       "          4.22812224e+01,  3.05732964e+01, -4.50498209e-01],\n",
       "        [ 9.05896225e+01,  2.27054644e+00,  5.55068144e+02, ...,\n",
       "          1.03960294e+02,  1.30264067e+01, -2.91799925e+00],\n",
       "        [ 1.20789719e+02,  5.31019829e-02,  2.40338555e+03, ...,\n",
       "          9.84474162e+01,  3.38142418e+01,  2.74735384e+00]]),\n",
       " array([[0.   , 0.005],\n",
       "        [0.   , 0.005],\n",
       "        [0.   , 0.005],\n",
       "        ...,\n",
       "        [0.   , 0.005],\n",
       "        [0.   , 0.005],\n",
       "        [0.   , 0.005]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.005]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_wwwtilde_small_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:37  Extracting evaluation sample. Sampling according to ('theta', array([ 0.   , -0.005]))\n",
      "10:37  Effective number of samples: 987.564710969861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.32951599e+02, -2.98489904e+00,  3.70151570e+02, ...,\n",
       "          1.12577105e+02,  6.07643343e+00, -7.35909144e-02],\n",
       "        [ 1.07900330e+02, -2.71692061e+00,  2.32934420e+02, ...,\n",
       "          7.48271537e+01,  8.92589877e+00, -1.20320844e-01],\n",
       "        [ 1.30245819e+02,  1.72092533e+00,  7.36644100e+02, ...,\n",
       "          4.37636023e+01,  4.95122451e+01,  2.59473737e+00],\n",
       "        ...,\n",
       "        [ 1.65513168e+02, -9.71721947e-01,  7.96032643e+02, ...,\n",
       "          1.30639832e+02,  4.01425286e+01,  4.59745724e-01],\n",
       "        [ 9.47796783e+01, -3.07862496e+00,  2.06380654e+02, ...,\n",
       "          1.01431551e+02,  1.39677137e+01,  2.94336041e+00],\n",
       "        [ 1.23226509e+02, -2.50864840e+00,  2.81923381e+02, ...,\n",
       "          1.15361937e+02,  1.19702688e+01,  1.66102595e-01]]),\n",
       " array([[ 0.   , -0.005],\n",
       "        [ 0.   , -0.005],\n",
       "        [ 0.   , -0.005],\n",
       "        ...,\n",
       "        [ 0.   , -0.005],\n",
       "        [ 0.   , -0.005],\n",
       "        [ 0.   , -0.005]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,-0.005]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_wwwtilde_smallnegative_tight',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xsec test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_benchmarks, xsecs_benchmarks, xsec_errors_benchmarks = sa.extract_cross_sections(\n",
    "    theta=multiple_benchmark_thetas(['sm', 'morphing_basis_vector_1', 'morphing_basis_vector_2', 'morphing_basis_vector_3', 'morphing_basis_vector_4', 'morphing_basis_vector_5'])\n",
    ")\n",
    "\n",
    "thetas_morphing, xsecs_morphing, xsec_errors_morphing = sa.extract_cross_sections(\n",
    "    theta=random_morphing_thetas(1000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmin, cmax = 0., 0.15\n",
    "\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "\n",
    "sc = plt.scatter(thetas_morphing[:,0], thetas_morphing[:,1], c=xsecs_morphing,\n",
    "            s=40., cmap='viridis', vmin=cmin, vmax=cmax,\n",
    "            marker='o')\n",
    "\n",
    "plt.scatter(thetas_benchmarks[:,0], thetas_benchmarks[:,1], c=xsecs_benchmarks,\n",
    "            s=200., cmap='viridis', vmin=cmin, vmax=cmax,lw=2., edgecolor='black',\n",
    "            marker='s')\n",
    "\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label('xsec [pb]')\n",
    "\n",
    "plt.xlim(-0.05,.05)\n",
    "plt.ylim(-0.05,.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observable distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bsm1, _ = sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.02,0.]),\n",
    "    n_samples=1000000,\n",
    "    folder=None,\n",
    "    filename=None\n",
    ")\n",
    "\n",
    "x_bsm2, _ = sa.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.02]),\n",
    "    n_samples=1000000,\n",
    "    folder=None,\n",
    "    filename=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 25\n",
    "n_observables = x_sm.shape[1]\n",
    "n_cols = 3\n",
    "n_rows = (n_observables + n_cols - 1) // n_cols\n",
    "labels = sa.observables.keys()\n",
    "\n",
    "plt.figure(figsize=(4. * n_cols, 4. * n_rows))\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    xmin = np.percentile(x_sm[:,i], 5.)\n",
    "    xmax = np.percentile(x_sm[:,i], 95.)\n",
    "    xwidth = xmax - xmin\n",
    "    xmin -= xwidth * 0.1\n",
    "    xmax += xwidth * 0.1\n",
    "    x_range = (xmin, xmax)\n",
    "    \n",
    "    ax = plt.subplot(n_rows, n_cols, i+1)\n",
    "       \n",
    "    plt.hist(x_sm[:,i], histtype='step', range=x_range, bins=bins, lw=1.5, label=r'SM', density=True) \n",
    "    plt.hist(x_bsm1[:,i], histtype='step', range=x_range, bins=bins, lw=1.5, label=r'$f_{WWW} = 0.02$', density=True)\n",
    "    plt.hist(x_bsm2[:,i], histtype='step', range=x_range, bins=bins, lw=1.5, label=r'$f_{\\tilde{W}WW} = 0.02$', density=True) \n",
    "    \n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.xlabel(label)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('observables.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same without cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:59  Loading data from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/samples.h5\n",
      "09:59  Found 2 parameters:\n",
      "09:59     cWWW (LHA: dim6 1, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "09:59     cWWWtilde (LHA: dim6 2, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "09:59  Found 6 benchmarks:\n",
      "09:59     sm: cWWW = 0.00e+00, cWWWtilde = 0.00e+00\n",
      "09:59     morphing_basis_vector_1: cWWW = -6.07e-03, cWWWtilde = -1.84e-02\n",
      "09:59     morphing_basis_vector_2: cWWW = 1.00e-02, cWWWtilde = 1.70e-02\n",
      "09:59     morphing_basis_vector_3: cWWW = -1.99e-02, cWWWtilde = 1.87e-02\n",
      "09:59     morphing_basis_vector_4: cWWW = 1.97e-02, cWWWtilde = -1.53e-02\n",
      "09:59     morphing_basis_vector_5: cWWW = -1.65e-02, cWWWtilde = -6.33e-03\n",
      "09:59  Found 27 observables: et_miss, phi_miss, e_visible, eta_visible, e_l1, pt_l1, eta_l1, phi_l1, e_a1, pt_a1, eta_a1, phi_a1, e_j1, pt_j1, eta_j1, phi_j1, deltaphi_l1_met, deltaphi_a1_met, m_l1_met, pt_l1_met, m_l1_a1, deltaeta_l1_a1, deltaphi_l1_a1, m_a1_l1_met, pt_a1_l1_met, mt, phi_resurrection\n",
      "09:59  Found 1812119 events\n",
      "09:59  Found morphing setup with 6 components\n"
     ]
    }
   ],
   "source": [
    "sa_all = SampleAugmenter(sample_dir + 'samples.h5', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SALLY training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    _, _, _ = sa_all.extract_samples_train_local(\n",
    "        theta=constant_morphing_theta([0.,0.]),\n",
    "        n_samples=1000000,\n",
    "        folder=sample_dir + 'train_local',\n",
    "        filename='train_' + str(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RASCAL training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:24  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "20:24  Warning: large statistical uncertainty on the total cross section for theta = [0.07791764 0.01067051]: (2.050965579850999 +/- 0.24176955898825894) pb\n",
      "20:26  Warning: large statistical uncertainty on the total cross section for theta = [0.06940603 0.01497984]: (1.9939371233360141 +/- 0.19980982019852953) pb\n",
      "20:38  Warning: large statistical uncertainty on the total cross section for theta = [-0.0748044  -0.01275692]: (2.041776151458567 +/- 0.21991867515272065) pb\n",
      "20:41  Warning: large statistical uncertainty on the total cross section for theta = [0.07415406 0.00108356]: (2.0167303637673264 +/- 0.20399880162454204) pb\n",
      "20:42  Effective number of samples: mean 18735.451822467512, with individual thetas ranging from 2322.3888180349477 to 31751.946921952687\n",
      "20:52  Warning: large statistical uncertainty on the total cross section for theta = [-0.07432582 -0.00696292]: (2.0324864536639424 +/- 0.20759108393477851) pb\n",
      "21:01  Warning: large statistical uncertainty on the total cross section for theta = [0.07745462 0.00372713]: (2.0423541561832934 +/- 0.2271605005547999) pb\n",
      "21:01  Effective number of samples: mean 18651.752386717002, with individual thetas ranging from 2077.114708078007 to 31799.98275505042\n",
      "21:01  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "21:01  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "21:13  Warning: large statistical uncertainty on the total cross section for theta = [0.06879908 0.02595545]: (2.012439565033162 +/- 0.21459075920281492) pb\n",
      "21:18  Warning: large statistical uncertainty on the total cross section for theta = [-0.05931227 -0.04912488]: (2.0487503508274756 +/- 0.20508259221891728) pb\n",
      "21:18  Warning: large statistical uncertainty on the total cross section for theta = [-0.08450815  0.01749977]: (2.1286324080529546 +/- 0.22514245379745307) pb\n",
      "21:19  Effective number of samples: mean 18626.368203602047, with individual thetas ranging from 2043.7639340713567 to 31578.858131357334\n",
      "21:23  Warning: large statistical uncertainty on the total cross section for theta = [-0.08780641  0.014122  ]: (2.1521236820835767 +/- 0.2507841177073874) pb\n",
      "21:26  Warning: large statistical uncertainty on the total cross section for theta = [-0.07664126  0.00100955]: (2.0481112231028895 +/- 0.20759637563055813) pb\n",
      "21:38  Effective number of samples: mean 18767.192792092068, with individual thetas ranging from 1852.904095628294 to 31823.63525245131\n",
      "21:38  Oversampling: created 1000000 training samples from 500000 original unweighted events\n",
      "21:38  Extracting training sample for ratio-based methods. Numerator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)])), denominator hypothesis: ('random', (5000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "21:48  Warning: large statistical uncertainty on the total cross section for theta = [-0.05992592 -0.06662686]: (2.154636003931518 +/- 0.2595354766656416) pb\n",
      "21:48  Warning: large statistical uncertainty on the total cross section for theta = [0.06279728 0.03816231]: (2.012643765557847 +/- 0.20354569899722022) pb\n",
      "21:56  Effective number of samples: mean 18816.34514429764, with individual thetas ranging from 1920.629822005671 to 31705.20114039749\n",
      "21:56  Warning: large statistical uncertainty on the total cross section for theta = [-0.0708882  -0.01623156]: (2.017670000396002 +/- 0.20354982416727882) pb\n",
      "22:05  Warning: large statistical uncertainty on the total cross section for theta = [0.06558586 0.02765025]: (1.9955058106794858 +/- 0.1995957181561379) pb\n",
      "22:08  Warning: large statistical uncertainty on the total cross section for theta = [-0.0764912  -0.00428384]: (2.047691290755708 +/- 0.21544360270881405) pb\n",
      "22:09  Warning: large statistical uncertainty on the total cross section for theta = [0.06858159 0.01791459]: (1.9931350224892128 +/- 0.19996414286557423) pb\n",
      "22:09  Warning: large statistical uncertainty on the total cross section for theta = [0.0638123 0.033644 ]: (2.002641229189262 +/- 0.2005130607648618) pb\n",
      "22:13  Effective number of samples: mean 18786.58700592559, with individual thetas ranging from 2495.4933525869665 to 31720.918696921606\n",
      "22:13  Oversampling: created 1000000 training samples from 500000 original unweighted events\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    sa_all.extract_samples_train_more_ratios(\n",
    "        theta0=random_morphing_thetas(5000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)]),\n",
    "        theta1=random_morphing_thetas(5000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)]),\n",
    "        additional_thetas=[random_morphing_thetas(5000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)])\n",
    "                           for _ in range(1)],\n",
    "        n_samples=500000,\n",
    "        folder=sample_dir + 'train_ratios',\n",
    "        filename='train_' + str(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCANDAL training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:13  Extracting training sample for non-local score-based methods. Sampling and score evaluation according to ('random', (10000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "22:28  Warning: large statistical uncertainty on the total cross section for theta = [0.07094557 0.01584932]: (2.0060693965993366 +/- 0.20978329079385769) pb\n",
      "22:46  Warning: large statistical uncertainty on the total cross section for theta = [0.06965976 0.03794414]: (2.057090415908185 +/- 0.24212802692628468) pb\n",
      "22:46  Warning: large statistical uncertainty on the total cross section for theta = [0.06565121 0.03655114]: (2.024814493974599 +/- 0.21616540465222228) pb\n",
      "22:46  Warning: large statistical uncertainty on the total cross section for theta = [-0.07613161 -0.04317153]: (2.1373524153752506 +/- 0.2878005822569212) pb\n",
      "22:47  Effective number of samples: mean 18677.33796939828, with individual thetas ranging from 1996.8344538242934 to 31664.01956073995\n",
      "22:47  Extracting training sample for non-local score-based methods. Sampling and score evaluation according to ('random', (10000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "22:55  Warning: large statistical uncertainty on the total cross section for theta = [0.0778366  0.01839011]: (2.0616402148401747 +/- 0.25492632287545347) pb\n",
      "23:00  Warning: large statistical uncertainty on the total cross section for theta = [-0.0686213  -0.03836318]: (2.062168061070654 +/- 0.23135455431914326) pb\n",
      "23:09  Warning: large statistical uncertainty on the total cross section for theta = [-0.06466242 -0.06015819]: (2.14340692885132 +/- 0.2639169390110141) pb\n",
      "23:22  Effective number of samples: mean 18830.192911429436, with individual thetas ranging from 1966.8410927848777 to 31712.91900678367\n",
      "23:22  Extracting training sample for non-local score-based methods. Sampling and score evaluation according to ('random', (10000, [('gaussian', 0.0, 0.02), ('gaussian', 0.0, 0.02)]))\n",
      "23:23  Warning: large statistical uncertainty on the total cross section for theta = [-0.07333406 -0.03135723]: (2.071750417236302 +/- 0.24489772108013944) pb\n",
      "23:25  Warning: large statistical uncertainty on the total cross section for theta = [-0.07259991 -0.04191335]: (2.1051779707790246 +/- 0.26276781142009853) pb\n",
      "23:36  Warning: large statistical uncertainty on the total cross section for theta = [-0.0736974 -0.0164248]: (2.038717820418327 +/- 0.21976493323676288) pb\n",
      "23:39  Warning: large statistical uncertainty on the total cross section for theta = [0.07346695 0.02200545]: (2.0360007093448473 +/- 0.23483074777228868) pb\n",
      "23:42  Warning: large statistical uncertainty on the total cross section for theta = [0.06616001 0.02969433]: (2.005198453375442 +/- 0.20631546301614884) pb\n",
      "23:43  Warning: large statistical uncertainty on the total cross section for theta = [0.06691585 0.03697723]: (2.0347508385118687 +/- 0.22417329247664333) pb\n",
      "23:57  Effective number of samples: mean 18666.61700630918, with individual thetas ranging from 2082.1037760698605 to 31791.423652492296\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    _, _, _ = sa_all.extract_samples_train_global(\n",
    "        theta=random_morphing_thetas(10000, [('gaussian', 0., 0.02), ('gaussian', 0., 0.02)]),\n",
    "        n_samples=1000000,\n",
    "        folder=sample_dir + 'train_scandal',\n",
    "        filename='train_' + str(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = sa_all.extract_samples_train_plain(\n",
    "    theta=constant_morphing_theta([0.,0.]),\n",
    "    n_samples=1000000,\n",
    "    folder=sample_dir + 'validation',\n",
    "    filename='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = sa_all.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.]),\n",
    "    n_samples=1000000,\n",
    "    folder=sample_dir + 'test',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:35  Extracting evaluation sample. Sampling according to ('theta', array([0., 0.]))\n",
      "09:35  Effective number of samples: 31624.695477491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 33.63955688,  -1.32547581,  78.75690037, ...,   4.8128867 ,\n",
       "          45.5395498 ,   1.25617526],\n",
       "        [ 34.86075592,  -1.12120962,  61.00724132, ...,   9.202712  ,\n",
       "          32.519492  ,   0.65004966],\n",
       "        [ 24.37664986,  -0.35482651,  73.75482329, ...,  17.13900984,\n",
       "          25.77555574,  -0.81200949],\n",
       "        ...,\n",
       "        [ 32.48851776,   0.85764343,  69.83294366, ...,   7.05666343,\n",
       "          37.67651509,  -0.6945806 ],\n",
       "        [ 27.93987274,   1.27250886, 204.45277512, ...,  22.22741193,\n",
       "          15.90669642,  -2.4953326 ],\n",
       "        [ 35.40591049,   2.32230139,  77.60011941, ...,   3.1489973 ,\n",
       "          38.86250583,   0.61047389]]), array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_all.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_sm',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:59  Extracting evaluation sample. Sampling according to ('theta', array([0.02, 0.  ]))\n",
      "09:59  Effective number of samples: 3095.4724877464905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 4.61141739e+01, -2.73424649e+00,  2.27482723e+02, ...,\n",
       "          5.63601857e+01,  3.77629742e+01, -3.98108857e-01],\n",
       "        [ 4.54617882e+01,  1.26141322e+00,  1.24027757e+02, ...,\n",
       "          2.79403951e+01,  2.87716368e+01, -2.59429185e+00],\n",
       "        [ 2.92661781e+01,  2.03325009e+00,  6.82095041e+01, ...,\n",
       "          3.73196028e+01,  5.97169686e+00, -2.97392435e-02],\n",
       "        ...,\n",
       "        [ 4.00937996e+01, -1.14860785e+00,  1.92984388e+02, ...,\n",
       "          7.46425158e+01,  1.69630078e-01, -2.93841221e+00],\n",
       "        [ 2.48513508e+01,  1.49243534e-01,  6.84489512e+01, ...,\n",
       "          3.63272853e+01,  3.05801054e+01,  2.40797754e+00],\n",
       "        [ 5.07174911e+01,  8.88021588e-02,  2.71527280e+02, ...,\n",
       "          1.47594181e+01,  7.22855281e+01,  1.06345882e+00]]),\n",
       " array([[0.02, 0.  ],\n",
       "        [0.02, 0.  ],\n",
       "        [0.02, 0.  ],\n",
       "        ...,\n",
       "        [0.02, 0.  ],\n",
       "        [0.02, 0.  ],\n",
       "        [0.02, 0.  ]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_all.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.02,0.]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_www',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:59  Extracting evaluation sample. Sampling according to ('theta', array([0.  , 0.02]))\n",
      "09:59  Effective number of samples: 3098.0642083404823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 4.41705627e+01, -8.95153940e-01,  7.50651612e+01, ...,\n",
       "          2.85605103e+01,  6.37702337e+01, -1.79635355e+00],\n",
       "        [ 6.55903015e+01,  1.13249612e+00,  6.60149519e+02, ...,\n",
       "          1.16195792e+02,  1.72467281e+00,  1.96026153e+00],\n",
       "        [ 3.18176022e+01,  4.11449909e-01,  9.08938832e+01, ...,\n",
       "          1.92315213e+01,  2.97873467e+01,  2.23080913e+00],\n",
       "        ...,\n",
       "        [ 4.04289017e+01,  1.85120416e+00,  4.01068205e+01, ...,\n",
       "          1.62859981e+00,  5.16281080e+01,  9.29954165e-01],\n",
       "        [ 4.90747871e+01,  1.97064793e+00,  1.84243887e+02, ...,\n",
       "          5.34057040e+01,  5.14223205e+01, -1.61017218e+00],\n",
       "        [ 3.32412987e+01, -1.32163799e+00,  7.02739579e+01, ...,\n",
       "          3.13776623e+01,  5.05438720e+01,  2.84102456e+00]]),\n",
       " array([[0.  , 0.02],\n",
       "        [0.  , 0.02],\n",
       "        [0.  , 0.02],\n",
       "        ...,\n",
       "        [0.  , 0.02],\n",
       "        [0.  , 0.02],\n",
       "        [0.  , 0.02]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_all.extract_samples_test(\n",
    "    theta=constant_morphing_theta([0.,0.02]),\n",
    "    n_samples=100000,\n",
    "    folder=sample_dir + 'test_wwwtilde',\n",
    "    filename='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
