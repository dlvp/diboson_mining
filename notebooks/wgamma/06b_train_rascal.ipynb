{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f9deb73c-b62f-4cff-8d83-724074098c92"
    }
   },
   "source": [
    "# Train RASCAL ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Marco Farina, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "fe57a76c-4838-44c4-b0cc-5ee166785e4a"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)-5.5s %(name)-20.20s %(levelname)-7.7s %(message)s', datefmt='%H:%M', level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "f3463c40-6421-42a1-8681-527c3ec42541"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "b2c73eca-c625-4f7a-9cee-4ccb2dcbb3e9"
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(filename, use_tight_cuts=True, n_estimators=n_estimators, **kwargs):\n",
    "    cut_label = '_tight' if use_tight_cuts else ''\n",
    "    \n",
    "    ensemble = EnsembleForge(n_estimators, debug=False)\n",
    "\n",
    "    ensemble.train_all(\n",
    "        method='rascal',\n",
    "        x_filename=[sample_dir + 'train_ratio{}/x_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        theta0_filename=[sample_dir + 'train_ratio{}/theta0_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        t_xz0_filename=[sample_dir + 'train_ratio{}/t_xz_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        r_xz_filename=[sample_dir + 'train_ratio{}/r_xz_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        y_filename=[sample_dir + 'train_ratio{}/y_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    ensemble.save(model_dir + 'rascal_ensemble_' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45e7f73-8f4c-4261-a381-4b7ad6af120f"
    }
   },
   "source": [
    "## All observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56  Training 1 estimators in ensemble\n",
      "11:56  Training estimator 1 / 1 in ensemble\n",
      "11:56  Starting training\n",
      "11:56    Method:                 rascal\n",
      "11:56    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio/x_train_0.npy\n",
      "11:56                   theta0 at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio/theta0_train_0.npy\n",
      "11:56                   y at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio/y_train_0.npy\n",
      "11:56                   r_xz at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio/r_xz_train_0.npy\n",
      "11:56                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio/t_xz_train_0.npy\n",
      "11:56    Features:               all\n",
      "11:56    Method:                 rascal\n",
      "11:56    Hidden layers:          (100, 100, 100, 100)\n",
      "11:56    Activation function:    tanh\n",
      "11:56    alpha:                  1.0\n",
      "11:56    Batch size:             128\n",
      "11:56    Trainer:                amsgrad\n",
      "11:56    Epochs:                 10\n",
      "11:56    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "11:56    Validation split:       None\n",
      "11:56    Early stopping:         True\n",
      "11:56    Scale inputs:           True\n",
      "11:56    Shuffle labels          False\n",
      "11:56    Regularization:         None\n",
      "11:56  Loading training data\n",
      "11:56  Found 100000 samples with 2 parameters and 27 observables\n",
      "11:56  Rescaling inputs\n",
      "11:56  Creating model for method rascal\n",
      "11:56  Training model\n",
      "12:20    Epoch 1: train loss 18.46 ([9.50717520e-03 1.84507461e+01])\n",
      "12:29    Epoch 2: train loss 18.46 ([9.20086342e-03 1.84488645e+01])\n",
      "12:38    Epoch 3: train loss 18.45 ([9.56860095e-03 1.84440880e+01])\n",
      "12:44    Epoch 4: train loss 18.45 ([9.33454631e-03 1.84406294e+01])\n",
      "12:50    Epoch 5: train loss 18.45 ([9.54095348e-03 1.84354902e+01])\n",
      "12:57    Epoch 6: train loss 18.44 ([9.53303022e-03 1.84288588e+01])\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all',\n",
    "    use_tight_cuts=False,\n",
    "    n_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:37  Training 1 estimators in ensemble\n",
      "08:37  Training estimator 1 / 1 in ensemble\n",
      "08:37  Starting training\n",
      "08:37    Method:                 rascal\n",
      "08:37    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio_tight/x_train_0.npy\n",
      "08:37                   theta0 at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio_tight/theta0_train_0.npy\n",
      "08:37                   y at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio_tight/y_train_0.npy\n",
      "08:37                   r_xz at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio_tight/r_xz_train_0.npy\n",
      "08:37                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_ratio_tight/t_xz_train_0.npy\n",
      "08:37    Features:               all\n",
      "08:37    Method:                 rascal\n",
      "08:37    Hidden layers:          (100, 100, 100, 100)\n",
      "08:37    Activation function:    tanh\n",
      "08:37    alpha:                  1.0\n",
      "08:37    Batch size:             128\n",
      "08:37    Trainer:                amsgrad\n",
      "08:37    Epochs:                 10\n",
      "08:37    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "08:37    Validation split:       None\n",
      "08:37    Early stopping:         True\n",
      "08:37    Scale inputs:           True\n",
      "08:37    Shuffle labels          False\n",
      "08:37    Regularization:         None\n",
      "08:37  Loading training data\n",
      "08:37  Found 100000 samples with 2 parameters and 27 observables\n",
      "08:37  Rescaling inputs\n",
      "08:37  Creating model for method rascal\n",
      "08:37  Training model\n",
      "09:06    Epoch 1: train loss 1487.35 ([  19.75460009 1467.59263064])\n",
      "09:16    Epoch 2: train loss 1486.28 ([  19.74967    1466.53006065])\n",
      "09:25    Epoch 3: train loss 1487.23 ([  19.72353092 1467.50555845])\n",
      "09:33    Epoch 4: train loss 1484.86 ([  19.69080382 1465.17116433])\n",
      "09:43    Epoch 5: train loss 1484.74 ([  19.67591379 1465.06543099])\n",
      "11:24    Epoch 6: train loss 1485.17 ([  19.67003604 1465.50496336])\n",
      "11:33    Epoch 7: train loss 1484.91 ([  19.66463649 1465.24592161])\n",
      "11:40    Epoch 8: train loss 1484.45 ([  19.66218427 1464.78326219])\n",
      "11:48    Epoch 9: train loss 1484.81 ([  19.66011459 1465.15387529])\n",
      "11:56    Epoch 10: train loss 1484.47 ([  19.65816381 1464.80970372])\n",
      "11:56  Finished training\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all_tight',\n",
    "    use_tight_cuts=True,\n",
    "    n_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just resurrection phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'resurrection',\n",
    "    use_tight_cuts=True,\n",
    "    features=[[26] for _ in range(n_estimators)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
