{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:24  \n",
      "11:24  ------------------------------------------------------------\n",
      "11:24  |                                                          |\n",
      "11:24  |  MadMiner v2018.10.22                                    |\n",
      "11:24  |                                                          |\n",
      "11:24  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "11:24  |                                                          |\n",
      "11:24  ------------------------------------------------------------\n",
      "11:24  \n"
     ]
    }
   ],
   "source": [
    "n_estimators = 10\n",
    "\n",
    "ensemble = EnsembleForge(\n",
    "    [MLForge(debug=False) for _ in range(n_estimators)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SALLY on all observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.train_all(\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(10)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(10)],\n",
    "    n_epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_split=None,\n",
    "    n_hidden=[(50,), (100,), (50,50), (50,20), (100,100), (100, 20), (50,50,50), (50,20,10), (100,100,100), (100, 50, 20)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.save(model_dir + 'sally_ensemble_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d toy study (delta phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:25  Training 10 estimators in ensemble\n",
      "11:25  Training estimator 1 / 10 in ensemble\n",
      "11:25  Starting training\n",
      "11:25    Method:                 sally\n",
      "11:25    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "11:25                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "11:25    Features:               [25]\n",
      "11:25    Method:                 sally\n",
      "11:25    Hidden layers:          (50,)\n",
      "11:25    Activation function:    tanh\n",
      "11:25    Batch size:             256\n",
      "11:25    Epochs:                 10\n",
      "11:25    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:25    Validation split:       None\n",
      "11:25    Early stopping:         True\n",
      "11:25  Loading training data\n",
      "11:25  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:25  Only using 1 of 27 observables\n",
      "11:25  Creating model for method sally\n",
      "11:25  Training model\n",
      "11:26    Epoch 1: train loss 29.17 ([29.16542148])\n",
      "11:26    Epoch 2: train loss 29.16 ([29.16170808])\n",
      "11:26    Epoch 3: train loss 29.16 ([29.15850279])\n",
      "11:26    Epoch 4: train loss 29.16 ([29.15672386])\n",
      "11:26    Epoch 5: train loss 29.16 ([29.1597863])\n",
      "11:27    Epoch 6: train loss 29.16 ([29.15545621])\n",
      "11:27    Epoch 7: train loss 29.16 ([29.15553416])\n",
      "11:27    Epoch 8: train loss 29.16 ([29.16212757])\n",
      "11:27    Epoch 9: train loss 29.15 ([29.15465053])\n",
      "11:27    Epoch 10: train loss 29.15 ([29.15449185])\n",
      "11:27  Finished training\n",
      "11:27  Training estimator 2 / 10 in ensemble\n",
      "11:27  Starting training\n",
      "11:27    Method:                 sally\n",
      "11:27    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "11:27                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "11:27    Features:               [25]\n",
      "11:27    Method:                 sally\n",
      "11:27    Hidden layers:          (100,)\n",
      "11:27    Activation function:    tanh\n",
      "11:27    Batch size:             256\n",
      "11:27    Epochs:                 10\n",
      "11:27    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:27    Validation split:       None\n",
      "11:27    Early stopping:         True\n",
      "11:27  Loading training data\n",
      "11:27  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:27  Only using 1 of 27 observables\n",
      "11:27  Creating model for method sally\n",
      "11:27  Training model\n",
      "11:28    Epoch 1: train loss 22.15 ([22.14687053])\n",
      "11:28    Epoch 2: train loss 22.14 ([22.13873847])\n",
      "11:28    Epoch 3: train loss 22.15 ([22.14540931])\n",
      "11:28    Epoch 4: train loss 22.13 ([22.1323155])\n",
      "11:28    Epoch 5: train loss 22.13 ([22.13298955])\n",
      "11:29    Epoch 6: train loss 22.13 ([22.12997303])\n",
      "11:29    Epoch 7: train loss 22.13 ([22.12906297])\n",
      "11:29    Epoch 8: train loss 22.13 ([22.12893687])\n",
      "11:29    Epoch 9: train loss 22.13 ([22.1294432])\n",
      "11:29    Epoch 10: train loss 22.13 ([22.12845182])\n",
      "11:29  Finished training\n",
      "11:29  Training estimator 3 / 10 in ensemble\n",
      "11:29  Starting training\n",
      "11:29    Method:                 sally\n",
      "11:29    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "11:29                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "11:29    Features:               [25]\n",
      "11:29    Method:                 sally\n",
      "11:29    Hidden layers:          (50, 50)\n",
      "11:29    Activation function:    tanh\n",
      "11:29    Batch size:             256\n",
      "11:29    Epochs:                 10\n",
      "11:29    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:29    Validation split:       None\n",
      "11:29    Early stopping:         True\n",
      "11:29  Loading training data\n",
      "11:29  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:29  Only using 1 of 27 observables\n",
      "11:29  Creating model for method sally\n",
      "11:29  Training model\n",
      "11:30    Epoch 1: train loss 26.43 ([26.42673395])\n",
      "11:30    Epoch 2: train loss 26.42 ([26.42023119])\n",
      "11:30    Epoch 3: train loss 26.42 ([26.41836361])\n",
      "11:31    Epoch 4: train loss 26.42 ([26.41739528])\n",
      "11:31    Epoch 5: train loss 26.42 ([26.41736363])\n",
      "11:31    Epoch 6: train loss 26.42 ([26.41694144])\n",
      "11:31    Epoch 7: train loss 26.42 ([26.4167111])\n",
      "11:31    Epoch 8: train loss 26.42 ([26.41707878])\n",
      "11:32    Epoch 9: train loss 26.42 ([26.41716502])\n",
      "11:32    Epoch 10: train loss 26.42 ([26.41636172])\n",
      "11:32  Finished training\n",
      "11:32  Training estimator 4 / 10 in ensemble\n",
      "11:32  Starting training\n",
      "11:32    Method:                 sally\n",
      "11:32    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "11:32                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "11:32    Features:               [25]\n",
      "11:32    Method:                 sally\n",
      "11:32    Hidden layers:          (50, 20)\n",
      "11:32    Activation function:    tanh\n",
      "11:32    Batch size:             256\n",
      "11:32    Epochs:                 10\n",
      "11:32    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:32    Validation split:       None\n",
      "11:32    Early stopping:         True\n",
      "11:32  Loading training data\n",
      "11:32  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:32  Only using 1 of 27 observables\n",
      "11:32  Creating model for method sally\n",
      "11:32  Training model\n",
      "11:32    Epoch 1: train loss 43.47 ([43.46582376])\n",
      "11:32    Epoch 2: train loss 43.46 ([43.46048104])\n",
      "11:33    Epoch 3: train loss 43.46 ([43.45928434])\n",
      "11:33    Epoch 4: train loss 43.46 ([43.45994449])\n",
      "11:33    Epoch 5: train loss 43.46 ([43.45782564])\n",
      "11:33    Epoch 6: train loss 43.46 ([43.45757975])\n",
      "11:33    Epoch 7: train loss 43.46 ([43.45717753])\n",
      "11:34    Epoch 8: train loss 43.46 ([43.45730979])\n",
      "11:34    Epoch 9: train loss 43.46 ([43.4568072])\n",
      "11:34    Epoch 10: train loss 43.46 ([43.45702563])\n",
      "11:34  Finished training\n",
      "11:34  Training estimator 5 / 10 in ensemble\n",
      "11:34  Starting training\n",
      "11:34    Method:                 sally\n",
      "11:34    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "11:34                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "11:34    Features:               [25]\n",
      "11:34    Method:                 sally\n",
      "11:34    Hidden layers:          (100, 100)\n",
      "11:34    Activation function:    tanh\n",
      "11:34    Batch size:             256\n",
      "11:34    Epochs:                 10\n",
      "11:34    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:34    Validation split:       None\n",
      "11:34    Early stopping:         True\n",
      "11:34  Loading training data\n",
      "11:34  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:34  Only using 1 of 27 observables\n",
      "11:34  Creating model for method sally\n",
      "11:34  Training model\n",
      "11:35    Epoch 1: train loss 21.21 ([21.21391521])\n",
      "11:35    Epoch 2: train loss 21.21 ([21.20527201])\n",
      "11:35    Epoch 3: train loss 21.20 ([21.20356264])\n",
      "11:35    Epoch 4: train loss 21.20 ([21.20246832])\n",
      "11:36    Epoch 5: train loss 21.20 ([21.20236214])\n",
      "11:36    Epoch 6: train loss 21.20 ([21.20211759])\n",
      "11:36    Epoch 7: train loss 21.20 ([21.20179854])\n",
      "11:36    Epoch 8: train loss 21.20 ([21.20130925])\n",
      "11:37    Epoch 9: train loss 21.20 ([21.20097239])\n",
      "11:37    Epoch 10: train loss 21.20 ([21.20115174])\n",
      "11:37  Finished training\n",
      "11:37  Training estimator 6 / 10 in ensemble\n",
      "11:37  Starting training\n",
      "11:37    Method:                 sally\n",
      "11:37    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n",
      "11:37                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n",
      "11:37    Features:               [25]\n",
      "11:37    Method:                 sally\n",
      "11:37    Hidden layers:          (100, 20)\n",
      "11:37    Activation function:    tanh\n",
      "11:37    Batch size:             256\n",
      "11:37    Epochs:                 10\n",
      "11:37    Learning rate:          0.002 initially, decaying to 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:37    Validation split:       None\n",
      "11:37    Early stopping:         True\n",
      "11:37  Loading training data\n",
      "11:37  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:37  Only using 1 of 27 observables\n",
      "11:37  Creating model for method sally\n",
      "11:37  Training model\n",
      "11:37    Epoch 1: train loss 77.20 ([77.19947301])\n",
      "11:38    Epoch 2: train loss 77.17 ([77.16726001])\n",
      "11:38    Epoch 3: train loss 77.17 ([77.16543468])\n",
      "11:38    Epoch 4: train loss 77.17 ([77.16857775])\n",
      "11:38    Epoch 5: train loss 77.17 ([77.16540014])\n",
      "11:38    Epoch 6: train loss 77.16 ([77.16268287])\n",
      "11:39    Epoch 7: train loss 77.16 ([77.1622499])\n",
      "11:39    Epoch 8: train loss 77.16 ([77.16375371])\n",
      "11:39    Epoch 9: train loss 77.16 ([77.16281778])\n",
      "11:39    Epoch 10: train loss 77.16 ([77.16103634])\n",
      "11:39  Finished training\n",
      "11:39  Training estimator 7 / 10 in ensemble\n",
      "11:39  Starting training\n",
      "11:39    Method:                 sally\n",
      "11:39    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "11:39                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "11:39    Features:               [25]\n",
      "11:39    Method:                 sally\n",
      "11:39    Hidden layers:          (50, 50, 50)\n",
      "11:39    Activation function:    tanh\n",
      "11:39    Batch size:             256\n",
      "11:39    Epochs:                 10\n",
      "11:39    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:39    Validation split:       None\n",
      "11:39    Early stopping:         True\n",
      "11:39  Loading training data\n",
      "11:39  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:39  Only using 1 of 27 observables\n",
      "11:39  Creating model for method sally\n",
      "11:39  Training model\n",
      "11:40    Epoch 1: train loss 56.98 ([56.9766548])\n",
      "11:40    Epoch 2: train loss 56.97 ([56.97214148])\n",
      "11:40    Epoch 3: train loss 56.97 ([56.96967224])\n",
      "11:41    Epoch 4: train loss 56.97 ([56.96964991])\n",
      "11:41    Epoch 5: train loss 56.97 ([56.96867256])\n",
      "11:41    Epoch 6: train loss 56.97 ([56.96872005])\n",
      "11:41    Epoch 7: train loss 56.97 ([56.96794027])\n",
      "11:42    Epoch 8: train loss 56.97 ([56.96881558])\n",
      "11:42    Epoch 9: train loss 56.97 ([56.96803168])\n",
      "11:42    Epoch 10: train loss 56.97 ([56.96740471])\n",
      "11:42  Finished training\n",
      "11:42  Training estimator 8 / 10 in ensemble\n",
      "11:42  Starting training\n",
      "11:42    Method:                 sally\n",
      "11:42    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "11:42                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "11:42    Features:               [25]\n",
      "11:42    Method:                 sally\n",
      "11:42    Hidden layers:          (50, 20, 10)\n",
      "11:42    Activation function:    tanh\n",
      "11:42    Batch size:             256\n",
      "11:42    Epochs:                 10\n",
      "11:42    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:42    Validation split:       None\n",
      "11:42    Early stopping:         True\n",
      "11:42  Loading training data\n",
      "11:42  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:42  Only using 1 of 27 observables\n",
      "11:42  Creating model for method sally\n",
      "11:42  Training model\n",
      "11:42    Epoch 1: train loss 19.03 ([19.029735])\n",
      "11:43    Epoch 2: train loss 19.03 ([19.02674873])\n",
      "11:43    Epoch 3: train loss 19.03 ([19.02618889])\n",
      "11:43    Epoch 4: train loss 19.03 ([19.02577064])\n",
      "11:43    Epoch 5: train loss 19.03 ([19.02575724])\n",
      "11:43    Epoch 6: train loss 19.03 ([19.02531781])\n",
      "11:44    Epoch 7: train loss 19.03 ([19.02653328])\n",
      "11:44    Epoch 8: train loss 19.03 ([19.02502952])\n",
      "11:44    Epoch 9: train loss 19.02 ([19.02490533])\n",
      "11:44    Epoch 10: train loss 19.03 ([19.0273741])\n",
      "11:44  Finished training\n",
      "11:44  Training estimator 9 / 10 in ensemble\n",
      "11:44  Starting training\n",
      "11:44    Method:                 sally\n",
      "11:44    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "11:44                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "11:44    Features:               [25]\n",
      "11:44    Method:                 sally\n",
      "11:44    Hidden layers:          (100, 100, 100)\n",
      "11:44    Activation function:    tanh\n",
      "11:44    Batch size:             256\n",
      "11:44    Epochs:                 10\n",
      "11:44    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:44    Validation split:       None\n",
      "11:44    Early stopping:         True\n",
      "11:44  Loading training data\n",
      "11:44  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:44  Only using 1 of 27 observables\n",
      "11:44  Creating model for method sally\n",
      "11:44  Training model\n",
      "11:45    Epoch 1: train loss 21.10 ([21.10191293])\n",
      "11:45    Epoch 2: train loss 21.10 ([21.09807011])\n",
      "11:45    Epoch 3: train loss 21.10 ([21.09803144])\n",
      "11:46    Epoch 4: train loss 21.10 ([21.10026391])\n",
      "11:46    Epoch 5: train loss 21.09 ([21.09471743])\n",
      "11:46    Epoch 6: train loss 21.09 ([21.09418013])\n",
      "11:47    Epoch 7: train loss 21.10 ([21.09768556])\n",
      "11:47    Epoch 8: train loss 21.09 ([21.09463449])\n",
      "11:47    Epoch 9: train loss 21.09 ([21.09391334])\n",
      "11:48    Epoch 10: train loss 21.09 ([21.0937418])\n",
      "11:48  Finished training\n",
      "11:48  Training estimator 10 / 10 in ensemble\n",
      "11:48  Starting training\n",
      "11:48    Method:                 sally\n",
      "11:48    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "11:48                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "11:48    Features:               [25]\n",
      "11:48    Method:                 sally\n",
      "11:48    Hidden layers:          (100, 50, 20)\n",
      "11:48    Activation function:    tanh\n",
      "11:48    Batch size:             256\n",
      "11:48    Epochs:                 10\n",
      "11:48    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:48    Validation split:       None\n",
      "11:48    Early stopping:         True\n",
      "11:48  Loading training data\n",
      "11:48  Found 1000000 samples with 2 parameters and 27 observables\n",
      "11:48  Only using 1 of 27 observables\n",
      "11:48  Creating model for method sally\n",
      "11:48  Training model\n",
      "11:48    Epoch 1: train loss 34.11 ([34.11144091])\n",
      "11:48    Epoch 2: train loss 34.11 ([34.1083068])\n",
      "11:49    Epoch 3: train loss 34.11 ([34.10630671])\n",
      "11:49    Epoch 4: train loss 34.11 ([34.10518753])\n",
      "11:49    Epoch 5: train loss 34.10 ([34.10332824])\n",
      "11:49    Epoch 6: train loss 34.10 ([34.10338768])\n",
      "11:50    Epoch 7: train loss 34.10 ([34.1028746])\n",
      "11:50    Epoch 8: train loss 34.10 ([34.10180341])\n",
      "11:50    Epoch 9: train loss 34.10 ([34.10357968])\n",
      "11:50    Epoch 10: train loss 34.10 ([34.10152288])\n",
      "11:50  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble.train_all(\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(10)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(10)],\n",
    "    features=[ [25] for _ in range(10)],\n",
    "    n_epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_split=None,\n",
    "    n_hidden=[(50,), (100,), (50,50), (50,20), (100,100), (100, 20), (50,50,50), (50,20,10), (100,100,100), (100, 50, 20)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:50  Calculating expectation for 10 estimators in ensemble\n",
      "11:50  Starting evaluation for estimator 1 / 10 in ensemble\n",
      "11:50  Loading evaluation data\n",
      "11:50  Starting score evaluation\n",
      "11:51  Starting evaluation for estimator 2 / 10 in ensemble\n",
      "11:51  Loading evaluation data\n",
      "11:51  Starting score evaluation\n",
      "11:51  Starting evaluation for estimator 3 / 10 in ensemble\n",
      "11:51  Loading evaluation data\n",
      "11:51  Starting score evaluation\n",
      "11:51  Starting evaluation for estimator 4 / 10 in ensemble\n",
      "11:51  Loading evaluation data\n",
      "11:51  Starting score evaluation\n",
      "11:51  Starting evaluation for estimator 5 / 10 in ensemble\n",
      "11:51  Loading evaluation data\n",
      "11:51  Starting score evaluation\n",
      "11:51  Starting evaluation for estimator 6 / 10 in ensemble\n",
      "11:51  Loading evaluation data\n",
      "11:51  Starting score evaluation\n",
      "11:51  Starting evaluation for estimator 7 / 10 in ensemble\n",
      "11:51  Loading evaluation data\n",
      "11:51  Starting score evaluation\n",
      "11:51  Starting evaluation for estimator 8 / 10 in ensemble\n",
      "11:51  Loading evaluation data\n",
      "11:51  Starting score evaluation\n",
      "11:52  Starting evaluation for estimator 9 / 10 in ensemble\n",
      "11:52  Loading evaluation data\n",
      "11:52  Starting score evaluation\n",
      "11:52  Starting evaluation for estimator 10 / 10 in ensemble\n",
      "11:52  Loading evaluation data\n",
      "11:52  Starting score evaluation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01108136,  0.01226927],\n",
       "       [-0.02025858, -0.03946016],\n",
       "       [-0.00724483, -0.00818603],\n",
       "       [-0.00711934,  0.01605911],\n",
       "       [-0.00019295,  0.00029173],\n",
       "       [ 0.0075682 ,  0.01714741],\n",
       "       [ 0.00396435, -0.00194454],\n",
       "       [ 0.00240622, -0.00631471],\n",
       "       [ 0.00656226,  0.00237199],\n",
       "       [-0.00282423, -0.00644198]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:52  Saving ensemble setup to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/ensemble.json\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_0_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_0_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_1_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_1_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_2_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_2_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_3_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_3_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_4_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_4_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_5_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_5_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_6_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_6_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_7_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_7_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_8_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_8_state_dict.pt\n",
      "11:52  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_9_settings.json\n",
      "11:52  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_9_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "ensemble.save(model_dir + 'sally_ensemble_deltaphi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
