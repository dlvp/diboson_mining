{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 20\n",
    "n_hidden = (100,100)\n",
    "n_epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SALLY on all observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:56  \n",
      "14:56  ------------------------------------------------------------\n",
      "14:56  |                                                          |\n",
      "14:56  |  MadMiner v2018.10.26                                    |\n",
      "14:56  |                                                          |\n",
      "14:56  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "14:56  |                                                          |\n",
      "14:56  ------------------------------------------------------------\n",
      "14:56  \n",
      "14:56  Training 20 estimators in ensemble\n",
      "14:56  Training estimator 1 / 20 in ensemble\n",
      "14:56  Starting training\n",
      "14:56    Method:                 sally\n",
      "14:56    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "14:56                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "14:56    Features:               all\n",
      "14:56    Method:                 sally\n",
      "14:56    Hidden layers:          (100, 100)\n",
      "14:56    Activation function:    tanh\n",
      "14:56    Batch size:             128\n",
      "14:56    Epochs:                 10\n",
      "14:56    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "14:56    Validation split:       None\n",
      "14:56    Early stopping:         True\n",
      "14:56  Loading training data\n",
      "14:56  Found 1000000 samples with 2 parameters and 29 observables\n",
      "14:56  Creating model for method sally\n",
      "14:56  Training model\n",
      "14:57    Epoch 1: train loss 18.54 ([18.54089168])\n",
      "14:57    Epoch 2: train loss 18.54 ([18.5392123])\n",
      "14:57    Epoch 3: train loss 18.53 ([18.53076225])\n",
      "14:58    Epoch 4: train loss 18.52 ([18.52350804])\n",
      "14:58    Epoch 5: train loss 18.52 ([18.51847153])\n",
      "14:58    Epoch 6: train loss 18.51 ([18.51243521])\n",
      "14:59    Epoch 7: train loss 18.51 ([18.50905225])\n",
      "14:59    Epoch 8: train loss 18.51 ([18.50535414])\n",
      "14:59    Epoch 9: train loss 18.50 ([18.50311906])\n",
      "14:59    Epoch 10: train loss 18.50 ([18.49891354])\n",
      "14:59  Finished training\n",
      "14:59  Training estimator 2 / 20 in ensemble\n",
      "14:59  Starting training\n",
      "14:59    Method:                 sally\n",
      "14:59    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "14:59                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "14:59    Features:               all\n",
      "14:59    Method:                 sally\n",
      "14:59    Hidden layers:          (100, 100)\n",
      "14:59    Activation function:    tanh\n",
      "14:59    Batch size:             128\n",
      "14:59    Epochs:                 10\n",
      "14:59    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "14:59    Validation split:       None\n",
      "14:59    Early stopping:         True\n",
      "14:59  Loading training data\n",
      "14:59  Found 1000000 samples with 2 parameters and 29 observables\n",
      "14:59  Creating model for method sally\n",
      "14:59  Training model\n",
      "15:00    Epoch 1: train loss 15.97 ([15.97467092])\n",
      "15:00    Epoch 2: train loss 15.97 ([15.96573938])\n",
      "15:01    Epoch 3: train loss 15.96 ([15.96022673])\n",
      "15:01    Epoch 4: train loss 15.95 ([15.95276562])\n",
      "15:01    Epoch 5: train loss 15.96 ([15.95781349])\n",
      "15:01    Epoch 6: train loss 15.94 ([15.94083045])\n",
      "15:02    Epoch 7: train loss 15.94 ([15.93616816])\n",
      "15:02    Epoch 8: train loss 16.32 ([16.31641499])\n",
      "15:02    Epoch 9: train loss 15.93 ([15.92986936])\n",
      "15:03    Epoch 10: train loss 15.93 ([15.92642291])\n",
      "15:03  Finished training\n",
      "15:03  Training estimator 3 / 20 in ensemble\n",
      "15:03  Starting training\n",
      "15:03    Method:                 sally\n",
      "15:03    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "15:03                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "15:03    Features:               all\n",
      "15:03    Method:                 sally\n",
      "15:03    Hidden layers:          (100, 100)\n",
      "15:03    Activation function:    tanh\n",
      "15:03    Batch size:             128\n",
      "15:03    Epochs:                 10\n",
      "15:03    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:03    Validation split:       None\n",
      "15:03    Early stopping:         True\n",
      "15:03  Loading training data\n",
      "15:03  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:03  Creating model for method sally\n",
      "15:03  Training model\n",
      "15:03    Epoch 1: train loss 53.49 ([53.49412033])\n",
      "15:04    Epoch 2: train loss 53.48 ([53.48373171])\n",
      "15:04    Epoch 3: train loss 53.47 ([53.47325848])\n",
      "15:04    Epoch 4: train loss 53.47 ([53.46811578])\n",
      "15:04    Epoch 5: train loss 53.46 ([53.45945152])\n",
      "15:05    Epoch 6: train loss 53.46 ([53.45547944])\n",
      "15:05    Epoch 7: train loss 53.45 ([53.44998171])\n",
      "15:05    Epoch 8: train loss 53.44 ([53.4444883])\n",
      "15:06    Epoch 9: train loss 53.44 ([53.44042263])\n",
      "15:06    Epoch 10: train loss 53.44 ([53.43824319])\n",
      "15:06  Finished training\n",
      "15:06  Training estimator 4 / 20 in ensemble\n",
      "15:06  Starting training\n",
      "15:06    Method:                 sally\n",
      "15:06    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "15:06                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "15:06    Features:               all\n",
      "15:06    Method:                 sally\n",
      "15:06    Hidden layers:          (100, 100)\n",
      "15:06    Activation function:    tanh\n",
      "15:06    Batch size:             128\n",
      "15:06    Epochs:                 10\n",
      "15:06    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:06    Validation split:       None\n",
      "15:06    Early stopping:         True\n",
      "15:06  Loading training data\n",
      "15:06  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:06  Creating model for method sally\n",
      "15:06  Training model\n",
      "15:06    Epoch 1: train loss 27.76 ([27.75816435])\n",
      "15:07    Epoch 2: train loss 27.76 ([27.76179716])\n",
      "15:07    Epoch 3: train loss 27.75 ([27.75114476])\n",
      "15:07    Epoch 4: train loss 27.74 ([27.74485512])\n",
      "15:08    Epoch 5: train loss 27.74 ([27.73692592])\n",
      "15:08    Epoch 6: train loss 27.73 ([27.73376266])\n",
      "15:08    Epoch 7: train loss 27.73 ([27.72991539])\n",
      "15:09    Epoch 8: train loss 27.73 ([27.72781197])\n",
      "15:09    Epoch 9: train loss 27.72 ([27.72396839])\n",
      "15:09    Epoch 10: train loss 27.72 ([27.72249422])\n",
      "15:09  Finished training\n",
      "15:09  Training estimator 5 / 20 in ensemble\n",
      "15:09  Starting training\n",
      "15:09    Method:                 sally\n",
      "15:09    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "15:09                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "15:09    Features:               all\n",
      "15:09    Method:                 sally\n",
      "15:09    Hidden layers:          (100, 100)\n",
      "15:09    Activation function:    tanh\n",
      "15:09    Batch size:             128\n",
      "15:09    Epochs:                 10\n",
      "15:09    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:09    Validation split:       None\n",
      "15:09    Early stopping:         True\n",
      "15:09  Loading training data\n",
      "15:09  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:09  Creating model for method sally\n",
      "15:09  Training model\n",
      "15:10    Epoch 1: train loss 17.97 ([17.96938837])\n",
      "15:10    Epoch 2: train loss 17.97 ([17.96587163])\n",
      "15:10    Epoch 3: train loss 17.96 ([17.95532701])\n",
      "15:11    Epoch 4: train loss 17.95 ([17.94892035])\n",
      "15:11    Epoch 5: train loss 17.94 ([17.94197543])\n",
      "15:11    Epoch 6: train loss 17.94 ([17.93868147])\n",
      "15:11    Epoch 7: train loss 17.93 ([17.93418986])\n",
      "15:12    Epoch 8: train loss 17.93 ([17.93107587])\n",
      "15:12    Epoch 9: train loss 17.93 ([17.92748054])\n",
      "15:12    Epoch 10: train loss 17.92 ([17.92380853])\n",
      "15:12  Finished training\n",
      "15:12  Training estimator 6 / 20 in ensemble\n",
      "15:12  Starting training\n",
      "15:12    Method:                 sally\n",
      "15:12    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n",
      "15:12                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:12    Features:               all\n",
      "15:12    Method:                 sally\n",
      "15:12    Hidden layers:          (100, 100)\n",
      "15:12    Activation function:    tanh\n",
      "15:12    Batch size:             128\n",
      "15:12    Epochs:                 10\n",
      "15:12    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:12    Validation split:       None\n",
      "15:12    Early stopping:         True\n",
      "15:12  Loading training data\n",
      "15:12  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:12  Creating model for method sally\n",
      "15:12  Training model\n",
      "15:13    Epoch 1: train loss 21.21 ([21.21066907])\n",
      "15:13    Epoch 2: train loss 21.20 ([21.20481706])\n",
      "15:13    Epoch 3: train loss 21.20 ([21.1980824])\n",
      "15:14    Epoch 4: train loss 21.19 ([21.19277125])\n",
      "15:14    Epoch 5: train loss 21.19 ([21.18650977])\n",
      "15:14    Epoch 6: train loss 21.18 ([21.18168797])\n",
      "15:15    Epoch 7: train loss 21.18 ([21.17679799])\n",
      "15:15    Epoch 8: train loss 21.17 ([21.17409654])\n",
      "15:15    Epoch 9: train loss 21.17 ([21.16976884])\n",
      "15:30    Epoch 10: train loss 21.17 ([21.16547836])\n",
      "15:30  Finished training\n",
      "15:30  Training estimator 7 / 20 in ensemble\n",
      "15:30  Starting training\n",
      "15:30    Method:                 sally\n",
      "15:30    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "15:30                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "15:30    Features:               all\n",
      "15:30    Method:                 sally\n",
      "15:30    Hidden layers:          (100, 100)\n",
      "15:30    Activation function:    tanh\n",
      "15:30    Batch size:             128\n",
      "15:30    Epochs:                 10\n",
      "15:30    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:30    Validation split:       None\n",
      "15:30    Early stopping:         True\n",
      "15:30  Loading training data\n",
      "15:30  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:30  Creating model for method sally\n",
      "15:30  Training model\n",
      "15:30    Epoch 1: train loss 15.94 ([15.93902704])\n",
      "15:31    Epoch 2: train loss 15.93 ([15.93438856])\n",
      "15:31    Epoch 3: train loss 15.93 ([15.92620079])\n",
      "15:31    Epoch 4: train loss 15.92 ([15.92052801])\n",
      "15:32    Epoch 5: train loss 15.92 ([15.91600666])\n",
      "15:32    Epoch 6: train loss 15.91 ([15.91144215])\n",
      "15:32    Epoch 7: train loss 15.90 ([15.90470535])\n",
      "15:33    Epoch 8: train loss 15.90 ([15.90333557])\n",
      "15:33    Epoch 9: train loss 15.90 ([15.899907])\n",
      "15:33    Epoch 10: train loss 15.90 ([15.89697261])\n",
      "15:33  Finished training\n",
      "15:33  Training estimator 8 / 20 in ensemble\n",
      "15:33  Starting training\n",
      "15:33    Method:                 sally\n",
      "15:33    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "15:33                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "15:33    Features:               all\n",
      "15:33    Method:                 sally\n",
      "15:33    Hidden layers:          (100, 100)\n",
      "15:33    Activation function:    tanh\n",
      "15:33    Batch size:             128\n",
      "15:33    Epochs:                 10\n",
      "15:33    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:33    Validation split:       None\n",
      "15:33    Early stopping:         True\n",
      "15:33  Loading training data\n",
      "15:33  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:33  Creating model for method sally\n",
      "15:33  Training model\n",
      "15:34    Epoch 1: train loss 27.65 ([27.64544424])\n",
      "15:34    Epoch 2: train loss 27.64 ([27.64323998])\n",
      "15:35    Epoch 3: train loss 27.63 ([27.63285733])\n",
      "15:35    Epoch 4: train loss 27.63 ([27.62755072])\n",
      "15:35    Epoch 5: train loss 27.62 ([27.6216621])\n",
      "15:36    Epoch 6: train loss 27.62 ([27.61673025])\n",
      "15:36    Epoch 7: train loss 27.62 ([27.61855141])\n",
      "15:36    Epoch 8: train loss 27.61 ([27.60585412])\n",
      "15:37    Epoch 9: train loss 27.60 ([27.60401409])\n",
      "15:37    Epoch 10: train loss 27.60 ([27.59916451])\n",
      "15:37  Finished training\n",
      "15:37  Training estimator 9 / 20 in ensemble\n",
      "15:37  Starting training\n",
      "15:37    Method:                 sally\n",
      "15:37    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "15:37                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "15:37    Features:               all\n",
      "15:37    Method:                 sally\n",
      "15:37    Hidden layers:          (100, 100)\n",
      "15:37    Activation function:    tanh\n",
      "15:37    Batch size:             128\n",
      "15:37    Epochs:                 10\n",
      "15:37    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:37    Validation split:       None\n",
      "15:37    Early stopping:         True\n",
      "15:37  Loading training data\n",
      "15:37  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:37  Creating model for method sally\n",
      "15:37  Training model\n",
      "15:37    Epoch 1: train loss 21.02 ([21.01619289])\n",
      "15:38    Epoch 2: train loss 21.01 ([21.01117503])\n",
      "15:38    Epoch 3: train loss 21.00 ([21.00466789])\n",
      "15:38    Epoch 4: train loss 20.99 ([20.99484161])\n",
      "15:39    Epoch 5: train loss 20.99 ([20.99048636])\n",
      "15:39    Epoch 6: train loss 20.98 ([20.98275413])\n",
      "15:39    Epoch 7: train loss 20.98 ([20.97842013])\n",
      "15:40    Epoch 8: train loss 20.97 ([20.97442822])\n",
      "15:40    Epoch 9: train loss 20.97 ([20.97240409])\n",
      "15:40    Epoch 10: train loss 20.97 ([20.97058979])\n",
      "15:40  Finished training\n",
      "15:40  Training estimator 10 / 20 in ensemble\n",
      "15:40  Starting training\n",
      "15:40    Method:                 sally\n",
      "15:40    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "15:40                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "15:40    Features:               all\n",
      "15:40    Method:                 sally\n",
      "15:40    Hidden layers:          (100, 100)\n",
      "15:40    Activation function:    tanh\n",
      "15:40    Batch size:             128\n",
      "15:40    Epochs:                 10\n",
      "15:40    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:40    Validation split:       None\n",
      "15:40    Early stopping:         True\n",
      "15:40  Loading training data\n",
      "15:40  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:40  Creating model for method sally\n",
      "15:40  Training model\n",
      "15:41    Epoch 1: train loss 47.36 ([47.35812838])\n",
      "15:41    Epoch 2: train loss 47.35 ([47.354257])\n",
      "15:42    Epoch 3: train loss 47.35 ([47.34969754])\n",
      "15:42    Epoch 4: train loss 47.34 ([47.34354063])\n",
      "15:42    Epoch 5: train loss 47.34 ([47.3381628])\n",
      "15:43    Epoch 6: train loss 47.33 ([47.33218988])\n",
      "15:43    Epoch 7: train loss 47.33 ([47.32844763])\n",
      "15:43    Epoch 8: train loss 47.33 ([47.32510277])\n",
      "15:44    Epoch 9: train loss 47.32 ([47.32067581])\n",
      "15:44    Epoch 10: train loss 47.32 ([47.31822953])\n",
      "15:44  Finished training\n",
      "15:44  Training estimator 11 / 20 in ensemble\n",
      "15:44  Starting training\n",
      "15:44    Method:                 sally\n",
      "15:44    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_10.npy\n",
      "15:44                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_10.npy\n",
      "15:44    Features:               all\n",
      "15:44    Method:                 sally\n",
      "15:44    Hidden layers:          (100, 100)\n",
      "15:44    Activation function:    tanh\n",
      "15:44    Batch size:             128\n",
      "15:44    Epochs:                 10\n",
      "15:44    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:44    Validation split:       None\n",
      "15:44    Early stopping:         True\n",
      "15:44  Loading training data\n",
      "15:44  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:44  Creating model for method sally\n",
      "15:44  Training model\n",
      "15:45    Epoch 1: train loss 17.00 ([16.99912366])\n",
      "15:45    Epoch 2: train loss 16.99 ([16.99296879])\n",
      "15:45    Epoch 3: train loss 16.99 ([16.98615192])\n",
      "15:46    Epoch 4: train loss 16.98 ([16.97834795])\n",
      "15:46    Epoch 5: train loss 16.98 ([16.98079601])\n",
      "15:46    Epoch 6: train loss 16.97 ([16.96927118])\n",
      "15:47    Epoch 7: train loss 16.96 ([16.96489753])\n",
      "15:47    Epoch 8: train loss 16.96 ([16.96027784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:47    Epoch 9: train loss 16.96 ([16.95817606])\n",
      "15:47    Epoch 10: train loss 16.95 ([16.95388096])\n",
      "15:47  Finished training\n",
      "15:47  Training estimator 12 / 20 in ensemble\n",
      "15:47  Starting training\n",
      "15:47    Method:                 sally\n",
      "15:47    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_11.npy\n",
      "15:47                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_11.npy\n",
      "15:47    Features:               all\n",
      "15:47    Method:                 sally\n",
      "15:47    Hidden layers:          (100, 100)\n",
      "15:47    Activation function:    tanh\n",
      "15:47    Batch size:             128\n",
      "15:47    Epochs:                 10\n",
      "15:47    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:47    Validation split:       None\n",
      "15:47    Early stopping:         True\n",
      "15:47  Loading training data\n",
      "15:47  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:47  Creating model for method sally\n",
      "15:47  Training model\n",
      "15:48    Epoch 1: train loss 17.48 ([17.48309961])\n",
      "15:48    Epoch 2: train loss 17.48 ([17.47896506])\n",
      "15:49    Epoch 3: train loss 17.47 ([17.47161213])\n",
      "15:49    Epoch 4: train loss 17.47 ([17.46520634])\n",
      "15:49    Epoch 5: train loss 17.46 ([17.45995412])\n",
      "15:50    Epoch 6: train loss 17.45 ([17.45355607])\n",
      "15:50    Epoch 7: train loss 17.45 ([17.44928803])\n",
      "15:50    Epoch 8: train loss 17.44 ([17.44431827])\n",
      "15:51    Epoch 9: train loss 17.44 ([17.44157261])\n",
      "15:51    Epoch 10: train loss 17.44 ([17.43818119])\n",
      "15:51  Finished training\n",
      "15:51  Training estimator 13 / 20 in ensemble\n",
      "15:51  Starting training\n",
      "15:51    Method:                 sally\n",
      "15:51    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_12.npy\n",
      "15:51                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_12.npy\n",
      "15:51    Features:               all\n",
      "15:51    Method:                 sally\n",
      "15:51    Hidden layers:          (100, 100)\n",
      "15:51    Activation function:    tanh\n",
      "15:51    Batch size:             128\n",
      "15:51    Epochs:                 10\n",
      "15:51    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:51    Validation split:       None\n",
      "15:51    Early stopping:         True\n",
      "15:51  Loading training data\n",
      "15:51  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:51  Creating model for method sally\n",
      "15:51  Training model\n",
      "15:52    Epoch 1: train loss 18.14 ([18.14312127])\n",
      "15:52    Epoch 2: train loss 18.14 ([18.13630464])\n",
      "15:52    Epoch 3: train loss 18.13 ([18.12791602])\n",
      "15:53    Epoch 4: train loss 18.12 ([18.12156141])\n",
      "15:53    Epoch 5: train loss 18.12 ([18.11658422])\n",
      "15:53    Epoch 6: train loss 18.11 ([18.11006149])\n",
      "15:54    Epoch 7: train loss 18.11 ([18.10685757])\n",
      "15:54    Epoch 8: train loss 18.10 ([18.1031478])\n",
      "15:54    Epoch 9: train loss 18.10 ([18.10031981])\n",
      "15:55    Epoch 10: train loss 18.10 ([18.09801688])\n",
      "15:55  Finished training\n",
      "15:55  Training estimator 14 / 20 in ensemble\n",
      "15:55  Starting training\n",
      "15:55    Method:                 sally\n",
      "15:55    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_13.npy\n",
      "15:55                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_13.npy\n",
      "15:55    Features:               all\n",
      "15:55    Method:                 sally\n",
      "15:55    Hidden layers:          (100, 100)\n",
      "15:55    Activation function:    tanh\n",
      "15:55    Batch size:             128\n",
      "15:55    Epochs:                 10\n",
      "15:55    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:55    Validation split:       None\n",
      "15:55    Early stopping:         True\n",
      "15:55  Loading training data\n",
      "15:55  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:55  Creating model for method sally\n",
      "15:55  Training model\n",
      "15:55    Epoch 1: train loss 12.51 ([12.50773042])\n",
      "15:56    Epoch 2: train loss 12.50 ([12.50229702])\n",
      "15:56    Epoch 3: train loss 12.50 ([12.49660247])\n",
      "15:56    Epoch 4: train loss 12.49 ([12.49101878])\n",
      "15:57    Epoch 5: train loss 12.49 ([12.48613254])\n",
      "15:57    Epoch 6: train loss 12.48 ([12.4812546])\n",
      "15:57    Epoch 7: train loss 12.48 ([12.47654558])\n",
      "15:57    Epoch 8: train loss 12.47 ([12.4740569])\n",
      "15:58    Epoch 9: train loss 12.47 ([12.4700118])\n",
      "15:58    Epoch 10: train loss 12.47 ([12.46798684])\n",
      "15:58  Finished training\n",
      "15:58  Training estimator 15 / 20 in ensemble\n",
      "15:58  Starting training\n",
      "15:58    Method:                 sally\n",
      "15:58    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_14.npy\n",
      "15:58                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_14.npy\n",
      "15:58    Features:               all\n",
      "15:58    Method:                 sally\n",
      "15:58    Hidden layers:          (100, 100)\n",
      "15:58    Activation function:    tanh\n",
      "15:58    Batch size:             128\n",
      "15:58    Epochs:                 10\n",
      "15:58    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "15:58    Validation split:       None\n",
      "15:58    Early stopping:         True\n",
      "15:58  Loading training data\n",
      "15:58  Found 1000000 samples with 2 parameters and 29 observables\n",
      "15:58  Creating model for method sally\n",
      "15:58  Training model\n",
      "15:59    Epoch 1: train loss 22.64 ([22.63764049])\n",
      "15:59    Epoch 2: train loss 22.64 ([22.6369102])\n",
      "15:59    Epoch 3: train loss 22.62 ([22.62442468])\n",
      "16:00    Epoch 4: train loss 22.62 ([22.61885837])\n",
      "16:00    Epoch 5: train loss 22.61 ([22.61140385])\n",
      "16:00    Epoch 6: train loss 22.61 ([22.60726348])\n",
      "16:00    Epoch 7: train loss 22.60 ([22.60242708])\n",
      "16:01    Epoch 8: train loss 22.60 ([22.60119696])\n",
      "16:01    Epoch 9: train loss 22.60 ([22.59737344])\n",
      "16:01    Epoch 10: train loss 22.59 ([22.59423764])\n",
      "16:01  Finished training\n",
      "16:01  Training estimator 16 / 20 in ensemble\n",
      "16:01  Starting training\n",
      "16:01    Method:                 sally\n",
      "16:01    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_15.npy\n",
      "16:01                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_15.npy\n",
      "16:01    Features:               all\n",
      "16:01    Method:                 sally\n",
      "16:01    Hidden layers:          (100, 100)\n",
      "16:01    Activation function:    tanh\n",
      "16:01    Batch size:             128\n",
      "16:01    Epochs:                 10\n",
      "16:01    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:01    Validation split:       None\n",
      "16:01    Early stopping:         True\n",
      "16:01  Loading training data\n",
      "16:01  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:01  Creating model for method sally\n",
      "16:01  Training model\n",
      "16:02    Epoch 1: train loss 15.57 ([15.5721162])\n",
      "16:02    Epoch 2: train loss 15.57 ([15.56682831])\n",
      "16:02    Epoch 3: train loss 15.56 ([15.5605106])\n",
      "16:03    Epoch 4: train loss 15.68 ([15.67854111])\n",
      "16:03    Epoch 5: train loss 15.55 ([15.54809114])\n",
      "16:03    Epoch 6: train loss 15.54 ([15.54317056])\n",
      "16:04    Epoch 7: train loss 15.54 ([15.53926965])\n",
      "16:04    Epoch 8: train loss 15.54 ([15.53531541])\n",
      "16:04    Epoch 9: train loss 15.53 ([15.53272751])\n",
      "16:05    Epoch 10: train loss 15.53 ([15.5291887])\n",
      "16:05  Finished training\n",
      "16:05  Training estimator 17 / 20 in ensemble\n",
      "16:05  Starting training\n",
      "16:05    Method:                 sally\n",
      "16:05    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_16.npy\n",
      "16:05                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_16.npy\n",
      "16:05    Features:               all\n",
      "16:05    Method:                 sally\n",
      "16:05    Hidden layers:          (100, 100)\n",
      "16:05    Activation function:    tanh\n",
      "16:05    Batch size:             128\n",
      "16:05    Epochs:                 10\n",
      "16:05    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:05    Validation split:       None\n",
      "16:05    Early stopping:         True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:05  Loading training data\n",
      "16:05  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:05  Creating model for method sally\n",
      "16:05  Training model\n",
      "16:05    Epoch 1: train loss 17.45 ([17.45484665])\n",
      "16:05    Epoch 2: train loss 17.45 ([17.44524187])\n",
      "16:06    Epoch 3: train loss 17.44 ([17.4397533])\n",
      "16:06    Epoch 4: train loss 17.43 ([17.43174506])\n",
      "16:06    Epoch 5: train loss 17.43 ([17.42705939])\n",
      "16:07    Epoch 6: train loss 17.42 ([17.4237265])\n",
      "16:07    Epoch 7: train loss 17.42 ([17.41803609])\n",
      "16:07    Epoch 8: train loss 17.42 ([17.41500709])\n",
      "16:08    Epoch 9: train loss 17.41 ([17.41099418])\n",
      "16:08    Epoch 10: train loss 17.41 ([17.40764218])\n",
      "16:08  Finished training\n",
      "16:08  Training estimator 18 / 20 in ensemble\n",
      "16:08  Starting training\n",
      "16:08    Method:                 sally\n",
      "16:08    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_17.npy\n",
      "16:08                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_17.npy\n",
      "16:08    Features:               all\n",
      "16:08    Method:                 sally\n",
      "16:08    Hidden layers:          (100, 100)\n",
      "16:08    Activation function:    tanh\n",
      "16:08    Batch size:             128\n",
      "16:08    Epochs:                 10\n",
      "16:08    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:08    Validation split:       None\n",
      "16:08    Early stopping:         True\n",
      "16:08  Loading training data\n",
      "16:08  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:08  Creating model for method sally\n",
      "16:08  Training model\n",
      "16:09    Epoch 1: train loss 18.10 ([18.10109305])\n",
      "16:09    Epoch 2: train loss 18.10 ([18.09994811])\n",
      "16:09    Epoch 3: train loss 18.09 ([18.08759317])\n",
      "16:10    Epoch 4: train loss 18.08 ([18.08381322])\n",
      "16:10    Epoch 5: train loss 18.08 ([18.07744735])\n",
      "16:10    Epoch 6: train loss 18.07 ([18.07327137])\n",
      "16:11    Epoch 7: train loss 18.07 ([18.07065683])\n",
      "16:11    Epoch 8: train loss 18.07 ([18.06743493])\n",
      "16:12    Epoch 9: train loss 18.06 ([18.06327609])\n",
      "16:13    Epoch 10: train loss 18.06 ([18.06064043])\n",
      "16:13  Finished training\n",
      "16:13  Training estimator 19 / 20 in ensemble\n",
      "16:13  Starting training\n",
      "16:13    Method:                 sally\n",
      "16:13    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_18.npy\n",
      "16:13                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_18.npy\n",
      "16:13    Features:               all\n",
      "16:13    Method:                 sally\n",
      "16:13    Hidden layers:          (100, 100)\n",
      "16:13    Activation function:    tanh\n",
      "16:13    Batch size:             128\n",
      "16:13    Epochs:                 10\n",
      "16:13    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:13    Validation split:       None\n",
      "16:13    Early stopping:         True\n",
      "16:13  Loading training data\n",
      "16:13  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:13  Creating model for method sally\n",
      "16:13  Training model\n",
      "16:14    Epoch 1: train loss 44.30 ([44.29750659])\n",
      "16:15    Epoch 2: train loss 44.29 ([44.29361251])\n",
      "16:15    Epoch 3: train loss 44.29 ([44.28710644])\n",
      "16:16    Epoch 4: train loss 44.28 ([44.28143347])\n",
      "16:17    Epoch 5: train loss 44.27 ([44.2719652])\n",
      "16:18    Epoch 6: train loss 44.27 ([44.26895436])\n",
      "16:18    Epoch 7: train loss 44.27 ([44.26702038])\n",
      "16:19    Epoch 8: train loss 44.26 ([44.26198148])\n",
      "16:20    Epoch 9: train loss 44.26 ([44.25835602])\n",
      "16:21    Epoch 10: train loss 44.25 ([44.25376237])\n",
      "16:21  Finished training\n",
      "16:21  Training estimator 20 / 20 in ensemble\n",
      "16:21  Starting training\n",
      "16:21    Method:                 sally\n",
      "16:21    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_19.npy\n",
      "16:21                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_19.npy\n",
      "16:21    Features:               all\n",
      "16:21    Method:                 sally\n",
      "16:21    Hidden layers:          (100, 100)\n",
      "16:21    Activation function:    tanh\n",
      "16:21    Batch size:             128\n",
      "16:21    Epochs:                 10\n",
      "16:21    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:21    Validation split:       None\n",
      "16:21    Early stopping:         True\n",
      "16:21  Loading training data\n",
      "16:21  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:21  Creating model for method sally\n",
      "16:21  Training model\n",
      "16:22    Epoch 1: train loss 15.79 ([15.78505958])\n",
      "16:22    Epoch 2: train loss 15.78 ([15.78245114])\n",
      "16:23    Epoch 3: train loss 15.78 ([15.77624186])\n",
      "16:24    Epoch 4: train loss 15.77 ([15.77088882])\n",
      "16:25    Epoch 5: train loss 15.76 ([15.76277011])\n",
      "16:25    Epoch 6: train loss 15.76 ([15.75874787])\n",
      "16:26    Epoch 7: train loss 15.76 ([15.75598564])\n",
      "16:27    Epoch 8: train loss 15.76 ([15.75508577])\n",
      "16:27    Epoch 9: train loss 15.75 ([15.74850169])\n",
      "16:28    Epoch 10: train loss 15.75 ([15.74638518])\n",
      "16:28  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble_all = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_all.train_all(\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:28  Calculating expectation for 20 estimators in ensemble\n",
      "16:28  Starting evaluation for estimator 1 / 20 in ensemble\n",
      "16:28  Loading evaluation data\n",
      "16:28  Starting score evaluation\n",
      "16:28  Starting evaluation for estimator 2 / 20 in ensemble\n",
      "16:28  Loading evaluation data\n",
      "16:28  Starting score evaluation\n",
      "16:28  Starting evaluation for estimator 3 / 20 in ensemble\n",
      "16:28  Loading evaluation data\n",
      "16:28  Starting score evaluation\n",
      "16:29  Starting evaluation for estimator 4 / 20 in ensemble\n",
      "16:29  Loading evaluation data\n",
      "16:29  Starting score evaluation\n",
      "16:29  Starting evaluation for estimator 5 / 20 in ensemble\n",
      "16:29  Loading evaluation data\n",
      "16:29  Starting score evaluation\n",
      "16:29  Starting evaluation for estimator 6 / 20 in ensemble\n",
      "16:29  Loading evaluation data\n",
      "16:29  Starting score evaluation\n",
      "16:30  Starting evaluation for estimator 7 / 20 in ensemble\n",
      "16:30  Loading evaluation data\n",
      "16:30  Starting score evaluation\n",
      "16:30  Starting evaluation for estimator 8 / 20 in ensemble\n",
      "16:30  Loading evaluation data\n",
      "16:30  Starting score evaluation\n",
      "16:30  Starting evaluation for estimator 9 / 20 in ensemble\n",
      "16:30  Loading evaluation data\n",
      "16:30  Starting score evaluation\n",
      "16:31  Starting evaluation for estimator 10 / 20 in ensemble\n",
      "16:31  Loading evaluation data\n",
      "16:31  Starting score evaluation\n",
      "16:31  Starting evaluation for estimator 11 / 20 in ensemble\n",
      "16:31  Loading evaluation data\n",
      "16:31  Starting score evaluation\n",
      "16:31  Starting evaluation for estimator 12 / 20 in ensemble\n",
      "16:31  Loading evaluation data\n",
      "16:31  Starting score evaluation\n",
      "16:32  Starting evaluation for estimator 13 / 20 in ensemble\n",
      "16:32  Loading evaluation data\n",
      "16:32  Starting score evaluation\n",
      "16:32  Starting evaluation for estimator 14 / 20 in ensemble\n",
      "16:32  Loading evaluation data\n",
      "16:32  Starting score evaluation\n",
      "16:33  Starting evaluation for estimator 15 / 20 in ensemble\n",
      "16:33  Loading evaluation data\n",
      "16:33  Starting score evaluation\n",
      "16:33  Starting evaluation for estimator 16 / 20 in ensemble\n",
      "16:33  Loading evaluation data\n",
      "16:33  Starting score evaluation\n",
      "16:33  Starting evaluation for estimator 17 / 20 in ensemble\n",
      "16:33  Loading evaluation data\n",
      "16:33  Starting score evaluation\n",
      "16:34  Starting evaluation for estimator 18 / 20 in ensemble\n",
      "16:34  Loading evaluation data\n",
      "16:34  Starting score evaluation\n",
      "16:34  Starting evaluation for estimator 19 / 20 in ensemble\n",
      "16:34  Loading evaluation data\n",
      "16:34  Starting score evaluation\n",
      "16:34  Starting evaluation for estimator 20 / 20 in ensemble\n",
      "16:34  Loading evaluation data\n",
      "16:35  Starting score evaluation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.1157300e-02,  3.5557713e-02],\n",
       "       [ 4.2227305e-02,  2.2247573e-02],\n",
       "       [ 4.3938544e-02,  8.2605416e-03],\n",
       "       [ 1.5424059e-02,  1.1764613e-02],\n",
       "       [ 1.6029024e-02,  2.1971285e-02],\n",
       "       [-5.9176539e-03, -2.5282262e-02],\n",
       "       [ 3.6881778e-02,  2.3823624e-02],\n",
       "       [-4.9999077e-02,  4.9175002e-02],\n",
       "       [-7.8570209e-02,  1.1715643e-02],\n",
       "       [-5.7677967e-03, -9.8513411e-03],\n",
       "       [-3.0349173e-02, -1.1419740e-02],\n",
       "       [-3.6383120e-05, -3.9214902e-02],\n",
       "       [-2.5129890e-02, -7.0967138e-02],\n",
       "       [ 1.8388072e-02,  2.5392491e-02],\n",
       "       [ 3.3762254e-02,  1.4068673e-02],\n",
       "       [ 5.2451864e-02,  4.1743319e-02],\n",
       "       [ 4.3338899e-02, -2.1235945e-02],\n",
       "       [ 2.2035375e-02,  9.4163790e-04],\n",
       "       [-3.9819833e-02, -8.7405525e-02],\n",
       "       [ 3.2246809e-02, -1.5028991e-02]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_all.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:35  Saving ensemble setup to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/ensemble.json\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_0_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_0_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_1_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_1_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_2_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_2_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_3_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_3_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_4_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_4_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_5_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_5_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_6_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_6_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_7_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_7_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_8_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_8_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_9_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_9_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_10_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_10_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_11_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_11_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_12_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_12_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_13_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_13_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_14_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_14_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_15_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_15_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_16_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_16_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_17_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_17_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_18_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_18_state_dict.pt\n",
      "16:35  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_19_settings.json\n",
      "16:35  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_19_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "ensemble_all.save(model_dir + 'sally_ensemble_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d toy study (delta phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:35  Training 20 estimators in ensemble\n",
      "16:35  Training estimator 1 / 20 in ensemble\n",
      "16:35  Starting training\n",
      "16:35    Method:                 sally\n",
      "16:35    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "16:35                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "16:35    Features:               [20]\n",
      "16:35    Method:                 sally\n",
      "16:35    Hidden layers:          (100, 100)\n",
      "16:35    Activation function:    tanh\n",
      "16:35    Batch size:             128\n",
      "16:35    Epochs:                 10\n",
      "16:35    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:35    Validation split:       None\n",
      "16:35    Early stopping:         True\n",
      "16:35  Loading training data\n",
      "16:35  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:35  Only using 1 of 29 observables\n",
      "16:35  Creating model for method sally\n",
      "16:35  Training model\n",
      "16:36    Epoch 1: train loss 18.53 ([18.53177296])\n",
      "16:37    Epoch 2: train loss 18.53 ([18.52855994])\n",
      "16:38    Epoch 3: train loss 18.52 ([18.52346874])\n",
      "16:39    Epoch 4: train loss 18.52 ([18.52236543])\n",
      "16:40    Epoch 5: train loss 18.52 ([18.52095886])\n",
      "16:41    Epoch 6: train loss 18.52 ([18.52083373])\n",
      "16:41    Epoch 7: train loss 18.52 ([18.52026956])\n",
      "16:42    Epoch 8: train loss 18.52 ([18.52014545])\n",
      "16:43    Epoch 9: train loss 18.52 ([18.51977543])\n",
      "16:44    Epoch 10: train loss 18.52 ([18.52043823])\n",
      "16:44  Finished training\n",
      "16:44  Training estimator 2 / 20 in ensemble\n",
      "16:44  Starting training\n",
      "16:44    Method:                 sally\n",
      "16:44    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "16:44                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "16:44    Features:               [20]\n",
      "16:44    Method:                 sally\n",
      "16:44    Hidden layers:          (100, 100)\n",
      "16:44    Activation function:    tanh\n",
      "16:44    Batch size:             128\n",
      "16:44    Epochs:                 10\n",
      "16:44    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:44    Validation split:       None\n",
      "16:44    Early stopping:         True\n",
      "16:44  Loading training data\n",
      "16:44  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:44  Only using 1 of 29 observables\n",
      "16:44  Creating model for method sally\n",
      "16:44  Training model\n",
      "16:46    Epoch 1: train loss 15.96 ([15.96429934])\n",
      "16:47    Epoch 2: train loss 15.96 ([15.9571233])\n",
      "16:48    Epoch 3: train loss 15.96 ([15.95527635])\n",
      "16:49    Epoch 4: train loss 15.95 ([15.95430533])\n",
      "16:49    Epoch 5: train loss 15.95 ([15.95417639])\n",
      "16:50    Epoch 6: train loss 15.95 ([15.95378606])\n",
      "16:50    Epoch 7: train loss 15.95 ([15.95458707])\n",
      "16:51    Epoch 8: train loss 15.96 ([15.95509817])\n",
      "16:52    Epoch 9: train loss 15.95 ([15.95479586])\n",
      "16:53    Epoch 10: train loss 15.95 ([15.95349322])\n",
      "16:53  Finished training\n",
      "16:53  Training estimator 3 / 20 in ensemble\n",
      "16:53  Starting training\n",
      "16:53    Method:                 sally\n",
      "16:53    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "16:53                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "16:53    Features:               [20]\n",
      "16:53    Method:                 sally\n",
      "16:53    Hidden layers:          (100, 100)\n",
      "16:53    Activation function:    tanh\n",
      "16:53    Batch size:             128\n",
      "16:53    Epochs:                 10\n",
      "16:53    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:53    Validation split:       None\n",
      "16:53    Early stopping:         True\n",
      "16:53  Loading training data\n",
      "16:53  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:53  Only using 1 of 29 observables\n",
      "16:53  Creating model for method sally\n",
      "16:53  Training model\n",
      "16:54    Epoch 1: train loss 53.48 ([53.48247727])\n",
      "16:54    Epoch 2: train loss 53.48 ([53.48382343])\n",
      "16:55    Epoch 3: train loss 53.48 ([53.48105851])\n",
      "16:55    Epoch 4: train loss 53.47 ([53.47359121])\n",
      "16:56    Epoch 5: train loss 53.47 ([53.4703382])\n",
      "16:56    Epoch 6: train loss 53.47 ([53.46925278])\n",
      "16:57    Epoch 7: train loss 53.47 ([53.46603678])\n",
      "16:57    Epoch 8: train loss 53.47 ([53.46812312])\n",
      "16:58    Epoch 9: train loss 53.46 ([53.46337443])\n",
      "16:58    Epoch 10: train loss 53.46 ([53.46302902])\n",
      "16:58  Finished training\n",
      "16:58  Training estimator 4 / 20 in ensemble\n",
      "16:58  Starting training\n",
      "16:58    Method:                 sally\n",
      "16:58    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "16:58                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "16:58    Features:               [20]\n",
      "16:58    Method:                 sally\n",
      "16:58    Hidden layers:          (100, 100)\n",
      "16:58    Activation function:    tanh\n",
      "16:58    Batch size:             128\n",
      "16:58    Epochs:                 10\n",
      "16:58    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "16:58    Validation split:       None\n",
      "16:58    Early stopping:         True\n",
      "16:58  Loading training data\n",
      "16:58  Found 1000000 samples with 2 parameters and 29 observables\n",
      "16:58  Only using 1 of 29 observables\n",
      "16:58  Creating model for method sally\n",
      "16:58  Training model\n",
      "16:59    Epoch 1: train loss 27.76 ([27.75951231])\n",
      "16:59    Epoch 2: train loss 27.76 ([27.76217291])\n",
      "17:00    Epoch 3: train loss 27.76 ([27.75901158])\n",
      "17:00    Epoch 4: train loss 27.75 ([27.75322797])\n",
      "17:01    Epoch 5: train loss 27.75 ([27.74873414])\n",
      "17:01    Epoch 6: train loss 27.75 ([27.74752901])\n",
      "17:02    Epoch 7: train loss 27.74 ([27.74489975])\n",
      "17:02    Epoch 8: train loss 27.74 ([27.74302217])\n",
      "17:03    Epoch 9: train loss 27.74 ([27.74243343])\n",
      "17:04    Epoch 10: train loss 27.74 ([27.7413633])\n",
      "17:04  Finished training\n",
      "17:04  Training estimator 5 / 20 in ensemble\n",
      "17:04  Starting training\n",
      "17:04    Method:                 sally\n",
      "17:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "17:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "17:04    Features:               [20]\n",
      "17:04    Method:                 sally\n",
      "17:04    Hidden layers:          (100, 100)\n",
      "17:04    Activation function:    tanh\n",
      "17:04    Batch size:             128\n",
      "17:04    Epochs:                 10\n",
      "17:04    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "17:04    Validation split:       None\n",
      "17:04    Early stopping:         True\n",
      "17:04  Loading training data\n",
      "17:04  Found 1000000 samples with 2 parameters and 29 observables\n",
      "17:04  Only using 1 of 29 observables\n",
      "17:04  Creating model for method sally\n",
      "17:04  Training model\n",
      "17:05    Epoch 1: train loss 17.96 ([17.96254313])\n",
      "17:05    Epoch 2: train loss 17.96 ([17.95550531])\n",
      "17:06    Epoch 3: train loss 17.95 ([17.9521446])\n",
      "17:06    Epoch 4: train loss 17.95 ([17.95056319])\n",
      "17:07    Epoch 5: train loss 17.95 ([17.95083597])\n",
      "17:07    Epoch 6: train loss 17.95 ([17.94976511])\n",
      "17:08    Epoch 7: train loss 17.95 ([17.94918877])\n",
      "17:08    Epoch 8: train loss 17.95 ([17.94875291])\n",
      "17:09    Epoch 9: train loss 17.95 ([17.95121342])\n",
      "17:09    Epoch 10: train loss 17.95 ([17.94842513])\n",
      "17:09  Finished training\n",
      "17:09  Training estimator 6 / 20 in ensemble\n",
      "17:09  Starting training\n",
      "17:09    Method:                 sally\n",
      "17:09    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n",
      "17:09                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n",
      "17:09    Features:               [20]\n",
      "17:09    Method:                 sally\n",
      "17:09    Hidden layers:          (100, 100)\n",
      "17:09    Activation function:    tanh\n",
      "17:09    Batch size:             128\n",
      "17:09    Epochs:                 10\n",
      "17:09    Learning rate:          0.002 initially, decaying to 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:09    Validation split:       None\n",
      "17:09    Early stopping:         True\n",
      "17:09  Loading training data\n",
      "17:09  Found 1000000 samples with 2 parameters and 29 observables\n",
      "17:09  Only using 1 of 29 observables\n",
      "17:09  Creating model for method sally\n",
      "17:09  Training model\n",
      "17:10    Epoch 1: train loss 21.21 ([21.20779252])\n",
      "17:11    Epoch 2: train loss 21.20 ([21.19950415])\n",
      "17:11    Epoch 3: train loss 21.20 ([21.19562017])\n",
      "17:12    Epoch 4: train loss 21.19 ([21.19288243])\n",
      "17:12    Epoch 5: train loss 21.19 ([21.19108921])\n",
      "17:12    Epoch 6: train loss 21.19 ([21.19015671])\n",
      "17:13    Epoch 7: train loss 21.19 ([21.1896353])\n",
      "17:13    Epoch 8: train loss 21.19 ([21.18979933])\n",
      "17:13    Epoch 9: train loss 21.19 ([21.18921426])\n",
      "17:13    Epoch 10: train loss 21.19 ([21.18884981])\n",
      "17:13  Finished training\n",
      "17:13  Training estimator 7 / 20 in ensemble\n",
      "17:13  Starting training\n",
      "17:13    Method:                 sally\n",
      "17:13    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "17:13                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "17:13    Features:               [20]\n",
      "17:13    Method:                 sally\n",
      "17:13    Hidden layers:          (100, 100)\n",
      "17:13    Activation function:    tanh\n",
      "17:13    Batch size:             128\n",
      "17:13    Epochs:                 10\n",
      "17:13    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "17:13    Validation split:       None\n",
      "17:13    Early stopping:         True\n",
      "17:13  Loading training data\n",
      "17:14  Found 1000000 samples with 2 parameters and 29 observables\n",
      "17:14  Only using 1 of 29 observables\n",
      "17:14  Creating model for method sally\n",
      "17:14  Training model\n",
      "17:14    Epoch 1: train loss 15.93 ([15.93235809])\n",
      "17:14    Epoch 2: train loss 15.92 ([15.92478894])\n",
      "17:15    Epoch 3: train loss 15.92 ([15.92137603])\n",
      "17:15    Epoch 4: train loss 15.92 ([15.92005732])\n",
      "17:15    Epoch 5: train loss 15.92 ([15.91881276])\n",
      "17:15    Epoch 6: train loss 15.92 ([15.91861566])\n",
      "17:16    Epoch 7: train loss 15.92 ([15.91805453])\n",
      "17:16    Epoch 8: train loss 15.92 ([15.91755082])\n",
      "17:16    Epoch 9: train loss 15.92 ([15.91781939])\n",
      "17:17    Epoch 10: train loss 15.92 ([15.91834376])\n",
      "17:17  Finished training\n",
      "17:17  Training estimator 8 / 20 in ensemble\n",
      "17:17  Starting training\n",
      "17:17    Method:                 sally\n",
      "17:17    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "17:17                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "17:17    Features:               [20]\n",
      "17:17    Method:                 sally\n",
      "17:17    Hidden layers:          (100, 100)\n",
      "17:17    Activation function:    tanh\n",
      "17:17    Batch size:             128\n",
      "17:17    Epochs:                 10\n",
      "17:17    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "17:17    Validation split:       None\n",
      "17:17    Early stopping:         True\n",
      "17:17  Loading training data\n",
      "17:17  Found 1000000 samples with 2 parameters and 29 observables\n",
      "17:17  Only using 1 of 29 observables\n",
      "17:17  Creating model for method sally\n",
      "17:17  Training model\n",
      "17:17    Epoch 1: train loss 27.65 ([27.64845902])\n",
      "17:17    Epoch 2: train loss 27.64 ([27.63678006])\n",
      "17:18    Epoch 3: train loss 27.63 ([27.6317942])\n",
      "17:18    Epoch 4: train loss 27.63 ([27.62900601])\n",
      "17:18    Epoch 5: train loss 27.63 ([27.62727186])\n",
      "17:19    Epoch 6: train loss 27.63 ([27.62521015])\n",
      "17:19    Epoch 7: train loss 27.62 ([27.62309206])\n",
      "17:19    Epoch 8: train loss 27.62 ([27.62435411])\n",
      "17:20    Epoch 9: train loss 27.62 ([27.62152979])\n",
      "17:20    Epoch 10: train loss 27.62 ([27.62159597])\n",
      "17:20  Finished training\n",
      "17:20  Training estimator 9 / 20 in ensemble\n",
      "17:20  Starting training\n",
      "17:20    Method:                 sally\n",
      "17:20    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "17:20                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "17:20    Features:               [20]\n",
      "17:20    Method:                 sally\n",
      "17:20    Hidden layers:          (100, 100)\n",
      "17:20    Activation function:    tanh\n",
      "17:20    Batch size:             128\n",
      "17:20    Epochs:                 10\n",
      "17:20    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "17:20    Validation split:       None\n",
      "17:20    Early stopping:         True\n",
      "17:20  Loading training data\n",
      "17:20  Found 1000000 samples with 2 parameters and 29 observables\n",
      "17:20  Only using 1 of 29 observables\n",
      "17:20  Creating model for method sally\n",
      "17:20  Training model\n",
      "17:20    Epoch 1: train loss 21.01 ([21.00761748])\n",
      "17:21    Epoch 2: train loss 21.01 ([21.00766362])\n",
      "17:21    Epoch 3: train loss 21.00 ([21.0018538])\n",
      "17:21    Epoch 4: train loss 21.00 ([20.99811884])\n",
      "17:22    Epoch 5: train loss 21.00 ([20.99805934])\n",
      "17:22    Epoch 6: train loss 21.00 ([20.99644783])\n",
      "17:22    Epoch 7: train loss 21.00 ([20.99516592])\n",
      "17:22    Epoch 8: train loss 20.99 ([20.99490894])\n",
      "17:23    Epoch 9: train loss 20.99 ([20.99430642])\n",
      "17:23    Epoch 10: train loss 20.99 ([20.99397126])\n",
      "17:23  Finished training\n",
      "17:23  Training estimator 10 / 20 in ensemble\n",
      "17:23  Starting training\n",
      "17:23    Method:                 sally\n",
      "17:23    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "17:23                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "17:23    Features:               [20]\n",
      "17:23    Method:                 sally\n",
      "17:23    Hidden layers:          (100, 100)\n",
      "17:23    Activation function:    tanh\n",
      "17:23    Batch size:             128\n",
      "17:23    Epochs:                 10\n",
      "17:23    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "17:23    Validation split:       None\n",
      "17:23    Early stopping:         True\n",
      "17:23  Loading training data\n",
      "17:23  Found 1000000 samples with 2 parameters and 29 observables\n",
      "17:23  Only using 1 of 29 observables\n",
      "17:23  Creating model for method sally\n",
      "17:23  Training model\n",
      "17:23    Epoch 1: train loss 47.35 ([47.35172452])\n",
      "17:24    Epoch 2: train loss 47.35 ([47.34932868])\n",
      "17:24    Epoch 3: train loss 47.35 ([47.34743392])\n",
      "17:24    Epoch 4: train loss 47.35 ([47.34579856])\n",
      "17:25    Epoch 5: train loss 47.35 ([47.34832955])\n"
     ]
    }
   ],
   "source": [
    "ensemble_deltaphi = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_deltaphi.train_all(\n",
    "    features=[ [20] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_deltaphi.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_deltaphi.save(model_dir + 'sally_ensemble_deltaphi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d toy study (MET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_met = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_met.train_all(\n",
    "    features=[ [0] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_met.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_met.save(model_dir + 'sally_ensemble_deltaphi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
