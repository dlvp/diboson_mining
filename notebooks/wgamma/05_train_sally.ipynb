{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 20\n",
    "n_hidden = (100,100)\n",
    "n_epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SALLY on all observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:56  Training 20 estimators in ensemble\n",
      "13:56  Training estimator 1 / 20 in ensemble\n",
      "13:56  Starting training\n",
      "13:56    Method:                 sally\n",
      "13:56    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "13:56                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "13:56    Features:               all\n",
      "13:56    Method:                 sally\n",
      "13:56    Hidden layers:          (100, 100)\n",
      "13:56    Activation function:    tanh\n",
      "13:56    Batch size:             128\n",
      "13:56    Epochs:                 10\n",
      "13:56    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "13:56    Validation split:       None\n",
      "13:56    Early stopping:         True\n",
      "13:56  Loading training data\n",
      "13:56  Found 1000000 samples with 2 parameters and 29 observables\n",
      "13:56  Creating model for method sally\n",
      "13:56  Training model\n",
      "13:56    Epoch 1: train loss 18.54 ([18.54146863])\n",
      "13:57    Epoch 2: train loss 18.54 ([18.53504629])\n",
      "13:57    Epoch 3: train loss 18.53 ([18.52772093])\n",
      "13:57    Epoch 4: train loss 18.52 ([18.52088221])\n",
      "13:58    Epoch 5: train loss 18.51 ([18.51454554])\n",
      "13:58    Epoch 6: train loss 18.51 ([18.50907489])\n",
      "13:58    Epoch 7: train loss 18.51 ([18.50544568])\n",
      "13:59    Epoch 8: train loss 18.50 ([18.50218257])\n",
      "13:59    Epoch 9: train loss 18.50 ([18.50068721])\n",
      "13:59    Epoch 10: train loss 18.51 ([18.50504333])\n",
      "13:59  Finished training\n",
      "13:59  Training estimator 2 / 20 in ensemble\n",
      "13:59  Starting training\n",
      "13:59    Method:                 sally\n",
      "13:59    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "13:59                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "13:59    Features:               all\n",
      "13:59    Method:                 sally\n",
      "13:59    Hidden layers:          (100, 100)\n",
      "13:59    Activation function:    tanh\n",
      "13:59    Batch size:             128\n",
      "13:59    Epochs:                 10\n",
      "13:59    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "13:59    Validation split:       None\n",
      "13:59    Early stopping:         True\n",
      "13:59  Loading training data\n",
      "13:59  Found 1000000 samples with 2 parameters and 29 observables\n",
      "13:59  Creating model for method sally\n",
      "13:59  Training model\n",
      "14:00    Epoch 1: train loss 15.97 ([15.97114766])\n",
      "14:00    Epoch 2: train loss 15.97 ([15.96750268])\n",
      "14:00    Epoch 3: train loss 15.96 ([15.96140945])\n",
      "14:01    Epoch 4: train loss 15.95 ([15.95215615])\n",
      "14:01    Epoch 5: train loss 15.95 ([15.94525754])\n",
      "14:01    Epoch 6: train loss 15.94 ([15.93966471])\n",
      "14:02    Epoch 7: train loss 15.94 ([15.93683863])\n",
      "14:02    Epoch 8: train loss 15.93 ([15.93371031])\n",
      "14:02    Epoch 9: train loss 15.93 ([15.92933463])\n",
      "14:03    Epoch 10: train loss 15.93 ([15.92703788])\n",
      "14:03  Finished training\n",
      "14:03  Training estimator 3 / 20 in ensemble\n",
      "14:03  Starting training\n",
      "14:03    Method:                 sally\n",
      "14:03    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "14:03                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "14:03    Features:               all\n",
      "14:03    Method:                 sally\n",
      "14:03    Hidden layers:          (100, 100)\n",
      "14:03    Activation function:    tanh\n",
      "14:03    Batch size:             128\n",
      "14:03    Epochs:                 10\n",
      "14:03    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "14:03    Validation split:       None\n",
      "14:03    Early stopping:         True\n",
      "14:03  Loading training data\n",
      "14:03  Found 1000000 samples with 2 parameters and 29 observables\n",
      "14:03  Creating model for method sally\n",
      "14:03  Training model\n",
      "14:03    Epoch 1: train loss 53.48 ([53.48326681])\n",
      "14:04    Epoch 2: train loss 53.48 ([53.48093343])\n",
      "14:04    Epoch 3: train loss 53.48 ([53.47524763])\n",
      "14:04    Epoch 4: train loss 53.47 ([53.46727803])\n",
      "14:05    Epoch 5: train loss 53.46 ([53.45984107])\n",
      "14:05    Epoch 6: train loss 53.46 ([53.45521587])\n",
      "14:05    Epoch 7: train loss 53.45 ([53.4506908])\n"
     ]
    }
   ],
   "source": [
    "ensemble_all = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_all.train_all(\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_all.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_all.save(model_dir + 'sally_ensemble_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d toy study (delta phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_deltaphi = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_deltaphi.train_all(\n",
    "    features=[ [20] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_deltaphi.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_deltaphi.save(model_dir + 'sally_ensemble_deltaphi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d toy study (MET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_met = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_met.train_all(\n",
    "    features=[ [0] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_met.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_met.save(model_dir + 'sally_ensemble_deltaphi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
