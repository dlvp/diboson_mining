{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SALLY\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forge instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:37  \n",
      "16:37  ------------------------------------------------------------\n",
      "16:37  |                                                          |\n",
      "16:37  |  MadMiner v2018.10.12                                    |\n",
      "16:37  |                                                          |\n",
      "16:37  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "16:37  |                                                          |\n",
      "16:37  ------------------------------------------------------------\n",
      "16:37  \n"
     ]
    }
   ],
   "source": [
    "forge = MLForge(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SALLY on all observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:18  Starting training\n",
      "17:18    Method:                 sally\n",
      "17:18    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:18                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:18    Features:               all\n",
      "17:18    Method:                 sally\n",
      "17:18    Hidden layers:          (100, 100, 100)\n",
      "17:18    Activation function:    tanh\n",
      "17:18    Batch size:             256\n",
      "17:18    Epochs:                 20\n",
      "17:18    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:18    Validation split:       None\n",
      "17:18    Early stopping:         True\n",
      "17:18  Loading training data\n",
      "17:18  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:18  Creating model for method sally\n",
      "17:18  Training model\n",
      "17:19    Epoch 2: train loss 24.82 ([24.82367218])\n",
      "17:20    Epoch 4: train loss 24.82 ([24.81813576])\n",
      "17:21    Epoch 6: train loss 24.80 ([24.8049471])\n",
      "17:22    Epoch 8: train loss 24.80 ([24.80222857])\n",
      "17:22    Epoch 10: train loss 24.79 ([24.79405199])\n",
      "17:23    Epoch 12: train loss 24.95 ([24.94736396])\n",
      "17:24    Epoch 14: train loss 24.75 ([24.74942276])\n",
      "17:24    Epoch 16: train loss 24.73 ([24.72710563])\n",
      "17:25    Epoch 18: train loss 24.70 ([24.69725477])\n",
      "17:25    Epoch 20: train loss 24.66 ([24.6634835])\n",
      "17:25  Finished training\n",
      "17:25  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_0_settings.json\n",
      "17:25  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_0_state_dict.pt\n",
      "17:25  Starting training\n",
      "17:25    Method:                 sally\n",
      "17:25    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:25                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:25    Features:               all\n",
      "17:25    Method:                 sally\n",
      "17:25    Hidden layers:          (100, 100, 100)\n",
      "17:25    Activation function:    tanh\n",
      "17:25    Batch size:             256\n",
      "17:25    Epochs:                 20\n",
      "17:25    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:25    Validation split:       None\n",
      "17:25    Early stopping:         True\n",
      "17:25  Loading training data\n",
      "17:25  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:25  Creating model for method sally\n",
      "17:25  Training model\n",
      "17:26    Epoch 2: train loss 24.82 ([24.82389781])\n",
      "17:27    Epoch 4: train loss 24.82 ([24.81783742])\n",
      "17:28    Epoch 6: train loss 24.81 ([24.81108939])\n",
      "17:28    Epoch 8: train loss 24.80 ([24.80015285])\n",
      "17:29    Epoch 10: train loss 24.78 ([24.78384624])\n",
      "17:29    Epoch 12: train loss 24.77 ([24.7657872])\n",
      "17:30    Epoch 14: train loss 24.85 ([24.84534387])\n",
      "17:31    Epoch 16: train loss 24.73 ([24.732493])\n",
      "17:31    Epoch 18: train loss 24.70 ([24.70359024])\n",
      "17:32    Epoch 20: train loss 24.68 ([24.67946234])\n",
      "17:32  Finished training\n",
      "17:32  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_1_settings.json\n",
      "17:32  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_1_state_dict.pt\n",
      "17:32  Starting training\n",
      "17:32    Method:                 sally\n",
      "17:32    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:32                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:32    Features:               all\n",
      "17:32    Method:                 sally\n",
      "17:32    Hidden layers:          (100, 100, 100)\n",
      "17:32    Activation function:    tanh\n",
      "17:32    Batch size:             256\n",
      "17:32    Epochs:                 20\n",
      "17:32    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:32    Validation split:       None\n",
      "17:32    Early stopping:         True\n",
      "17:32  Loading training data\n",
      "17:32  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:32  Creating model for method sally\n",
      "17:32  Training model\n",
      "17:33    Epoch 2: train loss 24.83 ([24.8254405])\n",
      "17:33    Epoch 4: train loss 24.82 ([24.82280723])\n",
      "17:34    Epoch 6: train loss 24.81 ([24.81028578])\n",
      "17:35    Epoch 8: train loss 24.80 ([24.79757847])\n",
      "17:35    Epoch 10: train loss 24.78 ([24.78127398])\n",
      "17:36    Epoch 12: train loss 24.76 ([24.76284792])\n",
      "17:37    Epoch 14: train loss 24.75 ([24.74975809])\n",
      "17:37    Epoch 16: train loss 24.72 ([24.71995982])\n",
      "17:38    Epoch 18: train loss 24.69 ([24.69343287])\n",
      "17:38    Epoch 20: train loss 24.68 ([24.67721824])\n",
      "17:38  Finished training\n",
      "17:38  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_2_settings.json\n",
      "17:38  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_2_state_dict.pt\n",
      "17:38  Starting training\n",
      "17:38    Method:                 sally\n",
      "17:38    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:38                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:38    Features:               all\n",
      "17:38    Method:                 sally\n",
      "17:38    Hidden layers:          (100, 100, 100)\n",
      "17:38    Activation function:    tanh\n",
      "17:38    Batch size:             256\n",
      "17:38    Epochs:                 20\n",
      "17:38    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:38    Validation split:       None\n",
      "17:38    Early stopping:         True\n",
      "17:38  Loading training data\n",
      "17:38  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:38  Creating model for method sally\n",
      "17:38  Training model\n",
      "17:39    Epoch 2: train loss 24.83 ([24.82534495])\n",
      "17:40    Epoch 4: train loss 24.82 ([24.81783255])\n",
      "17:40    Epoch 6: train loss 24.81 ([24.80649422])\n",
      "17:41    Epoch 8: train loss 24.80 ([24.79615233])\n",
      "17:42    Epoch 10: train loss 24.78 ([24.77568601])\n",
      "17:42    Epoch 12: train loss 24.76 ([24.76156581])\n",
      "17:43    Epoch 14: train loss 24.74 ([24.74210645])\n",
      "17:43    Epoch 16: train loss 24.72 ([24.71602153])\n",
      "17:44    Epoch 18: train loss 24.68 ([24.68262186])\n",
      "17:44    Epoch 20: train loss 24.66 ([24.66076795])\n",
      "17:44  Finished training\n",
      "17:44  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_3_settings.json\n",
      "17:44  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_3_state_dict.pt\n",
      "17:44  Starting training\n",
      "17:44    Method:                 sally\n",
      "17:44    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:44                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:44    Features:               all\n",
      "17:44    Method:                 sally\n",
      "17:44    Hidden layers:          (100, 100, 100)\n",
      "17:44    Activation function:    tanh\n",
      "17:44    Batch size:             256\n",
      "17:44    Epochs:                 20\n",
      "17:44    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:44    Validation split:       None\n",
      "17:44    Early stopping:         True\n",
      "17:44  Loading training data\n",
      "17:44  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:44  Creating model for method sally\n",
      "17:44  Training model\n",
      "17:45    Epoch 2: train loss 24.82 ([24.82482741])\n",
      "17:46    Epoch 4: train loss 24.81 ([24.8145901])\n",
      "17:46    Epoch 6: train loss 24.81 ([24.80938959])\n",
      "17:47    Epoch 8: train loss 24.80 ([24.79883996])\n",
      "17:48    Epoch 10: train loss 24.78 ([24.78315217])\n",
      "17:48    Epoch 12: train loss 24.77 ([24.76665413])\n",
      "17:49    Epoch 14: train loss 24.75 ([24.74827804])\n",
      "17:50    Epoch 16: train loss 24.71 ([24.71357271])\n",
      "17:50    Epoch 18: train loss 24.69 ([24.69407905])\n",
      "17:51    Epoch 20: train loss 24.66 ([24.66054236])\n",
      "17:51  Finished training\n",
      "17:51  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_4_settings.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:51  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_4_state_dict.pt\n",
      "17:51  Starting training\n",
      "17:51    Method:                 sally\n",
      "17:51    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:51                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:51    Features:               all\n",
      "17:51    Method:                 sally\n",
      "17:51    Hidden layers:          (100, 100, 100)\n",
      "17:51    Activation function:    tanh\n",
      "17:51    Batch size:             256\n",
      "17:51    Epochs:                 20\n",
      "17:51    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:51    Validation split:       None\n",
      "17:51    Early stopping:         True\n",
      "17:51  Loading training data\n",
      "17:51  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:51  Creating model for method sally\n",
      "17:51  Training model\n",
      "17:52    Epoch 2: train loss 24.83 ([24.82735474])\n",
      "17:52    Epoch 4: train loss 24.82 ([24.81797793])\n",
      "17:53    Epoch 6: train loss 24.81 ([24.80693038])\n",
      "17:54    Epoch 8: train loss 24.79 ([24.78939456])\n",
      "17:54    Epoch 10: train loss 24.78 ([24.77824059])\n",
      "17:55    Epoch 12: train loss 24.77 ([24.76707642])\n",
      "17:55    Epoch 14: train loss 24.74 ([24.74168359])\n",
      "17:56    Epoch 16: train loss 24.72 ([24.71622697])\n",
      "17:57    Epoch 18: train loss 24.69 ([24.69052376])\n",
      "17:57    Epoch 20: train loss 24.65 ([24.65255225])\n",
      "17:57  Finished training\n",
      "17:57  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_5_settings.json\n",
      "17:57  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_5_state_dict.pt\n",
      "17:57  Starting training\n",
      "17:57    Method:                 sally\n",
      "17:57    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:57                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:57    Features:               all\n",
      "17:57    Method:                 sally\n",
      "17:57    Hidden layers:          (100, 100, 100)\n",
      "17:57    Activation function:    tanh\n",
      "17:57    Batch size:             256\n",
      "17:57    Epochs:                 20\n",
      "17:57    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:57    Validation split:       None\n",
      "17:57    Early stopping:         True\n",
      "17:57  Loading training data\n",
      "17:57  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:57  Creating model for method sally\n",
      "17:57  Training model\n",
      "17:58    Epoch 2: train loss 24.82 ([24.82289275])\n",
      "17:59    Epoch 4: train loss 24.82 ([24.81647127])\n",
      "17:59    Epoch 6: train loss 24.81 ([24.81224404])\n",
      "18:00    Epoch 8: train loss 24.80 ([24.80037331])\n",
      "18:01    Epoch 10: train loss 24.78 ([24.78049344])\n",
      "18:01    Epoch 12: train loss 24.76 ([24.76345632])\n",
      "18:02    Epoch 14: train loss 24.75 ([24.74829467])\n",
      "18:02    Epoch 16: train loss 24.72 ([24.72478106])\n",
      "18:03    Epoch 18: train loss 24.70 ([24.69996893])\n",
      "18:04    Epoch 20: train loss 24.68 ([24.67859439])\n",
      "18:04  Finished training\n",
      "18:04  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_6_settings.json\n",
      "18:04  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_6_state_dict.pt\n",
      "18:04  Starting training\n",
      "18:04    Method:                 sally\n",
      "18:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "18:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "18:04    Features:               all\n",
      "18:04    Method:                 sally\n",
      "18:04    Hidden layers:          (100, 100, 100)\n",
      "18:04    Activation function:    tanh\n",
      "18:04    Batch size:             256\n",
      "18:04    Epochs:                 20\n",
      "18:04    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "18:04    Validation split:       None\n",
      "18:04    Early stopping:         True\n",
      "18:04  Loading training data\n",
      "18:04  Found 1000000 samples with 2 parameters and 27 observables\n",
      "18:04  Creating model for method sally\n",
      "18:04  Training model\n",
      "18:05    Epoch 2: train loss 24.83 ([24.82515675])\n",
      "18:05    Epoch 4: train loss 24.81 ([24.81452639])\n",
      "18:06    Epoch 6: train loss 24.81 ([24.80808997])\n",
      "18:06    Epoch 8: train loss 24.80 ([24.79745568])\n",
      "18:07    Epoch 10: train loss 24.78 ([24.7811896])\n",
      "18:08    Epoch 12: train loss 24.77 ([24.76888823])\n",
      "18:08    Epoch 14: train loss 24.74 ([24.74486481])\n",
      "18:09    Epoch 16: train loss 24.72 ([24.72170829])\n",
      "18:09    Epoch 18: train loss 24.70 ([24.70238913])\n",
      "18:10    Epoch 20: train loss 24.69 ([24.68553677])\n",
      "18:10  Finished training\n",
      "18:10  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_7_settings.json\n",
      "18:10  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_7_state_dict.pt\n",
      "18:10  Starting training\n",
      "18:10    Method:                 sally\n",
      "18:10    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "18:10                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "18:10    Features:               all\n",
      "18:10    Method:                 sally\n",
      "18:10    Hidden layers:          (100, 100, 100)\n",
      "18:10    Activation function:    tanh\n",
      "18:10    Batch size:             256\n",
      "18:10    Epochs:                 20\n",
      "18:10    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "18:10    Validation split:       None\n",
      "18:10    Early stopping:         True\n",
      "18:10  Loading training data\n",
      "18:10  Found 1000000 samples with 2 parameters and 27 observables\n",
      "18:10  Creating model for method sally\n",
      "18:10  Training model\n",
      "18:11    Epoch 2: train loss 24.82 ([24.8246607])\n",
      "18:11    Epoch 4: train loss 24.82 ([24.8169737])\n",
      "18:12    Epoch 6: train loss 24.81 ([24.81310649])\n",
      "18:13    Epoch 8: train loss 24.80 ([24.79787536])\n",
      "18:13    Epoch 10: train loss 24.78 ([24.77647417])\n",
      "18:14    Epoch 12: train loss 24.77 ([24.76786871])\n",
      "18:14    Epoch 14: train loss 24.75 ([24.74945038])\n",
      "18:15    Epoch 16: train loss 24.72 ([24.72314425])\n",
      "18:16    Epoch 18: train loss 24.70 ([24.70148916])\n",
      "18:16    Epoch 20: train loss 24.68 ([24.68216255])\n",
      "18:16  Finished training\n",
      "18:16  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_8_settings.json\n",
      "18:16  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_8_state_dict.pt\n",
      "18:16  Starting training\n",
      "18:16    Method:                 sally\n",
      "18:16    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "18:16                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "18:16    Features:               all\n",
      "18:16    Method:                 sally\n",
      "18:16    Hidden layers:          (100, 100, 100)\n",
      "18:16    Activation function:    tanh\n",
      "18:16    Batch size:             256\n",
      "18:16    Epochs:                 20\n",
      "18:16    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "18:16    Validation split:       None\n",
      "18:16    Early stopping:         True\n",
      "18:16  Loading training data\n",
      "18:16  Found 1000000 samples with 2 parameters and 27 observables\n",
      "18:16  Creating model for method sally\n",
      "18:16  Training model\n",
      "18:17    Epoch 2: train loss 24.83 ([24.82666867])\n",
      "18:18    Epoch 4: train loss 24.81 ([24.81394569])\n",
      "18:18    Epoch 6: train loss 24.82 ([24.81542014])\n",
      "18:19    Epoch 8: train loss 24.80 ([24.80037674])\n",
      "18:20    Epoch 10: train loss 24.79 ([24.78848133])\n",
      "18:20    Epoch 12: train loss 24.77 ([24.77400144])\n",
      "18:21    Epoch 14: train loss 24.75 ([24.74741462])\n",
      "18:21    Epoch 16: train loss 24.72 ([24.72271185])\n",
      "18:22    Epoch 18: train loss 24.69 ([24.6938727])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:23    Epoch 20: train loss 24.67 ([24.6662217])\n",
      "18:23  Finished training\n",
      "18:23  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_9_settings.json\n",
      "18:23  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_all_9_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    forge.train(\n",
    "        method='sally',\n",
    "        x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "        t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "        n_epochs=20,\n",
    "        batch_size=256,\n",
    "        validation_split=None\n",
    "    )\n",
    "\n",
    "    forge.save(model_dir + 'sally_all_' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train just on individual observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:04  Starting training\n",
      "17:04    Method:                 sally\n",
      "17:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:04    Features:               [0, 4, 9]\n",
      "17:04    Method:                 sally\n",
      "17:04    Hidden layers:          (100, 100, 100)\n",
      "17:04    Activation function:    tanh\n",
      "17:04    Batch size:             256\n",
      "17:04    Epochs:                 20\n",
      "17:04    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:04    Validation split:       None\n",
      "17:04    Early stopping:         True\n",
      "17:04  Loading training data\n",
      "17:04  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:04  Only using 3 of 27 observables\n",
      "17:04  Creating model for method sally\n",
      "17:04  Training model\n",
      "17:05    Epoch 2: train loss 24.83 ([24.83068309])\n",
      "17:05    Epoch 4: train loss 24.83 ([24.82816149])\n",
      "17:06    Epoch 6: train loss 24.82 ([24.82477692])\n",
      "17:07    Epoch 8: train loss 24.82 ([24.82149155])\n",
      "17:08    Epoch 10: train loss 24.82 ([24.81562674])\n",
      "17:08    Epoch 12: train loss 24.81 ([24.81131894])\n",
      "17:09    Epoch 14: train loss 24.81 ([24.80831957])\n",
      "17:10    Epoch 16: train loss 24.80 ([24.80043825])\n",
      "17:11    Epoch 18: train loss 24.80 ([24.80288371])\n",
      "17:11    Epoch 20: train loss 24.79 ([24.78921657])\n",
      "17:11  Finished training\n",
      "17:11  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_pts_settings.json\n",
      "17:11  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_pts_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[0,4,9],\n",
    "    n_epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=None\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_pts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:11  Starting training\n",
      "17:11    Method:                 sally\n",
      "17:11    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "17:11                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "17:11    Features:               [21, 22, 25]\n",
      "17:11    Method:                 sally\n",
      "17:11    Hidden layers:          (100, 100, 100)\n",
      "17:11    Activation function:    tanh\n",
      "17:11    Batch size:             256\n",
      "17:11    Epochs:                 20\n",
      "17:11    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "17:11    Validation split:       None\n",
      "17:11    Early stopping:         True\n",
      "17:11  Loading training data\n",
      "17:11  Found 1000000 samples with 2 parameters and 27 observables\n",
      "17:11  Only using 3 of 27 observables\n",
      "17:11  Creating model for method sally\n",
      "17:11  Training model\n",
      "17:12    Epoch 2: train loss 24.83 ([24.82877266])\n",
      "17:13    Epoch 4: train loss 24.83 ([24.83069635])\n",
      "17:14    Epoch 6: train loss 24.82 ([24.82410643])\n",
      "17:14    Epoch 8: train loss 24.85 ([24.85071362])\n",
      "17:15    Epoch 10: train loss 24.82 ([24.82200982])\n",
      "17:15    Epoch 12: train loss 24.82 ([24.82140693])\n",
      "17:16    Epoch 14: train loss 24.82 ([24.82049373])\n",
      "17:17    Epoch 16: train loss 24.82 ([24.81962482])\n",
      "17:17    Epoch 18: train loss 24.82 ([24.81903511])\n",
      "17:18    Epoch 20: train loss 24.82 ([24.81864321])\n",
      "17:18  Finished training\n",
      "17:18  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphis_settings.json\n",
      "17:18  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphis_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[21,22,25],\n",
    "    n_epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=None\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_deltaphis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[0],\n",
    "    n_epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=None\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_met')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[4],\n",
    "    n_epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=None\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_ptl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[9],\n",
    "    n_epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=None\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_pta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[25],\n",
    "    n_epochs=20,\n",
    "    batch_size=256,\n",
    "    validation_split=None\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_deltaphi_al')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delta phi variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54  Starting training\n",
      "15:54    Method:                 sally\n",
      "15:54    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "15:54                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "15:54    Features:               [25]\n",
      "15:54    Method:                 sally\n",
      "15:54    Hidden layers:          (100, 100, 100)\n",
      "15:54    Activation function:    tanh\n",
      "15:54    Batch size:             256\n",
      "15:54    Epochs:                 10\n",
      "15:54    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "15:54    Validation split:       None\n",
      "15:54    Early stopping:         True\n",
      "15:54  Loading training data\n",
      "15:54  Found 1000000 samples with 2 parameters and 27 observables\n",
      "15:54  Only using 1 of 27 observables\n",
      "15:54  Creating model for method sally\n",
      "15:54  Training model\n",
      "15:54    Epoch 1: train loss 24.94 ([24.94450307])\n",
      "15:54    Epoch 2: train loss 24.90 ([24.89811951])\n",
      "15:55    Epoch 3: train loss 24.88 ([24.88289192])\n",
      "15:55    Epoch 4: train loss 24.86 ([24.86286096])\n",
      "15:56    Epoch 5: train loss 24.85 ([24.85235801])\n",
      "15:56    Epoch 6: train loss 24.84 ([24.84341593])\n",
      "15:56    Epoch 7: train loss 24.84 ([24.84005492])\n",
      "15:57    Epoch 8: train loss 24.84 ([24.83661095])\n",
      "15:57    Epoch 9: train loss 24.84 ([24.83503318])\n",
      "15:57    Epoch 10: train loss 24.84 ([24.83674081])\n",
      "15:57  Finished training\n",
      "15:57  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_1_settings.json\n",
      "15:57  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_1_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[25],\n",
    "    n_epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_split=None,\n",
    "    initial_lr=0.01,\n",
    "    final_lr=0.0001\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_deltaphi_la_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:06  Starting training\n",
      "16:06    Method:                 sally\n",
      "16:06    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train.npy\n",
      "16:06                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train.npy\n",
      "16:06    Features:               [25]\n",
      "16:06    Method:                 sally\n",
      "16:06    Hidden layers:          (100, 100, 100)\n",
      "16:06    Activation function:    tanh\n",
      "16:06    Batch size:             256\n",
      "16:06    Epochs:                 10\n",
      "16:06    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "16:06    Validation split:       None\n",
      "16:06    Early stopping:         True\n",
      "16:06  Loading training data\n",
      "16:06  Found 1000000 samples with 2 parameters and 27 observables\n",
      "16:06  Only using 1 of 27 observables\n",
      "16:06  Creating model for method sally\n",
      "16:06  Training model\n",
      "16:07    Epoch 1: train loss 24.94 ([24.93807698])\n",
      "16:07    Epoch 2: train loss 24.91 ([24.90790476])\n",
      "16:08    Epoch 3: train loss 24.88 ([24.87926488])\n",
      "16:08    Epoch 4: train loss 24.86 ([24.86232993])\n",
      "16:08    Epoch 5: train loss 24.85 ([24.85156556])\n",
      "16:09    Epoch 6: train loss 24.86 ([24.86230912])\n",
      "16:09    Epoch 7: train loss 24.84 ([24.83979924])\n",
      "16:09    Epoch 8: train loss 24.83 ([24.83204032])\n",
      "16:10    Epoch 9: train loss 24.83 ([24.83227242])\n",
      "16:10    Epoch 10: train loss 24.83 ([24.82952907])\n",
      "16:10  Finished training\n",
      "16:10  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_2_settings.json\n",
      "16:10  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_2_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'train_local/x_train.npy',\n",
    "    t_xz0_filename=sample_dir + 'train_local/t_xz_train.npy',\n",
    "    features=[25],\n",
    "    n_epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_split=None,\n",
    "    initial_lr=0.01,\n",
    "    final_lr=0.0001\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_deltaphi_la_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:58  Starting training\n",
      "15:58    Method:                 sally\n",
      "15:58    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/all_local/x_all.npy\n",
      "15:58                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/all_local/t_xz_all.npy\n",
      "15:58    Features:               [25]\n",
      "15:58    Method:                 sally\n",
      "15:58    Hidden layers:          (100, 100, 100)\n",
      "15:58    Activation function:    tanh\n",
      "15:58    Batch size:             256\n",
      "15:58    Epochs:                 10\n",
      "15:58    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "15:58    Validation split:       None\n",
      "15:58    Early stopping:         True\n",
      "15:58  Loading training data\n",
      "15:58  Found 1000000 samples with 2 parameters and 27 observables\n",
      "15:58  Only using 1 of 27 observables\n",
      "15:58  Creating model for method sally\n",
      "15:58  Training model\n",
      "15:58    Epoch 1: train loss 25.02 ([25.02128876])\n",
      "15:58    Epoch 2: train loss 24.99 ([24.98898835])\n",
      "15:59    Epoch 3: train loss 24.96 ([24.96494446])\n",
      "15:59    Epoch 4: train loss 24.95 ([24.94922362])\n",
      "16:00    Epoch 5: train loss 24.95 ([24.95025364])\n",
      "16:00    Epoch 6: train loss 24.93 ([24.9309041])\n",
      "16:00    Epoch 7: train loss 24.92 ([24.92314869])\n",
      "16:01    Epoch 8: train loss 24.92 ([24.9172167])\n",
      "16:01    Epoch 9: train loss 24.92 ([24.91519571])\n",
      "16:02    Epoch 10: train loss 24.91 ([24.91376029])\n",
      "16:02  Finished training\n",
      "16:02  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_big_1_settings.json\n",
      "16:02  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_big_1_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'all_local/x_all.npy',\n",
    "    t_xz0_filename=sample_dir + 'all_local/t_xz_all.npy',\n",
    "    features=[25],\n",
    "    n_epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_split=None,\n",
    "    initial_lr=0.01,\n",
    "    final_lr=0.0001\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_deltaphi_la_big_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:02  Starting training\n",
      "16:02    Method:                 sally\n",
      "16:02    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/all_local/x_all.npy\n",
      "16:02                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/all_local/t_xz_all.npy\n",
      "16:02    Features:               [25]\n",
      "16:02    Method:                 sally\n",
      "16:02    Hidden layers:          (100, 100, 100)\n",
      "16:02    Activation function:    tanh\n",
      "16:02    Batch size:             256\n",
      "16:02    Epochs:                 10\n",
      "16:02    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "16:02    Validation split:       None\n",
      "16:02    Early stopping:         True\n",
      "16:02  Loading training data\n",
      "16:02  Found 1000000 samples with 2 parameters and 27 observables\n",
      "16:02  Only using 1 of 27 observables\n",
      "16:02  Creating model for method sally\n",
      "16:02  Training model\n",
      "16:02    Epoch 1: train loss 25.03 ([25.02658608])\n",
      "16:03    Epoch 2: train loss 24.98 ([24.98288769])\n",
      "16:03    Epoch 3: train loss 24.97 ([24.96530231])\n",
      "16:03    Epoch 4: train loss 24.95 ([24.94717665])\n",
      "16:04    Epoch 5: train loss 24.94 ([24.93664335])\n",
      "16:04    Epoch 6: train loss 24.93 ([24.92835338])\n",
      "16:04    Epoch 7: train loss 24.92 ([24.92018679])\n",
      "16:05    Epoch 8: train loss 24.92 ([24.91783207])\n",
      "16:05    Epoch 9: train loss 24.91 ([24.91458891])\n",
      "16:05    Epoch 10: train loss 24.92 ([24.91945381])\n",
      "16:05  Finished training\n",
      "16:05  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_big_2_settings.json\n",
      "16:05  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_deltaphi_la_big_2_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "forge.train(\n",
    "    method='sally',\n",
    "    x_filename=sample_dir + 'all_local/x_all.npy',\n",
    "    t_xz0_filename=sample_dir + 'all_local/t_xz_all.npy',\n",
    "    features=[25],\n",
    "    n_epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_split=None,\n",
    "    initial_lr=0.01,\n",
    "    final_lr=0.0001\n",
    ")\n",
    "\n",
    "forge.save(model_dir + 'sally_deltaphi_la_big_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
