{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f9deb73c-b62f-4cff-8d83-724074098c92"
    }
   },
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "fe57a76c-4838-44c4-b0cc-5ee166785e4a"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "f3463c40-6421-42a1-8681-527c3ec42541"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "b2c73eca-c625-4f7a-9cee-4ccb2dcbb3e9"
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9c4780e4-775d-4cbd-8f3d-64fbd2b45344"
    }
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "98a6ae38-08cd-4e31-a7a4-5a370df5c84e"
    }
   },
   "outputs": [],
   "source": [
    "n_estimators = 20\n",
    "n_hidden = (100,100)\n",
    "n_epochs = 20\n",
    "batch_size = 128\n",
    "initial_lr = 0.001\n",
    "final_lr = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45e7f73-8f4c-4261-a381-4b7ad6af120f"
    }
   },
   "source": [
    "## Train SALLY on all observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "be3db4db-cc81-42e8-8796-dfc021acf234"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:40  \n",
      "21:40  ------------------------------------------------------------\n",
      "21:40  |                                                          |\n",
      "21:40  |  MadMiner v2018.10.26                                    |\n",
      "21:40  |                                                          |\n",
      "21:40  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "21:40  |                                                          |\n",
      "21:40  ------------------------------------------------------------\n",
      "21:40  \n",
      "21:40  Training 20 estimators in ensemble\n",
      "21:40  Training estimator 1 / 20 in ensemble\n",
      "21:40  Starting training\n",
      "21:40    Method:                 sally\n",
      "21:40    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "21:40                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "21:40    Features:               all\n",
      "21:40    Method:                 sally\n",
      "21:40    Hidden layers:          (100, 100)\n",
      "21:40    Activation function:    tanh\n",
      "21:40    Batch size:             128\n",
      "21:40    Epochs:                 20\n",
      "21:40    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "21:40    Validation split:       None\n",
      "21:40    Early stopping:         True\n",
      "21:40  Loading training data\n",
      "21:40  Found 1000000 samples with 2 parameters and 29 observables\n",
      "21:40  Creating model for method sally\n",
      "21:40  Training model\n",
      "21:41    Epoch 2: train loss 18.54 ([18.53997622])\n",
      "21:42    Epoch 4: train loss 18.53 ([18.53280304])\n",
      "21:42    Epoch 6: train loss 18.53 ([18.52691334])\n",
      "21:43    Epoch 8: train loss 18.52 ([18.51905806])\n",
      "21:44    Epoch 10: train loss 18.51 ([18.51020231])\n",
      "21:44    Epoch 12: train loss 18.51 ([18.50682093])\n",
      "21:45    Epoch 14: train loss 18.50 ([18.50124716])\n",
      "21:46    Epoch 16: train loss 18.50 ([18.49917512])\n",
      "21:46    Epoch 18: train loss 18.50 ([18.49706615])\n",
      "21:47    Epoch 20: train loss 18.49 ([18.49456744])\n",
      "21:47  Finished training\n",
      "21:47  Training estimator 2 / 20 in ensemble\n",
      "21:47  Starting training\n",
      "21:47    Method:                 sally\n",
      "21:47    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "21:47                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "21:47    Features:               all\n",
      "21:47    Method:                 sally\n",
      "21:47    Hidden layers:          (100, 100)\n",
      "21:47    Activation function:    tanh\n",
      "21:47    Batch size:             128\n",
      "21:47    Epochs:                 20\n",
      "21:47    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "21:47    Validation split:       None\n",
      "21:47    Early stopping:         True\n",
      "21:47  Loading training data\n",
      "21:47  Found 1000000 samples with 2 parameters and 29 observables\n",
      "21:47  Creating model for method sally\n",
      "21:47  Training model\n",
      "21:48    Epoch 2: train loss 15.97 ([15.97143462])\n",
      "21:49    Epoch 4: train loss 15.96 ([15.96093121])\n",
      "21:49    Epoch 6: train loss 15.95 ([15.9540416])\n",
      "21:50    Epoch 8: train loss 15.95 ([15.94821725])\n",
      "21:51    Epoch 10: train loss 15.94 ([15.94123144])\n",
      "21:51    Epoch 12: train loss 15.94 ([15.93554094])\n",
      "21:52    Epoch 14: train loss 15.93 ([15.93284162])\n",
      "21:53    Epoch 16: train loss 15.93 ([15.93015294])\n",
      "21:53    Epoch 18: train loss 15.93 ([15.92546342])\n",
      "21:54    Epoch 20: train loss 15.92 ([15.92220818])\n",
      "21:54  Finished training\n",
      "21:54  Training estimator 3 / 20 in ensemble\n",
      "21:54  Starting training\n",
      "21:54    Method:                 sally\n",
      "21:54    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "21:54                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "21:54    Features:               all\n",
      "21:54    Method:                 sally\n",
      "21:54    Hidden layers:          (100, 100)\n",
      "21:54    Activation function:    tanh\n",
      "21:54    Batch size:             128\n",
      "21:54    Epochs:                 20\n",
      "21:54    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "21:54    Validation split:       None\n",
      "21:54    Early stopping:         True\n",
      "21:54  Loading training data\n",
      "21:54  Found 1000000 samples with 2 parameters and 29 observables\n",
      "21:54  Creating model for method sally\n",
      "21:54  Training model\n",
      "21:55    Epoch 2: train loss 53.49 ([53.49182212])\n",
      "21:55    Epoch 4: train loss 53.48 ([53.47673802])\n",
      "21:56    Epoch 6: train loss 53.47 ([53.46869327])\n",
      "21:57    Epoch 8: train loss 53.46 ([53.46223839])\n",
      "21:57    Epoch 10: train loss 53.45 ([53.45390505])\n",
      "21:58    Epoch 12: train loss 53.45 ([53.44915965])\n",
      "21:59    Epoch 14: train loss 53.45 ([53.44632091])\n",
      "22:00    Epoch 16: train loss 53.44 ([53.44284723])\n",
      "22:00    Epoch 18: train loss 53.44 ([53.43724069])\n",
      "22:01    Epoch 20: train loss 53.44 ([53.43514347])\n",
      "22:01  Finished training\n",
      "22:01  Training estimator 4 / 20 in ensemble\n",
      "22:01  Starting training\n",
      "22:01    Method:                 sally\n",
      "22:01    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "22:01                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "22:01    Features:               all\n",
      "22:01    Method:                 sally\n",
      "22:01    Hidden layers:          (100, 100)\n",
      "22:01    Activation function:    tanh\n",
      "22:01    Batch size:             128\n",
      "22:01    Epochs:                 20\n",
      "22:01    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:01    Validation split:       None\n",
      "22:01    Early stopping:         True\n",
      "22:01  Loading training data\n",
      "22:01  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:01  Creating model for method sally\n",
      "22:01  Training model\n",
      "22:02    Epoch 2: train loss 27.77 ([27.76500807])\n",
      "22:03    Epoch 4: train loss 27.76 ([27.75622174])\n",
      "22:03    Epoch 6: train loss 27.75 ([27.74689005])\n",
      "22:04    Epoch 8: train loss 27.74 ([27.74199241])\n",
      "22:05    Epoch 10: train loss 27.74 ([27.73890009])\n",
      "22:05    Epoch 12: train loss 27.73 ([27.73199269])\n",
      "22:06    Epoch 14: train loss 27.73 ([27.72856823])\n",
      "22:07    Epoch 16: train loss 27.73 ([27.72599238])\n",
      "22:08    Epoch 18: train loss 27.72 ([27.72405726])\n",
      "22:08    Epoch 20: train loss 27.72 ([27.72232999])\n",
      "22:08  Finished training\n",
      "22:08  Training estimator 5 / 20 in ensemble\n",
      "22:08  Starting training\n",
      "22:08    Method:                 sally\n",
      "22:08    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "22:08                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "22:08    Features:               all\n",
      "22:08    Method:                 sally\n",
      "22:08    Hidden layers:          (100, 100)\n",
      "22:08    Activation function:    tanh\n",
      "22:08    Batch size:             128\n",
      "22:08    Epochs:                 20\n",
      "22:08    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:08    Validation split:       None\n",
      "22:08    Early stopping:         True\n",
      "22:08  Loading training data\n",
      "22:08  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:08  Creating model for method sally\n",
      "22:08  Training model\n",
      "22:09    Epoch 2: train loss 17.97 ([17.96858536])\n",
      "22:10    Epoch 4: train loss 17.96 ([17.96151795])\n",
      "22:11    Epoch 6: train loss 17.95 ([17.95282848])\n",
      "22:11    Epoch 8: train loss 17.94 ([17.94490914])\n",
      "22:12    Epoch 10: train loss 17.94 ([17.94315451])\n",
      "22:13    Epoch 12: train loss 17.94 ([17.93829382])\n",
      "22:13    Epoch 14: train loss 17.93 ([17.93337585])\n",
      "22:14    Epoch 16: train loss 17.93 ([17.92954603])\n",
      "22:15    Epoch 18: train loss 17.93 ([17.92570636])\n",
      "22:16    Epoch 20: train loss 17.92 ([17.92282071])\n",
      "22:16  Finished training\n",
      "22:16  Training estimator 6 / 20 in ensemble\n",
      "22:16  Starting training\n",
      "22:16    Method:                 sally\n",
      "22:16    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n",
      "22:16                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:16    Features:               all\n",
      "22:16    Method:                 sally\n",
      "22:16    Hidden layers:          (100, 100)\n",
      "22:16    Activation function:    tanh\n",
      "22:16    Batch size:             128\n",
      "22:16    Epochs:                 20\n",
      "22:16    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:16    Validation split:       None\n",
      "22:16    Early stopping:         True\n",
      "22:16  Loading training data\n",
      "22:16  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:16  Creating model for method sally\n",
      "22:16  Training model\n",
      "22:16    Epoch 2: train loss 21.21 ([21.2104542])\n",
      "22:17    Epoch 4: train loss 21.20 ([21.20129979])\n",
      "22:18    Epoch 6: train loss 21.19 ([21.1927511])\n",
      "22:18    Epoch 8: train loss 21.19 ([21.18890209])\n",
      "22:19    Epoch 10: train loss 21.18 ([21.18146434])\n",
      "22:20    Epoch 12: train loss 21.17 ([21.17402208])\n",
      "22:20    Epoch 14: train loss 21.17 ([21.17002762])\n",
      "22:21    Epoch 16: train loss 21.16 ([21.16466516])\n",
      "22:22    Epoch 18: train loss 21.16 ([21.16441933])\n",
      "22:22    Epoch 20: train loss 21.16 ([21.16185344])\n",
      "22:22  Finished training\n",
      "22:22  Training estimator 7 / 20 in ensemble\n",
      "22:22  Starting training\n",
      "22:22    Method:                 sally\n",
      "22:22    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "22:22                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "22:22    Features:               all\n",
      "22:22    Method:                 sally\n",
      "22:22    Hidden layers:          (100, 100)\n",
      "22:22    Activation function:    tanh\n",
      "22:22    Batch size:             128\n",
      "22:22    Epochs:                 20\n",
      "22:22    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:22    Validation split:       None\n",
      "22:22    Early stopping:         True\n",
      "22:22  Loading training data\n",
      "22:22  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:22  Creating model for method sally\n",
      "22:22  Training model\n",
      "22:23    Epoch 2: train loss 15.94 ([15.93878818])\n",
      "22:24    Epoch 4: train loss 15.93 ([15.93113033])\n",
      "22:24    Epoch 6: train loss 15.93 ([15.92570057])\n",
      "22:25    Epoch 8: train loss 15.92 ([15.9192629])\n",
      "22:25    Epoch 10: train loss 15.91 ([15.91470512])\n",
      "22:26    Epoch 12: train loss 15.91 ([15.91048691])\n",
      "22:27    Epoch 14: train loss 15.91 ([15.90585397])\n",
      "22:27    Epoch 16: train loss 15.90 ([15.90183405])\n",
      "22:28    Epoch 18: train loss 15.90 ([15.89910213])\n",
      "22:29    Epoch 20: train loss 15.90 ([15.8980792])\n",
      "22:29  Finished training\n",
      "22:29  Training estimator 8 / 20 in ensemble\n",
      "22:29  Starting training\n",
      "22:29    Method:                 sally\n",
      "22:29    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "22:29                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "22:29    Features:               all\n",
      "22:29    Method:                 sally\n",
      "22:29    Hidden layers:          (100, 100)\n",
      "22:29    Activation function:    tanh\n",
      "22:29    Batch size:             128\n",
      "22:29    Epochs:                 20\n",
      "22:29    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:29    Validation split:       None\n",
      "22:29    Early stopping:         True\n",
      "22:29  Loading training data\n",
      "22:29  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:29  Creating model for method sally\n",
      "22:29  Training model\n",
      "22:29    Epoch 2: train loss 27.65 ([27.64729615])\n",
      "22:30    Epoch 4: train loss 27.64 ([27.63840953])\n",
      "22:31    Epoch 6: train loss 27.63 ([27.62767673])\n",
      "22:31    Epoch 8: train loss 27.62 ([27.62078021])\n",
      "22:32    Epoch 10: train loss 27.62 ([27.61571055])\n",
      "22:33    Epoch 12: train loss 27.61 ([27.61126418])\n",
      "22:33    Epoch 14: train loss 27.61 ([27.60513237])\n",
      "22:34    Epoch 16: train loss 27.60 ([27.6018656])\n",
      "22:35    Epoch 18: train loss 27.60 ([27.5959201])\n",
      "22:35    Epoch 20: train loss 27.59 ([27.59423068])\n",
      "22:35  Finished training\n",
      "22:35  Training estimator 9 / 20 in ensemble\n",
      "22:35  Starting training\n",
      "22:35    Method:                 sally\n",
      "22:35    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "22:35                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "22:35    Features:               all\n",
      "22:35    Method:                 sally\n",
      "22:35    Hidden layers:          (100, 100)\n",
      "22:35    Activation function:    tanh\n",
      "22:35    Batch size:             128\n",
      "22:35    Epochs:                 20\n",
      "22:35    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:35    Validation split:       None\n",
      "22:35    Early stopping:         True\n",
      "22:35  Loading training data\n",
      "22:35  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:35  Creating model for method sally\n",
      "22:35  Training model\n",
      "22:36    Epoch 2: train loss 21.01 ([21.01476139])\n",
      "22:37    Epoch 4: train loss 21.01 ([21.00945454])\n",
      "22:37    Epoch 6: train loss 21.00 ([20.99906929])\n",
      "22:38    Epoch 8: train loss 20.99 ([20.99290038])\n",
      "22:39    Epoch 10: train loss 20.99 ([20.98624045])\n",
      "22:39    Epoch 12: train loss 20.98 ([20.98329075])\n",
      "22:40    Epoch 14: train loss 20.98 ([20.97716671])\n",
      "22:41    Epoch 16: train loss 20.97 ([20.97349454])\n",
      "22:42    Epoch 18: train loss 20.97 ([20.97153204])\n",
      "22:42    Epoch 20: train loss 20.97 ([20.96931386])\n",
      "22:42  Finished training\n",
      "22:42  Training estimator 10 / 20 in ensemble\n",
      "22:42  Starting training\n",
      "22:42    Method:                 sally\n",
      "22:42    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "22:42                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "22:42    Features:               all\n",
      "22:42    Method:                 sally\n",
      "22:42    Hidden layers:          (100, 100)\n",
      "22:42    Activation function:    tanh\n",
      "22:42    Batch size:             128\n",
      "22:42    Epochs:                 20\n",
      "22:42    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:42    Validation split:       None\n",
      "22:42    Early stopping:         True\n",
      "22:42  Loading training data\n",
      "22:42  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:42  Creating model for method sally\n",
      "22:42  Training model\n",
      "22:43    Epoch 2: train loss 47.36 ([47.35907764])\n",
      "22:44    Epoch 4: train loss 47.35 ([47.35270826])\n",
      "22:44    Epoch 6: train loss 47.35 ([47.34677442])\n",
      "22:45    Epoch 8: train loss 47.34 ([47.33843559])\n",
      "22:46    Epoch 10: train loss 47.33 ([47.32933499])\n",
      "22:46    Epoch 12: train loss 47.33 ([47.32529957])\n",
      "22:47    Epoch 14: train loss 47.32 ([47.31763775])\n",
      "22:48    Epoch 16: train loss 47.32 ([47.31853758])\n",
      "22:48    Epoch 18: train loss 47.32 ([47.31596206])\n",
      "22:49    Epoch 20: train loss 47.31 ([47.31213108])\n",
      "22:49  Finished training\n",
      "22:49  Training estimator 11 / 20 in ensemble\n",
      "22:49  Starting training\n",
      "22:49    Method:                 sally\n",
      "22:49    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_10.npy\n",
      "22:49                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_10.npy\n",
      "22:49    Features:               all\n",
      "22:49    Method:                 sally\n",
      "22:49    Hidden layers:          (100, 100)\n",
      "22:49    Activation function:    tanh\n",
      "22:49    Batch size:             128\n",
      "22:49    Epochs:                 20\n",
      "22:49    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:49    Validation split:       None\n",
      "22:49    Early stopping:         True\n",
      "22:49  Loading training data\n",
      "22:49  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:49  Creating model for method sally\n",
      "22:49  Training model\n",
      "22:50    Epoch 2: train loss 17.00 ([17.00397915])\n",
      "22:50    Epoch 4: train loss 17.00 ([16.99605601])\n",
      "22:51    Epoch 6: train loss 16.98 ([16.98166286])\n",
      "22:52    Epoch 8: train loss 16.98 ([16.97726691])\n",
      "22:52    Epoch 10: train loss 16.97 ([16.97210476])\n",
      "22:53    Epoch 12: train loss 16.97 ([16.96779716])\n",
      "22:54    Epoch 14: train loss 16.96 ([16.96212219])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:54    Epoch 16: train loss 16.96 ([16.96042802])\n",
      "22:55    Epoch 18: train loss 16.96 ([16.95803412])\n",
      "22:56    Epoch 20: train loss 16.95 ([16.95380618])\n",
      "22:56  Finished training\n",
      "22:56  Training estimator 12 / 20 in ensemble\n",
      "22:56  Starting training\n",
      "22:56    Method:                 sally\n",
      "22:56    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_11.npy\n",
      "22:56                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_11.npy\n",
      "22:56    Features:               all\n",
      "22:56    Method:                 sally\n",
      "22:56    Hidden layers:          (100, 100)\n",
      "22:56    Activation function:    tanh\n",
      "22:56    Batch size:             128\n",
      "22:56    Epochs:                 20\n",
      "22:56    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "22:56    Validation split:       None\n",
      "22:56    Early stopping:         True\n",
      "22:56  Loading training data\n",
      "22:56  Found 1000000 samples with 2 parameters and 29 observables\n",
      "22:56  Creating model for method sally\n",
      "22:56  Training model\n",
      "22:57    Epoch 2: train loss 17.48 ([17.48494715])\n",
      "22:57    Epoch 4: train loss 17.48 ([17.47623745])\n",
      "22:58    Epoch 6: train loss 17.47 ([17.46808966])\n",
      "22:58    Epoch 8: train loss 17.46 ([17.46300834])\n",
      "22:59    Epoch 10: train loss 17.46 ([17.4567822])\n",
      "23:00    Epoch 12: train loss 17.45 ([17.45270383])\n",
      "23:00    Epoch 14: train loss 17.45 ([17.44694929])\n",
      "23:01    Epoch 16: train loss 17.44 ([17.44253658])\n",
      "23:02    Epoch 18: train loss 17.44 ([17.439902])\n",
      "23:02    Epoch 20: train loss 17.44 ([17.43621449])\n",
      "23:02  Finished training\n",
      "23:02  Training estimator 13 / 20 in ensemble\n",
      "23:02  Starting training\n",
      "23:02    Method:                 sally\n",
      "23:02    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_12.npy\n",
      "23:02                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_12.npy\n",
      "23:02    Features:               all\n",
      "23:02    Method:                 sally\n",
      "23:02    Hidden layers:          (100, 100)\n",
      "23:02    Activation function:    tanh\n",
      "23:02    Batch size:             128\n",
      "23:02    Epochs:                 20\n",
      "23:02    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:02    Validation split:       None\n",
      "23:02    Early stopping:         True\n",
      "23:02  Loading training data\n",
      "23:02  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:02  Creating model for method sally\n",
      "23:02  Training model\n",
      "23:03    Epoch 2: train loss 18.14 ([18.14216097])\n",
      "23:04    Epoch 4: train loss 18.13 ([18.13448695])\n",
      "23:04    Epoch 6: train loss 18.13 ([18.12568251])\n",
      "23:05    Epoch 8: train loss 18.12 ([18.11824526])\n",
      "23:06    Epoch 10: train loss 18.11 ([18.11374484])\n",
      "23:06    Epoch 12: train loss 18.11 ([18.11076554])\n",
      "23:07    Epoch 14: train loss 18.10 ([18.10466304])\n",
      "23:08    Epoch 16: train loss 18.10 ([18.10340984])\n",
      "23:08    Epoch 18: train loss 18.10 ([18.09742794])\n",
      "23:09    Epoch 20: train loss 18.09 ([18.09283413])\n",
      "23:09  Finished training\n",
      "23:09  Training estimator 14 / 20 in ensemble\n",
      "23:09  Starting training\n",
      "23:09    Method:                 sally\n",
      "23:09    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_13.npy\n",
      "23:09                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_13.npy\n",
      "23:09    Features:               all\n",
      "23:09    Method:                 sally\n",
      "23:09    Hidden layers:          (100, 100)\n",
      "23:09    Activation function:    tanh\n",
      "23:09    Batch size:             128\n",
      "23:09    Epochs:                 20\n",
      "23:09    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:09    Validation split:       None\n",
      "23:09    Early stopping:         True\n",
      "23:09  Loading training data\n",
      "23:09  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:09  Creating model for method sally\n",
      "23:09  Training model\n",
      "23:10    Epoch 2: train loss 12.51 ([12.5085008])\n",
      "23:11    Epoch 4: train loss 12.50 ([12.50119754])\n",
      "23:11    Epoch 6: train loss 12.49 ([12.49484698])\n",
      "23:12    Epoch 8: train loss 12.49 ([12.49017936])\n",
      "23:12    Epoch 10: train loss 12.48 ([12.48493602])\n",
      "23:13    Epoch 12: train loss 12.48 ([12.47921251])\n",
      "23:14    Epoch 14: train loss 12.48 ([12.47538279])\n",
      "23:14    Epoch 16: train loss 12.47 ([12.47139209])\n",
      "23:15    Epoch 18: train loss 12.47 ([12.46701817])\n",
      "23:16    Epoch 20: train loss 12.46 ([12.46413422])\n",
      "23:16  Finished training\n",
      "23:16  Training estimator 15 / 20 in ensemble\n",
      "23:16  Starting training\n",
      "23:16    Method:                 sally\n",
      "23:16    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_14.npy\n",
      "23:16                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_14.npy\n",
      "23:16    Features:               all\n",
      "23:16    Method:                 sally\n",
      "23:16    Hidden layers:          (100, 100)\n",
      "23:16    Activation function:    tanh\n",
      "23:16    Batch size:             128\n",
      "23:16    Epochs:                 20\n",
      "23:16    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:16    Validation split:       None\n",
      "23:16    Early stopping:         True\n",
      "23:16  Loading training data\n",
      "23:16  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:16  Creating model for method sally\n",
      "23:16  Training model\n",
      "23:17    Epoch 2: train loss 22.64 ([22.63780624])\n",
      "23:17    Epoch 4: train loss 22.63 ([22.63117791])\n",
      "23:18    Epoch 6: train loss 22.62 ([22.6208167])\n",
      "23:18    Epoch 8: train loss 22.62 ([22.61677926])\n",
      "23:19    Epoch 10: train loss 22.61 ([22.60961901])\n",
      "23:20    Epoch 12: train loss 22.61 ([22.60645756])\n",
      "23:20    Epoch 14: train loss 22.60 ([22.60191437])\n",
      "23:21    Epoch 16: train loss 22.60 ([22.59755003])\n",
      "23:22    Epoch 18: train loss 22.59 ([22.59331884])\n",
      "23:22    Epoch 20: train loss 22.59 ([22.58849063])\n",
      "23:22  Finished training\n",
      "23:22  Training estimator 16 / 20 in ensemble\n",
      "23:22  Starting training\n",
      "23:22    Method:                 sally\n",
      "23:22    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_15.npy\n",
      "23:22                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_15.npy\n",
      "23:22    Features:               all\n",
      "23:22    Method:                 sally\n",
      "23:22    Hidden layers:          (100, 100)\n",
      "23:22    Activation function:    tanh\n",
      "23:22    Batch size:             128\n",
      "23:22    Epochs:                 20\n",
      "23:22    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:22    Validation split:       None\n",
      "23:22    Early stopping:         True\n",
      "23:22  Loading training data\n",
      "23:22  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:22  Creating model for method sally\n",
      "23:22  Training model\n",
      "23:23    Epoch 2: train loss 15.57 ([15.57323211])\n",
      "23:24    Epoch 4: train loss 15.56 ([15.56477186])\n",
      "23:24    Epoch 6: train loss 15.56 ([15.55840452])\n",
      "23:25    Epoch 8: train loss 15.55 ([15.5523735])\n",
      "23:26    Epoch 10: train loss 15.55 ([15.54697476])\n",
      "23:26    Epoch 12: train loss 15.54 ([15.54328647])\n",
      "23:27    Epoch 14: train loss 15.54 ([15.53905627])\n",
      "23:28    Epoch 16: train loss 15.54 ([15.53993294])\n",
      "23:28    Epoch 18: train loss 15.53 ([15.53320473])\n",
      "23:29    Epoch 20: train loss 15.53 ([15.53119835])\n",
      "23:29  Finished training\n",
      "23:29  Training estimator 17 / 20 in ensemble\n",
      "23:29  Starting training\n",
      "23:29    Method:                 sally\n",
      "23:29    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_16.npy\n",
      "23:29                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_16.npy\n",
      "23:29    Features:               all\n",
      "23:29    Method:                 sally\n",
      "23:29    Hidden layers:          (100, 100)\n",
      "23:29    Activation function:    tanh\n",
      "23:29    Batch size:             128\n",
      "23:29    Epochs:                 20\n",
      "23:29    Learning rate:          0.002 initially, decaying to 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29    Validation split:       None\n",
      "23:29    Early stopping:         True\n",
      "23:29  Loading training data\n",
      "23:29  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:29  Creating model for method sally\n",
      "23:29  Training model\n",
      "23:30    Epoch 2: train loss 17.45 ([17.45280555])\n",
      "23:31    Epoch 4: train loss 17.44 ([17.44440517])\n",
      "23:31    Epoch 6: train loss 17.44 ([17.43552967])\n",
      "23:32    Epoch 8: train loss 17.43 ([17.42725864])\n",
      "23:33    Epoch 10: train loss 17.42 ([17.42293276])\n",
      "23:33    Epoch 12: train loss 17.42 ([17.41857858])\n",
      "23:34    Epoch 14: train loss 17.41 ([17.41264606])\n",
      "23:35    Epoch 16: train loss 17.43 ([17.42605152])\n",
      "23:35    Epoch 18: train loss 17.41 ([17.40529531])\n",
      "23:36    Epoch 20: train loss 17.40 ([17.40176731])\n",
      "23:36  Finished training\n",
      "23:36  Training estimator 18 / 20 in ensemble\n",
      "23:36  Starting training\n",
      "23:36    Method:                 sally\n",
      "23:36    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_17.npy\n",
      "23:36                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_17.npy\n",
      "23:36    Features:               all\n",
      "23:36    Method:                 sally\n",
      "23:36    Hidden layers:          (100, 100)\n",
      "23:36    Activation function:    tanh\n",
      "23:36    Batch size:             128\n",
      "23:36    Epochs:                 20\n",
      "23:36    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:36    Validation split:       None\n",
      "23:36    Early stopping:         True\n",
      "23:36  Loading training data\n",
      "23:36  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:36  Creating model for method sally\n",
      "23:36  Training model\n",
      "23:37    Epoch 2: train loss 18.11 ([18.1131668])\n",
      "23:37    Epoch 4: train loss 18.09 ([18.09193689])\n",
      "23:38    Epoch 6: train loss 18.09 ([18.08699616])\n",
      "23:39    Epoch 8: train loss 18.08 ([18.07854742])\n",
      "23:39    Epoch 10: train loss 18.07 ([18.07437644])\n",
      "23:40    Epoch 12: train loss 18.07 ([18.06891618])\n",
      "23:41    Epoch 14: train loss 18.06 ([18.06462356])\n",
      "23:41    Epoch 16: train loss 18.06 ([18.06258479])\n",
      "23:42    Epoch 18: train loss 18.06 ([18.05788503])\n",
      "23:43    Epoch 20: train loss 18.05 ([18.05423959])\n",
      "23:43  Finished training\n",
      "23:43  Training estimator 19 / 20 in ensemble\n",
      "23:43  Starting training\n",
      "23:43    Method:                 sally\n",
      "23:43    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_18.npy\n",
      "23:43                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_18.npy\n",
      "23:43    Features:               all\n",
      "23:43    Method:                 sally\n",
      "23:43    Hidden layers:          (100, 100)\n",
      "23:43    Activation function:    tanh\n",
      "23:43    Batch size:             128\n",
      "23:43    Epochs:                 20\n",
      "23:43    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:43    Validation split:       None\n",
      "23:43    Early stopping:         True\n",
      "23:43  Loading training data\n",
      "23:43  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:43  Creating model for method sally\n",
      "23:43  Training model\n",
      "23:43    Epoch 2: train loss 44.30 ([44.29977437])\n",
      "23:44    Epoch 4: train loss 44.29 ([44.28929589])\n",
      "23:45    Epoch 6: train loss 44.30 ([44.300526])\n",
      "23:45    Epoch 8: train loss 44.28 ([44.27665384])\n",
      "23:46    Epoch 10: train loss 44.28 ([44.27518881])\n",
      "23:47    Epoch 12: train loss 44.27 ([44.26592058])\n",
      "23:47    Epoch 14: train loss 44.26 ([44.26206125])\n",
      "23:48    Epoch 16: train loss 44.26 ([44.25523219])\n",
      "23:49    Epoch 18: train loss 44.25 ([44.25168483])\n",
      "23:49    Epoch 20: train loss 44.25 ([44.25069816])\n",
      "23:49  Finished training\n",
      "23:49  Training estimator 20 / 20 in ensemble\n",
      "23:49  Starting training\n",
      "23:49    Method:                 sally\n",
      "23:49    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_19.npy\n",
      "23:49                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_19.npy\n",
      "23:49    Features:               all\n",
      "23:49    Method:                 sally\n",
      "23:49    Hidden layers:          (100, 100)\n",
      "23:49    Activation function:    tanh\n",
      "23:49    Batch size:             128\n",
      "23:49    Epochs:                 20\n",
      "23:49    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:49    Validation split:       None\n",
      "23:49    Early stopping:         True\n",
      "23:49  Loading training data\n",
      "23:49  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:49  Creating model for method sally\n",
      "23:49  Training model\n",
      "23:50    Epoch 2: train loss 15.79 ([15.78828895])\n",
      "23:51    Epoch 4: train loss 15.78 ([15.7801021])\n",
      "23:51    Epoch 6: train loss 15.77 ([15.77288242])\n",
      "23:52    Epoch 8: train loss 15.77 ([15.7678721])\n",
      "23:53    Epoch 10: train loss 15.76 ([15.7630499])\n",
      "23:53    Epoch 12: train loss 15.76 ([15.7574686])\n",
      "23:54    Epoch 14: train loss 15.75 ([15.75453064])\n",
      "23:55    Epoch 16: train loss 15.75 ([15.74885321])\n",
      "23:55    Epoch 18: train loss 15.75 ([15.74539614])\n",
      "23:56    Epoch 20: train loss 15.74 ([15.74296019])\n",
      "23:56  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble_all = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_all.train_all(\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "add9d876-2e73-4578-8d43-722df0c790d5"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:56  Calculating expectation for 20 estimators in ensemble\n",
      "23:56  Starting evaluation for estimator 1 / 20 in ensemble\n",
      "23:56  Loading evaluation data\n",
      "23:56  Starting score evaluation\n",
      "23:56  Starting evaluation for estimator 2 / 20 in ensemble\n",
      "23:56  Loading evaluation data\n",
      "23:56  Starting score evaluation\n",
      "23:56  Starting evaluation for estimator 3 / 20 in ensemble\n",
      "23:56  Loading evaluation data\n",
      "23:56  Starting score evaluation\n",
      "23:57  Starting evaluation for estimator 4 / 20 in ensemble\n",
      "23:57  Loading evaluation data\n",
      "23:57  Starting score evaluation\n",
      "23:57  Starting evaluation for estimator 5 / 20 in ensemble\n",
      "23:57  Loading evaluation data\n",
      "23:57  Starting score evaluation\n",
      "23:57  Starting evaluation for estimator 6 / 20 in ensemble\n",
      "23:57  Loading evaluation data\n",
      "23:57  Starting score evaluation\n",
      "23:57  Starting evaluation for estimator 7 / 20 in ensemble\n",
      "23:57  Loading evaluation data\n",
      "23:57  Starting score evaluation\n",
      "23:57  Starting evaluation for estimator 8 / 20 in ensemble\n",
      "23:57  Loading evaluation data\n",
      "23:57  Starting score evaluation\n",
      "23:57  Starting evaluation for estimator 9 / 20 in ensemble\n",
      "23:57  Loading evaluation data\n",
      "23:57  Starting score evaluation\n",
      "23:58  Starting evaluation for estimator 10 / 20 in ensemble\n",
      "23:58  Loading evaluation data\n",
      "23:58  Starting score evaluation\n",
      "23:58  Starting evaluation for estimator 11 / 20 in ensemble\n",
      "23:58  Loading evaluation data\n",
      "23:58  Starting score evaluation\n",
      "23:58  Starting evaluation for estimator 12 / 20 in ensemble\n",
      "23:58  Loading evaluation data\n",
      "23:58  Starting score evaluation\n",
      "23:58  Starting evaluation for estimator 13 / 20 in ensemble\n",
      "23:58  Loading evaluation data\n",
      "23:58  Starting score evaluation\n",
      "23:58  Starting evaluation for estimator 14 / 20 in ensemble\n",
      "23:58  Loading evaluation data\n",
      "23:58  Starting score evaluation\n",
      "23:58  Starting evaluation for estimator 15 / 20 in ensemble\n",
      "23:58  Loading evaluation data\n",
      "23:58  Starting score evaluation\n",
      "23:58  Starting evaluation for estimator 16 / 20 in ensemble\n",
      "23:58  Loading evaluation data\n",
      "23:59  Starting score evaluation\n",
      "23:59  Starting evaluation for estimator 17 / 20 in ensemble\n",
      "23:59  Loading evaluation data\n",
      "23:59  Starting score evaluation\n",
      "23:59  Starting evaluation for estimator 18 / 20 in ensemble\n",
      "23:59  Loading evaluation data\n",
      "23:59  Starting score evaluation\n",
      "23:59  Starting evaluation for estimator 19 / 20 in ensemble\n",
      "23:59  Loading evaluation data\n",
      "23:59  Starting score evaluation\n",
      "23:59  Starting evaluation for estimator 20 / 20 in ensemble\n",
      "23:59  Loading evaluation data\n",
      "23:59  Starting score evaluation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.01433866, -0.00798974],\n",
       "       [-0.04412725,  0.02471908],\n",
       "       [-0.06542948,  0.0835643 ],\n",
       "       [-0.02332889, -0.00558355],\n",
       "       [ 0.02657468,  0.0145047 ],\n",
       "       [ 0.11239411, -0.03549213],\n",
       "       [ 0.00559056, -0.00027227],\n",
       "       [-0.07079547,  0.10741747],\n",
       "       [-0.00762126,  0.01911212],\n",
       "       [ 0.00617709,  0.01502894],\n",
       "       [ 0.00371833, -0.03548462],\n",
       "       [ 0.01541766, -0.01456542],\n",
       "       [ 0.06796021,  0.00998996],\n",
       "       [ 0.02345792, -0.02461899],\n",
       "       [-0.00599976,  0.01418786],\n",
       "       [ 0.01237708, -0.0282448 ],\n",
       "       [-0.02025609,  0.01516213],\n",
       "       [-0.00509163,  0.00717454],\n",
       "       [ 0.00775625, -0.04099903],\n",
       "       [-0.02500463, -0.03304806]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_all.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "be8f7de9-1057-4b69-990f-b80f8752be24"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:59  Saving ensemble setup to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/ensemble.json\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_0_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_0_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_1_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_1_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_2_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_2_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_3_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_3_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_4_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_4_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_5_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_5_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_6_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_6_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_7_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_7_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_8_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_8_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_9_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_9_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_10_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_10_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_11_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_11_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_12_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_12_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_13_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_13_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_14_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_14_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_15_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_15_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_16_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_16_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_17_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_17_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_18_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_18_state_dict.pt\n",
      "23:59  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_19_settings.json\n",
      "23:59  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all/estimator_19_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "ensemble_all.save(model_dir + 'sally_ensemble_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ede24e6c-05b8-4c8f-9a32-fd890e75873a"
    }
   },
   "source": [
    "## 1d toy study (delta phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "c43f5a5b-fc70-4c69-b4c6-4d64dc7eba29"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:59  Training 20 estimators in ensemble\n",
      "23:59  Training estimator 1 / 20 in ensemble\n",
      "23:59  Starting training\n",
      "23:59    Method:                 sally\n",
      "23:59    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "23:59                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "23:59    Features:               [20]\n",
      "23:59    Method:                 sally\n",
      "23:59    Hidden layers:          (100, 100)\n",
      "23:59    Activation function:    tanh\n",
      "23:59    Batch size:             128\n",
      "23:59    Epochs:                 20\n",
      "23:59    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "23:59    Validation split:       None\n",
      "23:59    Early stopping:         True\n",
      "23:59  Loading training data\n",
      "23:59  Found 1000000 samples with 2 parameters and 29 observables\n",
      "23:59  Only using 1 of 29 observables\n",
      "23:59  Creating model for method sally\n",
      "23:59  Training model\n",
      "00:00    Epoch 2: train loss 18.53 ([18.53116525])\n",
      "00:01    Epoch 4: train loss 18.53 ([18.52501775])\n",
      "00:01    Epoch 6: train loss 18.52 ([18.52420072])\n",
      "00:02    Epoch 8: train loss 18.52 ([18.52275387])\n",
      "00:03    Epoch 10: train loss 18.52 ([18.52155758])\n",
      "00:03    Epoch 12: train loss 18.52 ([18.52197478])\n",
      "00:04    Epoch 14: train loss 18.52 ([18.52087975])\n",
      "00:04    Epoch 16: train loss 18.52 ([18.52101896])\n",
      "00:05    Epoch 18: train loss 18.52 ([18.52048455])\n",
      "00:05    Epoch 20: train loss 18.52 ([18.5205545])\n",
      "00:05  Finished training\n",
      "00:05  Training estimator 2 / 20 in ensemble\n",
      "00:05  Starting training\n",
      "00:05    Method:                 sally\n",
      "00:05    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "00:05                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "00:05    Features:               [20]\n",
      "00:05    Method:                 sally\n",
      "00:05    Hidden layers:          (100, 100)\n",
      "00:05    Activation function:    tanh\n",
      "00:05    Batch size:             128\n",
      "00:05    Epochs:                 20\n",
      "00:05    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:05    Validation split:       None\n",
      "00:05    Early stopping:         True\n",
      "00:05  Loading training data\n",
      "00:05  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:05  Only using 1 of 29 observables\n",
      "00:05  Creating model for method sally\n",
      "00:05  Training model\n",
      "00:06    Epoch 2: train loss 15.96 ([15.95518416])\n",
      "00:07    Epoch 4: train loss 15.95 ([15.95460588])\n",
      "00:07    Epoch 6: train loss 15.95 ([15.95423545])\n",
      "00:08    Epoch 8: train loss 15.96 ([15.95506164])\n",
      "00:08    Epoch 10: train loss 15.95 ([15.95380211])\n",
      "00:09    Epoch 12: train loss 15.95 ([15.95398711])\n",
      "00:10    Epoch 14: train loss 15.95 ([15.95386588])\n",
      "00:10    Epoch 16: train loss 15.95 ([15.95381451])\n",
      "00:11    Epoch 18: train loss 15.95 ([15.9536025])\n",
      "00:11    Epoch 20: train loss 15.95 ([15.95361918])\n",
      "00:11  Finished training\n",
      "00:11  Training estimator 3 / 20 in ensemble\n",
      "00:11  Starting training\n",
      "00:11    Method:                 sally\n",
      "00:11    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "00:11                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "00:11    Features:               [20]\n",
      "00:11    Method:                 sally\n",
      "00:11    Hidden layers:          (100, 100)\n",
      "00:11    Activation function:    tanh\n",
      "00:11    Batch size:             128\n",
      "00:11    Epochs:                 20\n",
      "00:11    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:11    Validation split:       None\n",
      "00:11    Early stopping:         True\n",
      "00:11  Loading training data\n",
      "00:11  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:11  Only using 1 of 29 observables\n",
      "00:11  Creating model for method sally\n",
      "00:11  Training model\n",
      "00:12    Epoch 2: train loss 53.49 ([53.48723374])\n",
      "00:13    Epoch 4: train loss 53.49 ([53.48758101])\n",
      "00:13    Epoch 6: train loss 53.48 ([53.48105027])\n",
      "00:14    Epoch 8: train loss 53.47 ([53.47314554])\n",
      "00:14    Epoch 10: train loss 53.47 ([53.47112789])\n",
      "00:15    Epoch 12: train loss 53.47 ([53.46847444])\n",
      "00:16    Epoch 14: train loss 53.47 ([53.46959862])\n",
      "00:16    Epoch 16: train loss 53.47 ([53.46562604])\n",
      "00:17    Epoch 18: train loss 53.46 ([53.46410091])\n",
      "00:17    Epoch 20: train loss 53.46 ([53.46313132])\n",
      "00:17  Finished training\n",
      "00:17  Training estimator 4 / 20 in ensemble\n",
      "00:17  Starting training\n",
      "00:17    Method:                 sally\n",
      "00:17    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "00:17                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "00:17    Features:               [20]\n",
      "00:17    Method:                 sally\n",
      "00:17    Hidden layers:          (100, 100)\n",
      "00:17    Activation function:    tanh\n",
      "00:17    Batch size:             128\n",
      "00:17    Epochs:                 20\n",
      "00:17    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:17    Validation split:       None\n",
      "00:17    Early stopping:         True\n",
      "00:17  Loading training data\n",
      "00:17  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:17  Only using 1 of 29 observables\n",
      "00:17  Creating model for method sally\n",
      "00:17  Training model\n",
      "00:18    Epoch 2: train loss 27.76 ([27.76236253])\n",
      "00:19    Epoch 4: train loss 27.76 ([27.76071841])\n",
      "00:19    Epoch 6: train loss 27.76 ([27.75552098])\n",
      "00:20    Epoch 8: train loss 27.75 ([27.75075157])\n",
      "00:20    Epoch 10: train loss 27.75 ([27.74740176])\n",
      "00:21    Epoch 12: train loss 27.75 ([27.74587898])\n",
      "00:21    Epoch 14: train loss 27.74 ([27.74390567])\n",
      "00:22    Epoch 16: train loss 27.74 ([27.7431447])\n",
      "00:23    Epoch 18: train loss 27.74 ([27.74206585])\n",
      "00:23    Epoch 20: train loss 27.74 ([27.74080825])\n",
      "00:23  Finished training\n",
      "00:23  Training estimator 5 / 20 in ensemble\n",
      "00:23  Starting training\n",
      "00:23    Method:                 sally\n",
      "00:23    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "00:23                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "00:23    Features:               [20]\n",
      "00:23    Method:                 sally\n",
      "00:23    Hidden layers:          (100, 100)\n",
      "00:23    Activation function:    tanh\n",
      "00:23    Batch size:             128\n",
      "00:23    Epochs:                 20\n",
      "00:23    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:23    Validation split:       None\n",
      "00:23    Early stopping:         True\n",
      "00:23  Loading training data\n",
      "00:23  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:23  Only using 1 of 29 observables\n",
      "00:23  Creating model for method sally\n",
      "00:23  Training model\n",
      "00:24    Epoch 2: train loss 17.96 ([17.96492218])\n",
      "00:25    Epoch 4: train loss 17.95 ([17.95150186])\n",
      "00:25    Epoch 6: train loss 17.96 ([17.96148812])\n",
      "00:26    Epoch 8: train loss 17.95 ([17.94979456])\n",
      "00:26    Epoch 10: train loss 17.95 ([17.94966713])\n",
      "00:27    Epoch 12: train loss 17.95 ([17.94930806])\n",
      "00:27    Epoch 14: train loss 17.95 ([17.9494573])\n",
      "00:28    Epoch 16: train loss 17.95 ([17.94914624])\n",
      "00:29    Epoch 18: train loss 17.95 ([17.94895465])\n",
      "00:29    Epoch 20: train loss 17.95 ([17.94966475])\n",
      "00:29  Finished training\n",
      "00:29  Training estimator 6 / 20 in ensemble\n",
      "00:29  Starting training\n",
      "00:29    Method:                 sally\n",
      "00:29    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n",
      "00:29                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n",
      "00:29    Features:               [20]\n",
      "00:29    Method:                 sally\n",
      "00:29    Hidden layers:          (100, 100)\n",
      "00:29    Activation function:    tanh\n",
      "00:29    Batch size:             128\n",
      "00:29    Epochs:                 20\n",
      "00:29    Learning rate:          0.002 initially, decaying to 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:29    Validation split:       None\n",
      "00:29    Early stopping:         True\n",
      "00:29  Loading training data\n",
      "00:29  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:29  Only using 1 of 29 observables\n",
      "00:29  Creating model for method sally\n",
      "00:29  Training model\n",
      "00:30    Epoch 2: train loss 21.21 ([21.20873806])\n",
      "00:31    Epoch 4: train loss 21.20 ([21.20120494])\n",
      "00:31    Epoch 6: train loss 21.19 ([21.19467101])\n",
      "00:32    Epoch 8: train loss 21.19 ([21.19351106])\n",
      "00:32    Epoch 10: train loss 21.19 ([21.19176383])\n",
      "00:33    Epoch 12: train loss 21.19 ([21.19122556])\n",
      "00:33    Epoch 14: train loss 21.19 ([21.18980352])\n",
      "00:34    Epoch 16: train loss 21.19 ([21.18935256])\n",
      "00:35    Epoch 18: train loss 21.19 ([21.18934567])\n",
      "00:35    Epoch 20: train loss 21.19 ([21.18909334])\n",
      "00:35  Finished training\n",
      "00:35  Training estimator 7 / 20 in ensemble\n",
      "00:35  Starting training\n",
      "00:35    Method:                 sally\n",
      "00:35    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "00:35                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "00:35    Features:               [20]\n",
      "00:35    Method:                 sally\n",
      "00:35    Hidden layers:          (100, 100)\n",
      "00:35    Activation function:    tanh\n",
      "00:35    Batch size:             128\n",
      "00:35    Epochs:                 20\n",
      "00:35    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:35    Validation split:       None\n",
      "00:35    Early stopping:         True\n",
      "00:35  Loading training data\n",
      "00:35  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:35  Only using 1 of 29 observables\n",
      "00:35  Creating model for method sally\n",
      "00:35  Training model\n",
      "00:36    Epoch 2: train loss 15.93 ([15.92743416])\n",
      "00:36    Epoch 4: train loss 15.92 ([15.92141564])\n",
      "00:37    Epoch 6: train loss 15.92 ([15.9194445])\n",
      "00:38    Epoch 8: train loss 15.92 ([15.91884629])\n",
      "00:38    Epoch 10: train loss 15.92 ([15.91842145])\n",
      "00:39    Epoch 12: train loss 15.92 ([15.91824599])\n",
      "00:39    Epoch 14: train loss 15.92 ([15.91790298])\n",
      "00:40    Epoch 16: train loss 15.92 ([15.9176102])\n",
      "00:40    Epoch 18: train loss 15.92 ([15.91761499])\n",
      "00:41    Epoch 20: train loss 15.92 ([15.91746784])\n",
      "00:41  Finished training\n",
      "00:41  Training estimator 8 / 20 in ensemble\n",
      "00:41  Starting training\n",
      "00:41    Method:                 sally\n",
      "00:41    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "00:41                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "00:41    Features:               [20]\n",
      "00:41    Method:                 sally\n",
      "00:41    Hidden layers:          (100, 100)\n",
      "00:41    Activation function:    tanh\n",
      "00:41    Batch size:             128\n",
      "00:41    Epochs:                 20\n",
      "00:41    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:41    Validation split:       None\n",
      "00:41    Early stopping:         True\n",
      "00:41  Loading training data\n",
      "00:41  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:41  Only using 1 of 29 observables\n",
      "00:41  Creating model for method sally\n",
      "00:41  Training model\n",
      "00:42    Epoch 2: train loss 27.64 ([27.64439145])\n",
      "00:42    Epoch 4: train loss 27.64 ([27.63735373])\n",
      "00:43    Epoch 6: train loss 27.63 ([27.63283289])\n",
      "00:44    Epoch 8: train loss 27.63 ([27.62595885])\n",
      "00:44    Epoch 10: train loss 27.62 ([27.623762])\n",
      "00:45    Epoch 12: train loss 27.62 ([27.62206022])\n",
      "00:45    Epoch 14: train loss 27.62 ([27.62146678])\n",
      "00:46    Epoch 16: train loss 27.63 ([27.63021678])\n",
      "00:46    Epoch 18: train loss 27.62 ([27.62232256])\n",
      "00:47    Epoch 20: train loss 27.62 ([27.62031952])\n",
      "00:47  Finished training\n",
      "00:47  Training estimator 9 / 20 in ensemble\n",
      "00:47  Starting training\n",
      "00:47    Method:                 sally\n",
      "00:47    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "00:47                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "00:47    Features:               [20]\n",
      "00:47    Method:                 sally\n",
      "00:47    Hidden layers:          (100, 100)\n",
      "00:47    Activation function:    tanh\n",
      "00:47    Batch size:             128\n",
      "00:47    Epochs:                 20\n",
      "00:47    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:47    Validation split:       None\n",
      "00:47    Early stopping:         True\n",
      "00:47  Loading training data\n",
      "00:47  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:47  Only using 1 of 29 observables\n",
      "00:47  Creating model for method sally\n",
      "00:47  Training model\n",
      "00:48    Epoch 2: train loss 21.02 ([21.01687632])\n",
      "00:48    Epoch 4: train loss 21.00 ([20.99953164])\n",
      "00:49    Epoch 6: train loss 20.99 ([20.99495819])\n",
      "00:49    Epoch 8: train loss 21.00 ([20.99508813])\n",
      "00:50    Epoch 10: train loss 21.00 ([20.99534097])\n",
      "00:51    Epoch 12: train loss 21.00 ([20.9952548])\n",
      "00:51    Epoch 14: train loss 20.99 ([20.99467621])\n",
      "00:52    Epoch 16: train loss 20.99 ([20.99468009])\n",
      "00:52    Epoch 18: train loss 20.99 ([20.9944837])\n",
      "00:53    Epoch 20: train loss 20.99 ([20.99448287])\n",
      "00:53  Finished training\n",
      "00:53  Training estimator 10 / 20 in ensemble\n",
      "00:53  Starting training\n",
      "00:53    Method:                 sally\n",
      "00:53    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "00:53                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "00:53    Features:               [20]\n",
      "00:53    Method:                 sally\n",
      "00:53    Hidden layers:          (100, 100)\n",
      "00:53    Activation function:    tanh\n",
      "00:53    Batch size:             128\n",
      "00:53    Epochs:                 20\n",
      "00:53    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:53    Validation split:       None\n",
      "00:53    Early stopping:         True\n",
      "00:53  Loading training data\n",
      "00:53  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:53  Only using 1 of 29 observables\n",
      "00:53  Creating model for method sally\n",
      "00:53  Training model\n",
      "00:54    Epoch 2: train loss 47.36 ([47.35638501])\n",
      "00:54    Epoch 4: train loss 47.35 ([47.34555437])\n",
      "00:55    Epoch 6: train loss 47.34 ([47.3431456])\n",
      "00:55    Epoch 8: train loss 47.34 ([47.3409281])\n",
      "00:56    Epoch 10: train loss 47.34 ([47.33997278])\n",
      "00:57    Epoch 12: train loss 47.34 ([47.33905047])\n",
      "00:57    Epoch 14: train loss 47.34 ([47.33892851])\n",
      "00:58    Epoch 16: train loss 47.34 ([47.33854158])\n",
      "00:58    Epoch 18: train loss 47.34 ([47.33839984])\n",
      "00:59    Epoch 20: train loss 47.34 ([47.33811409])\n",
      "00:59  Finished training\n",
      "00:59  Training estimator 11 / 20 in ensemble\n",
      "00:59  Starting training\n",
      "00:59    Method:                 sally\n",
      "00:59    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_10.npy\n",
      "00:59                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_10.npy\n",
      "00:59    Features:               [20]\n",
      "00:59    Method:                 sally\n",
      "00:59    Hidden layers:          (100, 100)\n",
      "00:59    Activation function:    tanh\n",
      "00:59    Batch size:             128\n",
      "00:59    Epochs:                 20\n",
      "00:59    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "00:59    Validation split:       None\n",
      "00:59    Early stopping:         True\n",
      "00:59  Loading training data\n",
      "00:59  Found 1000000 samples with 2 parameters and 29 observables\n",
      "00:59  Only using 1 of 29 observables\n",
      "00:59  Creating model for method sally\n",
      "00:59  Training model\n",
      "01:00    Epoch 2: train loss 16.99 ([16.98752939])\n",
      "01:00    Epoch 4: train loss 16.98 ([16.98223565])\n",
      "01:01    Epoch 6: train loss 16.98 ([16.97966992])\n",
      "01:01    Epoch 8: train loss 16.98 ([16.97868289])\n",
      "01:02    Epoch 10: train loss 16.98 ([16.97811449])\n",
      "01:03    Epoch 12: train loss 16.98 ([16.97749578])\n",
      "01:03    Epoch 14: train loss 16.98 ([16.97731455])\n",
      "01:04    Epoch 16: train loss 16.98 ([16.97704964])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:04    Epoch 18: train loss 16.98 ([16.97736391])\n",
      "01:05    Epoch 20: train loss 16.98 ([16.97683994])\n",
      "01:05  Finished training\n",
      "01:05  Training estimator 12 / 20 in ensemble\n",
      "01:05  Starting training\n",
      "01:05    Method:                 sally\n",
      "01:05    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_11.npy\n",
      "01:05                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_11.npy\n",
      "01:05    Features:               [20]\n",
      "01:05    Method:                 sally\n",
      "01:05    Hidden layers:          (100, 100)\n",
      "01:05    Activation function:    tanh\n",
      "01:05    Batch size:             128\n",
      "01:05    Epochs:                 20\n",
      "01:05    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:05    Validation split:       None\n",
      "01:05    Early stopping:         True\n",
      "01:05  Loading training data\n",
      "01:05  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:05  Only using 1 of 29 observables\n",
      "01:05  Creating model for method sally\n",
      "01:05  Training model\n",
      "01:06    Epoch 2: train loss 17.48 ([17.47726915])\n",
      "01:06    Epoch 4: train loss 17.47 ([17.47314735])\n",
      "01:07    Epoch 6: train loss 17.47 ([17.4681754])\n",
      "01:07    Epoch 8: train loss 17.47 ([17.46537085])\n",
      "01:08    Epoch 10: train loss 17.46 ([17.46465068])\n",
      "01:08    Epoch 12: train loss 17.46 ([17.463889])\n",
      "01:09    Epoch 14: train loss 17.46 ([17.46344164])\n",
      "01:10    Epoch 16: train loss 17.46 ([17.46294422])\n",
      "01:10    Epoch 18: train loss 17.47 ([17.46595074])\n",
      "01:11    Epoch 20: train loss 17.46 ([17.46386202])\n",
      "01:11  Finished training\n",
      "01:11  Training estimator 13 / 20 in ensemble\n",
      "01:11  Starting training\n",
      "01:11    Method:                 sally\n",
      "01:11    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_12.npy\n",
      "01:11                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_12.npy\n",
      "01:11    Features:               [20]\n",
      "01:11    Method:                 sally\n",
      "01:11    Hidden layers:          (100, 100)\n",
      "01:11    Activation function:    tanh\n",
      "01:11    Batch size:             128\n",
      "01:11    Epochs:                 20\n",
      "01:11    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:11    Validation split:       None\n",
      "01:11    Early stopping:         True\n",
      "01:11  Loading training data\n",
      "01:11  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:11  Only using 1 of 29 observables\n",
      "01:11  Creating model for method sally\n",
      "01:11  Training model\n",
      "01:12    Epoch 2: train loss 18.13 ([18.1344122])\n",
      "01:12    Epoch 4: train loss 18.13 ([18.12675121])\n",
      "01:13    Epoch 6: train loss 18.12 ([18.12491839])\n",
      "01:13    Epoch 8: train loss 18.13 ([18.12649202])\n",
      "01:14    Epoch 10: train loss 18.12 ([18.12419583])\n",
      "01:14    Epoch 12: train loss 18.12 ([18.12406296])\n",
      "01:15    Epoch 14: train loss 18.12 ([18.12393017])\n",
      "01:16    Epoch 16: train loss 18.12 ([18.12372436])\n",
      "01:16    Epoch 18: train loss 18.12 ([18.12357993])\n",
      "01:17    Epoch 20: train loss 18.12 ([18.12363781])\n",
      "01:17  Finished training\n",
      "01:17  Training estimator 14 / 20 in ensemble\n",
      "01:17  Starting training\n",
      "01:17    Method:                 sally\n",
      "01:17    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_13.npy\n",
      "01:17                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_13.npy\n",
      "01:17    Features:               [20]\n",
      "01:17    Method:                 sally\n",
      "01:17    Hidden layers:          (100, 100)\n",
      "01:17    Activation function:    tanh\n",
      "01:17    Batch size:             128\n",
      "01:17    Epochs:                 20\n",
      "01:17    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:17    Validation split:       None\n",
      "01:17    Early stopping:         True\n",
      "01:17  Loading training data\n",
      "01:17  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:17  Only using 1 of 29 observables\n",
      "01:17  Creating model for method sally\n",
      "01:17  Training model\n",
      "01:17    Epoch 2: train loss 12.49 ([12.49454145])\n",
      "01:18    Epoch 4: train loss 12.49 ([12.49352787])\n",
      "01:19    Epoch 6: train loss 12.49 ([12.49296262])\n",
      "01:19    Epoch 8: train loss 12.49 ([12.4926301])\n",
      "01:20    Epoch 10: train loss 12.49 ([12.4922927])\n",
      "01:20    Epoch 12: train loss 12.49 ([12.49222591])\n",
      "01:21    Epoch 14: train loss 12.49 ([12.49198954])\n",
      "01:21    Epoch 16: train loss 12.49 ([12.49212789])\n",
      "01:22    Epoch 18: train loss 12.49 ([12.49196305])\n",
      "01:23    Epoch 20: train loss 12.49 ([12.49191693])\n",
      "01:23  Finished training\n",
      "01:23  Training estimator 15 / 20 in ensemble\n",
      "01:23  Starting training\n",
      "01:23    Method:                 sally\n",
      "01:23    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_14.npy\n",
      "01:23                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_14.npy\n",
      "01:23    Features:               [20]\n",
      "01:23    Method:                 sally\n",
      "01:23    Hidden layers:          (100, 100)\n",
      "01:23    Activation function:    tanh\n",
      "01:23    Batch size:             128\n",
      "01:23    Epochs:                 20\n",
      "01:23    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:23    Validation split:       None\n",
      "01:23    Early stopping:         True\n",
      "01:23  Loading training data\n",
      "01:23  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:23  Only using 1 of 29 observables\n",
      "01:23  Creating model for method sally\n",
      "01:23  Training model\n",
      "01:23    Epoch 2: train loss 22.62 ([22.62115529])\n",
      "01:24    Epoch 4: train loss 22.62 ([22.61564614])\n",
      "01:25    Epoch 6: train loss 22.62 ([22.61510734])\n",
      "01:25    Epoch 8: train loss 22.61 ([22.61449443])\n",
      "01:26    Epoch 10: train loss 22.61 ([22.61381094])\n",
      "01:26    Epoch 12: train loss 22.61 ([22.6137074])\n",
      "01:27    Epoch 14: train loss 22.62 ([22.61943655])\n",
      "01:27    Epoch 16: train loss 22.61 ([22.61359388])\n",
      "01:28    Epoch 18: train loss 22.61 ([22.61316192])\n",
      "01:29    Epoch 20: train loss 22.61 ([22.61346771])\n",
      "01:29  Finished training\n",
      "01:29  Training estimator 16 / 20 in ensemble\n",
      "01:29  Starting training\n",
      "01:29    Method:                 sally\n",
      "01:29    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_15.npy\n",
      "01:29                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_15.npy\n",
      "01:29    Features:               [20]\n",
      "01:29    Method:                 sally\n",
      "01:29    Hidden layers:          (100, 100)\n",
      "01:29    Activation function:    tanh\n",
      "01:29    Batch size:             128\n",
      "01:29    Epochs:                 20\n",
      "01:29    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:29    Validation split:       None\n",
      "01:29    Early stopping:         True\n",
      "01:29  Loading training data\n",
      "01:29  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:29  Only using 1 of 29 observables\n",
      "01:29  Creating model for method sally\n",
      "01:29  Training model\n",
      "01:29    Epoch 2: train loss 15.56 ([15.55867889])\n",
      "01:30    Epoch 4: train loss 15.56 ([15.55540352])\n",
      "01:30    Epoch 6: train loss 15.55 ([15.5548168])\n",
      "01:31    Epoch 8: train loss 15.55 ([15.55410739])\n",
      "01:32    Epoch 10: train loss 15.55 ([15.55393557])\n",
      "01:32    Epoch 12: train loss 15.55 ([15.55381889])\n",
      "01:33    Epoch 14: train loss 15.56 ([15.5550375])\n",
      "01:33    Epoch 16: train loss 15.55 ([15.55339665])\n",
      "01:34    Epoch 18: train loss 15.55 ([15.55470926])\n",
      "01:34    Epoch 20: train loss 15.55 ([15.5531485])\n",
      "01:34  Finished training\n",
      "01:34  Training estimator 17 / 20 in ensemble\n",
      "01:34  Starting training\n",
      "01:34    Method:                 sally\n",
      "01:34    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_16.npy\n",
      "01:34                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_16.npy\n",
      "01:34    Features:               [20]\n",
      "01:34    Method:                 sally\n",
      "01:34    Hidden layers:          (100, 100)\n",
      "01:34    Activation function:    tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:34    Batch size:             128\n",
      "01:34    Epochs:                 20\n",
      "01:34    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:34    Validation split:       None\n",
      "01:34    Early stopping:         True\n",
      "01:34  Loading training data\n",
      "01:35  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:35  Only using 1 of 29 observables\n",
      "01:35  Creating model for method sally\n",
      "01:35  Training model\n",
      "01:35    Epoch 2: train loss 17.44 ([17.44425149])\n",
      "01:36    Epoch 4: train loss 17.44 ([17.43526646])\n",
      "01:36    Epoch 6: train loss 17.43 ([17.43436998])\n",
      "01:37    Epoch 8: train loss 17.43 ([17.43389831])\n",
      "01:38    Epoch 10: train loss 17.43 ([17.43356307])\n",
      "01:38    Epoch 12: train loss 17.43 ([17.43346514])\n",
      "01:39    Epoch 14: train loss 17.43 ([17.43315392])\n",
      "01:39    Epoch 16: train loss 17.43 ([17.43298645])\n",
      "01:40    Epoch 18: train loss 17.43 ([17.43345226])\n",
      "01:40    Epoch 20: train loss 17.43 ([17.4325266])\n",
      "01:40  Finished training\n",
      "01:40  Training estimator 18 / 20 in ensemble\n",
      "01:40  Starting training\n",
      "01:40    Method:                 sally\n",
      "01:40    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_17.npy\n",
      "01:40                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_17.npy\n",
      "01:40    Features:               [20]\n",
      "01:40    Method:                 sally\n",
      "01:40    Hidden layers:          (100, 100)\n",
      "01:40    Activation function:    tanh\n",
      "01:40    Batch size:             128\n",
      "01:40    Epochs:                 20\n",
      "01:40    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:40    Validation split:       None\n",
      "01:40    Early stopping:         True\n",
      "01:40  Loading training data\n",
      "01:40  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:40  Only using 1 of 29 observables\n",
      "01:40  Creating model for method sally\n",
      "01:40  Training model\n",
      "01:41    Epoch 2: train loss 18.10 ([18.10165393])\n",
      "01:42    Epoch 4: train loss 18.09 ([18.08982837])\n",
      "01:42    Epoch 6: train loss 18.09 ([18.08802791])\n",
      "01:43    Epoch 8: train loss 18.09 ([18.08611013])\n",
      "01:44    Epoch 10: train loss 18.09 ([18.08540843])\n",
      "01:44    Epoch 12: train loss 18.08 ([18.08454867])\n",
      "01:45    Epoch 14: train loss 18.08 ([18.08371402])\n",
      "01:45    Epoch 16: train loss 18.08 ([18.08345869])\n",
      "01:46    Epoch 18: train loss 18.08 ([18.08373459])\n",
      "01:46    Epoch 20: train loss 18.08 ([18.08290279])\n",
      "01:46  Finished training\n",
      "01:46  Training estimator 19 / 20 in ensemble\n",
      "01:46  Starting training\n",
      "01:46    Method:                 sally\n",
      "01:46    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_18.npy\n",
      "01:46                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_18.npy\n",
      "01:46    Features:               [20]\n",
      "01:46    Method:                 sally\n",
      "01:46    Hidden layers:          (100, 100)\n",
      "01:46    Activation function:    tanh\n",
      "01:46    Batch size:             128\n",
      "01:46    Epochs:                 20\n",
      "01:46    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:46    Validation split:       None\n",
      "01:46    Early stopping:         True\n",
      "01:46  Loading training data\n",
      "01:46  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:46  Only using 1 of 29 observables\n",
      "01:46  Creating model for method sally\n",
      "01:46  Training model\n",
      "01:47    Epoch 2: train loss 44.30 ([44.30308732])\n",
      "01:48    Epoch 4: train loss 44.30 ([44.29723955])\n",
      "01:48    Epoch 6: train loss 44.29 ([44.29078281])\n",
      "01:49    Epoch 8: train loss 44.28 ([44.28399371])\n",
      "01:49    Epoch 10: train loss 44.28 ([44.28189048])\n",
      "01:50    Epoch 12: train loss 44.28 ([44.28150978])\n",
      "01:51    Epoch 14: train loss 44.28 ([44.27813394])\n",
      "01:51    Epoch 16: train loss 44.28 ([44.2755434])\n",
      "01:52    Epoch 18: train loss 44.27 ([44.27497634])\n",
      "01:52    Epoch 20: train loss 44.28 ([44.28088766])\n",
      "01:52  Finished training\n",
      "01:52  Training estimator 20 / 20 in ensemble\n",
      "01:52  Starting training\n",
      "01:52    Method:                 sally\n",
      "01:52    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_19.npy\n",
      "01:52                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_19.npy\n",
      "01:52    Features:               [20]\n",
      "01:52    Method:                 sally\n",
      "01:52    Hidden layers:          (100, 100)\n",
      "01:52    Activation function:    tanh\n",
      "01:52    Batch size:             128\n",
      "01:52    Epochs:                 20\n",
      "01:52    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "01:52    Validation split:       None\n",
      "01:52    Early stopping:         True\n",
      "01:52  Loading training data\n",
      "01:52  Found 1000000 samples with 2 parameters and 29 observables\n",
      "01:52  Only using 1 of 29 observables\n",
      "01:52  Creating model for method sally\n",
      "01:52  Training model\n",
      "01:53    Epoch 2: train loss 15.77 ([15.77486401])\n",
      "01:54    Epoch 4: train loss 15.77 ([15.77209969])\n",
      "01:54    Epoch 6: train loss 15.77 ([15.7709254])\n",
      "01:55    Epoch 8: train loss 15.77 ([15.77034252])\n",
      "01:56    Epoch 10: train loss 15.77 ([15.76995142])\n",
      "01:56    Epoch 12: train loss 15.77 ([15.76977279])\n",
      "01:57    Epoch 14: train loss 15.77 ([15.7691733])\n",
      "01:57    Epoch 16: train loss 15.77 ([15.77219176])\n",
      "01:58    Epoch 18: train loss 15.77 ([15.76879358])\n",
      "01:58    Epoch 20: train loss 15.77 ([15.76872118])\n",
      "01:58  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble_deltaphi = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_deltaphi.train_all(\n",
    "    features=[ [20] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "239d930c-cd8c-4586-862d-a68f24491d1e"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:58  Calculating expectation for 20 estimators in ensemble\n",
      "01:58  Starting evaluation for estimator 1 / 20 in ensemble\n",
      "01:58  Loading evaluation data\n",
      "01:58  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 2 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 3 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 4 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 5 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 6 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 7 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 8 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "01:59  Starting evaluation for estimator 9 / 20 in ensemble\n",
      "01:59  Loading evaluation data\n",
      "01:59  Starting score evaluation\n",
      "02:00  Starting evaluation for estimator 10 / 20 in ensemble\n",
      "02:00  Loading evaluation data\n",
      "02:00  Starting score evaluation\n",
      "02:00  Starting evaluation for estimator 11 / 20 in ensemble\n",
      "02:00  Loading evaluation data\n",
      "02:00  Starting score evaluation\n",
      "02:00  Starting evaluation for estimator 12 / 20 in ensemble\n",
      "02:00  Loading evaluation data\n",
      "02:00  Starting score evaluation\n",
      "02:00  Starting evaluation for estimator 13 / 20 in ensemble\n",
      "02:00  Loading evaluation data\n",
      "02:00  Starting score evaluation\n",
      "02:00  Starting evaluation for estimator 14 / 20 in ensemble\n",
      "02:00  Loading evaluation data\n",
      "02:00  Starting score evaluation\n",
      "02:00  Starting evaluation for estimator 15 / 20 in ensemble\n",
      "02:00  Loading evaluation data\n",
      "02:00  Starting score evaluation\n",
      "02:00  Starting evaluation for estimator 16 / 20 in ensemble\n",
      "02:00  Loading evaluation data\n",
      "02:00  Starting score evaluation\n",
      "02:01  Starting evaluation for estimator 17 / 20 in ensemble\n",
      "02:01  Loading evaluation data\n",
      "02:01  Starting score evaluation\n",
      "02:01  Starting evaluation for estimator 18 / 20 in ensemble\n",
      "02:01  Loading evaluation data\n",
      "02:01  Starting score evaluation\n",
      "02:01  Starting evaluation for estimator 19 / 20 in ensemble\n",
      "02:01  Loading evaluation data\n",
      "02:01  Starting score evaluation\n",
      "02:01  Starting evaluation for estimator 20 / 20 in ensemble\n",
      "02:01  Loading evaluation data\n",
      "02:01  Starting score evaluation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00875856,  0.00459889],\n",
       "       [-0.0003045 ,  0.00149938],\n",
       "       [ 0.00439043, -0.00443414],\n",
       "       [-0.0059252 ,  0.01023495],\n",
       "       [-0.00315193, -0.00054421],\n",
       "       [ 0.00304334,  0.00724456],\n",
       "       [ 0.00237222, -0.00301501],\n",
       "       [ 0.0007224 ,  0.00481131],\n",
       "       [-0.00355629,  0.00685876],\n",
       "       [ 0.00090163, -0.00755925],\n",
       "       [ 0.0026124 , -0.01008341],\n",
       "       [ 0.00877647,  0.00730935],\n",
       "       [ 0.00096675, -0.0042282 ],\n",
       "       [-0.00017658, -0.00820993],\n",
       "       [-0.00691816, -0.00035836],\n",
       "       [-0.0018715 ,  0.0006327 ],\n",
       "       [ 0.00078935, -0.00366219],\n",
       "       [ 0.00461002,  0.0142154 ],\n",
       "       [ 0.00450602,  0.0049802 ],\n",
       "       [ 0.00160791,  0.00054987]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_deltaphi.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "cba2d9c4-c9db-4362-889f-06e8197075ca"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:01  Saving ensemble setup to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/ensemble.json\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_0_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_0_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_1_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_1_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_2_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_2_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_3_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_3_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_4_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_4_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_5_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_5_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_6_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_6_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_7_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_7_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_8_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_8_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_9_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_9_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_10_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_10_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_11_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_11_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_12_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_12_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_13_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_13_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_14_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_14_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_15_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_15_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_16_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_16_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_17_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_17_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_18_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_18_state_dict.pt\n",
      "02:01  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_19_settings.json\n",
      "02:01  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_deltaphi/estimator_19_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "ensemble_deltaphi.save(model_dir + 'sally_ensemble_deltaphi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "45eafc2d-c3ba-493e-b2c3-7f36175d31e5"
    }
   },
   "source": [
    "## 1d toy study (MET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "eacce39b-9ad3-46c4-915a-2d4d412918c0"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:01  Training 20 estimators in ensemble\n",
      "02:01  Training estimator 1 / 20 in ensemble\n",
      "02:01  Starting training\n",
      "02:01    Method:                 sally\n",
      "02:01    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "02:01                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "02:01    Features:               [0]\n",
      "02:01    Method:                 sally\n",
      "02:01    Hidden layers:          (100, 100)\n",
      "02:01    Activation function:    tanh\n",
      "02:01    Batch size:             128\n",
      "02:01    Epochs:                 20\n",
      "02:01    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:01    Validation split:       None\n",
      "02:01    Early stopping:         True\n",
      "02:01  Loading training data\n",
      "02:01  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:01  Only using 1 of 29 observables\n",
      "02:01  Creating model for method sally\n",
      "02:01  Training model\n",
      "02:02    Epoch 2: train loss 18.55 ([18.55081943])\n",
      "02:02    Epoch 4: train loss 18.54 ([18.5441461])\n",
      "02:03    Epoch 6: train loss 18.54 ([18.53655158])\n",
      "02:04    Epoch 8: train loss 18.53 ([18.53373033])\n",
      "02:04    Epoch 10: train loss 18.53 ([18.52976536])\n",
      "02:05    Epoch 12: train loss 18.53 ([18.52846132])\n",
      "02:06    Epoch 14: train loss 18.53 ([18.52849869])\n",
      "02:06    Epoch 16: train loss 18.53 ([18.52577819])\n",
      "02:07    Epoch 18: train loss 18.53 ([18.53276829])\n",
      "02:08    Epoch 20: train loss 18.52 ([18.52285248])\n",
      "02:08  Finished training\n",
      "02:08  Training estimator 2 / 20 in ensemble\n",
      "02:08  Starting training\n",
      "02:08    Method:                 sally\n",
      "02:08    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "02:08                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "02:08    Features:               [0]\n",
      "02:08    Method:                 sally\n",
      "02:08    Hidden layers:          (100, 100)\n",
      "02:08    Activation function:    tanh\n",
      "02:08    Batch size:             128\n",
      "02:08    Epochs:                 20\n",
      "02:08    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:08    Validation split:       None\n",
      "02:08    Early stopping:         True\n",
      "02:08  Loading training data\n",
      "02:08  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:08  Only using 1 of 29 observables\n",
      "02:08  Creating model for method sally\n",
      "02:08  Training model\n",
      "02:08    Epoch 2: train loss 15.98 ([15.98145184])\n",
      "02:09    Epoch 4: train loss 15.97 ([15.97405149])\n",
      "02:10    Epoch 6: train loss 15.97 ([15.96927649])\n",
      "02:10    Epoch 8: train loss 15.96 ([15.96444112])\n",
      "02:11    Epoch 10: train loss 15.96 ([15.96201655])\n",
      "02:12    Epoch 12: train loss 15.96 ([15.95952577])\n",
      "02:12    Epoch 14: train loss 15.96 ([15.9580597])\n",
      "02:13    Epoch 16: train loss 15.96 ([15.95720158])\n",
      "02:14    Epoch 18: train loss 15.96 ([15.95618877])\n",
      "02:14    Epoch 20: train loss 15.96 ([15.95627781])\n",
      "02:14  Finished training\n",
      "02:14  Training estimator 3 / 20 in ensemble\n",
      "02:14  Starting training\n",
      "02:14    Method:                 sally\n",
      "02:14    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "02:14                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "02:14    Features:               [0]\n",
      "02:14    Method:                 sally\n",
      "02:14    Hidden layers:          (100, 100)\n",
      "02:14    Activation function:    tanh\n",
      "02:14    Batch size:             128\n",
      "02:14    Epochs:                 20\n",
      "02:14    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:14    Validation split:       None\n",
      "02:14    Early stopping:         True\n",
      "02:14  Loading training data\n",
      "02:14  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:14  Only using 1 of 29 observables\n",
      "02:14  Creating model for method sally\n",
      "02:14  Training model\n",
      "02:15    Epoch 2: train loss 53.50 ([53.49804174])\n",
      "02:16    Epoch 4: train loss 53.49 ([53.48868457])\n",
      "02:16    Epoch 6: train loss 53.48 ([53.48380358])\n",
      "02:17    Epoch 8: train loss 53.48 ([53.47716726])\n",
      "02:18    Epoch 10: train loss 53.47 ([53.47364848])\n",
      "02:18    Epoch 12: train loss 53.47 ([53.47117406])\n",
      "02:19    Epoch 14: train loss 53.47 ([53.46928667])\n",
      "02:20    Epoch 16: train loss 53.47 ([53.46686503])\n",
      "02:20    Epoch 18: train loss 53.47 ([53.46618964])\n",
      "02:21    Epoch 20: train loss 53.47 ([53.46953094])\n",
      "02:21  Finished training\n",
      "02:21  Training estimator 4 / 20 in ensemble\n",
      "02:21  Starting training\n",
      "02:21    Method:                 sally\n",
      "02:21    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "02:21                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "02:21    Features:               [0]\n",
      "02:21    Method:                 sally\n",
      "02:21    Hidden layers:          (100, 100)\n",
      "02:21    Activation function:    tanh\n",
      "02:21    Batch size:             128\n",
      "02:21    Epochs:                 20\n",
      "02:21    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:21    Validation split:       None\n",
      "02:21    Early stopping:         True\n",
      "02:21  Loading training data\n",
      "02:21  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:21  Only using 1 of 29 observables\n",
      "02:21  Creating model for method sally\n",
      "02:21  Training model\n",
      "02:22    Epoch 2: train loss 27.77 ([27.77411721])\n",
      "02:22    Epoch 4: train loss 27.77 ([27.76531809])\n",
      "02:23    Epoch 6: train loss 27.76 ([27.76044602])\n",
      "02:23    Epoch 8: train loss 27.75 ([27.75411302])\n",
      "02:24    Epoch 10: train loss 27.75 ([27.7508961])\n",
      "02:25    Epoch 12: train loss 27.75 ([27.74868734])\n",
      "02:25    Epoch 14: train loss 27.75 ([27.74669])\n",
      "02:26    Epoch 16: train loss 27.74 ([27.74474368])\n",
      "02:26    Epoch 18: train loss 27.74 ([27.74398343])\n",
      "02:27    Epoch 20: train loss 27.74 ([27.74221645])\n",
      "02:27  Finished training\n",
      "02:27  Training estimator 5 / 20 in ensemble\n",
      "02:27  Starting training\n",
      "02:27    Method:                 sally\n",
      "02:27    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "02:27                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "02:27    Features:               [0]\n",
      "02:27    Method:                 sally\n",
      "02:27    Hidden layers:          (100, 100)\n",
      "02:27    Activation function:    tanh\n",
      "02:27    Batch size:             128\n",
      "02:27    Epochs:                 20\n",
      "02:27    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:27    Validation split:       None\n",
      "02:27    Early stopping:         True\n",
      "02:27  Loading training data\n",
      "02:27  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:27  Only using 1 of 29 observables\n",
      "02:27  Creating model for method sally\n",
      "02:27  Training model\n",
      "02:28    Epoch 2: train loss 17.98 ([17.97890919])\n",
      "02:28    Epoch 4: train loss 17.97 ([17.96929158])\n",
      "02:29    Epoch 6: train loss 17.97 ([17.96616769])\n",
      "02:30    Epoch 8: train loss 17.96 ([17.96176166])\n",
      "02:30    Epoch 10: train loss 17.96 ([17.95907741])\n",
      "02:31    Epoch 12: train loss 17.96 ([17.95611225])\n",
      "02:32    Epoch 14: train loss 17.95 ([17.95445472])\n",
      "02:32    Epoch 16: train loss 17.95 ([17.95338399])\n",
      "02:33    Epoch 18: train loss 17.95 ([17.95239616])\n",
      "02:34    Epoch 20: train loss 17.95 ([17.95166992])\n",
      "02:34  Finished training\n",
      "02:34  Training estimator 6 / 20 in ensemble\n",
      "02:34  Starting training\n",
      "02:34    Method:                 sally\n",
      "02:34    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n",
      "02:34                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n",
      "02:34    Features:               [0]\n",
      "02:34    Method:                 sally\n",
      "02:34    Hidden layers:          (100, 100)\n",
      "02:34    Activation function:    tanh\n",
      "02:34    Batch size:             128\n",
      "02:34    Epochs:                 20\n",
      "02:34    Learning rate:          0.002 initially, decaying to 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:34    Validation split:       None\n",
      "02:34    Early stopping:         True\n",
      "02:34  Loading training data\n",
      "02:34  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:34  Only using 1 of 29 observables\n",
      "02:34  Creating model for method sally\n",
      "02:34  Training model\n",
      "02:34    Epoch 2: train loss 21.22 ([21.21900682])\n",
      "02:35    Epoch 4: train loss 21.21 ([21.2132529])\n",
      "02:36    Epoch 6: train loss 21.21 ([21.20515026])\n",
      "02:36    Epoch 8: train loss 21.20 ([21.20273598])\n",
      "02:37    Epoch 10: train loss 21.20 ([21.20007542])\n",
      "02:38    Epoch 12: train loss 21.20 ([21.19698787])\n",
      "02:38    Epoch 14: train loss 21.20 ([21.19551774])\n",
      "02:39    Epoch 16: train loss 21.19 ([21.19478414])\n",
      "02:40    Epoch 18: train loss 21.19 ([21.19325749])\n",
      "02:40    Epoch 20: train loss 21.19 ([21.19233094])\n",
      "02:40  Finished training\n",
      "02:40  Training estimator 7 / 20 in ensemble\n",
      "02:40  Starting training\n",
      "02:40    Method:                 sally\n",
      "02:40    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "02:40                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "02:40    Features:               [0]\n",
      "02:40    Method:                 sally\n",
      "02:40    Hidden layers:          (100, 100)\n",
      "02:40    Activation function:    tanh\n",
      "02:40    Batch size:             128\n",
      "02:40    Epochs:                 20\n",
      "02:40    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:40    Validation split:       None\n",
      "02:40    Early stopping:         True\n",
      "02:40  Loading training data\n",
      "02:40  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:40  Only using 1 of 29 observables\n",
      "02:40  Creating model for method sally\n",
      "02:40  Training model\n",
      "02:41    Epoch 2: train loss 15.94 ([15.94484607])\n",
      "02:42    Epoch 4: train loss 15.94 ([15.9403804])\n",
      "02:42    Epoch 6: train loss 15.93 ([15.93412137])\n",
      "02:43    Epoch 8: train loss 15.93 ([15.92992154])\n",
      "02:43    Epoch 10: train loss 15.93 ([15.93130006])\n",
      "02:44    Epoch 12: train loss 15.93 ([15.92546221])\n",
      "02:45    Epoch 14: train loss 15.92 ([15.92352967])\n",
      "02:45    Epoch 16: train loss 15.92 ([15.92307422])\n",
      "02:46    Epoch 18: train loss 15.92 ([15.92218773])\n",
      "02:47    Epoch 20: train loss 15.92 ([15.92097233])\n",
      "02:47  Finished training\n",
      "02:47  Training estimator 8 / 20 in ensemble\n",
      "02:47  Starting training\n",
      "02:47    Method:                 sally\n",
      "02:47    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "02:47                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "02:47    Features:               [0]\n",
      "02:47    Method:                 sally\n",
      "02:47    Hidden layers:          (100, 100)\n",
      "02:47    Activation function:    tanh\n",
      "02:47    Batch size:             128\n",
      "02:47    Epochs:                 20\n",
      "02:47    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:47    Validation split:       None\n",
      "02:47    Early stopping:         True\n",
      "02:47  Loading training data\n",
      "02:47  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:47  Only using 1 of 29 observables\n",
      "02:47  Creating model for method sally\n",
      "02:47  Training model\n",
      "02:47    Epoch 2: train loss 27.65 ([27.65302088])\n",
      "02:48    Epoch 4: train loss 27.65 ([27.64675166])\n",
      "02:49    Epoch 6: train loss 27.64 ([27.63939726])\n",
      "02:49    Epoch 8: train loss 27.64 ([27.63501177])\n",
      "02:50    Epoch 10: train loss 27.63 ([27.6327795])\n",
      "02:51    Epoch 12: train loss 27.63 ([27.62918962])\n",
      "02:51    Epoch 14: train loss 27.63 ([27.62751869])\n",
      "02:52    Epoch 16: train loss 27.63 ([27.62623655])\n",
      "02:53    Epoch 18: train loss 27.63 ([27.62538362])\n",
      "02:53    Epoch 20: train loss 27.62 ([27.6249558])\n",
      "02:53  Finished training\n",
      "02:53  Training estimator 9 / 20 in ensemble\n",
      "02:53  Starting training\n",
      "02:53    Method:                 sally\n",
      "02:53    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "02:53                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "02:53    Features:               [0]\n",
      "02:53    Method:                 sally\n",
      "02:53    Hidden layers:          (100, 100)\n",
      "02:53    Activation function:    tanh\n",
      "02:53    Batch size:             128\n",
      "02:53    Epochs:                 20\n",
      "02:53    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "02:53    Validation split:       None\n",
      "02:53    Early stopping:         True\n",
      "02:53  Loading training data\n",
      "02:53  Found 1000000 samples with 2 parameters and 29 observables\n",
      "02:53  Only using 1 of 29 observables\n",
      "02:53  Creating model for method sally\n",
      "02:53  Training model\n",
      "02:54    Epoch 2: train loss 21.03 ([21.02529514])\n",
      "02:55    Epoch 4: train loss 21.02 ([21.01717082])\n",
      "02:55    Epoch 6: train loss 21.01 ([21.01115401])\n",
      "02:56    Epoch 8: train loss 21.01 ([21.0071865])\n",
      "02:57    Epoch 10: train loss 21.00 ([21.00323823])\n",
      "02:57    Epoch 12: train loss 21.00 ([21.00046043])\n",
      "02:58    Epoch 14: train loss 21.00 ([20.99929357])\n",
      "02:58    Epoch 16: train loss 21.00 ([20.9977636])\n",
      "02:59    Epoch 18: train loss 21.00 ([20.99695395])\n",
      "03:00    Epoch 20: train loss 21.00 ([20.99551285])\n",
      "03:00  Finished training\n",
      "03:00  Training estimator 10 / 20 in ensemble\n",
      "03:00  Starting training\n",
      "03:00    Method:                 sally\n",
      "03:00    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "03:00                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "03:00    Features:               [0]\n",
      "03:00    Method:                 sally\n",
      "03:00    Hidden layers:          (100, 100)\n",
      "03:00    Activation function:    tanh\n",
      "03:00    Batch size:             128\n",
      "03:00    Epochs:                 20\n",
      "03:00    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:00    Validation split:       None\n",
      "03:00    Early stopping:         True\n",
      "03:00  Loading training data\n",
      "03:00  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:00  Only using 1 of 29 observables\n",
      "03:00  Creating model for method sally\n",
      "03:00  Training model\n",
      "03:01    Epoch 2: train loss 47.38 ([47.38432633])\n",
      "03:01    Epoch 4: train loss 47.37 ([47.36617329])\n",
      "03:02    Epoch 6: train loss 47.36 ([47.35866297])\n",
      "03:02    Epoch 8: train loss 47.35 ([47.35482153])\n",
      "03:03    Epoch 10: train loss 47.35 ([47.35014018])\n",
      "03:04    Epoch 12: train loss 47.35 ([47.34776695])\n",
      "03:04    Epoch 14: train loss 47.35 ([47.34631396])\n",
      "03:05    Epoch 16: train loss 47.34 ([47.34459339])\n",
      "03:06    Epoch 18: train loss 47.34 ([47.344035])\n",
      "03:06    Epoch 20: train loss 47.34 ([47.34321391])\n",
      "03:06  Finished training\n",
      "03:06  Training estimator 11 / 20 in ensemble\n",
      "03:06  Starting training\n",
      "03:06    Method:                 sally\n",
      "03:06    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_10.npy\n",
      "03:06                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_10.npy\n",
      "03:06    Features:               [0]\n",
      "03:06    Method:                 sally\n",
      "03:06    Hidden layers:          (100, 100)\n",
      "03:06    Activation function:    tanh\n",
      "03:06    Batch size:             128\n",
      "03:06    Epochs:                 20\n",
      "03:06    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:06    Validation split:       None\n",
      "03:06    Early stopping:         True\n",
      "03:06  Loading training data\n",
      "03:06  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:06  Only using 1 of 29 observables\n",
      "03:06  Creating model for method sally\n",
      "03:06  Training model\n",
      "03:07    Epoch 2: train loss 17.01 ([17.00638405])\n",
      "03:08    Epoch 4: train loss 17.00 ([17.00025718])\n",
      "03:08    Epoch 6: train loss 16.99 ([16.99426362])\n",
      "03:09    Epoch 8: train loss 16.99 ([16.99027278])\n",
      "03:10    Epoch 10: train loss 16.99 ([16.98977997])\n",
      "03:10    Epoch 12: train loss 16.99 ([16.98551056])\n",
      "03:11    Epoch 14: train loss 16.99 ([16.98644539])\n",
      "03:12    Epoch 16: train loss 17.00 ([16.99990563])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:12    Epoch 18: train loss 16.98 ([16.98204427])\n",
      "03:13    Epoch 20: train loss 16.98 ([16.98071614])\n",
      "03:13  Finished training\n",
      "03:13  Training estimator 12 / 20 in ensemble\n",
      "03:13  Starting training\n",
      "03:13    Method:                 sally\n",
      "03:13    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_11.npy\n",
      "03:13                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_11.npy\n",
      "03:13    Features:               [0]\n",
      "03:13    Method:                 sally\n",
      "03:13    Hidden layers:          (100, 100)\n",
      "03:13    Activation function:    tanh\n",
      "03:13    Batch size:             128\n",
      "03:13    Epochs:                 20\n",
      "03:13    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:13    Validation split:       None\n",
      "03:13    Early stopping:         True\n",
      "03:13  Loading training data\n",
      "03:13  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:13  Only using 1 of 29 observables\n",
      "03:13  Creating model for method sally\n",
      "03:13  Training model\n",
      "03:14    Epoch 2: train loss 17.49 ([17.49339947])\n",
      "03:14    Epoch 4: train loss 17.48 ([17.48482124])\n",
      "03:15    Epoch 6: train loss 17.48 ([17.47921034])\n",
      "03:15    Epoch 8: train loss 17.48 ([17.47623748])\n",
      "03:16    Epoch 10: train loss 17.47 ([17.47344811])\n",
      "03:17    Epoch 12: train loss 17.47 ([17.47156966])\n",
      "03:17    Epoch 14: train loss 17.47 ([17.47143688])\n",
      "03:18    Epoch 16: train loss 17.47 ([17.46864874])\n",
      "03:19    Epoch 18: train loss 17.47 ([17.46758602])\n",
      "03:19    Epoch 20: train loss 17.47 ([17.46733254])\n",
      "03:19  Finished training\n",
      "03:19  Training estimator 13 / 20 in ensemble\n",
      "03:19  Starting training\n",
      "03:19    Method:                 sally\n",
      "03:19    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_12.npy\n",
      "03:19                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_12.npy\n",
      "03:19    Features:               [0]\n",
      "03:19    Method:                 sally\n",
      "03:19    Hidden layers:          (100, 100)\n",
      "03:19    Activation function:    tanh\n",
      "03:19    Batch size:             128\n",
      "03:19    Epochs:                 20\n",
      "03:19    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:19    Validation split:       None\n",
      "03:19    Early stopping:         True\n",
      "03:19  Loading training data\n",
      "03:19  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:19  Only using 1 of 29 observables\n",
      "03:19  Creating model for method sally\n",
      "03:19  Training model\n",
      "03:20    Epoch 2: train loss 18.15 ([18.15059358])\n",
      "03:21    Epoch 4: train loss 18.15 ([18.14535368])\n",
      "03:21    Epoch 6: train loss 18.14 ([18.14047447])\n",
      "03:22    Epoch 8: train loss 18.14 ([18.13556005])\n",
      "03:23    Epoch 10: train loss 18.13 ([18.13383179])\n",
      "03:23    Epoch 12: train loss 18.13 ([18.13018606])\n",
      "03:24    Epoch 14: train loss 18.13 ([18.12855793])\n",
      "03:25    Epoch 16: train loss 18.13 ([18.12696375])\n",
      "03:25    Epoch 18: train loss 18.13 ([18.12632032])\n",
      "03:26    Epoch 20: train loss 18.13 ([18.12593153])\n",
      "03:26  Finished training\n",
      "03:26  Training estimator 14 / 20 in ensemble\n",
      "03:26  Starting training\n",
      "03:26    Method:                 sally\n",
      "03:26    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_13.npy\n",
      "03:26                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_13.npy\n",
      "03:26    Features:               [0]\n",
      "03:26    Method:                 sally\n",
      "03:26    Hidden layers:          (100, 100)\n",
      "03:26    Activation function:    tanh\n",
      "03:26    Batch size:             128\n",
      "03:26    Epochs:                 20\n",
      "03:26    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:26    Validation split:       None\n",
      "03:26    Early stopping:         True\n",
      "03:26  Loading training data\n",
      "03:26  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:26  Only using 1 of 29 observables\n",
      "03:26  Creating model for method sally\n",
      "03:26  Training model\n",
      "03:27    Epoch 2: train loss 12.52 ([12.51707204])\n",
      "03:27    Epoch 4: train loss 12.51 ([12.51235854])\n",
      "03:28    Epoch 6: train loss 12.51 ([12.50755416])\n",
      "03:29    Epoch 8: train loss 12.50 ([12.50300607])\n",
      "03:29    Epoch 10: train loss 12.50 ([12.5005925])\n",
      "03:30    Epoch 12: train loss 12.50 ([12.49876924])\n",
      "03:30    Epoch 14: train loss 12.50 ([12.49695743])\n",
      "03:31    Epoch 16: train loss 12.50 ([12.4957988])\n",
      "03:32    Epoch 18: train loss 12.49 ([12.49394878])\n",
      "03:32    Epoch 20: train loss 12.49 ([12.49353345])\n",
      "03:32  Finished training\n",
      "03:32  Training estimator 15 / 20 in ensemble\n",
      "03:32  Starting training\n",
      "03:32    Method:                 sally\n",
      "03:32    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_14.npy\n",
      "03:32                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_14.npy\n",
      "03:32    Features:               [0]\n",
      "03:32    Method:                 sally\n",
      "03:32    Hidden layers:          (100, 100)\n",
      "03:32    Activation function:    tanh\n",
      "03:32    Batch size:             128\n",
      "03:32    Epochs:                 20\n",
      "03:32    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:32    Validation split:       None\n",
      "03:32    Early stopping:         True\n",
      "03:32  Loading training data\n",
      "03:32  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:32  Only using 1 of 29 observables\n",
      "03:32  Creating model for method sally\n",
      "03:32  Training model\n",
      "03:33    Epoch 2: train loss 22.64 ([22.64360541])\n",
      "03:34    Epoch 4: train loss 22.64 ([22.63804203])\n",
      "03:34    Epoch 6: train loss 22.63 ([22.63245455])\n",
      "03:35    Epoch 8: train loss 22.63 ([22.6275017])\n",
      "03:36    Epoch 10: train loss 22.62 ([22.6245602])\n",
      "03:36    Epoch 12: train loss 22.62 ([22.62146153])\n",
      "03:37    Epoch 14: train loss 22.62 ([22.61944879])\n",
      "03:38    Epoch 16: train loss 22.62 ([22.61861294])\n",
      "03:38    Epoch 18: train loss 22.62 ([22.61884443])\n",
      "03:39    Epoch 20: train loss 22.62 ([22.61528721])\n",
      "03:39  Finished training\n",
      "03:39  Training estimator 16 / 20 in ensemble\n",
      "03:39  Starting training\n",
      "03:39    Method:                 sally\n",
      "03:39    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_15.npy\n",
      "03:39                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_15.npy\n",
      "03:39    Features:               [0]\n",
      "03:39    Method:                 sally\n",
      "03:39    Hidden layers:          (100, 100)\n",
      "03:39    Activation function:    tanh\n",
      "03:39    Batch size:             128\n",
      "03:39    Epochs:                 20\n",
      "03:39    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:39    Validation split:       None\n",
      "03:39    Early stopping:         True\n",
      "03:39  Loading training data\n",
      "03:39  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:39  Only using 1 of 29 observables\n",
      "03:39  Creating model for method sally\n",
      "03:39  Training model\n",
      "03:40    Epoch 2: train loss 15.58 ([15.57991865])\n",
      "03:40    Epoch 4: train loss 15.57 ([15.57231432])\n",
      "03:41    Epoch 6: train loss 15.57 ([15.56846868])\n",
      "03:41    Epoch 8: train loss 15.56 ([15.5639621])\n",
      "03:42    Epoch 10: train loss 15.56 ([15.56205652])\n",
      "03:43    Epoch 12: train loss 15.56 ([15.56021675])\n",
      "03:43    Epoch 14: train loss 15.57 ([15.56525279])\n",
      "03:44    Epoch 16: train loss 15.56 ([15.55716491])\n",
      "03:45    Epoch 18: train loss 15.56 ([15.55627902])\n",
      "03:45    Epoch 20: train loss 15.56 ([15.55551904])\n",
      "03:45  Finished training\n",
      "03:45  Training estimator 17 / 20 in ensemble\n",
      "03:45  Starting training\n",
      "03:45    Method:                 sally\n",
      "03:45    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_16.npy\n",
      "03:45                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_16.npy\n",
      "03:45    Features:               [0]\n",
      "03:45    Method:                 sally\n",
      "03:45    Hidden layers:          (100, 100)\n",
      "03:45    Activation function:    tanh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:45    Batch size:             128\n",
      "03:45    Epochs:                 20\n",
      "03:45    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:45    Validation split:       None\n",
      "03:45    Early stopping:         True\n",
      "03:45  Loading training data\n",
      "03:45  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:45  Only using 1 of 29 observables\n",
      "03:45  Creating model for method sally\n",
      "03:45  Training model\n",
      "03:46    Epoch 2: train loss 17.46 ([17.46170746])\n",
      "03:47    Epoch 4: train loss 17.45 ([17.45390543])\n",
      "03:47    Epoch 6: train loss 17.45 ([17.44887938])\n",
      "03:48    Epoch 8: train loss 17.45 ([17.44596141])\n",
      "03:49    Epoch 10: train loss 17.44 ([17.44220913])\n",
      "03:49    Epoch 12: train loss 17.44 ([17.43906627])\n",
      "03:50    Epoch 14: train loss 17.44 ([17.43859459])\n",
      "03:51    Epoch 16: train loss 17.44 ([17.43705118])\n",
      "03:51    Epoch 18: train loss 17.44 ([17.43639376])\n",
      "03:52    Epoch 20: train loss 17.44 ([17.43535924])\n",
      "03:52  Finished training\n",
      "03:52  Training estimator 18 / 20 in ensemble\n",
      "03:52  Starting training\n",
      "03:52    Method:                 sally\n",
      "03:52    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_17.npy\n",
      "03:52                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_17.npy\n",
      "03:52    Features:               [0]\n",
      "03:52    Method:                 sally\n",
      "03:52    Hidden layers:          (100, 100)\n",
      "03:52    Activation function:    tanh\n",
      "03:52    Batch size:             128\n",
      "03:52    Epochs:                 20\n",
      "03:52    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:52    Validation split:       None\n",
      "03:52    Early stopping:         True\n",
      "03:52  Loading training data\n",
      "03:52  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:52  Only using 1 of 29 observables\n",
      "03:52  Creating model for method sally\n",
      "03:52  Training model\n",
      "03:53    Epoch 2: train loss 18.11 ([18.11047351])\n",
      "03:53    Epoch 4: train loss 18.11 ([18.10966332])\n",
      "03:54    Epoch 6: train loss 18.10 ([18.09986899])\n",
      "03:55    Epoch 8: train loss 18.10 ([18.0953984])\n",
      "03:55    Epoch 10: train loss 18.09 ([18.0927457])\n",
      "03:56    Epoch 12: train loss 18.09 ([18.09127525])\n",
      "03:57    Epoch 14: train loss 18.09 ([18.08937895])\n",
      "03:57    Epoch 16: train loss 18.09 ([18.08807185])\n",
      "03:58    Epoch 18: train loss 18.09 ([18.08708543])\n",
      "03:58    Epoch 20: train loss 18.09 ([18.08626901])\n",
      "03:58  Finished training\n",
      "03:58  Training estimator 19 / 20 in ensemble\n",
      "03:58  Starting training\n",
      "03:58    Method:                 sally\n",
      "03:58    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_18.npy\n",
      "03:58                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_18.npy\n",
      "03:58    Features:               [0]\n",
      "03:58    Method:                 sally\n",
      "03:58    Hidden layers:          (100, 100)\n",
      "03:58    Activation function:    tanh\n",
      "03:58    Batch size:             128\n",
      "03:58    Epochs:                 20\n",
      "03:58    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "03:58    Validation split:       None\n",
      "03:58    Early stopping:         True\n",
      "03:58  Loading training data\n",
      "03:58  Found 1000000 samples with 2 parameters and 29 observables\n",
      "03:58  Only using 1 of 29 observables\n",
      "03:58  Creating model for method sally\n",
      "03:58  Training model\n",
      "03:59    Epoch 2: train loss 44.31 ([44.31006154])\n",
      "04:00    Epoch 4: train loss 44.30 ([44.30166791])\n",
      "04:00    Epoch 6: train loss 44.29 ([44.2925957])\n",
      "04:01    Epoch 8: train loss 44.29 ([44.28938493])\n",
      "04:02    Epoch 10: train loss 44.29 ([44.28631306])\n",
      "04:02    Epoch 12: train loss 44.28 ([44.2818447])\n",
      "04:03    Epoch 14: train loss 44.28 ([44.28019582])\n",
      "04:04    Epoch 16: train loss 44.28 ([44.27811862])\n",
      "04:04    Epoch 18: train loss 44.28 ([44.27724756])\n",
      "04:05    Epoch 20: train loss 44.28 ([44.27654939])\n",
      "04:05  Finished training\n",
      "04:05  Training estimator 20 / 20 in ensemble\n",
      "04:05  Starting training\n",
      "04:05    Method:                 sally\n",
      "04:05    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_19.npy\n",
      "04:05                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_19.npy\n",
      "04:05    Features:               [0]\n",
      "04:05    Method:                 sally\n",
      "04:05    Hidden layers:          (100, 100)\n",
      "04:05    Activation function:    tanh\n",
      "04:05    Batch size:             128\n",
      "04:05    Epochs:                 20\n",
      "04:05    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "04:05    Validation split:       None\n",
      "04:05    Early stopping:         True\n",
      "04:05  Loading training data\n",
      "04:05  Found 1000000 samples with 2 parameters and 29 observables\n",
      "04:05  Only using 1 of 29 observables\n",
      "04:05  Creating model for method sally\n",
      "04:05  Training model\n",
      "04:06    Epoch 2: train loss 15.80 ([15.79823871])\n",
      "04:06    Epoch 4: train loss 15.79 ([15.79110857])\n",
      "04:07    Epoch 6: train loss 15.78 ([15.78442591])\n",
      "04:08    Epoch 8: train loss 15.78 ([15.78045291])\n",
      "04:08    Epoch 10: train loss 15.78 ([15.77806229])\n",
      "04:09    Epoch 12: train loss 15.78 ([15.77657866])\n",
      "04:10    Epoch 14: train loss 15.77 ([15.7740116])\n",
      "04:10    Epoch 16: train loss 15.77 ([15.77318167])\n",
      "04:11    Epoch 18: train loss 15.77 ([15.772741])\n",
      "04:12    Epoch 20: train loss 15.77 ([15.77231683])\n",
      "04:12  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble_met = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_met.train_all(\n",
    "    features=[ [0] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "4dd7a14b-7f6f-40ad-a23f-5180dd46c98d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:12  Calculating expectation for 20 estimators in ensemble\n",
      "04:12  Starting evaluation for estimator 1 / 20 in ensemble\n",
      "04:12  Loading evaluation data\n",
      "04:12  Starting score evaluation\n",
      "04:12  Starting evaluation for estimator 2 / 20 in ensemble\n",
      "04:12  Loading evaluation data\n",
      "04:12  Starting score evaluation\n",
      "04:12  Starting evaluation for estimator 3 / 20 in ensemble\n",
      "04:12  Loading evaluation data\n",
      "04:12  Starting score evaluation\n",
      "04:12  Starting evaluation for estimator 4 / 20 in ensemble\n",
      "04:12  Loading evaluation data\n",
      "04:12  Starting score evaluation\n",
      "04:12  Starting evaluation for estimator 5 / 20 in ensemble\n",
      "04:12  Loading evaluation data\n",
      "04:12  Starting score evaluation\n",
      "04:12  Starting evaluation for estimator 6 / 20 in ensemble\n",
      "04:12  Loading evaluation data\n",
      "04:12  Starting score evaluation\n",
      "04:13  Starting evaluation for estimator 7 / 20 in ensemble\n",
      "04:13  Loading evaluation data\n",
      "04:13  Starting score evaluation\n",
      "04:13  Starting evaluation for estimator 8 / 20 in ensemble\n",
      "04:13  Loading evaluation data\n",
      "04:13  Starting score evaluation\n",
      "04:13  Starting evaluation for estimator 9 / 20 in ensemble\n",
      "04:13  Loading evaluation data\n",
      "04:13  Starting score evaluation\n",
      "04:13  Starting evaluation for estimator 10 / 20 in ensemble\n",
      "04:13  Loading evaluation data\n",
      "04:13  Starting score evaluation\n",
      "04:13  Starting evaluation for estimator 11 / 20 in ensemble\n",
      "04:13  Loading evaluation data\n",
      "04:13  Starting score evaluation\n",
      "04:13  Starting evaluation for estimator 12 / 20 in ensemble\n",
      "04:13  Loading evaluation data\n",
      "04:13  Starting score evaluation\n",
      "04:13  Starting evaluation for estimator 13 / 20 in ensemble\n",
      "04:13  Loading evaluation data\n",
      "04:13  Starting score evaluation\n",
      "04:14  Starting evaluation for estimator 14 / 20 in ensemble\n",
      "04:14  Loading evaluation data\n",
      "04:14  Starting score evaluation\n",
      "04:14  Starting evaluation for estimator 15 / 20 in ensemble\n",
      "04:14  Loading evaluation data\n",
      "04:14  Starting score evaluation\n",
      "04:14  Starting evaluation for estimator 16 / 20 in ensemble\n",
      "04:14  Loading evaluation data\n",
      "04:14  Starting score evaluation\n",
      "04:14  Starting evaluation for estimator 17 / 20 in ensemble\n",
      "04:14  Loading evaluation data\n",
      "04:14  Starting score evaluation\n",
      "04:14  Starting evaluation for estimator 18 / 20 in ensemble\n",
      "04:14  Loading evaluation data\n",
      "04:14  Starting score evaluation\n",
      "04:14  Starting evaluation for estimator 19 / 20 in ensemble\n",
      "04:14  Loading evaluation data\n",
      "04:14  Starting score evaluation\n",
      "04:14  Starting evaluation for estimator 20 / 20 in ensemble\n",
      "04:14  Loading evaluation data\n",
      "04:14  Starting score evaluation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.03217312,  0.04683511],\n",
       "       [ 0.00696393,  0.03543703],\n",
       "       [ 0.02575764,  0.01514627],\n",
       "       [-0.00298495,  0.04633479],\n",
       "       [ 0.07877649, -0.10351486],\n",
       "       [ 0.03489412, -0.04659313],\n",
       "       [-0.0472172 , -0.01366843],\n",
       "       [ 0.02494288, -0.11711625],\n",
       "       [ 0.02242893,  0.02772917],\n",
       "       [-0.0252324 , -0.03115297],\n",
       "       [-0.01470638, -0.0187749 ],\n",
       "       [ 0.0214741 , -0.02624243],\n",
       "       [ 0.01414475, -0.04351106],\n",
       "       [-0.04331799, -0.05038221],\n",
       "       [ 0.00418201, -0.02652313],\n",
       "       [ 0.06079252,  0.00274209],\n",
       "       [-0.01953946, -0.02757395],\n",
       "       [-0.07849615,  0.00724561],\n",
       "       [ 0.0044371 , -0.00227884],\n",
       "       [ 0.04675819,  0.01130327]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_met.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbpresent": {
     "id": "5c37b210-f29b-45f3-9988-b82ebba909a9"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:15  Saving ensemble setup to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/ensemble.json\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_0_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_0_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_1_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_1_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_2_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_2_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_3_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_3_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_4_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_4_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_5_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_5_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_6_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_6_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_7_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_7_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_8_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_8_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_9_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_9_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_10_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_10_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_11_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_11_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_12_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_12_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_13_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_13_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_14_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_14_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_15_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_15_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_16_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_16_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_17_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_17_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_18_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_18_state_dict.pt\n",
      "04:15  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_19_settings.json\n",
      "04:15  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_met/estimator_19_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "ensemble_met.save(model_dir + 'sally_ensemble_met')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "84cb788d-da26-4e03-8bc1-cddc335d12ed"
    }
   },
   "source": [
    "## 1d toy study (dummy observable: phi(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "9056bfd0-0c5a-4810-b89e-fa6976c5efa5"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:04  \n",
      "11:04  ------------------------------------------------------------\n",
      "11:04  |                                                          |\n",
      "11:04  |  MadMiner v2018.10.30                                    |\n",
      "11:04  |                                                          |\n",
      "11:04  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "11:04  |                                                          |\n",
      "11:04  ------------------------------------------------------------\n",
      "11:04  \n",
      "11:04  Training 20 estimators in ensemble\n",
      "11:04  Training estimator 1 / 20 in ensemble\n",
      "11:04  Starting training\n",
      "11:04    Method:                 sally\n",
      "11:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "11:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "11:04    Features:               [1]\n",
      "11:04    Method:                 sally\n",
      "11:04    Hidden layers:          (100, 100)\n",
      "11:04    Activation function:    tanh\n",
      "11:04    Batch size:             128\n",
      "11:04    Epochs:                 20\n",
      "11:04    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:04    Validation split:       None\n",
      "11:04    Early stopping:         True\n",
      "11:04  Loading training data\n",
      "11:04  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:04  Only using 1 of 29 observables\n",
      "11:04  Creating model for method sally\n",
      "11:04  Training model\n",
      "11:05    Epoch 2: train loss 18.52 ([18.52374802])\n",
      "11:05    Epoch 4: train loss 18.52 ([18.52294244])\n",
      "11:06    Epoch 6: train loss 18.52 ([18.52289469])\n",
      "11:07    Epoch 8: train loss 18.53 ([18.52784848])\n",
      "11:07    Epoch 10: train loss 18.52 ([18.52249176])\n",
      "11:08    Epoch 12: train loss 18.52 ([18.52252913])\n",
      "11:08    Epoch 14: train loss 18.52 ([18.52238263])\n",
      "11:09    Epoch 16: train loss 18.52 ([18.52242407])\n",
      "11:10    Epoch 18: train loss 18.52 ([18.52237293])\n",
      "11:10    Epoch 20: train loss 18.52 ([18.52239447])\n",
      "11:10  Finished training\n",
      "11:10  Training estimator 2 / 20 in ensemble\n",
      "11:10  Starting training\n",
      "11:10    Method:                 sally\n",
      "11:10    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "11:10                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "11:10    Features:               [1]\n",
      "11:10    Method:                 sally\n",
      "11:10    Hidden layers:          (100, 100)\n",
      "11:10    Activation function:    tanh\n",
      "11:10    Batch size:             128\n",
      "11:10    Epochs:                 20\n",
      "11:10    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:10    Validation split:       None\n",
      "11:10    Early stopping:         True\n",
      "11:10  Loading training data\n",
      "11:10  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:10  Only using 1 of 29 observables\n",
      "11:10  Creating model for method sally\n",
      "11:10  Training model\n",
      "11:11    Epoch 2: train loss 15.96 ([15.95513858])\n",
      "11:12    Epoch 4: train loss 15.95 ([15.95463728])\n",
      "11:12    Epoch 6: train loss 15.95 ([15.95426543])\n",
      "11:13    Epoch 8: train loss 15.95 ([15.95437507])\n",
      "11:13    Epoch 10: train loss 15.95 ([15.95425704])\n",
      "11:14    Epoch 12: train loss 15.95 ([15.95484461])\n",
      "11:15    Epoch 14: train loss 15.95 ([15.95390924])\n",
      "11:15    Epoch 16: train loss 15.95 ([15.95389801])\n",
      "11:16    Epoch 18: train loss 15.95 ([15.95397426])\n",
      "11:16    Epoch 20: train loss 15.95 ([15.95379247])\n",
      "11:16  Finished training\n",
      "11:16  Training estimator 3 / 20 in ensemble\n",
      "11:16  Starting training\n",
      "11:16    Method:                 sally\n",
      "11:16    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "11:16                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "11:16    Features:               [1]\n",
      "11:16    Method:                 sally\n",
      "11:16    Hidden layers:          (100, 100)\n",
      "11:16    Activation function:    tanh\n",
      "11:16    Batch size:             128\n",
      "11:16    Epochs:                 20\n",
      "11:16    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:16    Validation split:       None\n",
      "11:16    Early stopping:         True\n",
      "11:16  Loading training data\n",
      "11:16  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:16  Only using 1 of 29 observables\n",
      "11:16  Creating model for method sally\n",
      "11:16  Training model\n",
      "11:17    Epoch 2: train loss 53.47 ([53.4699199])\n",
      "11:18    Epoch 4: train loss 53.46 ([53.4645769])\n",
      "11:18    Epoch 6: train loss 53.46 ([53.46405087])\n",
      "11:19    Epoch 8: train loss 53.46 ([53.46384805])\n",
      "11:19    Epoch 10: train loss 53.46 ([53.46354067])\n",
      "11:20    Epoch 12: train loss 53.46 ([53.46356866])\n",
      "11:21    Epoch 14: train loss 53.46 ([53.46381292])\n",
      "11:21    Epoch 16: train loss 53.46 ([53.46359967])\n",
      "11:22    Epoch 18: train loss 53.46 ([53.46353044])\n",
      "11:22    Epoch 20: train loss 53.46 ([53.46338894])\n",
      "11:22  Finished training\n",
      "11:22  Training estimator 4 / 20 in ensemble\n",
      "11:22  Starting training\n",
      "11:22    Method:                 sally\n",
      "11:22    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "11:22                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "11:22    Features:               [1]\n",
      "11:22    Method:                 sally\n",
      "11:22    Hidden layers:          (100, 100)\n",
      "11:22    Activation function:    tanh\n",
      "11:22    Batch size:             128\n",
      "11:22    Epochs:                 20\n",
      "11:22    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:22    Validation split:       None\n",
      "11:22    Early stopping:         True\n",
      "11:22  Loading training data\n",
      "11:22  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:22  Only using 1 of 29 observables\n",
      "11:22  Creating model for method sally\n",
      "11:22  Training model\n",
      "11:23    Epoch 2: train loss 27.74 ([27.74347513])\n",
      "11:24    Epoch 4: train loss 27.75 ([27.74588388])\n",
      "11:24    Epoch 6: train loss 27.74 ([27.74161645])\n",
      "11:25    Epoch 8: train loss 27.74 ([27.74129904])\n",
      "11:25    Epoch 10: train loss 27.74 ([27.74305058])\n",
      "11:26    Epoch 12: train loss 27.74 ([27.74125471])\n",
      "11:27    Epoch 14: train loss 27.74 ([27.74130555])\n",
      "11:27    Epoch 16: train loss 27.74 ([27.74120216])\n",
      "11:28    Epoch 18: train loss 27.74 ([27.74110494])\n",
      "11:28    Epoch 20: train loss 27.74 ([27.74140642])\n",
      "11:28  Finished training\n",
      "11:28  Training estimator 5 / 20 in ensemble\n",
      "11:28  Starting training\n",
      "11:28    Method:                 sally\n",
      "11:28    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "11:28                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "11:28    Features:               [1]\n",
      "11:28    Method:                 sally\n",
      "11:28    Hidden layers:          (100, 100)\n",
      "11:28    Activation function:    tanh\n",
      "11:28    Batch size:             128\n",
      "11:28    Epochs:                 20\n",
      "11:28    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:28    Validation split:       None\n",
      "11:28    Early stopping:         True\n",
      "11:28  Loading training data\n",
      "11:28  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:28  Only using 1 of 29 observables\n",
      "11:28  Creating model for method sally\n",
      "11:28  Training model\n",
      "11:29    Epoch 2: train loss 17.95 ([17.95106008])\n",
      "11:30    Epoch 4: train loss 17.95 ([17.95151282])\n",
      "11:30    Epoch 6: train loss 17.95 ([17.95015175])\n",
      "11:31    Epoch 8: train loss 17.95 ([17.95012774])\n",
      "11:31    Epoch 10: train loss 17.95 ([17.94991483])\n",
      "11:32    Epoch 12: train loss 17.95 ([17.9512699])\n",
      "11:33    Epoch 14: train loss 17.95 ([17.94993325])\n",
      "11:33    Epoch 16: train loss 17.95 ([17.94984697])\n",
      "11:34    Epoch 18: train loss 17.95 ([17.94992711])\n",
      "11:34    Epoch 20: train loss 17.95 ([17.94980342])\n",
      "11:34  Finished training\n",
      "11:34  Training estimator 6 / 20 in ensemble\n",
      "11:34  Starting training\n",
      "11:34    Method:                 sally\n",
      "11:34    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:34                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n",
      "11:34    Features:               [1]\n",
      "11:34    Method:                 sally\n",
      "11:34    Hidden layers:          (100, 100)\n",
      "11:34    Activation function:    tanh\n",
      "11:34    Batch size:             128\n",
      "11:34    Epochs:                 20\n",
      "11:34    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:34    Validation split:       None\n",
      "11:34    Early stopping:         True\n",
      "11:34  Loading training data\n",
      "11:34  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:34  Only using 1 of 29 observables\n",
      "11:34  Creating model for method sally\n",
      "11:34  Training model\n",
      "11:35    Epoch 2: train loss 21.19 ([21.19221174])\n",
      "11:35    Epoch 4: train loss 21.19 ([21.19251303])\n",
      "11:36    Epoch 6: train loss 21.19 ([21.19148343])\n",
      "11:37    Epoch 8: train loss 21.19 ([21.19104368])\n",
      "11:37    Epoch 10: train loss 21.19 ([21.19115245])\n",
      "11:38    Epoch 12: train loss 21.19 ([21.19100685])\n",
      "11:38    Epoch 14: train loss 21.19 ([21.19126839])\n",
      "11:39    Epoch 16: train loss 21.19 ([21.19082692])\n",
      "11:39    Epoch 18: train loss 21.19 ([21.19153946])\n",
      "11:40    Epoch 20: train loss 21.19 ([21.19080616])\n",
      "11:40  Finished training\n",
      "11:40  Training estimator 7 / 20 in ensemble\n",
      "11:40  Starting training\n",
      "11:40    Method:                 sally\n",
      "11:40    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "11:40                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "11:40    Features:               [1]\n",
      "11:40    Method:                 sally\n",
      "11:40    Hidden layers:          (100, 100)\n",
      "11:40    Activation function:    tanh\n",
      "11:40    Batch size:             128\n",
      "11:40    Epochs:                 20\n",
      "11:40    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:40    Validation split:       None\n",
      "11:40    Early stopping:         True\n",
      "11:40  Loading training data\n",
      "11:40  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:40  Only using 1 of 29 observables\n",
      "11:40  Creating model for method sally\n",
      "11:40  Training model\n",
      "11:41    Epoch 2: train loss 15.92 ([15.92094327])\n",
      "11:41    Epoch 4: train loss 15.92 ([15.91986983])\n",
      "11:42    Epoch 6: train loss 15.92 ([15.9196496])\n",
      "11:42    Epoch 8: train loss 15.92 ([15.91958803])\n",
      "11:43    Epoch 10: train loss 15.92 ([15.92171174])\n",
      "11:43    Epoch 12: train loss 15.92 ([15.91943016])\n",
      "11:44    Epoch 14: train loss 15.92 ([15.91948132])\n",
      "11:44    Epoch 16: train loss 15.92 ([15.91968251])\n",
      "11:45    Epoch 18: train loss 15.92 ([15.91966007])\n",
      "11:45    Epoch 20: train loss 15.92 ([15.91961867])\n",
      "11:45  Finished training\n",
      "11:45  Training estimator 8 / 20 in ensemble\n",
      "11:45  Starting training\n",
      "11:45    Method:                 sally\n",
      "11:45    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "11:45                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "11:45    Features:               [1]\n",
      "11:45    Method:                 sally\n",
      "11:45    Hidden layers:          (100, 100)\n",
      "11:45    Activation function:    tanh\n",
      "11:45    Batch size:             128\n",
      "11:45    Epochs:                 20\n",
      "11:45    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:45    Validation split:       None\n",
      "11:45    Early stopping:         True\n",
      "11:45  Loading training data\n",
      "11:46  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:46  Only using 1 of 29 observables\n",
      "11:46  Creating model for method sally\n",
      "11:46  Training model\n",
      "11:46    Epoch 2: train loss 27.63 ([27.62502728])\n",
      "11:47    Epoch 4: train loss 27.62 ([27.62332811])\n",
      "11:47    Epoch 6: train loss 27.62 ([27.62286531])\n",
      "11:48    Epoch 8: train loss 27.62 ([27.62308846])\n",
      "11:49    Epoch 10: train loss 27.62 ([27.6229147])\n",
      "11:49    Epoch 12: train loss 27.62 ([27.62297548])\n",
      "11:50    Epoch 14: train loss 27.62 ([27.62276867])\n",
      "11:50    Epoch 16: train loss 27.62 ([27.62250285])\n",
      "11:51    Epoch 18: train loss 27.62 ([27.62247251])\n",
      "11:52    Epoch 20: train loss 27.62 ([27.62257715])\n",
      "11:52  Finished training\n",
      "11:52  Training estimator 9 / 20 in ensemble\n",
      "11:52  Starting training\n",
      "11:52    Method:                 sally\n",
      "11:52    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "11:52                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "11:52    Features:               [1]\n",
      "11:52    Method:                 sally\n",
      "11:52    Hidden layers:          (100, 100)\n",
      "11:52    Activation function:    tanh\n",
      "11:52    Batch size:             128\n",
      "11:52    Epochs:                 20\n",
      "11:52    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:52    Validation split:       None\n",
      "11:52    Early stopping:         True\n",
      "11:52  Loading training data\n",
      "11:52  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:52  Only using 1 of 29 observables\n",
      "11:52  Creating model for method sally\n",
      "11:52  Training model\n",
      "11:52    Epoch 2: train loss 21.00 ([20.99571269])\n",
      "11:53    Epoch 4: train loss 21.00 ([20.99525582])\n",
      "11:54    Epoch 6: train loss 21.00 ([20.995735])\n",
      "11:54    Epoch 8: train loss 21.04 ([21.04257136])\n",
      "11:55    Epoch 10: train loss 20.99 ([20.99482266])\n",
      "11:55    Epoch 12: train loss 20.99 ([20.99467636])\n",
      "11:56    Epoch 14: train loss 20.99 ([20.99477334])\n",
      "11:57    Epoch 16: train loss 20.99 ([20.99467132])\n",
      "11:57    Epoch 18: train loss 20.99 ([20.99445867])\n",
      "11:58    Epoch 20: train loss 20.99 ([20.99456752])\n",
      "11:58  Finished training\n",
      "11:58  Training estimator 10 / 20 in ensemble\n",
      "11:58  Starting training\n",
      "11:58    Method:                 sally\n",
      "11:58    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "11:58                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "11:58    Features:               [1]\n",
      "11:58    Method:                 sally\n",
      "11:58    Hidden layers:          (100, 100)\n",
      "11:58    Activation function:    tanh\n",
      "11:58    Batch size:             128\n",
      "11:58    Epochs:                 20\n",
      "11:58    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:58    Validation split:       None\n",
      "11:58    Early stopping:         True\n",
      "11:58  Loading training data\n",
      "11:58  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:58  Only using 1 of 29 observables\n",
      "11:58  Creating model for method sally\n",
      "11:58  Training model\n",
      "11:59    Epoch 2: train loss 47.35 ([47.34570711])\n",
      "11:59    Epoch 4: train loss 47.34 ([47.3422581])\n",
      "12:00    Epoch 6: train loss 47.34 ([47.34209166])\n",
      "12:00    Epoch 8: train loss 47.34 ([47.34156634])\n",
      "12:01    Epoch 10: train loss 47.34 ([47.34195112])\n",
      "12:02    Epoch 12: train loss 47.34 ([47.34135369])\n",
      "12:02    Epoch 14: train loss 47.34 ([47.34133939])\n",
      "12:03    Epoch 16: train loss 47.34 ([47.34135332])\n",
      "12:04    Epoch 18: train loss 47.34 ([47.34132906])\n",
      "12:04    Epoch 20: train loss 47.34 ([47.34208641])\n",
      "12:04  Finished training\n",
      "12:04  Training estimator 11 / 20 in ensemble\n",
      "12:04  Starting training\n",
      "12:04    Method:                 sally\n",
      "12:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_10.npy\n",
      "12:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_10.npy\n",
      "12:04    Features:               [1]\n",
      "12:04    Method:                 sally\n",
      "12:04    Hidden layers:          (100, 100)\n",
      "12:04    Activation function:    tanh\n",
      "12:04    Batch size:             128\n",
      "12:04    Epochs:                 20\n",
      "12:04    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:04    Validation split:       None\n",
      "12:04    Early stopping:         True\n",
      "12:04  Loading training data\n",
      "12:04  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:04  Only using 1 of 29 observables\n",
      "12:04  Creating model for method sally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04  Training model\n",
      "12:05    Epoch 2: train loss 16.98 ([16.98112871])\n",
      "12:06    Epoch 4: train loss 16.98 ([16.98463492])\n",
      "12:06    Epoch 6: train loss 16.98 ([16.98014126])\n",
      "12:07    Epoch 8: train loss 16.98 ([16.97981663])\n",
      "12:07    Epoch 10: train loss 16.98 ([16.9799963])\n",
      "12:08    Epoch 12: train loss 16.98 ([16.97987424])\n",
      "12:09    Epoch 14: train loss 16.98 ([16.97992094])\n",
      "12:09    Epoch 16: train loss 16.98 ([16.97983235])\n",
      "12:10    Epoch 18: train loss 16.98 ([16.98039699])\n",
      "12:11    Epoch 20: train loss 16.98 ([16.98443322])\n",
      "12:11  Finished training\n",
      "12:11  Training estimator 12 / 20 in ensemble\n",
      "12:11  Starting training\n",
      "12:11    Method:                 sally\n",
      "12:11    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_11.npy\n",
      "12:11                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_11.npy\n",
      "12:11    Features:               [1]\n",
      "12:11    Method:                 sally\n",
      "12:11    Hidden layers:          (100, 100)\n",
      "12:11    Activation function:    tanh\n",
      "12:11    Batch size:             128\n",
      "12:11    Epochs:                 20\n",
      "12:11    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:11    Validation split:       None\n",
      "12:11    Early stopping:         True\n",
      "12:11  Loading training data\n",
      "12:11  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:11  Only using 1 of 29 observables\n",
      "12:11  Creating model for method sally\n",
      "12:11  Training model\n",
      "12:11    Epoch 2: train loss 17.47 ([17.46792801])\n",
      "12:12    Epoch 4: train loss 17.47 ([17.4656623])\n",
      "12:13    Epoch 6: train loss 17.47 ([17.46545986])\n",
      "12:13    Epoch 8: train loss 17.47 ([17.46537127])\n",
      "12:14    Epoch 10: train loss 17.47 ([17.46574357])\n",
      "12:15    Epoch 12: train loss 17.47 ([17.46745447])\n",
      "12:15    Epoch 14: train loss 17.47 ([17.46520044])\n",
      "12:16    Epoch 16: train loss 17.47 ([17.46509459])\n",
      "12:17    Epoch 18: train loss 17.47 ([17.46512855])\n",
      "12:17    Epoch 20: train loss 17.47 ([17.46505329])\n",
      "12:17  Finished training\n",
      "12:17  Training estimator 13 / 20 in ensemble\n",
      "12:17  Starting training\n",
      "12:17    Method:                 sally\n",
      "12:17    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_12.npy\n",
      "12:17                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_12.npy\n",
      "12:17    Features:               [1]\n",
      "12:17    Method:                 sally\n",
      "12:17    Hidden layers:          (100, 100)\n",
      "12:17    Activation function:    tanh\n",
      "12:17    Batch size:             128\n",
      "12:17    Epochs:                 20\n",
      "12:17    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:17    Validation split:       None\n",
      "12:17    Early stopping:         True\n",
      "12:17  Loading training data\n",
      "12:17  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:17  Only using 1 of 29 observables\n",
      "12:17  Creating model for method sally\n",
      "12:17  Training model\n",
      "12:18    Epoch 2: train loss 18.13 ([18.12567315])\n",
      "12:19    Epoch 4: train loss 18.12 ([18.12495748])\n",
      "12:19    Epoch 6: train loss 18.13 ([18.1259082])\n",
      "12:20    Epoch 8: train loss 18.12 ([18.12459854])\n",
      "12:21    Epoch 10: train loss 18.12 ([18.12450647])\n",
      "12:21    Epoch 12: train loss 18.12 ([18.1244777])\n",
      "12:22    Epoch 14: train loss 18.12 ([18.12434567])\n",
      "12:23    Epoch 16: train loss 18.12 ([18.12442598])\n",
      "12:23    Epoch 18: train loss 18.12 ([18.12438202])\n",
      "12:24    Epoch 20: train loss 18.12 ([18.1245684])\n",
      "12:24  Finished training\n",
      "12:24  Training estimator 14 / 20 in ensemble\n",
      "12:24  Starting training\n",
      "12:24    Method:                 sally\n",
      "12:24    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_13.npy\n",
      "12:24                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_13.npy\n",
      "12:24    Features:               [1]\n",
      "12:24    Method:                 sally\n",
      "12:24    Hidden layers:          (100, 100)\n",
      "12:24    Activation function:    tanh\n",
      "12:24    Batch size:             128\n",
      "12:24    Epochs:                 20\n",
      "12:24    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:24    Validation split:       None\n",
      "12:24    Early stopping:         True\n",
      "12:24  Loading training data\n",
      "12:24  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:24  Only using 1 of 29 observables\n",
      "12:24  Creating model for method sally\n",
      "12:24  Training model\n",
      "12:25    Epoch 2: train loss 12.50 ([12.49768012])\n",
      "12:25    Epoch 4: train loss 12.49 ([12.49340007])\n",
      "12:26    Epoch 6: train loss 12.49 ([12.49314331])\n",
      "12:27    Epoch 8: train loss 12.49 ([12.49304075])\n",
      "12:27    Epoch 10: train loss 12.49 ([12.49300122])\n",
      "12:28    Epoch 12: train loss 12.49 ([12.49301863])\n",
      "12:29    Epoch 14: train loss 12.49 ([12.49293851])\n",
      "12:29    Epoch 16: train loss 12.49 ([12.49280905])\n",
      "12:30    Epoch 18: train loss 12.49 ([12.49282401])\n",
      "12:30    Epoch 20: train loss 12.49 ([12.49276028])\n",
      "12:30  Finished training\n",
      "12:30  Training estimator 15 / 20 in ensemble\n",
      "12:30  Starting training\n",
      "12:30    Method:                 sally\n",
      "12:30    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_14.npy\n",
      "12:30                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_14.npy\n",
      "12:30    Features:               [1]\n",
      "12:30    Method:                 sally\n",
      "12:30    Hidden layers:          (100, 100)\n",
      "12:30    Activation function:    tanh\n",
      "12:30    Batch size:             128\n",
      "12:30    Epochs:                 20\n",
      "12:30    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:30    Validation split:       None\n",
      "12:30    Early stopping:         True\n",
      "12:30  Loading training data\n",
      "12:30  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:30  Only using 1 of 29 observables\n",
      "12:30  Creating model for method sally\n",
      "12:30  Training model\n",
      "12:31    Epoch 2: train loss 22.65 ([22.65026793])\n",
      "12:32    Epoch 4: train loss 22.62 ([22.61562863])\n",
      "12:33    Epoch 6: train loss 22.62 ([22.61535412])\n",
      "12:33    Epoch 8: train loss 22.62 ([22.61535214])\n",
      "12:34    Epoch 10: train loss 22.62 ([22.61515257])\n",
      "12:35    Epoch 12: train loss 22.62 ([22.61513736])\n",
      "12:35    Epoch 14: train loss 22.62 ([22.61503325])\n",
      "12:36    Epoch 16: train loss 22.62 ([22.61508229])\n",
      "12:37    Epoch 18: train loss 22.62 ([22.61515565])\n",
      "12:37    Epoch 20: train loss 22.62 ([22.61500537])\n",
      "12:37  Finished training\n",
      "12:37  Training estimator 16 / 20 in ensemble\n",
      "12:37  Starting training\n",
      "12:37    Method:                 sally\n",
      "12:37    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_15.npy\n",
      "12:37                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_15.npy\n",
      "12:37    Features:               [1]\n",
      "12:37    Method:                 sally\n",
      "12:37    Hidden layers:          (100, 100)\n",
      "12:37    Activation function:    tanh\n",
      "12:37    Batch size:             128\n",
      "12:37    Epochs:                 20\n",
      "12:37    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:37    Validation split:       None\n",
      "12:37    Early stopping:         True\n",
      "12:37  Loading training data\n",
      "12:37  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:37  Only using 1 of 29 observables\n",
      "12:37  Creating model for method sally\n",
      "12:37  Training model\n",
      "12:38    Epoch 2: train loss 15.56 ([15.5556305])\n",
      "12:39    Epoch 4: train loss 15.55 ([15.55443953])\n",
      "12:40    Epoch 6: train loss 15.55 ([15.55429548])\n",
      "12:41    Epoch 8: train loss 15.56 ([15.55544278])\n",
      "12:41    Epoch 10: train loss 15.55 ([15.55491165])\n",
      "12:42    Epoch 12: train loss 15.55 ([15.55400466])\n",
      "12:43    Epoch 14: train loss 15.55 ([15.55408081])\n",
      "12:43    Epoch 16: train loss 15.55 ([15.55432158])\n",
      "12:44    Epoch 18: train loss 15.55 ([15.55381881])\n",
      "12:45    Epoch 20: train loss 15.55 ([15.55385492])\n",
      "12:45  Finished training\n",
      "12:45  Training estimator 17 / 20 in ensemble\n",
      "12:45  Starting training\n",
      "12:45    Method:                 sally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:45    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_16.npy\n",
      "12:45                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_16.npy\n",
      "12:45    Features:               [1]\n",
      "12:45    Method:                 sally\n",
      "12:45    Hidden layers:          (100, 100)\n",
      "12:45    Activation function:    tanh\n",
      "12:45    Batch size:             128\n",
      "12:45    Epochs:                 20\n",
      "12:45    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:45    Validation split:       None\n",
      "12:45    Early stopping:         True\n",
      "12:45  Loading training data\n",
      "12:45  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:45  Only using 1 of 29 observables\n",
      "12:45  Creating model for method sally\n",
      "12:45  Training model\n",
      "12:45    Epoch 2: train loss 17.44 ([17.43560842])\n",
      "12:46    Epoch 4: train loss 17.44 ([17.43956035])\n",
      "12:47    Epoch 6: train loss 17.43 ([17.43409762])\n",
      "12:47    Epoch 8: train loss 17.43 ([17.43409621])\n",
      "12:48    Epoch 10: train loss 17.43 ([17.43381232])\n",
      "12:49    Epoch 12: train loss 17.43 ([17.43384123])\n",
      "12:49    Epoch 14: train loss 17.45 ([17.45373089])\n",
      "12:50    Epoch 16: train loss 17.43 ([17.43397139])\n",
      "12:50    Epoch 18: train loss 17.43 ([17.43363568])\n",
      "12:51    Epoch 20: train loss 17.43 ([17.43392368])\n",
      "12:51  Finished training\n",
      "12:51  Training estimator 18 / 20 in ensemble\n",
      "12:51  Starting training\n",
      "12:51    Method:                 sally\n",
      "12:51    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_17.npy\n",
      "12:51                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_17.npy\n",
      "12:51    Features:               [1]\n",
      "12:51    Method:                 sally\n",
      "12:51    Hidden layers:          (100, 100)\n",
      "12:51    Activation function:    tanh\n",
      "12:51    Batch size:             128\n",
      "12:51    Epochs:                 20\n",
      "12:51    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:51    Validation split:       None\n",
      "12:51    Early stopping:         True\n",
      "12:51  Loading training data\n",
      "12:51  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:51  Only using 1 of 29 observables\n",
      "12:51  Creating model for method sally\n",
      "12:51  Training model\n",
      "12:52    Epoch 2: train loss 18.09 ([18.08685307])\n",
      "12:52    Epoch 4: train loss 18.09 ([18.08539492])\n",
      "12:53    Epoch 6: train loss 18.09 ([18.08537795])\n",
      "12:54    Epoch 8: train loss 18.09 ([18.0876684])\n",
      "12:54    Epoch 10: train loss 18.09 ([18.08514285])\n",
      "12:55    Epoch 12: train loss 18.09 ([18.08502516])\n",
      "12:55    Epoch 14: train loss 18.08 ([18.08499882])\n",
      "12:56    Epoch 16: train loss 18.08 ([18.08490909])\n",
      "12:57    Epoch 18: train loss 18.09 ([18.08521315])\n",
      "12:57    Epoch 20: train loss 18.08 ([18.08488764])\n",
      "12:57  Finished training\n",
      "12:57  Training estimator 19 / 20 in ensemble\n",
      "12:57  Starting training\n",
      "12:57    Method:                 sally\n",
      "12:57    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_18.npy\n",
      "12:57                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_18.npy\n",
      "12:57    Features:               [1]\n",
      "12:57    Method:                 sally\n",
      "12:57    Hidden layers:          (100, 100)\n",
      "12:57    Activation function:    tanh\n",
      "12:57    Batch size:             128\n",
      "12:57    Epochs:                 20\n",
      "12:57    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:57    Validation split:       None\n",
      "12:57    Early stopping:         True\n",
      "12:57  Loading training data\n",
      "12:57  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:57  Only using 1 of 29 observables\n",
      "12:57  Creating model for method sally\n",
      "12:57  Training model\n",
      "12:58    Epoch 2: train loss 44.28 ([44.27728584])\n",
      "12:59    Epoch 4: train loss 44.28 ([44.28225489])\n",
      "12:59    Epoch 6: train loss 44.28 ([44.27501917])\n",
      "13:00    Epoch 8: train loss 44.28 ([44.27500417])\n",
      "13:00    Epoch 10: train loss 44.27 ([44.27469442])\n",
      "13:01    Epoch 12: train loss 44.28 ([44.27549578])\n",
      "13:02    Epoch 14: train loss 44.27 ([44.27459602])\n",
      "13:02    Epoch 16: train loss 44.27 ([44.2747975])\n",
      "13:03    Epoch 18: train loss 44.27 ([44.2745308])\n",
      "13:04    Epoch 20: train loss 44.27 ([44.27437662])\n",
      "13:04  Finished training\n",
      "13:04  Training estimator 20 / 20 in ensemble\n",
      "13:04  Starting training\n",
      "13:04    Method:                 sally\n",
      "13:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_19.npy\n",
      "13:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_19.npy\n",
      "13:04    Features:               [1]\n",
      "13:04    Method:                 sally\n",
      "13:04    Hidden layers:          (100, 100)\n",
      "13:04    Activation function:    tanh\n",
      "13:04    Batch size:             128\n",
      "13:04    Epochs:                 20\n",
      "13:04    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "13:04    Validation split:       None\n",
      "13:04    Early stopping:         True\n",
      "13:04  Loading training data\n",
      "13:04  Found 1000000 samples with 2 parameters and 29 observables\n",
      "13:04  Only using 1 of 29 observables\n",
      "13:04  Creating model for method sally\n",
      "13:04  Training model\n",
      "13:04    Epoch 2: train loss 15.77 ([15.77151131])\n",
      "13:05    Epoch 4: train loss 15.77 ([15.77375038])\n",
      "13:06    Epoch 6: train loss 15.77 ([15.7705007])\n",
      "13:06    Epoch 8: train loss 15.77 ([15.77049379])\n",
      "13:07    Epoch 10: train loss 15.77 ([15.77044886])\n",
      "13:08    Epoch 12: train loss 15.77 ([15.77031398])\n",
      "13:08    Epoch 14: train loss 15.77 ([15.77048181])\n",
      "13:09    Epoch 16: train loss 15.77 ([15.77024315])\n",
      "13:10    Epoch 18: train loss 15.77 ([15.77040132])\n",
      "13:10    Epoch 20: train loss 15.77 ([15.77035885])\n",
      "13:10  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble_dummy = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_dummy.train_all(\n",
    "    features=[ [1] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "cbfb4bf2-14a0-4b4c-a0f2-d2bd6484ef0d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:10  Calculating expectation for 20 estimators in ensemble\n",
      "13:10  Starting evaluation for estimator 1 / 20 in ensemble\n",
      "13:10  Loading evaluation data\n",
      "13:10  Starting score evaluation\n",
      "13:10  Starting evaluation for estimator 2 / 20 in ensemble\n",
      "13:10  Loading evaluation data\n",
      "13:10  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 3 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 4 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 5 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 6 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 7 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 8 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 9 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 10 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 11 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 12 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 13 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 14 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 15 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 16 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 17 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 18 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 19 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 20 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00308524, -0.00076297],\n",
       "       [ 0.00268906,  0.00290275],\n",
       "       [-0.004977  , -0.00132313],\n",
       "       [-0.00113649,  0.00535215],\n",
       "       [ 0.00422012,  0.00442748],\n",
       "       [-0.00161387,  0.00147769],\n",
       "       [ 0.00109053, -0.00408648],\n",
       "       [-0.00747247, -0.0048116 ],\n",
       "       [ 0.00667167,  0.00630002],\n",
       "       [ 0.00315804, -0.00579965],\n",
       "       [ 0.0108441 ,  0.00135383],\n",
       "       [ 0.00186662,  0.00564121],\n",
       "       [ 0.01288694, -0.0057633 ],\n",
       "       [-0.00887028, -0.00661671],\n",
       "       [-0.00691695, -0.00211028],\n",
       "       [-0.00157362,  0.00148581],\n",
       "       [ 0.00136739, -0.00128104],\n",
       "       [-0.00278229,  0.0009701 ],\n",
       "       [-0.01158568,  0.00037303],\n",
       "       [ 0.00571575,  0.00030452]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_dummy.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "07ca6a5c-68f8-4b09-aef8-b2bfc40d47e0"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14  Saving ensemble setup to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/ensemble.json\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_0_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_0_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_1_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_1_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_2_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_2_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_3_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_3_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_4_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_4_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_5_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_5_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_6_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_6_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_7_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_7_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_8_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_8_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_9_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_9_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_10_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_10_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_11_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_11_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_12_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_12_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_13_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_13_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_14_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_14_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_15_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_15_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_16_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_16_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_17_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_17_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_18_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_18_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_19_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_19_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "ensemble_dummy.save(model_dir + 'sally_ensemble_dummy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c0e6b85f-dbf0-4145-826f-d27b57ebcd85"
    }
   },
   "source": [
    "## 1d toy study (resurrection phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "7d39c984-d4a3-4f99-86d2-f5a6cf339bb4"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:04  \n",
      "11:04  ------------------------------------------------------------\n",
      "11:04  |                                                          |\n",
      "11:04  |  MadMiner v2018.10.30                                    |\n",
      "11:04  |                                                          |\n",
      "11:04  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "11:04  |                                                          |\n",
      "11:04  ------------------------------------------------------------\n",
      "11:04  \n",
      "11:04  Training 20 estimators in ensemble\n",
      "11:04  Training estimator 1 / 20 in ensemble\n",
      "11:04  Starting training\n",
      "11:04    Method:                 sally\n",
      "11:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_0.npy\n",
      "11:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_0.npy\n",
      "11:04    Features:               [1]\n",
      "11:04    Method:                 sally\n",
      "11:04    Hidden layers:          (100, 100)\n",
      "11:04    Activation function:    tanh\n",
      "11:04    Batch size:             128\n",
      "11:04    Epochs:                 20\n",
      "11:04    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:04    Validation split:       None\n",
      "11:04    Early stopping:         True\n",
      "11:04  Loading training data\n",
      "11:04  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:04  Only using 1 of 29 observables\n",
      "11:04  Creating model for method sally\n",
      "11:04  Training model\n",
      "11:05    Epoch 2: train loss 18.52 ([18.52374802])\n",
      "11:05    Epoch 4: train loss 18.52 ([18.52294244])\n",
      "11:06    Epoch 6: train loss 18.52 ([18.52289469])\n",
      "11:07    Epoch 8: train loss 18.53 ([18.52784848])\n",
      "11:07    Epoch 10: train loss 18.52 ([18.52249176])\n",
      "11:08    Epoch 12: train loss 18.52 ([18.52252913])\n",
      "11:08    Epoch 14: train loss 18.52 ([18.52238263])\n",
      "11:09    Epoch 16: train loss 18.52 ([18.52242407])\n",
      "11:10    Epoch 18: train loss 18.52 ([18.52237293])\n",
      "11:10    Epoch 20: train loss 18.52 ([18.52239447])\n",
      "11:10  Finished training\n",
      "11:10  Training estimator 2 / 20 in ensemble\n",
      "11:10  Starting training\n",
      "11:10    Method:                 sally\n",
      "11:10    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_1.npy\n",
      "11:10                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_1.npy\n",
      "11:10    Features:               [1]\n",
      "11:10    Method:                 sally\n",
      "11:10    Hidden layers:          (100, 100)\n",
      "11:10    Activation function:    tanh\n",
      "11:10    Batch size:             128\n",
      "11:10    Epochs:                 20\n",
      "11:10    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:10    Validation split:       None\n",
      "11:10    Early stopping:         True\n",
      "11:10  Loading training data\n",
      "11:10  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:10  Only using 1 of 29 observables\n",
      "11:10  Creating model for method sally\n",
      "11:10  Training model\n",
      "11:11    Epoch 2: train loss 15.96 ([15.95513858])\n",
      "11:12    Epoch 4: train loss 15.95 ([15.95463728])\n",
      "11:12    Epoch 6: train loss 15.95 ([15.95426543])\n",
      "11:13    Epoch 8: train loss 15.95 ([15.95437507])\n",
      "11:13    Epoch 10: train loss 15.95 ([15.95425704])\n",
      "11:14    Epoch 12: train loss 15.95 ([15.95484461])\n",
      "11:15    Epoch 14: train loss 15.95 ([15.95390924])\n",
      "11:15    Epoch 16: train loss 15.95 ([15.95389801])\n",
      "11:16    Epoch 18: train loss 15.95 ([15.95397426])\n",
      "11:16    Epoch 20: train loss 15.95 ([15.95379247])\n",
      "11:16  Finished training\n",
      "11:16  Training estimator 3 / 20 in ensemble\n",
      "11:16  Starting training\n",
      "11:16    Method:                 sally\n",
      "11:16    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_2.npy\n",
      "11:16                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_2.npy\n",
      "11:16    Features:               [1]\n",
      "11:16    Method:                 sally\n",
      "11:16    Hidden layers:          (100, 100)\n",
      "11:16    Activation function:    tanh\n",
      "11:16    Batch size:             128\n",
      "11:16    Epochs:                 20\n",
      "11:16    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:16    Validation split:       None\n",
      "11:16    Early stopping:         True\n",
      "11:16  Loading training data\n",
      "11:16  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:16  Only using 1 of 29 observables\n",
      "11:16  Creating model for method sally\n",
      "11:16  Training model\n",
      "11:17    Epoch 2: train loss 53.47 ([53.4699199])\n",
      "11:18    Epoch 4: train loss 53.46 ([53.4645769])\n",
      "11:18    Epoch 6: train loss 53.46 ([53.46405087])\n",
      "11:19    Epoch 8: train loss 53.46 ([53.46384805])\n",
      "11:19    Epoch 10: train loss 53.46 ([53.46354067])\n",
      "11:20    Epoch 12: train loss 53.46 ([53.46356866])\n",
      "11:21    Epoch 14: train loss 53.46 ([53.46381292])\n",
      "11:21    Epoch 16: train loss 53.46 ([53.46359967])\n",
      "11:22    Epoch 18: train loss 53.46 ([53.46353044])\n",
      "11:22    Epoch 20: train loss 53.46 ([53.46338894])\n",
      "11:22  Finished training\n",
      "11:22  Training estimator 4 / 20 in ensemble\n",
      "11:22  Starting training\n",
      "11:22    Method:                 sally\n",
      "11:22    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_3.npy\n",
      "11:22                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_3.npy\n",
      "11:22    Features:               [1]\n",
      "11:22    Method:                 sally\n",
      "11:22    Hidden layers:          (100, 100)\n",
      "11:22    Activation function:    tanh\n",
      "11:22    Batch size:             128\n",
      "11:22    Epochs:                 20\n",
      "11:22    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:22    Validation split:       None\n",
      "11:22    Early stopping:         True\n",
      "11:22  Loading training data\n",
      "11:22  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:22  Only using 1 of 29 observables\n",
      "11:22  Creating model for method sally\n",
      "11:22  Training model\n",
      "11:23    Epoch 2: train loss 27.74 ([27.74347513])\n",
      "11:24    Epoch 4: train loss 27.75 ([27.74588388])\n",
      "11:24    Epoch 6: train loss 27.74 ([27.74161645])\n",
      "11:25    Epoch 8: train loss 27.74 ([27.74129904])\n",
      "11:25    Epoch 10: train loss 27.74 ([27.74305058])\n",
      "11:26    Epoch 12: train loss 27.74 ([27.74125471])\n",
      "11:27    Epoch 14: train loss 27.74 ([27.74130555])\n",
      "11:27    Epoch 16: train loss 27.74 ([27.74120216])\n",
      "11:28    Epoch 18: train loss 27.74 ([27.74110494])\n",
      "11:28    Epoch 20: train loss 27.74 ([27.74140642])\n",
      "11:28  Finished training\n",
      "11:28  Training estimator 5 / 20 in ensemble\n",
      "11:28  Starting training\n",
      "11:28    Method:                 sally\n",
      "11:28    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_4.npy\n",
      "11:28                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_4.npy\n",
      "11:28    Features:               [1]\n",
      "11:28    Method:                 sally\n",
      "11:28    Hidden layers:          (100, 100)\n",
      "11:28    Activation function:    tanh\n",
      "11:28    Batch size:             128\n",
      "11:28    Epochs:                 20\n",
      "11:28    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:28    Validation split:       None\n",
      "11:28    Early stopping:         True\n",
      "11:28  Loading training data\n",
      "11:28  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:28  Only using 1 of 29 observables\n",
      "11:28  Creating model for method sally\n",
      "11:28  Training model\n",
      "11:29    Epoch 2: train loss 17.95 ([17.95106008])\n",
      "11:30    Epoch 4: train loss 17.95 ([17.95151282])\n",
      "11:30    Epoch 6: train loss 17.95 ([17.95015175])\n",
      "11:31    Epoch 8: train loss 17.95 ([17.95012774])\n",
      "11:31    Epoch 10: train loss 17.95 ([17.94991483])\n",
      "11:32    Epoch 12: train loss 17.95 ([17.9512699])\n",
      "11:33    Epoch 14: train loss 17.95 ([17.94993325])\n",
      "11:33    Epoch 16: train loss 17.95 ([17.94984697])\n",
      "11:34    Epoch 18: train loss 17.95 ([17.94992711])\n",
      "11:34    Epoch 20: train loss 17.95 ([17.94980342])\n",
      "11:34  Finished training\n",
      "11:34  Training estimator 6 / 20 in ensemble\n",
      "11:34  Starting training\n",
      "11:34    Method:                 sally\n",
      "11:34    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_5.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:34                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_5.npy\n",
      "11:34    Features:               [1]\n",
      "11:34    Method:                 sally\n",
      "11:34    Hidden layers:          (100, 100)\n",
      "11:34    Activation function:    tanh\n",
      "11:34    Batch size:             128\n",
      "11:34    Epochs:                 20\n",
      "11:34    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:34    Validation split:       None\n",
      "11:34    Early stopping:         True\n",
      "11:34  Loading training data\n",
      "11:34  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:34  Only using 1 of 29 observables\n",
      "11:34  Creating model for method sally\n",
      "11:34  Training model\n",
      "11:35    Epoch 2: train loss 21.19 ([21.19221174])\n",
      "11:35    Epoch 4: train loss 21.19 ([21.19251303])\n",
      "11:36    Epoch 6: train loss 21.19 ([21.19148343])\n",
      "11:37    Epoch 8: train loss 21.19 ([21.19104368])\n",
      "11:37    Epoch 10: train loss 21.19 ([21.19115245])\n",
      "11:38    Epoch 12: train loss 21.19 ([21.19100685])\n",
      "11:38    Epoch 14: train loss 21.19 ([21.19126839])\n",
      "11:39    Epoch 16: train loss 21.19 ([21.19082692])\n",
      "11:39    Epoch 18: train loss 21.19 ([21.19153946])\n",
      "11:40    Epoch 20: train loss 21.19 ([21.19080616])\n",
      "11:40  Finished training\n",
      "11:40  Training estimator 7 / 20 in ensemble\n",
      "11:40  Starting training\n",
      "11:40    Method:                 sally\n",
      "11:40    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_6.npy\n",
      "11:40                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_6.npy\n",
      "11:40    Features:               [1]\n",
      "11:40    Method:                 sally\n",
      "11:40    Hidden layers:          (100, 100)\n",
      "11:40    Activation function:    tanh\n",
      "11:40    Batch size:             128\n",
      "11:40    Epochs:                 20\n",
      "11:40    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:40    Validation split:       None\n",
      "11:40    Early stopping:         True\n",
      "11:40  Loading training data\n",
      "11:40  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:40  Only using 1 of 29 observables\n",
      "11:40  Creating model for method sally\n",
      "11:40  Training model\n",
      "11:41    Epoch 2: train loss 15.92 ([15.92094327])\n",
      "11:41    Epoch 4: train loss 15.92 ([15.91986983])\n",
      "11:42    Epoch 6: train loss 15.92 ([15.9196496])\n",
      "11:42    Epoch 8: train loss 15.92 ([15.91958803])\n",
      "11:43    Epoch 10: train loss 15.92 ([15.92171174])\n",
      "11:43    Epoch 12: train loss 15.92 ([15.91943016])\n",
      "11:44    Epoch 14: train loss 15.92 ([15.91948132])\n",
      "11:44    Epoch 16: train loss 15.92 ([15.91968251])\n",
      "11:45    Epoch 18: train loss 15.92 ([15.91966007])\n",
      "11:45    Epoch 20: train loss 15.92 ([15.91961867])\n",
      "11:45  Finished training\n",
      "11:45  Training estimator 8 / 20 in ensemble\n",
      "11:45  Starting training\n",
      "11:45    Method:                 sally\n",
      "11:45    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_7.npy\n",
      "11:45                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_7.npy\n",
      "11:45    Features:               [1]\n",
      "11:45    Method:                 sally\n",
      "11:45    Hidden layers:          (100, 100)\n",
      "11:45    Activation function:    tanh\n",
      "11:45    Batch size:             128\n",
      "11:45    Epochs:                 20\n",
      "11:45    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:45    Validation split:       None\n",
      "11:45    Early stopping:         True\n",
      "11:45  Loading training data\n",
      "11:46  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:46  Only using 1 of 29 observables\n",
      "11:46  Creating model for method sally\n",
      "11:46  Training model\n",
      "11:46    Epoch 2: train loss 27.63 ([27.62502728])\n",
      "11:47    Epoch 4: train loss 27.62 ([27.62332811])\n",
      "11:47    Epoch 6: train loss 27.62 ([27.62286531])\n",
      "11:48    Epoch 8: train loss 27.62 ([27.62308846])\n",
      "11:49    Epoch 10: train loss 27.62 ([27.6229147])\n",
      "11:49    Epoch 12: train loss 27.62 ([27.62297548])\n",
      "11:50    Epoch 14: train loss 27.62 ([27.62276867])\n",
      "11:50    Epoch 16: train loss 27.62 ([27.62250285])\n",
      "11:51    Epoch 18: train loss 27.62 ([27.62247251])\n",
      "11:52    Epoch 20: train loss 27.62 ([27.62257715])\n",
      "11:52  Finished training\n",
      "11:52  Training estimator 9 / 20 in ensemble\n",
      "11:52  Starting training\n",
      "11:52    Method:                 sally\n",
      "11:52    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_8.npy\n",
      "11:52                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_8.npy\n",
      "11:52    Features:               [1]\n",
      "11:52    Method:                 sally\n",
      "11:52    Hidden layers:          (100, 100)\n",
      "11:52    Activation function:    tanh\n",
      "11:52    Batch size:             128\n",
      "11:52    Epochs:                 20\n",
      "11:52    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:52    Validation split:       None\n",
      "11:52    Early stopping:         True\n",
      "11:52  Loading training data\n",
      "11:52  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:52  Only using 1 of 29 observables\n",
      "11:52  Creating model for method sally\n",
      "11:52  Training model\n",
      "11:52    Epoch 2: train loss 21.00 ([20.99571269])\n",
      "11:53    Epoch 4: train loss 21.00 ([20.99525582])\n",
      "11:54    Epoch 6: train loss 21.00 ([20.995735])\n",
      "11:54    Epoch 8: train loss 21.04 ([21.04257136])\n",
      "11:55    Epoch 10: train loss 20.99 ([20.99482266])\n",
      "11:55    Epoch 12: train loss 20.99 ([20.99467636])\n",
      "11:56    Epoch 14: train loss 20.99 ([20.99477334])\n",
      "11:57    Epoch 16: train loss 20.99 ([20.99467132])\n",
      "11:57    Epoch 18: train loss 20.99 ([20.99445867])\n",
      "11:58    Epoch 20: train loss 20.99 ([20.99456752])\n",
      "11:58  Finished training\n",
      "11:58  Training estimator 10 / 20 in ensemble\n",
      "11:58  Starting training\n",
      "11:58    Method:                 sally\n",
      "11:58    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_9.npy\n",
      "11:58                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_9.npy\n",
      "11:58    Features:               [1]\n",
      "11:58    Method:                 sally\n",
      "11:58    Hidden layers:          (100, 100)\n",
      "11:58    Activation function:    tanh\n",
      "11:58    Batch size:             128\n",
      "11:58    Epochs:                 20\n",
      "11:58    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "11:58    Validation split:       None\n",
      "11:58    Early stopping:         True\n",
      "11:58  Loading training data\n",
      "11:58  Found 1000000 samples with 2 parameters and 29 observables\n",
      "11:58  Only using 1 of 29 observables\n",
      "11:58  Creating model for method sally\n",
      "11:58  Training model\n",
      "11:59    Epoch 2: train loss 47.35 ([47.34570711])\n",
      "11:59    Epoch 4: train loss 47.34 ([47.3422581])\n",
      "12:00    Epoch 6: train loss 47.34 ([47.34209166])\n",
      "12:00    Epoch 8: train loss 47.34 ([47.34156634])\n",
      "12:01    Epoch 10: train loss 47.34 ([47.34195112])\n",
      "12:02    Epoch 12: train loss 47.34 ([47.34135369])\n",
      "12:02    Epoch 14: train loss 47.34 ([47.34133939])\n",
      "12:03    Epoch 16: train loss 47.34 ([47.34135332])\n",
      "12:04    Epoch 18: train loss 47.34 ([47.34132906])\n",
      "12:04    Epoch 20: train loss 47.34 ([47.34208641])\n",
      "12:04  Finished training\n",
      "12:04  Training estimator 11 / 20 in ensemble\n",
      "12:04  Starting training\n",
      "12:04    Method:                 sally\n",
      "12:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_10.npy\n",
      "12:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_10.npy\n",
      "12:04    Features:               [1]\n",
      "12:04    Method:                 sally\n",
      "12:04    Hidden layers:          (100, 100)\n",
      "12:04    Activation function:    tanh\n",
      "12:04    Batch size:             128\n",
      "12:04    Epochs:                 20\n",
      "12:04    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:04    Validation split:       None\n",
      "12:04    Early stopping:         True\n",
      "12:04  Loading training data\n",
      "12:04  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:04  Only using 1 of 29 observables\n",
      "12:04  Creating model for method sally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04  Training model\n",
      "12:05    Epoch 2: train loss 16.98 ([16.98112871])\n",
      "12:06    Epoch 4: train loss 16.98 ([16.98463492])\n",
      "12:06    Epoch 6: train loss 16.98 ([16.98014126])\n",
      "12:07    Epoch 8: train loss 16.98 ([16.97981663])\n",
      "12:07    Epoch 10: train loss 16.98 ([16.9799963])\n",
      "12:08    Epoch 12: train loss 16.98 ([16.97987424])\n",
      "12:09    Epoch 14: train loss 16.98 ([16.97992094])\n",
      "12:09    Epoch 16: train loss 16.98 ([16.97983235])\n",
      "12:10    Epoch 18: train loss 16.98 ([16.98039699])\n",
      "12:11    Epoch 20: train loss 16.98 ([16.98443322])\n",
      "12:11  Finished training\n",
      "12:11  Training estimator 12 / 20 in ensemble\n",
      "12:11  Starting training\n",
      "12:11    Method:                 sally\n",
      "12:11    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_11.npy\n",
      "12:11                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_11.npy\n",
      "12:11    Features:               [1]\n",
      "12:11    Method:                 sally\n",
      "12:11    Hidden layers:          (100, 100)\n",
      "12:11    Activation function:    tanh\n",
      "12:11    Batch size:             128\n",
      "12:11    Epochs:                 20\n",
      "12:11    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:11    Validation split:       None\n",
      "12:11    Early stopping:         True\n",
      "12:11  Loading training data\n",
      "12:11  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:11  Only using 1 of 29 observables\n",
      "12:11  Creating model for method sally\n",
      "12:11  Training model\n",
      "12:11    Epoch 2: train loss 17.47 ([17.46792801])\n",
      "12:12    Epoch 4: train loss 17.47 ([17.4656623])\n",
      "12:13    Epoch 6: train loss 17.47 ([17.46545986])\n",
      "12:13    Epoch 8: train loss 17.47 ([17.46537127])\n",
      "12:14    Epoch 10: train loss 17.47 ([17.46574357])\n",
      "12:15    Epoch 12: train loss 17.47 ([17.46745447])\n",
      "12:15    Epoch 14: train loss 17.47 ([17.46520044])\n",
      "12:16    Epoch 16: train loss 17.47 ([17.46509459])\n",
      "12:17    Epoch 18: train loss 17.47 ([17.46512855])\n",
      "12:17    Epoch 20: train loss 17.47 ([17.46505329])\n",
      "12:17  Finished training\n",
      "12:17  Training estimator 13 / 20 in ensemble\n",
      "12:17  Starting training\n",
      "12:17    Method:                 sally\n",
      "12:17    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_12.npy\n",
      "12:17                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_12.npy\n",
      "12:17    Features:               [1]\n",
      "12:17    Method:                 sally\n",
      "12:17    Hidden layers:          (100, 100)\n",
      "12:17    Activation function:    tanh\n",
      "12:17    Batch size:             128\n",
      "12:17    Epochs:                 20\n",
      "12:17    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:17    Validation split:       None\n",
      "12:17    Early stopping:         True\n",
      "12:17  Loading training data\n",
      "12:17  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:17  Only using 1 of 29 observables\n",
      "12:17  Creating model for method sally\n",
      "12:17  Training model\n",
      "12:18    Epoch 2: train loss 18.13 ([18.12567315])\n",
      "12:19    Epoch 4: train loss 18.12 ([18.12495748])\n",
      "12:19    Epoch 6: train loss 18.13 ([18.1259082])\n",
      "12:20    Epoch 8: train loss 18.12 ([18.12459854])\n",
      "12:21    Epoch 10: train loss 18.12 ([18.12450647])\n",
      "12:21    Epoch 12: train loss 18.12 ([18.1244777])\n",
      "12:22    Epoch 14: train loss 18.12 ([18.12434567])\n",
      "12:23    Epoch 16: train loss 18.12 ([18.12442598])\n",
      "12:23    Epoch 18: train loss 18.12 ([18.12438202])\n",
      "12:24    Epoch 20: train loss 18.12 ([18.1245684])\n",
      "12:24  Finished training\n",
      "12:24  Training estimator 14 / 20 in ensemble\n",
      "12:24  Starting training\n",
      "12:24    Method:                 sally\n",
      "12:24    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_13.npy\n",
      "12:24                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_13.npy\n",
      "12:24    Features:               [1]\n",
      "12:24    Method:                 sally\n",
      "12:24    Hidden layers:          (100, 100)\n",
      "12:24    Activation function:    tanh\n",
      "12:24    Batch size:             128\n",
      "12:24    Epochs:                 20\n",
      "12:24    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:24    Validation split:       None\n",
      "12:24    Early stopping:         True\n",
      "12:24  Loading training data\n",
      "12:24  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:24  Only using 1 of 29 observables\n",
      "12:24  Creating model for method sally\n",
      "12:24  Training model\n",
      "12:25    Epoch 2: train loss 12.50 ([12.49768012])\n",
      "12:25    Epoch 4: train loss 12.49 ([12.49340007])\n",
      "12:26    Epoch 6: train loss 12.49 ([12.49314331])\n",
      "12:27    Epoch 8: train loss 12.49 ([12.49304075])\n",
      "12:27    Epoch 10: train loss 12.49 ([12.49300122])\n",
      "12:28    Epoch 12: train loss 12.49 ([12.49301863])\n",
      "12:29    Epoch 14: train loss 12.49 ([12.49293851])\n",
      "12:29    Epoch 16: train loss 12.49 ([12.49280905])\n",
      "12:30    Epoch 18: train loss 12.49 ([12.49282401])\n",
      "12:30    Epoch 20: train loss 12.49 ([12.49276028])\n",
      "12:30  Finished training\n",
      "12:30  Training estimator 15 / 20 in ensemble\n",
      "12:30  Starting training\n",
      "12:30    Method:                 sally\n",
      "12:30    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_14.npy\n",
      "12:30                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_14.npy\n",
      "12:30    Features:               [1]\n",
      "12:30    Method:                 sally\n",
      "12:30    Hidden layers:          (100, 100)\n",
      "12:30    Activation function:    tanh\n",
      "12:30    Batch size:             128\n",
      "12:30    Epochs:                 20\n",
      "12:30    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:30    Validation split:       None\n",
      "12:30    Early stopping:         True\n",
      "12:30  Loading training data\n",
      "12:30  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:30  Only using 1 of 29 observables\n",
      "12:30  Creating model for method sally\n",
      "12:30  Training model\n",
      "12:31    Epoch 2: train loss 22.65 ([22.65026793])\n",
      "12:32    Epoch 4: train loss 22.62 ([22.61562863])\n",
      "12:33    Epoch 6: train loss 22.62 ([22.61535412])\n",
      "12:33    Epoch 8: train loss 22.62 ([22.61535214])\n",
      "12:34    Epoch 10: train loss 22.62 ([22.61515257])\n",
      "12:35    Epoch 12: train loss 22.62 ([22.61513736])\n",
      "12:35    Epoch 14: train loss 22.62 ([22.61503325])\n",
      "12:36    Epoch 16: train loss 22.62 ([22.61508229])\n",
      "12:37    Epoch 18: train loss 22.62 ([22.61515565])\n",
      "12:37    Epoch 20: train loss 22.62 ([22.61500537])\n",
      "12:37  Finished training\n",
      "12:37  Training estimator 16 / 20 in ensemble\n",
      "12:37  Starting training\n",
      "12:37    Method:                 sally\n",
      "12:37    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_15.npy\n",
      "12:37                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_15.npy\n",
      "12:37    Features:               [1]\n",
      "12:37    Method:                 sally\n",
      "12:37    Hidden layers:          (100, 100)\n",
      "12:37    Activation function:    tanh\n",
      "12:37    Batch size:             128\n",
      "12:37    Epochs:                 20\n",
      "12:37    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:37    Validation split:       None\n",
      "12:37    Early stopping:         True\n",
      "12:37  Loading training data\n",
      "12:37  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:37  Only using 1 of 29 observables\n",
      "12:37  Creating model for method sally\n",
      "12:37  Training model\n",
      "12:38    Epoch 2: train loss 15.56 ([15.5556305])\n",
      "12:39    Epoch 4: train loss 15.55 ([15.55443953])\n",
      "12:40    Epoch 6: train loss 15.55 ([15.55429548])\n",
      "12:41    Epoch 8: train loss 15.56 ([15.55544278])\n",
      "12:41    Epoch 10: train loss 15.55 ([15.55491165])\n",
      "12:42    Epoch 12: train loss 15.55 ([15.55400466])\n",
      "12:43    Epoch 14: train loss 15.55 ([15.55408081])\n",
      "12:43    Epoch 16: train loss 15.55 ([15.55432158])\n",
      "12:44    Epoch 18: train loss 15.55 ([15.55381881])\n",
      "12:45    Epoch 20: train loss 15.55 ([15.55385492])\n",
      "12:45  Finished training\n",
      "12:45  Training estimator 17 / 20 in ensemble\n",
      "12:45  Starting training\n",
      "12:45    Method:                 sally\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:45    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_16.npy\n",
      "12:45                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_16.npy\n",
      "12:45    Features:               [1]\n",
      "12:45    Method:                 sally\n",
      "12:45    Hidden layers:          (100, 100)\n",
      "12:45    Activation function:    tanh\n",
      "12:45    Batch size:             128\n",
      "12:45    Epochs:                 20\n",
      "12:45    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:45    Validation split:       None\n",
      "12:45    Early stopping:         True\n",
      "12:45  Loading training data\n",
      "12:45  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:45  Only using 1 of 29 observables\n",
      "12:45  Creating model for method sally\n",
      "12:45  Training model\n",
      "12:45    Epoch 2: train loss 17.44 ([17.43560842])\n",
      "12:46    Epoch 4: train loss 17.44 ([17.43956035])\n",
      "12:47    Epoch 6: train loss 17.43 ([17.43409762])\n",
      "12:47    Epoch 8: train loss 17.43 ([17.43409621])\n",
      "12:48    Epoch 10: train loss 17.43 ([17.43381232])\n",
      "12:49    Epoch 12: train loss 17.43 ([17.43384123])\n",
      "12:49    Epoch 14: train loss 17.45 ([17.45373089])\n",
      "12:50    Epoch 16: train loss 17.43 ([17.43397139])\n",
      "12:50    Epoch 18: train loss 17.43 ([17.43363568])\n",
      "12:51    Epoch 20: train loss 17.43 ([17.43392368])\n",
      "12:51  Finished training\n",
      "12:51  Training estimator 18 / 20 in ensemble\n",
      "12:51  Starting training\n",
      "12:51    Method:                 sally\n",
      "12:51    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_17.npy\n",
      "12:51                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_17.npy\n",
      "12:51    Features:               [1]\n",
      "12:51    Method:                 sally\n",
      "12:51    Hidden layers:          (100, 100)\n",
      "12:51    Activation function:    tanh\n",
      "12:51    Batch size:             128\n",
      "12:51    Epochs:                 20\n",
      "12:51    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:51    Validation split:       None\n",
      "12:51    Early stopping:         True\n",
      "12:51  Loading training data\n",
      "12:51  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:51  Only using 1 of 29 observables\n",
      "12:51  Creating model for method sally\n",
      "12:51  Training model\n",
      "12:52    Epoch 2: train loss 18.09 ([18.08685307])\n",
      "12:52    Epoch 4: train loss 18.09 ([18.08539492])\n",
      "12:53    Epoch 6: train loss 18.09 ([18.08537795])\n",
      "12:54    Epoch 8: train loss 18.09 ([18.0876684])\n",
      "12:54    Epoch 10: train loss 18.09 ([18.08514285])\n",
      "12:55    Epoch 12: train loss 18.09 ([18.08502516])\n",
      "12:55    Epoch 14: train loss 18.08 ([18.08499882])\n",
      "12:56    Epoch 16: train loss 18.08 ([18.08490909])\n",
      "12:57    Epoch 18: train loss 18.09 ([18.08521315])\n",
      "12:57    Epoch 20: train loss 18.08 ([18.08488764])\n",
      "12:57  Finished training\n",
      "12:57  Training estimator 19 / 20 in ensemble\n",
      "12:57  Starting training\n",
      "12:57    Method:                 sally\n",
      "12:57    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_18.npy\n",
      "12:57                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_18.npy\n",
      "12:57    Features:               [1]\n",
      "12:57    Method:                 sally\n",
      "12:57    Hidden layers:          (100, 100)\n",
      "12:57    Activation function:    tanh\n",
      "12:57    Batch size:             128\n",
      "12:57    Epochs:                 20\n",
      "12:57    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "12:57    Validation split:       None\n",
      "12:57    Early stopping:         True\n",
      "12:57  Loading training data\n",
      "12:57  Found 1000000 samples with 2 parameters and 29 observables\n",
      "12:57  Only using 1 of 29 observables\n",
      "12:57  Creating model for method sally\n",
      "12:57  Training model\n",
      "12:58    Epoch 2: train loss 44.28 ([44.27728584])\n",
      "12:59    Epoch 4: train loss 44.28 ([44.28225489])\n",
      "12:59    Epoch 6: train loss 44.28 ([44.27501917])\n",
      "13:00    Epoch 8: train loss 44.28 ([44.27500417])\n",
      "13:00    Epoch 10: train loss 44.27 ([44.27469442])\n",
      "13:01    Epoch 12: train loss 44.28 ([44.27549578])\n",
      "13:02    Epoch 14: train loss 44.27 ([44.27459602])\n",
      "13:02    Epoch 16: train loss 44.27 ([44.2747975])\n",
      "13:03    Epoch 18: train loss 44.27 ([44.2745308])\n",
      "13:04    Epoch 20: train loss 44.27 ([44.27437662])\n",
      "13:04  Finished training\n",
      "13:04  Training estimator 20 / 20 in ensemble\n",
      "13:04  Starting training\n",
      "13:04    Method:                 sally\n",
      "13:04    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/x_train_19.npy\n",
      "13:04                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local/t_xz_train_19.npy\n",
      "13:04    Features:               [1]\n",
      "13:04    Method:                 sally\n",
      "13:04    Hidden layers:          (100, 100)\n",
      "13:04    Activation function:    tanh\n",
      "13:04    Batch size:             128\n",
      "13:04    Epochs:                 20\n",
      "13:04    Learning rate:          0.002 initially, decaying to 0.0001\n",
      "13:04    Validation split:       None\n",
      "13:04    Early stopping:         True\n",
      "13:04  Loading training data\n",
      "13:04  Found 1000000 samples with 2 parameters and 29 observables\n",
      "13:04  Only using 1 of 29 observables\n",
      "13:04  Creating model for method sally\n",
      "13:04  Training model\n",
      "13:04    Epoch 2: train loss 15.77 ([15.77151131])\n",
      "13:05    Epoch 4: train loss 15.77 ([15.77375038])\n",
      "13:06    Epoch 6: train loss 15.77 ([15.7705007])\n",
      "13:06    Epoch 8: train loss 15.77 ([15.77049379])\n",
      "13:07    Epoch 10: train loss 15.77 ([15.77044886])\n",
      "13:08    Epoch 12: train loss 15.77 ([15.77031398])\n",
      "13:08    Epoch 14: train loss 15.77 ([15.77048181])\n",
      "13:09    Epoch 16: train loss 15.77 ([15.77024315])\n",
      "13:10    Epoch 18: train loss 15.77 ([15.77040132])\n",
      "13:10    Epoch 20: train loss 15.77 ([15.77035885])\n",
      "13:10  Finished training\n"
     ]
    }
   ],
   "source": [
    "ensemble_res = EnsembleForge(n_estimators)\n",
    "\n",
    "ensemble_res.train_all(\n",
    "    features=[ [30] for _ in range(n_estimators)],\n",
    "    method='sally',\n",
    "    x_filename=[sample_dir + 'train_local/x_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    t_xz0_filename=[sample_dir + 'train_local/t_xz_train_{}.npy'.format(i) for i in range(n_estimators)],\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=None,\n",
    "    n_hidden=n_hidden\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "92b1db79-876f-4d9d-9de5-1011c3d04633"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:10  Calculating expectation for 20 estimators in ensemble\n",
      "13:10  Starting evaluation for estimator 1 / 20 in ensemble\n",
      "13:10  Loading evaluation data\n",
      "13:10  Starting score evaluation\n",
      "13:10  Starting evaluation for estimator 2 / 20 in ensemble\n",
      "13:10  Loading evaluation data\n",
      "13:10  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 3 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 4 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 5 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 6 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 7 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:11  Starting evaluation for estimator 8 / 20 in ensemble\n",
      "13:11  Loading evaluation data\n",
      "13:11  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 9 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 10 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 11 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 12 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 13 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:12  Starting evaluation for estimator 14 / 20 in ensemble\n",
      "13:12  Loading evaluation data\n",
      "13:12  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 15 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 16 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 17 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 18 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 19 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n",
      "13:13  Starting evaluation for estimator 20 / 20 in ensemble\n",
      "13:13  Loading evaluation data\n",
      "13:13  Starting score evaluation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00308524, -0.00076297],\n",
       "       [ 0.00268906,  0.00290275],\n",
       "       [-0.004977  , -0.00132313],\n",
       "       [-0.00113649,  0.00535215],\n",
       "       [ 0.00422012,  0.00442748],\n",
       "       [-0.00161387,  0.00147769],\n",
       "       [ 0.00109053, -0.00408648],\n",
       "       [-0.00747247, -0.0048116 ],\n",
       "       [ 0.00667167,  0.00630002],\n",
       "       [ 0.00315804, -0.00579965],\n",
       "       [ 0.0108441 ,  0.00135383],\n",
       "       [ 0.00186662,  0.00564121],\n",
       "       [ 0.01288694, -0.0057633 ],\n",
       "       [-0.00887028, -0.00661671],\n",
       "       [-0.00691695, -0.00211028],\n",
       "       [-0.00157362,  0.00148581],\n",
       "       [ 0.00136739, -0.00128104],\n",
       "       [-0.00278229,  0.0009701 ],\n",
       "       [-0.01158568,  0.00037303],\n",
       "       [ 0.00571575,  0.00030452]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_res.calculate_expectation(\n",
    "    x_filename=sample_dir + 'validation/x_validation.npy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "77e6e176-ea25-4199-ac0e-e7fb37096e2d"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14  Saving ensemble setup to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/ensemble.json\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_0_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_0_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_1_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_1_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_2_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_2_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_3_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_3_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_4_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_4_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_5_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_5_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_6_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_6_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_7_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_7_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_8_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_8_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_9_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_9_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_10_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_10_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_11_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_11_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_12_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_12_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_13_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_13_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_14_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_14_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_15_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_15_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_16_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_16_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_17_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_17_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_18_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_18_state_dict.pt\n",
      "13:14  Saving settings to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_19_settings.json\n",
      "13:14  Saving state dictionary to /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_dummy/estimator_19_state_dict.pt\n"
     ]
    }
   ],
   "source": [
    "ensemble_res.save(model_dir + 'sally_ensemble_resurrection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7d171470-6c7e-4a74-8ca8-5589004e32d6"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
