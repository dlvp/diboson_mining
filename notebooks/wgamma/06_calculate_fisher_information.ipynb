{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Fisher information\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import madminer.core\n",
    "from madminer.fisherinformation import FisherInformation\n",
    "from madminer.plotting import plot_fisher_information_contours_2d\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'\n",
    "result_dir = base_dir + 'data/results/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_settings = [None, 1., 10., 100.]\n",
    "weight_setting_filenames = ['', '_w1', '_w10', '_w100']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FisherInformation instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:56  \n",
      "14:56  ------------------------------------------------------------\n",
      "14:56  |                                                          |\n",
      "14:56  |  MadMiner v2018.11.13                                    |\n",
      "14:56  |                                                          |\n",
      "14:56  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "14:56  |                                                          |\n",
      "14:56  ------------------------------------------------------------\n",
      "14:56  \n",
      "14:56  Loading data from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/samples.h5\n",
      "14:56  Found 2 parameters:\n",
      "14:56     cWWW (LHA: dim6 1, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "14:56     cWWWtilde (LHA: dim6 2, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "14:56  Found 6 benchmarks:\n",
      "14:56     sm: cWWW = 0.00e+00, cWWWtilde = 0.00e+00\n",
      "14:56     morphing_basis_vector_1: cWWW = -6.07e-03, cWWWtilde = -1.84e-02\n",
      "14:56     morphing_basis_vector_2: cWWW = 1.00e-02, cWWWtilde = 1.70e-02\n",
      "14:56     morphing_basis_vector_3: cWWW = -1.99e-02, cWWWtilde = 1.87e-02\n",
      "14:56     morphing_basis_vector_4: cWWW = 1.97e-02, cWWWtilde = -1.53e-02\n",
      "14:56     morphing_basis_vector_5: cWWW = -1.65e-02, cWWWtilde = -6.33e-03\n",
      "14:56  Found 27 observables: et_miss, phi_miss, e_visible, eta_visible, e_l1, pt_l1, eta_l1, phi_l1, e_a1, pt_a1, eta_a1, phi_a1, e_j1, pt_j1, eta_j1, phi_j1, deltaphi_l1_met, deltaphi_a1_met, m_l1_met, pt_l1_met, m_l1_a1, deltaeta_l1_a1, deltaphi_l1_a1, m_a1_l1_met, pt_a1_l1_met, mt, phi_resurrection\n",
      "14:56  Found 1812119 events\n",
      "14:56  Found morphing setup with 6 components\n",
      "14:56  Loading data from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/samples_tight.h5\n",
      "14:56  Found 2 parameters:\n",
      "14:56     cWWW (LHA: dim6 1, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "14:56     cWWWtilde (LHA: dim6 2, maximal power in squared ME: (2,), range: (-0.02, 0.02))\n",
      "14:56  Found 6 benchmarks:\n",
      "14:56     sm: cWWW = 0.00e+00, cWWWtilde = 0.00e+00\n",
      "14:56     morphing_basis_vector_1: cWWW = -6.07e-03, cWWWtilde = -1.84e-02\n",
      "14:56     morphing_basis_vector_2: cWWW = 1.00e-02, cWWWtilde = 1.70e-02\n",
      "14:56     morphing_basis_vector_3: cWWW = -1.99e-02, cWWWtilde = 1.87e-02\n",
      "14:56     morphing_basis_vector_4: cWWW = 1.97e-02, cWWWtilde = -1.53e-02\n",
      "14:56     morphing_basis_vector_5: cWWW = -1.65e-02, cWWWtilde = -6.33e-03\n",
      "14:56  Found 27 observables: et_miss, phi_miss, e_visible, eta_visible, e_l1, pt_l1, eta_l1, phi_l1, e_a1, pt_a1, eta_a1, phi_a1, e_j1, pt_j1, eta_j1, phi_j1, deltaphi_l1_met, deltaphi_a1_met, m_l1_met, pt_l1_met, m_l1_a1, deltaeta_l1_a1, deltaphi_l1_a1, m_a1_l1_met, pt_a1_l1_met, mt, phi_resurrection\n",
      "14:56  Found 1207773 events\n",
      "14:56  Found morphing setup with 6 components\n"
     ]
    }
   ],
   "source": [
    "fisher_all = FisherInformation(sample_dir + 'samples.h5', debug=True)\n",
    "fisher_tight = FisherInformation(sample_dir + 'samples_tight.h5', debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truth-level info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_info, cov = fisher_all.calculate_fisher_information_full_truth(\n",
    "    theta=[0.,0.],\n",
    "    luminosity = 300000.\n",
    ")\n",
    "\n",
    "np.save(result_dir + 'information_parton.npy', fisher_info)\n",
    "np.save(result_dir + 'information_covariance_parton.npy', cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_info, cov = fisher_tight.calculate_fisher_information_full_truth(\n",
    "    theta=[0.,0.],\n",
    "    luminosity = 300000.\n",
    ")\n",
    "\n",
    "np.save(result_dir + 'information_parton_tight.npy', fisher_info)\n",
    "np.save(result_dir + 'information_covariance_parton_tight.npy', cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate-only info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_info, cov = fisher_all.calculate_fisher_information_rate(\n",
    "    theta=[0.,0.],\n",
    "    luminosity = 300000.\n",
    ")\n",
    "\n",
    "np.save(result_dir + 'information_xsec.npy', fisher_info)\n",
    "np.save(result_dir + 'information_covariance_xsec.npy', cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_info, cov = fisher_tight.calculate_fisher_information_rate(\n",
    "    theta=[0.,0.],\n",
    "    luminosity = 300000.\n",
    ")\n",
    "\n",
    "np.save(result_dir + 'information_xsec_tight.npy', fisher_info)\n",
    "np.save(result_dir + 'information_covariance_xsec_tight.npy', cov)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Fisher info (ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculate_fisher_information_full_detector() got an unexpected keyword argument 'uncertainty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6c0f3198e346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mensemble_vote_expectation_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muncertainty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: calculate_fisher_information_full_detector() got an unexpected keyword argument 'uncertainty'"
     ]
    }
   ],
   "source": [
    "means, covs = fisher_all.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    luminosity=300000.,\n",
    "    model_file=model_dir + 'sally_ensemble_all',\n",
    "    ensemble_vote_expectation_weight=weight_settings,\n",
    "    test_split=0.5\n",
    ")\n",
    "\n",
    "for weight_filename, mean, cov in zip(weight_setting_filenames, means, covs):\n",
    "    np.save(result_dir + 'information_mean_full{}.npy'.format(weight_filename), mean)\n",
    "    np.save(result_dir + 'information_covariance_full{}.npy'.format(weight_filename), cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:46  Evaluating rate Fisher information\n",
      "21:47  Loading ensemble setup from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_all_tight/ensemble.json\n",
      "21:47  Found ensemble with 10 estimators and expectations [[ 0.0911617  -0.16387829]\n",
      " [ 0.13319454 -0.11376067]\n",
      " [ 0.02514527 -0.00822992]\n",
      " [-0.09863859  0.04448954]\n",
      " [ 0.22666614 -0.14302233]\n",
      " [ 0.13114008  0.00336235]\n",
      " [-0.08914433 -0.02287172]\n",
      " [-0.10113602 -0.02783563]\n",
      " [-0.01210352 -0.01167924]\n",
      " [ 0.11039541 -0.00848151]]\n",
      "21:47  Evaluating kinematic Fisher information on batch 1 / 7\n",
      "21:47  Evaluating kinematic Fisher information on batch 2 / 7\n",
      "21:47  Evaluating kinematic Fisher information on batch 3 / 7\n",
      "21:47  Evaluating kinematic Fisher information on batch 4 / 7\n",
      "21:48  Evaluating kinematic Fisher information on batch 5 / 7\n",
      "21:48  Evaluating kinematic Fisher information on batch 6 / 7\n",
      "21:48  Evaluating kinematic Fisher information on batch 7 / 7\n"
     ]
    }
   ],
   "source": [
    "means, covs = fisher_tight.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    luminosity=300000.,\n",
    "    model_file=model_dir + 'sally_ensemble_all_tight',\n",
    "    ensemble_vote_expectation_weight=weight_settings\n",
    ")\n",
    "\n",
    "for weight_filename, mean, cov in zip(weight_setting_filenames, means, covs):\n",
    "    np.save(result_dir + 'information_mean_full_tight{}.npy'.format(weight_filename), mean)\n",
    "    np.save(result_dir + 'information_covariance_full_tight{}.npy'.format(weight_filename), cov)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal observable set (ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:49  Evaluating rate Fisher information\n",
      "21:49  Loading ensemble setup from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_minimal/ensemble.json\n",
      "21:49  Found ensemble with 10 estimators and expectations [[ 0.00084352  0.02238362]\n",
      " [-0.01199366  0.01332431]\n",
      " [-0.00386162  0.00224334]\n",
      " [ 0.01450194  0.02153249]\n",
      " [ 0.02635764 -0.00887636]\n",
      " [ 0.02473497 -0.00167412]\n",
      " [ 0.0154885  -0.00740956]\n",
      " [-0.04929382  0.04634152]\n",
      " [ 0.01042279 -0.02585928]\n",
      " [-0.00034513 -0.01883029]]\n",
      "21:50  Evaluating kinematic Fisher information on batch 1 / 10\n",
      "21:50  Evaluating kinematic Fisher information on batch 2 / 10\n",
      "21:50  Evaluating kinematic Fisher information on batch 3 / 10\n",
      "21:50  Evaluating kinematic Fisher information on batch 4 / 10\n",
      "21:50  Evaluating kinematic Fisher information on batch 5 / 10\n",
      "21:50  Evaluating kinematic Fisher information on batch 6 / 10\n",
      "21:51  Evaluating kinematic Fisher information on batch 7 / 10\n",
      "21:51  Evaluating kinematic Fisher information on batch 8 / 10\n",
      "21:51  Evaluating kinematic Fisher information on batch 9 / 10\n",
      "21:51  Evaluating kinematic Fisher information on batch 10 / 10\n"
     ]
    }
   ],
   "source": [
    "means, covs = fisher_all.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    luminosity=300000.,\n",
    "    model_file=model_dir + 'sally_ensemble_minimal',\n",
    "    ensemble_vote_expectation_weight=weight_settings\n",
    ")\n",
    "\n",
    "for weight_filename, mean, cov in zip(weight_setting_filenames, means, covs):\n",
    "    np.save(result_dir + 'information_mean_minimal{}.npy'.format(weight_filename), mean)\n",
    "    np.save(result_dir + 'information_covariance_minimal{}.npy'.format(weight_filename), cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:11  Evaluating rate Fisher information\n",
      "08:11  Loading ensemble setup from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_minimal_tight/ensemble.json\n",
      "08:11  Found ensemble with 10 estimators and expectations [[ 0.07081794 -0.02416615]\n",
      " [ 0.09775881  0.07342587]\n",
      " [ 0.02155189 -0.1146758 ]\n",
      " [-0.25029388  0.11809271]\n",
      " [-0.01383648  0.03545747]\n",
      " [ 0.03916155 -0.08262159]\n",
      " [-0.09130371  0.15367286]\n",
      " [-0.05830761 -0.06824306]\n",
      " [ 0.01923683  0.00194588]\n",
      " [-0.16656899 -0.00395318]]\n",
      "08:11  Evaluating kinematic Fisher information on batch 1 / 7\n",
      "08:11  Evaluating kinematic Fisher information on batch 2 / 7\n",
      "08:12  Evaluating kinematic Fisher information on batch 3 / 7\n",
      "08:12  Evaluating kinematic Fisher information on batch 4 / 7\n",
      "08:12  Evaluating kinematic Fisher information on batch 5 / 7\n",
      "08:12  Evaluating kinematic Fisher information on batch 6 / 7\n",
      "08:12  Evaluating kinematic Fisher information on batch 7 / 7\n"
     ]
    }
   ],
   "source": [
    "means, covs = fisher_tight.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    luminosity=300000.,\n",
    "    model_file=model_dir + 'sally_ensemble_minimal_tight',\n",
    "    ensemble_vote_expectation_weight=weight_settings\n",
    ")\n",
    "\n",
    "for weight_filename, mean, cov in zip(weight_setting_filenames, means, covs):\n",
    "    np.save(result_dir + 'information_mean_minimal_tight{}.npy'.format(weight_filename), mean)\n",
    "    np.save(result_dir + 'information_covariance_minimal_tight{}.npy'.format(weight_filename), cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info in observables (ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:51  Evaluating rate Fisher information\n",
      "21:52  Loading ensemble setup from /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/models/wgamma/sally_ensemble_resurrection/ensemble.json\n",
      "21:52  Found ensemble with 10 estimators and expectations [[ 0.06343307 -0.04893372]\n",
      " [ 0.09478135 -0.01341373]\n",
      " [ 0.04839911 -0.00616729]\n",
      " [ 0.01964112  0.05162339]\n",
      " [ 0.08938077  0.00986628]\n",
      " [ 0.06625167 -0.0093354 ]\n",
      " [ 0.03805659 -0.0091226 ]\n",
      " [-0.01882457  0.02061494]\n",
      " [-0.07291223 -0.07865967]\n",
      " [ 0.00173969 -0.04213462]]\n"
     ]
    }
   ],
   "source": [
    "means, covs = fisher_tight.calculate_fisher_information_full_detector(\n",
    "    theta=[0.,0.],\n",
    "    luminosity=300000.,\n",
    "    model_file=model_dir + 'sally_ensemble_resurrection',\n",
    "    unweighted_x_sample_file = sample_dir + 'test_tight/x_test.npy',\n",
    "    ensemble_vote_expectation_weight=weight_settings\n",
    ")\n",
    "\n",
    "for weight_filename, mean, cov in zip(weight_setting_filenames, means, covs):\n",
    "    np.save(result_dir + 'information_mean_resurrection_tight{}.npy'.format(weight_filename), mean)\n",
    "    np.save(result_dir + 'information_covariance_resurrection_tight{}.npy'.format(weight_filename), cov)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['phi_resurrection', 'met', 'ptl', 'pta', 'deltaphi_lv', 'deltaphi_la']\n",
    "observables = ['phi_resurrection', 'et_miss', 'pt_l1', 'pt_a1', 'deltaphi_l1_met', 'deltaphi_l1_a1']\n",
    "bins = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi_resurrection\n",
      "met\n",
      "ptl\n",
      "pta\n",
      "deltaphi_lv\n",
      "deltaphi_la\n"
     ]
    }
   ],
   "source": [
    "for filename, obs in zip(filenames, observables):\n",
    "    print(filename)\n",
    "    info, cov = fisher_tight.calculate_fisher_information_hist1d(\n",
    "        theta=[0.,0.],\n",
    "        luminosity=300000.,\n",
    "        observable=obs,\n",
    "        nbins=bins,\n",
    "        histrange=None\n",
    "    )\n",
    "    \n",
    "    np.save(result_dir + 'information_histo_{}_tight.npy'.format(filename), info)\n",
    "    np.save(result_dir + 'information_covariance_histo_{}_tight.npy'.format(filename), cov)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
