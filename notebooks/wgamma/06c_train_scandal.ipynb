{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f9deb73c-b62f-4cff-8d83-724074098c92"
    }
   },
   "source": [
    "# Train SCANDAL ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Marco Farina, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "fe57a76c-4838-44c4-b0cc-5ee166785e4a"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "f3463c40-6421-42a1-8681-527c3ec42541"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "b2c73eca-c625-4f7a-9cee-4ccb2dcbb3e9"
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(filename, use_tight_cuts=True, n_estimators=n_estimators, **kwargs):\n",
    "    cut_label = '_tight' if use_tight_cuts else ''\n",
    "    \n",
    "    ensemble = EnsembleForge(n_estimators, debug=False)\n",
    "\n",
    "    ensemble.train_all(\n",
    "        method='scandal',\n",
    "        x_filename=[sample_dir + 'train_scandal{}/x_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        theta0_filename=[sample_dir + 'train_scandal{}/theta_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        t_xz0_filename=[sample_dir + 'train_scandal{}/t_xz_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    ensemble.save(model_dir + 'scandal_ensemble_' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45e7f73-8f4c-4261-a381-4b7ad6af120f"
    }
   },
   "source": [
    "## All observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'all',\n",
    "    use_tight_cuts=False,\n",
    "    n_hidden=(100,),\n",
    "    alpha=1.,\n",
    "    n_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:37  Training 3 estimators in ensemble\n",
      "08:37  Training estimator 1 / 3 in ensemble\n",
      "08:37  Starting training\n",
      "08:37    Method:                 scandal\n",
      "08:37    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/x_train_0.npy\n",
      "08:37                   theta0 at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/theta_train_0.npy\n",
      "08:37                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/t_xz_train_0.npy\n",
      "08:37    Features:               all\n",
      "08:37    Method:                 scandal\n",
      "08:37    Neural density est.:    mafmog\n",
      "08:37    MAF, number MADEs:      3\n",
      "08:37    MAF, batch norm:        False\n",
      "08:37    MAF, BN alpha:          0.1\n",
      "08:37    MAF MoG, components:    10\n",
      "08:37    Activation function:    tanh\n",
      "08:37    alpha:                  1.0\n",
      "08:37    Batch size:             128\n",
      "08:37    Trainer:                amsgrad\n",
      "08:37    Epochs:                 10\n",
      "08:37    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "08:37    Validation split:       None\n",
      "08:37    Early stopping:         True\n",
      "08:37    Scale inputs:           True\n",
      "08:37    Shuffle labels          False\n",
      "08:37    Regularization:         None\n",
      "08:37  Loading training data\n",
      "08:37  Found 100000 samples with 2 parameters and 27 observables\n",
      "08:37  Rescaling inputs\n",
      "08:37  Creating model for method scandal\n",
      "08:37  Training model\n",
      "09:09    Epoch 1: train loss 3375.89 ([  78.24951109 3297.64282312])\n",
      "09:22    Epoch 2: train loss 3447.13 ([  85.94659841 3361.18084553])\n",
      "09:33    Epoch 3: train loss 3123.45 ([  72.40049589 3051.05229971])\n",
      "09:45    Epoch 4: train loss 3076.04 ([  58.56010507 3017.47689008])\n",
      "11:29    Epoch 5: train loss 3065.35 ([  51.35717355 3013.99743551])\n",
      "11:39    Epoch 6: train loss 3057.49 ([  46.80296596 3010.68846329])\n",
      "11:49    Epoch 7: train loss 3051.57 ([  44.46859245 3007.09919251])\n",
      "12:06    Epoch 8: train loss 3041.98 ([  43.2169926  2998.76443333])\n",
      "12:27    Epoch 9: train loss 3039.34 ([  42.63807137 2996.70099337])\n",
      "12:38    Epoch 10: train loss 3036.33 ([  42.32852557 2994.0027476 ])\n",
      "12:38  Finished training\n",
      "12:38  Training estimator 2 / 3 in ensemble\n",
      "12:38  Starting training\n",
      "12:38    Method:                 scandal\n",
      "12:38    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/x_train_1.npy\n",
      "12:38                   theta0 at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/theta_train_1.npy\n",
      "12:38                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/t_xz_train_1.npy\n",
      "12:38    Features:               all\n",
      "12:38    Method:                 scandal\n",
      "12:38    Neural density est.:    mafmog\n",
      "12:38    MAF, number MADEs:      3\n",
      "12:38    MAF, batch norm:        False\n",
      "12:38    MAF, BN alpha:          0.1\n",
      "12:38    MAF MoG, components:    10\n",
      "12:38    Activation function:    tanh\n",
      "12:38    alpha:                  1.0\n",
      "12:38    Batch size:             128\n",
      "12:38    Trainer:                amsgrad\n",
      "12:38    Epochs:                 10\n",
      "12:38    Learning rate:          0.01 initially, decaying to 0.0001\n",
      "12:38    Validation split:       None\n",
      "12:38    Early stopping:         True\n",
      "12:38    Scale inputs:           True\n",
      "12:38    Shuffle labels          False\n",
      "12:38    Regularization:         None\n",
      "12:38  Loading training data\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/theta_train_1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bbd716cd5f4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-5-d08a88cc7c2a>\u001b[0m in \u001b[0;36mtrain_ensemble\u001b[0;34m(filename, use_tight_cuts, n_estimators, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtheta0_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_scandal{}/theta_train_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mt_xz0_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_scandal{}/t_xz_train_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/madminer/madminer/madminer/ml.py\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training estimator %s / %s in ensemble\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs_this_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta0_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta1_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/madminer/madminer/madminer/ml.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, method, x_filename, y_filename, theta0_filename, theta1_filename, r_xz_filename, t_xz0_filename, t_xz1_filename, features, nde_type, n_hidden, activation, maf_n_mades, maf_batch_norm, maf_batch_norm_alpha, maf_mog_n_components, alpha, trainer, n_epochs, batch_size, initial_lr, final_lr, nesterov_momentum, validation_split, early_stopping, scale_inputs, shuffle_labels, grad_x_regularization)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading training data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mtheta0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta0_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0mtheta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta1_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/projects/madminer/madminer/madminer/utils/various.py\u001b[0m in \u001b[0;36mload_and_check\u001b[0;34m(filename, warning_threshold)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mn_nans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/higgs_inference/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0mMem\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstored\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthen\u001b[0m \u001b[0maccess\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msecond\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_scandal_tight/theta_train_1.npy'"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all_tight',\n",
    "    use_tight_cuts=True,\n",
    "    n_hidden=(100,),\n",
    "    alpha=1.,\n",
    "    n_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just resurrection phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'resurrection',\n",
    "    use_tight_cuts=True,\n",
    "    features=[[26] for _ in range(n_estimators)]\n",
    "    nde_type='mafmog',\n",
    "    n_hidden=(100,),\n",
    "    alpha=1.\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
