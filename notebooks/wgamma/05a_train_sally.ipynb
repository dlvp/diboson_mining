{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f9deb73c-b62f-4cff-8d83-724074098c92"
    }
   },
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Marco Farina, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "fe57a76c-4838-44c4-b0cc-5ee166785e4a"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "f3463c40-6421-42a1-8681-527c3ec42541"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "b2c73eca-c625-4f7a-9cee-4ccb2dcbb3e9"
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(filename, use_tight_cuts=True, n_estimators=n_estimators, **kwargs):\n",
    "    cut_label = '_tight' if use_tight_cuts else ''\n",
    "    \n",
    "    ensemble = EnsembleForge(n_estimators, debug=False)\n",
    "\n",
    "    ensemble.train_all(\n",
    "        method='sally',\n",
    "        x_filename=[sample_dir + 'train_local{}/x_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        t_xz0_filename=[sample_dir + 'train_local{}/t_xz_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    ensemble.calculate_expectation(\n",
    "        x_filename=sample_dir + 'validation{}/x_validation.npy'.format(cut_label)\n",
    "    )\n",
    "\n",
    "    ensemble.save(model_dir + 'sally_ensemble_' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45e7f73-8f4c-4261-a381-4b7ad6af120f"
    }
   },
   "source": [
    "## All observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'all',\n",
    "    use_tight_cuts=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:51  \n",
      "16:51  ------------------------------------------------------------\n",
      "16:51  |                                                          |\n",
      "16:51  |  MadMiner v0.1.1                                         |\n",
      "16:51  |                                                          |\n",
      "16:51  |           Johann Brehmer, Kyle Cranmer, and Felix Kling  |\n",
      "16:51  |                                                          |\n",
      "16:51  ------------------------------------------------------------\n",
      "16:51  \n",
      "16:51  Training 3 estimators in ensemble\n",
      "16:51  Training estimator 1 / 3 in ensemble\n",
      "16:51  Starting training\n",
      "16:51    Method:                 sally\n",
      "16:51    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_0.npy\n",
      "16:51                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_0.npy\n",
      "16:51    Features:               all\n",
      "16:51    Method:                 sally\n",
      "16:51    Hidden layers:          (100, 100)\n",
      "16:51    Activation function:    tanh\n",
      "16:51    Batch size:             128\n",
      "16:51    Trainer:                amsgrad\n",
      "16:51    Epochs:                 50\n",
      "16:51    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "16:51    Validation split:       None\n",
      "16:51    Early stopping:         True\n",
      "16:51    Scale inputs:           True\n",
      "16:51    Shuffle labels          False\n",
      "16:51    Regularization:         None\n",
      "16:51  Loading training data\n",
      "16:51  Found 1000000 samples with 2 parameters and 33 observables\n",
      "16:51  Rescaling inputs\n",
      "16:51  Creating model for method sally\n",
      "16:51  Training model\n",
      "17:02    Epoch 5: train loss 3602.4241 (mse_score: 3602.4241)\n",
      "19:01    Epoch 10: train loss 3096.5837 (mse_score: 3096.5837)\n",
      "19:17    Epoch 15: train loss 2824.6101 (mse_score: 2824.6101)\n",
      "19:29    Epoch 20: train loss 2657.5175 (mse_score: 2657.5175)\n",
      "19:43    Epoch 25: train loss 2548.9273 (mse_score: 2548.9273)\n",
      "19:54    Epoch 30: train loss 2473.4897 (mse_score: 2473.4897)\n",
      "20:09    Epoch 35: train loss 2419.8326 (mse_score: 2419.8326)\n",
      "20:22    Epoch 40: train loss 2380.8526 (mse_score: 2380.8526)\n",
      "20:35    Epoch 45: train loss 2351.0888 (mse_score: 2351.0888)\n",
      "20:48    Epoch 50: train loss 2328.3185 (mse_score: 2328.3185)\n",
      "20:48  Finished training\n",
      "20:48  Training estimator 2 / 3 in ensemble\n",
      "20:48  Starting training\n",
      "20:48    Method:                 sally\n",
      "20:48    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_1.npy\n",
      "20:48                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_1.npy\n",
      "20:48    Features:               all\n",
      "20:48    Method:                 sally\n",
      "20:48    Hidden layers:          (100, 100)\n",
      "20:48    Activation function:    tanh\n",
      "20:48    Batch size:             128\n",
      "20:48    Trainer:                amsgrad\n",
      "20:48    Epochs:                 50\n",
      "20:48    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "20:48    Validation split:       None\n",
      "20:48    Early stopping:         True\n",
      "20:48    Scale inputs:           True\n",
      "20:48    Shuffle labels          False\n",
      "20:48    Regularization:         None\n",
      "20:48  Loading training data\n",
      "20:48  Found 1000000 samples with 2 parameters and 33 observables\n",
      "20:48  Rescaling inputs\n",
      "20:48  Creating model for method sally\n",
      "20:48  Training model\n",
      "21:01    Epoch 5: train loss 3586.4638 (mse_score: 3586.4638)\n",
      "21:17    Epoch 10: train loss 3101.0987 (mse_score: 3101.0987)\n",
      "21:31    Epoch 15: train loss 2846.4351 (mse_score: 2846.4351)\n",
      "21:45    Epoch 20: train loss 2694.1841 (mse_score: 2694.1841)\n",
      "21:52    Epoch 25: train loss 2594.4497 (mse_score: 2594.4497)\n",
      "21:59    Epoch 30: train loss 2524.4612 (mse_score: 2524.4612)\n",
      "22:07    Epoch 35: train loss 2473.9443 (mse_score: 2473.9443)\n",
      "22:14    Epoch 40: train loss 2436.0470 (mse_score: 2436.0470)\n",
      "22:21    Epoch 45: train loss 2408.6209 (mse_score: 2408.6209)\n",
      "22:29    Epoch 50: train loss 2387.6008 (mse_score: 2387.6008)\n",
      "22:29  Finished training\n",
      "22:29  Training estimator 3 / 3 in ensemble\n",
      "22:29  Starting training\n",
      "22:29    Method:                 sally\n",
      "22:29    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_2.npy\n",
      "22:29                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_2.npy\n",
      "22:29    Features:               all\n",
      "22:29    Method:                 sally\n",
      "22:29    Hidden layers:          (100, 100)\n",
      "22:29    Activation function:    tanh\n",
      "22:29    Batch size:             128\n",
      "22:29    Trainer:                amsgrad\n",
      "22:29    Epochs:                 50\n",
      "22:29    Learning rate:          0.001 initially, decaying to 0.0001\n",
      "22:29    Validation split:       None\n",
      "22:29    Early stopping:         True\n",
      "22:29    Scale inputs:           True\n",
      "22:29    Shuffle labels          False\n",
      "22:29    Regularization:         None\n",
      "22:29  Loading training data\n",
      "22:29  Found 1000000 samples with 2 parameters and 33 observables\n",
      "22:29  Rescaling inputs\n",
      "22:29  Creating model for method sally\n",
      "22:29  Training model\n",
      "22:38    Epoch 5: train loss 3541.8545 (mse_score: 3541.8545)\n",
      "22:46    Epoch 10: train loss 3055.6231 (mse_score: 3055.6231)\n",
      "22:54    Epoch 15: train loss 2795.4360 (mse_score: 2795.4360)\n",
      "23:02    Epoch 20: train loss 2639.4849 (mse_score: 2639.4849)\n",
      "23:10    Epoch 25: train loss 2537.3886 (mse_score: 2537.3886)\n",
      "23:18    Epoch 30: train loss 2464.8205 (mse_score: 2464.8205)\n",
      "23:26    Epoch 35: train loss 2412.2508 (mse_score: 2412.2508)\n",
      "23:34    Epoch 40: train loss 2373.5110 (mse_score: 2373.5110)\n",
      "23:42    Epoch 45: train loss 2343.7744 (mse_score: 2343.7744)\n",
      "23:50    Epoch 50: train loss 2321.4965 (mse_score: 2321.4965)\n",
      "23:50  Finished training\n",
      "23:50  Calculating expectation for 3 estimators in ensemble\n",
      "23:50  Starting evaluation for estimator 1 / 3 in ensemble\n",
      "23:50  Starting evaluation for estimator 2 / 3 in ensemble\n",
      "23:51  Starting evaluation for estimator 3 / 3 in ensemble\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all_tight',\n",
    "    use_tight_cuts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal observable basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_obs = [0,1] + list(range(4,12)) + list(range(16,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'minimal',\n",
    "    use_tight_cuts=False,\n",
    "    features=[min_obs for _ in range(n_estimators)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'minimal_tight',\n",
    "    use_tight_cuts=True,\n",
    "    features=[min_obs for _ in range(10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just resurrection phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble(\n",
    "    'resurrection',\n",
    "    use_tight_cuts=True,\n",
    "    features=[[26] for _ in range(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
