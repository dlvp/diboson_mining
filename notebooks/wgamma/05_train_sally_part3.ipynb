{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f9deb73c-b62f-4cff-8d83-724074098c92"
    }
   },
   "source": [
    "# Train SALLY ensemble\n",
    "\n",
    "Johann Brehmer, Kyle Cranmer, Felix Kling, Duccio Pappadopulo, Josh Ruderman 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "fe57a76c-4838-44c4-b0cc-5ee166785e4a"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "% matplotlib inline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from madminer.sampling import SampleAugmenter\n",
    "from madminer.sampling import multiple_benchmark_thetas\n",
    "from madminer.sampling import constant_morphing_theta, multiple_morphing_thetas, random_morphing_thetas\n",
    "from madminer.ml import MLForge, EnsembleForge\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s  %(message)s', datefmt='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "f3463c40-6421-42a1-8681-527c3ec42541"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/Users/johannbrehmer/work/projects/madminer/diboson_mining/'\n",
    "mg_dir = '/Users/johannbrehmer/work/projects/madminer/MG5_aMC_v2_6_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "b2c73eca-c625-4f7a-9cee-4ccb2dcbb3e9"
    }
   },
   "outputs": [],
   "source": [
    "sample_dir = base_dir + 'data/samples/wgamma/'\n",
    "card_dir = base_dir + 'cards/wgamma/'\n",
    "ufo_model_dir = card_dir + 'SMWgamma_UFO'\n",
    "run_card_dir = card_dir + 'run_cards/'\n",
    "mg_process_dir = base_dir + 'data/mg_processes/wgamma/'\n",
    "log_dir = base_dir + 'logs/wgamma/'\n",
    "temp_dir = base_dir + 'data/temp'\n",
    "delphes_dir = mg_dir + 'Delphes'\n",
    "model_dir = base_dir + 'data/models/wgamma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(filename, use_tight_cuts=True, n_estimators=10, **kwargs):\n",
    "    cut_label = '_tight' if use_tight_cuts else ''\n",
    "    \n",
    "    ensemble = EnsembleForge(n_estimators, debug=False)\n",
    "\n",
    "    ensemble.train_all(\n",
    "        method='sally',\n",
    "        x_filename=[sample_dir + 'train_local{}/x_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        t_xz0_filename=[sample_dir + 'train_local{}/t_xz_train_{}.npy'.format(cut_label, i) for i in range(n_estimators)],\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    ensemble.calculate_expectation(\n",
    "        x_filename=sample_dir + 'validation{}/x_validation.npy'.format(cut_label)\n",
    "    )\n",
    "\n",
    "    ensemble.save(model_dir + 'sally_ensemble_' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b45e7f73-8f4c-4261-a381-4b7ad6af120f"
    }
   },
   "source": [
    "## All observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble('all', use_tight_cuts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble('all_tight', use_tight_cuts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:16  Training 10 estimators in ensemble\n",
      "19:16  Training estimator 1 / 10 in ensemble\n",
      "19:16  Starting training\n",
      "19:16    Method:                 sally\n",
      "19:16    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_0.npy\n",
      "19:16                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_0.npy\n",
      "19:16    Features:               all\n",
      "19:16    Method:                 sally\n",
      "19:16    Hidden layers:          (100, 100)\n",
      "19:16    Activation function:    tanh\n",
      "19:16    Batch size:             128\n",
      "19:16    Trainer:                sgd\n",
      "19:16    Epochs:                 50\n",
      "19:16    Learning rate:          0.02 initially, decaying to 0.002\n",
      "19:16    Nesterov momentum:      0.9\n",
      "19:16    Validation split:       0.25\n",
      "19:16    Early stopping:         True\n",
      "19:16    Scale inputs:           True\n",
      "19:16  Loading training data\n",
      "19:16  Found 1000000 samples with 2 parameters and 26 observables\n",
      "19:16  Rescaling inputs\n",
      "19:16  Creating model for method sally\n",
      "19:16  Training model\n",
      "19:19    Epoch 5: train loss 5650.66 ([5650.6602807]), validation loss 5294.55 ([5294.54761837])\n",
      "19:22    Epoch 10: train loss 5561.41 ([5561.40625862]), validation loss 5223.11 ([5223.11279462]) (*)\n",
      "19:26    Epoch 15: train loss 5531.70 ([5531.69822045]), validation loss 6617.72 ([6617.72194572])\n",
      "19:29    Epoch 20: train loss 5509.22 ([5509.2174365]), validation loss 5204.14 ([5204.13501392])\n",
      "19:31    Epoch 25: train loss 5491.40 ([5491.3988429]), validation loss 5235.95 ([5235.94924152])\n",
      "19:34    Epoch 30: train loss 5476.75 ([5476.75045354]), validation loss 5200.28 ([5200.27513982])\n",
      "19:38    Epoch 35: train loss 5461.97 ([5461.97172831]), validation loss 5159.54 ([5159.54423204]) (*)\n",
      "19:41    Epoch 40: train loss 5450.64 ([5450.6428682]), validation loss 5285.75 ([5285.75019994])\n",
      "19:44    Epoch 45: train loss 5442.49 ([5442.48778161]), validation loss 5180.43 ([5180.42891481])\n",
      "19:47    Epoch 50: train loss 5433.56 ([5433.5556882]), validation loss 5170.70 ([5170.70040245])\n",
      "19:47  Early stopping after epoch 35, with loss 5159.54 compared to final loss 5170.70\n",
      "19:47  Finished training\n",
      "19:47  Training estimator 2 / 10 in ensemble\n",
      "19:47  Starting training\n",
      "19:47    Method:                 sally\n",
      "19:47    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_1.npy\n",
      "19:47                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_1.npy\n",
      "19:47    Features:               all\n",
      "19:47    Method:                 sally\n",
      "19:47    Hidden layers:          (100, 100)\n",
      "19:47    Activation function:    tanh\n",
      "19:47    Batch size:             128\n",
      "19:47    Trainer:                sgd\n",
      "19:47    Epochs:                 50\n",
      "19:47    Learning rate:          0.02 initially, decaying to 0.002\n",
      "19:47    Nesterov momentum:      0.9\n",
      "19:47    Validation split:       0.25\n",
      "19:47    Early stopping:         True\n",
      "19:47    Scale inputs:           True\n",
      "19:47  Loading training data\n",
      "19:47  Found 1000000 samples with 2 parameters and 26 observables\n",
      "19:47  Rescaling inputs\n",
      "19:47  Creating model for method sally\n",
      "19:47  Training model\n",
      "19:51    Epoch 5: train loss 7370.44 ([7370.44096079]), validation loss 12990.26 ([12990.25848063]) (*)\n",
      "19:54    Epoch 10: train loss 7291.18 ([7291.17780922]), validation loss 13039.56 ([13039.56006868])\n",
      "19:57    Epoch 15: train loss 7252.65 ([7252.65402431]), validation loss 13035.77 ([13035.77181692])\n",
      "20:00    Epoch 20: train loss 7223.72 ([7223.71806056]), validation loss 13117.64 ([13117.6445578])\n",
      "20:04    Epoch 25: train loss 7189.26 ([7189.25661553]), validation loss 12998.87 ([12998.86854073])\n",
      "20:07    Epoch 30: train loss 7161.03 ([7161.0332439]), validation loss 12981.83 ([12981.83094992])\n",
      "20:10    Epoch 35: train loss 7151.47 ([7151.46590468]), validation loss 12975.71 ([12975.71215853])\n",
      "20:13    Epoch 40: train loss 7129.79 ([7129.7938794]), validation loss 12948.73 ([12948.73472287])\n",
      "20:16    Epoch 45: train loss 7114.58 ([7114.58061072]), validation loss 12965.15 ([12965.15474396])\n",
      "20:20    Epoch 50: train loss 7102.54 ([7102.54047911]), validation loss 12932.38 ([12932.38263199]) (*)\n",
      "20:20  Early stopping did not improve performance\n",
      "20:20  Finished training\n",
      "20:20  Training estimator 3 / 10 in ensemble\n",
      "20:20  Starting training\n",
      "20:20    Method:                 sally\n",
      "20:20    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_2.npy\n",
      "20:20                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_2.npy\n",
      "20:20    Features:               all\n",
      "20:20    Method:                 sally\n",
      "20:20    Hidden layers:          (100, 100)\n",
      "20:20    Activation function:    tanh\n",
      "20:20    Batch size:             128\n",
      "20:20    Trainer:                sgd\n",
      "20:20    Epochs:                 50\n",
      "20:20    Learning rate:          0.02 initially, decaying to 0.002\n",
      "20:20    Nesterov momentum:      0.9\n",
      "20:20    Validation split:       0.25\n",
      "20:20    Early stopping:         True\n",
      "20:20    Scale inputs:           True\n",
      "20:20  Loading training data\n",
      "20:20  Found 1000000 samples with 2 parameters and 26 observables\n",
      "20:20  Rescaling inputs\n",
      "20:20  Creating model for method sally\n",
      "20:20  Training model\n",
      "20:23    Epoch 5: train loss 6866.33 ([6866.32734785]), validation loss 5313.11 ([5313.10960478])\n",
      "20:26    Epoch 10: train loss 6796.59 ([6796.58768041]), validation loss 5336.41 ([5336.41418623])\n",
      "20:30    Epoch 15: train loss 6747.45 ([6747.45100595]), validation loss 5230.97 ([5230.97348268])\n",
      "20:33    Epoch 20: train loss 6717.08 ([6717.0810155]), validation loss 5265.50 ([5265.49758785])\n",
      "20:36    Epoch 25: train loss 6687.40 ([6687.39691701]), validation loss 5374.78 ([5374.77532536])\n",
      "20:39    Epoch 30: train loss 6666.82 ([6666.82310274]), validation loss 5215.03 ([5215.03250156])\n",
      "20:42    Epoch 35: train loss 6655.88 ([6655.8757421]), validation loss 5180.24 ([5180.23910758])\n",
      "20:45    Epoch 40: train loss 6639.72 ([6639.7224326]), validation loss 5182.93 ([5182.92804132])\n",
      "20:49    Epoch 45: train loss 6628.97 ([6628.96744911]), validation loss 5169.08 ([5169.07505971]) (*)\n",
      "20:52    Epoch 50: train loss 6616.62 ([6616.61585168]), validation loss 5382.15 ([5382.14955159])\n",
      "20:52  Early stopping after epoch 45, with loss 5169.08 compared to final loss 5382.15\n",
      "20:52  Finished training\n",
      "20:52  Training estimator 4 / 10 in ensemble\n",
      "20:52  Starting training\n",
      "20:52    Method:                 sally\n",
      "20:52    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_3.npy\n",
      "20:52                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_3.npy\n",
      "20:52    Features:               all\n",
      "20:52    Method:                 sally\n",
      "20:52    Hidden layers:          (100, 100)\n",
      "20:52    Activation function:    tanh\n",
      "20:52    Batch size:             128\n",
      "20:52    Trainer:                sgd\n",
      "20:52    Epochs:                 50\n",
      "20:52    Learning rate:          0.02 initially, decaying to 0.002\n",
      "20:52    Nesterov momentum:      0.9\n",
      "20:52    Validation split:       0.25\n",
      "20:52    Early stopping:         True\n",
      "20:52    Scale inputs:           True\n",
      "20:52  Loading training data\n",
      "20:52  Found 1000000 samples with 2 parameters and 26 observables\n",
      "20:52  Rescaling inputs\n",
      "20:52  Creating model for method sally\n",
      "20:52  Training model\n",
      "20:55    Epoch 5: train loss 6145.98 ([6145.97728608]), validation loss 5135.00 ([5135.00293536])\n",
      "20:59    Epoch 10: train loss 6062.25 ([6062.25285417]), validation loss 5088.09 ([5088.0945124]) (*)\n",
      "21:02    Epoch 15: train loss 6018.46 ([6018.45748263]), validation loss 5099.29 ([5099.29070206])\n",
      "21:05    Epoch 20: train loss 5988.60 ([5988.60355146]), validation loss 5228.56 ([5228.55546581])\n",
      "21:08    Epoch 25: train loss 5960.04 ([5960.03631889]), validation loss 5336.69 ([5336.68895322])\n",
      "21:11    Epoch 30: train loss 5940.32 ([5940.31980989]), validation loss 5074.35 ([5074.34968034]) (*)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:14    Epoch 35: train loss 5932.02 ([5932.02091616]), validation loss 5077.60 ([5077.60439329])\n",
      "21:18    Epoch 40: train loss 5918.12 ([5918.12188172]), validation loss 5075.09 ([5075.08640423])\n",
      "21:21    Epoch 45: train loss 5912.79 ([5912.78671749]), validation loss 5097.44 ([5097.43643227])\n",
      "21:24    Epoch 50: train loss 5899.57 ([5899.57383503]), validation loss 5067.61 ([5067.60593191])\n",
      "21:24  Early stopping after epoch 43, with loss 5052.10 compared to final loss 5067.61\n",
      "21:24  Finished training\n",
      "21:24  Training estimator 5 / 10 in ensemble\n",
      "21:24  Starting training\n",
      "21:24    Method:                 sally\n",
      "21:24    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_4.npy\n",
      "21:24                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_4.npy\n",
      "21:24    Features:               all\n",
      "21:24    Method:                 sally\n",
      "21:24    Hidden layers:          (100, 100)\n",
      "21:24    Activation function:    tanh\n",
      "21:24    Batch size:             128\n",
      "21:24    Trainer:                sgd\n",
      "21:24    Epochs:                 50\n",
      "21:24    Learning rate:          0.02 initially, decaying to 0.002\n",
      "21:24    Nesterov momentum:      0.9\n",
      "21:24    Validation split:       0.25\n",
      "21:24    Early stopping:         True\n",
      "21:24    Scale inputs:           True\n",
      "21:24  Loading training data\n",
      "21:24  Found 1000000 samples with 2 parameters and 26 observables\n",
      "21:24  Rescaling inputs\n",
      "21:24  Creating model for method sally\n",
      "21:24  Training model\n",
      "21:28    Epoch 5: train loss 6763.37 ([6763.36674488]), validation loss 5226.11 ([5226.10614994]) (*)\n",
      "21:31    Epoch 10: train loss 6693.17 ([6693.17410202]), validation loss 5490.69 ([5490.6941786])\n",
      "21:34    Epoch 15: train loss 6655.29 ([6655.28527923]), validation loss 5221.35 ([5221.34699676]) (*)\n",
      "21:37    Epoch 20: train loss 6621.06 ([6621.05871658]), validation loss 5325.62 ([5325.61550443])\n",
      "21:40    Epoch 25: train loss 6594.74 ([6594.74376992]), validation loss 5223.67 ([5223.66787243])\n",
      "21:44    Epoch 30: train loss 6573.45 ([6573.44866962]), validation loss 5265.04 ([5265.03667728])\n",
      "21:47    Epoch 35: train loss 6554.88 ([6554.87756694]), validation loss 5218.24 ([5218.23772583])\n",
      "21:50    Epoch 40: train loss 6545.32 ([6545.31813779]), validation loss 5250.63 ([5250.63394195])\n",
      "21:53    Epoch 45: train loss 6533.17 ([6533.16794916]), validation loss 5213.29 ([5213.29296296])\n",
      "21:56    Epoch 50: train loss 6521.57 ([6521.56567184]), validation loss 5241.42 ([5241.41575548])\n",
      "21:56  Early stopping after epoch 39, with loss 5188.48 compared to final loss 5241.42\n",
      "21:56  Finished training\n",
      "21:56  Training estimator 6 / 10 in ensemble\n",
      "21:56  Starting training\n",
      "21:56    Method:                 sally\n",
      "21:56    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_5.npy\n",
      "21:56                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_5.npy\n",
      "21:56    Features:               all\n",
      "21:56    Method:                 sally\n",
      "21:56    Hidden layers:          (100, 100)\n",
      "21:56    Activation function:    tanh\n",
      "21:56    Batch size:             128\n",
      "21:56    Trainer:                sgd\n",
      "21:56    Epochs:                 50\n",
      "21:56    Learning rate:          0.02 initially, decaying to 0.002\n",
      "21:56    Nesterov momentum:      0.9\n",
      "21:56    Validation split:       0.25\n",
      "21:56    Early stopping:         True\n",
      "21:56    Scale inputs:           True\n",
      "21:56  Loading training data\n",
      "21:56  Found 1000000 samples with 2 parameters and 26 observables\n",
      "21:56  Rescaling inputs\n",
      "21:56  Creating model for method sally\n",
      "21:56  Training model\n",
      "22:00    Epoch 5: train loss 5289.10 ([5289.09699646]), validation loss 5231.57 ([5231.56846751])\n",
      "22:03    Epoch 10: train loss 5198.84 ([5198.84222152]), validation loss 4850.13 ([4850.12501092]) (*)\n",
      "22:06    Epoch 15: train loss 5171.83 ([5171.82716241]), validation loss 4861.88 ([4861.88157723])\n",
      "22:09    Epoch 20: train loss 5142.66 ([5142.66200973]), validation loss 4835.31 ([4835.30914024]) (*)\n",
      "22:12    Epoch 25: train loss 5123.94 ([5123.94197671]), validation loss 4904.90 ([4904.90229485])\n",
      "22:16    Epoch 30: train loss 5105.66 ([5105.65767444]), validation loss 4848.98 ([4848.97960771])\n",
      "22:19    Epoch 35: train loss 5092.74 ([5092.7427854]), validation loss 4831.91 ([4831.91373353])\n",
      "22:22    Epoch 40: train loss 5080.65 ([5080.65308473]), validation loss 4845.43 ([4845.42859671])\n",
      "22:25    Epoch 45: train loss 5074.26 ([5074.26418781]), validation loss 4821.42 ([4821.42222259])\n",
      "22:28    Epoch 50: train loss 5068.14 ([5068.13836881]), validation loss 4835.98 ([4835.97853187])\n",
      "22:28  Early stopping after epoch 47, with loss 4810.30 compared to final loss 4835.98\n",
      "22:28  Finished training\n",
      "22:28  Training estimator 7 / 10 in ensemble\n",
      "22:28  Starting training\n",
      "22:28    Method:                 sally\n",
      "22:28    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_6.npy\n",
      "22:28                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_6.npy\n",
      "22:28    Features:               all\n",
      "22:28    Method:                 sally\n",
      "22:28    Hidden layers:          (100, 100)\n",
      "22:28    Activation function:    tanh\n",
      "22:28    Batch size:             128\n",
      "22:28    Trainer:                sgd\n",
      "22:28    Epochs:                 50\n",
      "22:28    Learning rate:          0.02 initially, decaying to 0.002\n",
      "22:28    Nesterov momentum:      0.9\n",
      "22:28    Validation split:       0.25\n",
      "22:28    Early stopping:         True\n",
      "22:28    Scale inputs:           True\n",
      "22:28  Loading training data\n",
      "22:28  Found 1000000 samples with 2 parameters and 26 observables\n",
      "22:28  Rescaling inputs\n",
      "22:28  Creating model for method sally\n",
      "22:28  Training model\n",
      "22:31    Epoch 5: train loss 5802.88 ([5802.88194701]), validation loss 4340.04 ([4340.03895958])\n",
      "22:34    Epoch 10: train loss 5706.97 ([5706.96860753]), validation loss 4230.07 ([4230.06542299])\n",
      "22:36    Epoch 15: train loss 5680.39 ([5680.39182816]), validation loss 4219.31 ([4219.31205996])\n",
      "22:38    Epoch 20: train loss 5644.10 ([5644.10290718]), validation loss 4443.35 ([4443.35399391])\n",
      "22:41    Epoch 25: train loss 5616.23 ([5616.22626086]), validation loss 4278.21 ([4278.20745057])\n",
      "22:43    Epoch 30: train loss 5595.99 ([5595.98533096]), validation loss 4151.65 ([4151.64911164]) (*)\n",
      "22:45    Epoch 35: train loss 5585.06 ([5585.05526347]), validation loss 4230.15 ([4230.15293114])\n",
      "22:48    Epoch 40: train loss 5571.40 ([5571.40343979]), validation loss 4196.09 ([4196.09254404])\n",
      "22:50    Epoch 45: train loss 5571.81 ([5571.80711623]), validation loss 4395.00 ([4395.00046182])\n",
      "22:53    Epoch 50: train loss 5551.09 ([5551.08927737]), validation loss 4149.09 ([4149.09488147]) (*)\n",
      "22:53  Early stopping did not improve performance\n",
      "22:53  Finished training\n",
      "22:53  Training estimator 8 / 10 in ensemble\n",
      "22:53  Starting training\n",
      "22:53    Method:                 sally\n",
      "22:53    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_7.npy\n",
      "22:53                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_7.npy\n",
      "22:53    Features:               all\n",
      "22:53    Method:                 sally\n",
      "22:53    Hidden layers:          (100, 100)\n",
      "22:53    Activation function:    tanh\n",
      "22:53    Batch size:             128\n",
      "22:53    Trainer:                sgd\n",
      "22:53    Epochs:                 50\n",
      "22:53    Learning rate:          0.02 initially, decaying to 0.002\n",
      "22:53    Nesterov momentum:      0.9\n",
      "22:53    Validation split:       0.25\n",
      "22:53    Early stopping:         True\n",
      "22:53    Scale inputs:           True\n",
      "22:53  Loading training data\n",
      "22:53  Found 1000000 samples with 2 parameters and 26 observables\n",
      "22:53  Rescaling inputs\n",
      "22:53  Creating model for method sally\n",
      "22:53  Training model\n",
      "22:55    Epoch 5: train loss 4925.87 ([4925.86829248]), validation loss 5580.89 ([5580.8912071])\n",
      "22:58    Epoch 10: train loss 4884.79 ([4884.79042496]), validation loss 5426.53 ([5426.53232919])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:00    Epoch 15: train loss 4851.96 ([4851.96372476]), validation loss 5402.44 ([5402.44138356])\n",
      "23:02    Epoch 20: train loss 4822.99 ([4822.98845405]), validation loss 5326.74 ([5326.74492427])\n",
      "23:05    Epoch 25: train loss 4800.64 ([4800.63698006]), validation loss 5325.72 ([5325.71905275])\n",
      "23:07    Epoch 30: train loss 4786.18 ([4786.17944489]), validation loss 5290.92 ([5290.91999783])\n",
      "23:10    Epoch 35: train loss 4773.06 ([4773.06231986]), validation loss 5263.08 ([5263.07509045])\n",
      "23:12    Epoch 40: train loss 4763.97 ([4763.97155755]), validation loss 5287.26 ([5287.25582999])\n",
      "23:14    Epoch 45: train loss 4758.86 ([4758.86114838]), validation loss 5275.50 ([5275.50302253])\n",
      "23:17    Epoch 50: train loss 4746.42 ([4746.42001785]), validation loss 5279.99 ([5279.98654765])\n",
      "23:17  Early stopping after epoch 36, with loss 5249.51 compared to final loss 5279.99\n",
      "23:17  Finished training\n",
      "23:17  Training estimator 9 / 10 in ensemble\n",
      "23:17  Starting training\n",
      "23:17    Method:                 sally\n",
      "23:17    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_8.npy\n",
      "23:17                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_8.npy\n",
      "23:17    Features:               all\n",
      "23:17    Method:                 sally\n",
      "23:17    Hidden layers:          (100, 100)\n",
      "23:17    Activation function:    tanh\n",
      "23:17    Batch size:             128\n",
      "23:17    Trainer:                sgd\n",
      "23:17    Epochs:                 50\n",
      "23:17    Learning rate:          0.02 initially, decaying to 0.002\n",
      "23:17    Nesterov momentum:      0.9\n",
      "23:17    Validation split:       0.25\n",
      "23:17    Early stopping:         True\n",
      "23:17    Scale inputs:           True\n",
      "23:17  Loading training data\n",
      "23:17  Found 1000000 samples with 2 parameters and 26 observables\n",
      "23:17  Rescaling inputs\n",
      "23:17  Creating model for method sally\n",
      "23:17  Training model\n",
      "23:20    Epoch 5: train loss 5659.39 ([5659.38614229]), validation loss 6796.07 ([6796.06566771])\n",
      "23:22    Epoch 10: train loss 5602.44 ([5602.43862988]), validation loss 7241.63 ([7241.62537352])\n",
      "23:24    Epoch 15: train loss 5567.04 ([5567.03905714]), validation loss 6339.88 ([6339.8837518]) (*)\n",
      "23:27    Epoch 20: train loss 5539.39 ([5539.39121704]), validation loss 6360.91 ([6360.91458806])\n",
      "23:29    Epoch 25: train loss 5517.71 ([5517.70871269]), validation loss 6302.05 ([6302.0493641]) (*)\n",
      "23:31    Epoch 30: train loss 5503.77 ([5503.76933569]), validation loss 6358.16 ([6358.15538285])\n",
      "23:34    Epoch 35: train loss 5491.19 ([5491.18976059]), validation loss 6288.19 ([6288.18841382]) (*)\n",
      "23:36    Epoch 40: train loss 5477.95 ([5477.95111702]), validation loss 6362.90 ([6362.90031327])\n",
      "23:39    Epoch 45: train loss 5469.66 ([5469.66284942]), validation loss 6328.03 ([6328.0315586])\n",
      "23:41    Epoch 50: train loss 5460.96 ([5460.96183576]), validation loss 6334.84 ([6334.83721797])\n",
      "23:41  Early stopping after epoch 43, with loss 6286.61 compared to final loss 6334.84\n",
      "23:41  Finished training\n",
      "23:41  Training estimator 10 / 10 in ensemble\n",
      "23:41  Starting training\n",
      "23:41    Method:                 sally\n",
      "23:41    Training data: x at /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/x_train_9.npy\n",
      "23:41                   t_xz (theta0) at  /Users/johannbrehmer/work/projects/madminer/diboson_mining/data/samples/wgamma/train_local_tight/t_xz_train_9.npy\n",
      "23:41    Features:               all\n",
      "23:41    Method:                 sally\n",
      "23:41    Hidden layers:          (100, 100)\n",
      "23:41    Activation function:    tanh\n",
      "23:41    Batch size:             128\n",
      "23:41    Trainer:                sgd\n",
      "23:41    Epochs:                 50\n",
      "23:41    Learning rate:          0.02 initially, decaying to 0.002\n",
      "23:41    Nesterov momentum:      0.9\n",
      "23:41    Validation split:       0.25\n",
      "23:41    Early stopping:         True\n",
      "23:41    Scale inputs:           True\n",
      "23:41  Loading training data\n",
      "23:41  Found 1000000 samples with 2 parameters and 26 observables\n",
      "23:41  Rescaling inputs\n",
      "23:41  Creating model for method sally\n",
      "23:41  Training model\n",
      "23:43    Epoch 5: train loss 6161.17 ([6161.17146091]), validation loss 5393.06 ([5393.06157185])\n",
      "23:45    Epoch 10: train loss 6060.64 ([6060.64275131]), validation loss 5377.46 ([5377.46308482])\n",
      "23:46    Epoch 15: train loss 6008.20 ([6008.20303088]), validation loss 5331.55 ([5331.54519278])\n",
      "23:48    Epoch 20: train loss 5982.36 ([5982.35649815]), validation loss 5312.37 ([5312.36556235]) (*)\n",
      "23:50    Epoch 25: train loss 5959.95 ([5959.95247246]), validation loss 5306.28 ([5306.27778201])\n",
      "23:52    Epoch 30: train loss 5944.69 ([5944.69343993]), validation loss 5291.63 ([5291.6298226])\n",
      "23:54    Epoch 35: train loss 5929.16 ([5929.15813092]), validation loss 5277.79 ([5277.79397528])\n",
      "23:55    Epoch 40: train loss 5915.99 ([5915.99372374]), validation loss 5262.50 ([5262.49726834])\n",
      "23:57    Epoch 45: train loss 5902.77 ([5902.77129651]), validation loss 5272.35 ([5272.35222385])\n",
      "23:59    Epoch 50: train loss 5895.73 ([5895.72945239]), validation loss 5258.62 ([5258.61947784])\n",
      "23:59  Early stopping after epoch 46, with loss 5249.15 compared to final loss 5258.62\n",
      "23:59  Finished training\n",
      "23:59  Calculating expectation for 10 estimators in ensemble\n",
      "23:59  Starting evaluation for estimator 1 / 10 in ensemble\n",
      "23:59  Starting evaluation for estimator 2 / 10 in ensemble\n",
      "23:59  Starting evaluation for estimator 3 / 10 in ensemble\n",
      "23:59  Starting evaluation for estimator 4 / 10 in ensemble\n",
      "00:00  Starting evaluation for estimator 5 / 10 in ensemble\n",
      "00:00  Starting evaluation for estimator 6 / 10 in ensemble\n",
      "00:00  Starting evaluation for estimator 7 / 10 in ensemble\n",
      "00:00  Starting evaluation for estimator 8 / 10 in ensemble\n",
      "00:00  Starting evaluation for estimator 9 / 10 in ensemble\n",
      "00:01  Starting evaluation for estimator 10 / 10 in ensemble\n"
     ]
    }
   ],
   "source": [
    "train_ensemble(\n",
    "    'all_tight_sgd',\n",
    "    use_tight_cuts=True,\n",
    "    trainer='sgd',\n",
    "    nesterov_momentum=0.9,\n",
    "    initial_lr=0.02,\n",
    "    final_lr=0.002\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ensemble('resurrection_tight', use_tight_cuts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7d171470-6c7e-4a74-8ca8-5589004e32d6"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
